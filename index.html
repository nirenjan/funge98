<!-- created by calibre's pdftohtml -->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>Microsoft Word - .... 1</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<META name="generator" content="pdftohtml 0.36">
<META name="author" content="Administrator">
<META name="date" content="2005-04-02T09:36:43+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<A name=1></a><IMG src="index-1_1.jpg"><br>
<hr>
<A name=2></a>Preface&nbsp;<br>
&nbsp;&nbsp;&nbsp;Aims&nbsp;<br>
This&nbsp;book&nbsp;introduces the concepts and&nbsp;methodologies employed&nbsp;in&nbsp;designing&nbsp;a&nbsp;<br>
system-on-chip (SoC) based&nbsp;around a&nbsp;microprocessor core and&nbsp;in designing the&nbsp;<br>
microprocessor core itself.&nbsp;The principles of&nbsp;microprocessor design are&nbsp;made con-<br>
crete&nbsp;by&nbsp;extensive illustrations&nbsp;based upon the ARM.&nbsp;<br>
The&nbsp;aim&nbsp;of&nbsp;the book&nbsp;is to&nbsp;assist&nbsp;the reader&nbsp;in understanding&nbsp;how SoCs&nbsp;and micro-<br>
processors are&nbsp;designed&nbsp;and&nbsp;used, and&nbsp;why&nbsp;a&nbsp;modern&nbsp;processor is designed&nbsp;the&nbsp;way&nbsp;<br>
that&nbsp;it&nbsp;is. The&nbsp;reader who&nbsp;wishes&nbsp;to&nbsp;know&nbsp;only&nbsp;the&nbsp;general&nbsp;principles should&nbsp;find&nbsp;that&nbsp;<br>
the ARM illustrations add substance to&nbsp;issues&nbsp;which can otherwise&nbsp;appear somewhat&nbsp;<br>
ethereal; the reader who wishes to understand&nbsp;the&nbsp;design&nbsp;of&nbsp;the ARM should find&nbsp;that&nbsp;<br>
the&nbsp;general principles&nbsp;illuminate&nbsp;the&nbsp;rationale&nbsp;for the ARM&nbsp;being&nbsp;as&nbsp;it&nbsp;is.&nbsp;<br>
Other&nbsp;microprocessor architectures are&nbsp;not&nbsp;described&nbsp;in this&nbsp;book. The reader who&nbsp;<br>
wishes&nbsp;to&nbsp;make&nbsp;a&nbsp;comparative study&nbsp;of&nbsp;architectures will&nbsp;find&nbsp;the required&nbsp;informa-<br>
tion on&nbsp;the&nbsp;ARM here&nbsp;but must look&nbsp;elsewhere for information&nbsp;on&nbsp;other&nbsp;designs.&nbsp;<br>
Audience&nbsp;<br>
The book is intended to be of&nbsp;use to&nbsp;two&nbsp;distinct groups of&nbsp;readers:&nbsp;<br>
•&nbsp;&nbsp;Professional hardware and&nbsp;software engineers&nbsp;who are tasked with designing an&nbsp;<br>
SoC product&nbsp;which incorporates an&nbsp;ARM&nbsp;processor, or&nbsp;who are evaluating the&nbsp;<br>
ARM for a product, should find the book helpful in their duties. Although there&nbsp;<br>
is considerable&nbsp;overlap with&nbsp;ARM technical publications, this book&nbsp;provides a&nbsp;<br>
broader context with more background. It&nbsp;is not&nbsp;a substitute for the&nbsp;manufac&nbsp;<br>
turer's data,&nbsp;since&nbsp;much detail&nbsp;has had to&nbsp;be omitted,&nbsp;but&nbsp;it&nbsp;should&nbsp;be&nbsp;useful as&nbsp;an&nbsp;<br>
introductory&nbsp;overview&nbsp;and adjunct to that data.&nbsp;<br>
•&nbsp;&nbsp;Students of computer science, computer engineering and electrical engineering&nbsp;<br>
should find&nbsp;the material of&nbsp;value&nbsp;at&nbsp;several&nbsp;stages&nbsp;in&nbsp;their courses.&nbsp;Some&nbsp;chapters&nbsp;<br>
are&nbsp;closely based on course&nbsp;material&nbsp;previously&nbsp;used in undergraduate&nbsp;teaching;&nbsp;<br>
some&nbsp;other&nbsp;material is drawn from&nbsp;a&nbsp;postgraduate&nbsp;course.&nbsp;<br>
Prerequisite&nbsp;<br>
This&nbsp;book&nbsp;is not intended&nbsp;to&nbsp;be an&nbsp;introductory&nbsp;text&nbsp;on&nbsp;computer architecture&nbsp;or&nbsp;<br>
knowledge&nbsp;<br>
computer&nbsp;logic design. Readers&nbsp;are assumed&nbsp;to&nbsp;have&nbsp;a&nbsp;level of&nbsp;familiarity&nbsp;with these&nbsp;<br>
subjects equivalent to that of&nbsp;a second&nbsp;year undergraduate student&nbsp;in&nbsp;computer sci-<br>
ence&nbsp;or&nbsp;computer engineering.&nbsp;Some&nbsp;first year&nbsp;material&nbsp;is&nbsp;presented,&nbsp;but&nbsp;this&nbsp;is&nbsp;more&nbsp;<br>
by&nbsp;way of a&nbsp;refresher than&nbsp;as&nbsp;a first introduction to this&nbsp;material. No&nbsp;prior&nbsp;<br>
familiarity&nbsp;with&nbsp;the&nbsp;ARM processor is assumed.&nbsp;<br>
The ARM&nbsp;<br>
On&nbsp;26 April 1985,&nbsp;the first ARM&nbsp;prototypes&nbsp;arrived at&nbsp;Acorn&nbsp;Computers Limited&nbsp;in&nbsp;<br>
Cambridge,&nbsp;England,&nbsp;having&nbsp;been&nbsp;fabricated&nbsp;by&nbsp;VLSI Technology,&nbsp;Inc.,&nbsp;in&nbsp;San&nbsp;Jose,&nbsp;<br>
<hr>
<A name=3></a><b>iv&nbsp;</b><br>
<b>Preface</b>&nbsp;<br>
California. A&nbsp;few hours later they&nbsp;were&nbsp;running&nbsp;code, and&nbsp;a bottle&nbsp;<i>of Moet&nbsp;&amp;&nbsp;</i><br>
<i>Chan-don&nbsp;</i>was&nbsp;opened&nbsp;in&nbsp;celebration.&nbsp;For the remainder&nbsp;of&nbsp;the&nbsp;1980s&nbsp;the ARM&nbsp;was&nbsp;<br>
quietly&nbsp;developed to&nbsp;underpin Acorn's desktop&nbsp;products&nbsp;which form&nbsp;the basis of&nbsp;<br>
educational&nbsp;computing&nbsp;in&nbsp;the&nbsp;UK;&nbsp;over&nbsp;the&nbsp;1990s, in&nbsp;the&nbsp;care&nbsp;of&nbsp;ARM&nbsp;Limited,&nbsp;the&nbsp;<br>
ARM&nbsp;has sprung onto the&nbsp;world&nbsp;stage and&nbsp;has established&nbsp;a&nbsp;market-leading position&nbsp;<br>
in&nbsp;high-performance&nbsp;low-power and low-cost&nbsp;embedded&nbsp;applications.&nbsp;<br>
This&nbsp;prominent&nbsp;market position has increased ARM's resources and accelerated the&nbsp;<br>
rate at which new&nbsp;ARM-based developments appear.&nbsp;<br>
The highlights of&nbsp;the&nbsp;last decade of&nbsp;ARM development&nbsp;include:&nbsp;<br>
•&nbsp;&nbsp;the introduction of&nbsp;the novel compressed instruction&nbsp;format called&nbsp;'Thumb'&nbsp;<br>
which&nbsp;reduces cost and power&nbsp;dissipation&nbsp;in small&nbsp;systems;&nbsp;<br>
•&nbsp;&nbsp;significant&nbsp;steps upwards in&nbsp;performance&nbsp;with the&nbsp;ARM9, ARM&nbsp;10 and&nbsp;'Strong-&nbsp;<br>
ARM'&nbsp;processor&nbsp;families;&nbsp;<br>
•&nbsp;&nbsp;a state-of-the-art&nbsp;software development and debugging&nbsp;environment;&nbsp;<br>
•&nbsp;&nbsp;a very&nbsp;wide&nbsp;range&nbsp;of embedded&nbsp;applications&nbsp;based around&nbsp;ARM&nbsp;processor&nbsp;cores.&nbsp;<br>
Most&nbsp;of&nbsp;the&nbsp;principles of&nbsp;modern&nbsp;SoC&nbsp;and processor design are illustrated&nbsp;some-<br>
where&nbsp;in the&nbsp;ARM family, and ARM&nbsp;has&nbsp;led the&nbsp;way&nbsp;in&nbsp;the introduction of some&nbsp;con-<br>
cepts&nbsp;(such as dynamically&nbsp;decompressing&nbsp;the instruction stream).&nbsp;The inherent&nbsp;<br>
simplicity&nbsp;of&nbsp;the basic&nbsp;3-stage&nbsp;pipeline ARM&nbsp;core&nbsp;makes it&nbsp;a good&nbsp;pedagogical&nbsp;intro-<br>
ductory&nbsp;example&nbsp;to&nbsp;real&nbsp;processor&nbsp;design,&nbsp;whereas&nbsp;the&nbsp;debugging&nbsp;of&nbsp;a&nbsp;system&nbsp;based&nbsp;<br>
around an&nbsp;ARM&nbsp;core&nbsp;deeply&nbsp;embedded&nbsp;into&nbsp;a&nbsp;complex system&nbsp;chip&nbsp;represents&nbsp;the&nbsp;<br>
cutting-edge of&nbsp;technological&nbsp;development&nbsp;today.&nbsp;<br>
Book&nbsp;Structure Chapter 1 starts with a&nbsp;refresher on first&nbsp;year undergraduate processor design mate-<br>
rial. It&nbsp;illustrates the principle of abstraction in hardware&nbsp;design by&nbsp;reviewing the&nbsp;<br>
roles of logic and gate-level representations. It then introduces the important con-<br>
cept of&nbsp;the&nbsp;<i>Reduced&nbsp;Instruction Set Computer&nbsp;</i>(RISC)&nbsp;as background&nbsp;for&nbsp;what fol-<br>
lows, and&nbsp;closes&nbsp;with&nbsp;some&nbsp;comments on&nbsp;design&nbsp;for low power.&nbsp;<br>
Chapter&nbsp;2&nbsp;describes&nbsp;the&nbsp;ARM&nbsp;processor&nbsp;architecture&nbsp;in&nbsp;terms of the&nbsp;concepts intro-<br>
duced in the&nbsp;previous&nbsp;chapter,&nbsp;and Chapter&nbsp;3 is&nbsp;a&nbsp;gentle introduction to&nbsp;user-level&nbsp;<br>
assembly&nbsp;language programming&nbsp;and could be&nbsp;used&nbsp;in first&nbsp;year undergraduate&nbsp;teach-<br>
ing&nbsp;for this&nbsp;purpose.&nbsp;<br>
Chapter 4&nbsp;describes&nbsp;the organization and implementation&nbsp;of&nbsp;the&nbsp;3- and&nbsp;5-stage&nbsp;<br>
pipeline&nbsp;ARM&nbsp;processor cores&nbsp;at&nbsp;a&nbsp;level&nbsp;suitable&nbsp;for second&nbsp;year undergraduate&nbsp;teach-<br>
ing,&nbsp;and&nbsp;covers&nbsp;some&nbsp;implementation issues.&nbsp;<br>
Chapters 5 and&nbsp;6 go&nbsp;into&nbsp;the ARM instruction set architecture&nbsp;in increasing depth.&nbsp;<br>
Chapter 5&nbsp;goes back over the instruction&nbsp;set in&nbsp;more&nbsp;detail than&nbsp;was presented&nbsp;in&nbsp;<br>
Chapter&nbsp;3,&nbsp;including the binary&nbsp;representation of each&nbsp;instruction,&nbsp;and it&nbsp;penetrates&nbsp;<br>
more&nbsp;deeply&nbsp;into&nbsp;the&nbsp;comers of&nbsp;the instruction&nbsp;set.&nbsp;It&nbsp;is&nbsp;probably&nbsp;best&nbsp;read&nbsp;once and&nbsp;<br>
then used&nbsp;for&nbsp;reference.&nbsp;Chapter 6&nbsp;backs off&nbsp;a bit to&nbsp;consider&nbsp;what&nbsp;a&nbsp;high-level&nbsp;lan-<br>
guage (in&nbsp;this case, C)&nbsp;really&nbsp;needs&nbsp;and&nbsp;how those&nbsp;needs&nbsp;are&nbsp;met by&nbsp;the&nbsp;ARM instruc-<br>
tion&nbsp;set.&nbsp;This&nbsp;chapter&nbsp;is&nbsp;based&nbsp;on&nbsp;second&nbsp;year&nbsp;undergraduate&nbsp;material.&nbsp;<br>
<hr>
<A name=4></a><b>Preface</b>&nbsp;<br>
V&nbsp;<br>
Chapter&nbsp;7&nbsp;introduces&nbsp;the 'Thumb'&nbsp;instruction&nbsp;set&nbsp;which&nbsp;is&nbsp;an&nbsp;ARM&nbsp;innovation&nbsp;to&nbsp;<br>
address&nbsp;the&nbsp;code&nbsp;density&nbsp;and&nbsp;power requirements&nbsp;of small embedded systems. It is of&nbsp;<br>
peripheral&nbsp;interest to a&nbsp;generic study&nbsp;of&nbsp;computer&nbsp;science, but adds&nbsp;an&nbsp;interesting lat-<br>
eral&nbsp;perspective to&nbsp;a&nbsp;postgraduate&nbsp;course.&nbsp;<br>
Chapter&nbsp;8 raises the&nbsp;issues&nbsp;involved&nbsp;in&nbsp;debugging&nbsp;systems which use&nbsp;embedded&nbsp;<br>
processor cores&nbsp;and&nbsp;in&nbsp;the&nbsp;production&nbsp;testing&nbsp;of board-level&nbsp;systems. These issues are&nbsp;<br>
background&nbsp;to&nbsp;Chapter&nbsp;9 which&nbsp;introduces&nbsp;a&nbsp;number of different ARM&nbsp;integer cores,&nbsp;<br>
broadening the&nbsp;theme introduced&nbsp;in Chapter 4 to include&nbsp;cores with 'Thumb',&nbsp;debug&nbsp;<br>
hardware, and more&nbsp;sophisticated pipeline&nbsp;operation.&nbsp;<br>
Chapter&nbsp;10&nbsp;introduces&nbsp;the concept&nbsp;of&nbsp;memory&nbsp;hierarchy,&nbsp;discussing&nbsp;the&nbsp;principles&nbsp;<br>
of&nbsp;memory&nbsp;management and caches. Chapter 11 reviews the requirements of a&nbsp;<br>
modern operating system&nbsp;at&nbsp;a second&nbsp;year undergraduate level and&nbsp;describes the&nbsp;<br>
approach&nbsp;adopted by&nbsp;the ARM to&nbsp;address&nbsp;these requirements. Chapter&nbsp;12 introduces&nbsp;<br>
the&nbsp;integrated&nbsp;ARM&nbsp;CPU&nbsp;cores (including&nbsp;StrongARM)&nbsp;that&nbsp;incorporate&nbsp;full&nbsp;support&nbsp;<br>
for memory management.&nbsp;<br>
Chapter 13&nbsp;covers the issues of&nbsp;designing&nbsp;SoCs&nbsp;with&nbsp;embedded processor cores. Here,&nbsp;<br>
the ARM is&nbsp;at&nbsp;the leading&nbsp;edge of technology.&nbsp;Several&nbsp;examples are presented&nbsp;of produc-<br>
tion embedded&nbsp;system&nbsp;chips&nbsp;to&nbsp;show&nbsp;the solutions that have been developed&nbsp;to&nbsp;the&nbsp;many&nbsp;<br>
problems inherent in committing a complex application-specific system&nbsp;to silicon.&nbsp;<br>
Chapter&nbsp;14 moves away&nbsp;from&nbsp;mainstream&nbsp;ARM developments to&nbsp;describe&nbsp;the asyn-<br>
chronous ARM-compatible&nbsp;processors and&nbsp;systems developed at&nbsp;the&nbsp;University&nbsp;of&nbsp;<br>
Manchester, England,&nbsp;during the 1990s. After a&nbsp;decade of research&nbsp;the&nbsp;AMULET&nbsp;<br>
technology is, at the&nbsp;time&nbsp;of&nbsp;writing, about&nbsp;to take its&nbsp;first&nbsp;step&nbsp;into&nbsp;the commercial&nbsp;<br>
domain. Chapter 14 concludes with a&nbsp;description&nbsp;of the DRACO SoC design, the first&nbsp;<br>
commercial&nbsp;application of a 32-bit&nbsp;asynchronous&nbsp;microprocessor.&nbsp;<br>
A short&nbsp;appendix&nbsp;presents&nbsp;the fundamentals&nbsp;of&nbsp;computer&nbsp;logic&nbsp;design&nbsp;and&nbsp;the&nbsp;ter-<br>
minology&nbsp;which is used&nbsp;in&nbsp;Chapter 1.&nbsp;<br>
A glossary&nbsp;of the&nbsp;terms used&nbsp;in&nbsp;the&nbsp;book&nbsp;and&nbsp;a&nbsp;bibliography&nbsp;for further reading&nbsp;are&nbsp;<br>
appended&nbsp;at&nbsp;the&nbsp;end of&nbsp;the&nbsp;book, followed&nbsp;by&nbsp;a detailed&nbsp;index.&nbsp;<br>
Course&nbsp;<br>
The chapters&nbsp;are&nbsp;at&nbsp;an&nbsp;appropriate&nbsp;level&nbsp;for&nbsp;use&nbsp;on&nbsp;undergraduate&nbsp;courses&nbsp;as&nbsp;follows:&nbsp;<br>
relevance&nbsp;<br>
Year 1: Chapter 1&nbsp;(basic&nbsp;processor design); Chapter&nbsp;3 (assembly&nbsp;language program-<br>
ming); Chapter 5 (instruction binaries&nbsp;and&nbsp;reference for&nbsp;assembly&nbsp;language&nbsp;<br>
programming).&nbsp;<br>
Year 2:&nbsp;Chapter 4&nbsp;(simple pipeline processor&nbsp;design); Chapter&nbsp;6 (architectural sup-<br>
port&nbsp;for high-level languages); Chapters 10&nbsp;and&nbsp;11&nbsp;(memory hierarchy and&nbsp;<br>
architectural support for&nbsp;operating&nbsp;systems).&nbsp;<br>
Year 3: Chapter 8 (embedded system&nbsp;debug and test); Chapter 9 (advanced pipe-<br>
lined&nbsp;processor&nbsp;design);&nbsp;Chapter&nbsp;12&nbsp;(advanced CPUs); Chapter&nbsp;13 (example&nbsp;<br>
embedded systems).&nbsp;<br>
A postgraduate&nbsp;course could follow a theme across several&nbsp;chapters, such&nbsp;as proc-<br>
essor design&nbsp;(Chapters 1,&nbsp;2, 4,&nbsp;9, 10 and 12), instruction set design&nbsp;(Chapters 2, 3, 5,&nbsp;<br>
6,&nbsp;7&nbsp;and&nbsp;11)&nbsp;or embedded&nbsp;systems&nbsp;(Chapters 2,4, 5, 8, 9&nbsp;and&nbsp;13).&nbsp;<br>
<hr>
<A name=5></a><b>vi</b>&nbsp;<br>
<b>Preface</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Chapter&nbsp;14&nbsp;contains&nbsp;material relevant to&nbsp;a&nbsp;third&nbsp;year undergraduate&nbsp;or&nbsp;advanced&nbsp;<br>
postgraduate course on asynchronous design,&nbsp;but a great deal of&nbsp;additional back-<br>
ground material (not&nbsp;presented in&nbsp;this book) is&nbsp;also&nbsp;necessary.&nbsp;<br>
Support material&nbsp;<br>
Many of&nbsp;the&nbsp;figures&nbsp;and tables&nbsp;will&nbsp;be&nbsp;made&nbsp;freely available over&nbsp;the Internet&nbsp;for&nbsp;<br>
non-commercial use. The only&nbsp;constraint on&nbsp;such use is that this book&nbsp;should be a&nbsp;<br>
recommended&nbsp;text for any&nbsp;course which makes use of such&nbsp;material.&nbsp;Information&nbsp;<br>
about this and&nbsp;other&nbsp;support material&nbsp;may&nbsp;be&nbsp;found&nbsp;on&nbsp;the World&nbsp;Wide&nbsp;Web&nbsp;at:&nbsp;<br>
http://www.cs.man.ac.uk/amulet/publications/books/ARMsysArch&nbsp;<br>
Any enquiries&nbsp;relating to&nbsp;commercial&nbsp;use&nbsp;must&nbsp;be&nbsp;referred&nbsp;to&nbsp;the publishers. The&nbsp;<br>
assertion of&nbsp;the copyright for&nbsp;this book&nbsp;outlined&nbsp;on&nbsp;page iv&nbsp;remains unaffected.&nbsp;<br>
Feedback&nbsp;<br>
The author&nbsp;welcomes&nbsp;feedback on the&nbsp;style&nbsp;and content of&nbsp;this book, and details of&nbsp;<br>
any&nbsp;errors that&nbsp;are&nbsp;found. Please email any&nbsp;such information to:&nbsp;<br>
sfurber@cs.man.ac.uk&nbsp;<br>
<b>Acknowledgements</b>&nbsp;<br>
Many&nbsp;people&nbsp;have contributed&nbsp;to&nbsp;the success&nbsp;of the&nbsp;ARM over&nbsp;the past&nbsp;decade.&nbsp;As a&nbsp;<br>
policy&nbsp;decision&nbsp;I have not named&nbsp;in&nbsp;the text&nbsp;the&nbsp;individuals with&nbsp;principal&nbsp;responsi-<br>
bilities for the developments described therein since the&nbsp;lists&nbsp;would be long and&nbsp;<br>
attempts to abridge them&nbsp;invidious.&nbsp;History&nbsp;has a habit of&nbsp;focusing credit on one or&nbsp;<br>
two high-profile individuals,&nbsp;often at the expense of those who keep their heads&nbsp;<br>
down to get the&nbsp;job done on&nbsp;time.&nbsp;However, it is not&nbsp;possible to&nbsp;write&nbsp;a book on the&nbsp;<br>
ARM without&nbsp;mentioning Sophie Wilson whose original instruction&nbsp;set architecture&nbsp;<br>
survives,&nbsp;extended but otherwise&nbsp;largely unscathed, to&nbsp;this day.&nbsp;<br>
I would also like&nbsp;to acknowledge the support received&nbsp;from&nbsp;ARM Limited in&nbsp;giving&nbsp;<br>
access&nbsp;to&nbsp;their&nbsp;staff&nbsp;and&nbsp;design&nbsp;documentation,&nbsp;and I&nbsp;am&nbsp;grateful&nbsp;for&nbsp;the&nbsp;help I&nbsp;have&nbsp;<br>
received&nbsp;from&nbsp;ARM's semiconductor&nbsp;partners,&nbsp;particularly&nbsp;VLSI Technology,&nbsp;Inc.,&nbsp;<br>
which&nbsp;is now wholly&nbsp;owned by&nbsp;Philips&nbsp;Semiconductors.&nbsp;<br>
The&nbsp;book&nbsp;has&nbsp;been&nbsp;considerably&nbsp;enhanced&nbsp;by&nbsp;helpful&nbsp;comments from&nbsp;reviewers of&nbsp;<br>
draft&nbsp;versions.&nbsp;I am&nbsp;grateful for the&nbsp;sympathetic reception the&nbsp;drafts received&nbsp;and&nbsp;the&nbsp;<br>
direct suggestions for improvement&nbsp;that&nbsp;were&nbsp;returned.&nbsp;The publishers,&nbsp;Addison&nbsp;<br>
Wesley&nbsp;Longman Limited,&nbsp;have&nbsp;been&nbsp;very&nbsp;helpful&nbsp;in&nbsp;guiding&nbsp;my&nbsp;responses to&nbsp;these&nbsp;<br>
suggestions&nbsp;and&nbsp;in&nbsp;other&nbsp;aspects&nbsp;of&nbsp;authorship.&nbsp;<br>
Lastly&nbsp;I would like to&nbsp;thank my&nbsp;wife, Valerie, and my&nbsp;daughters, Alison and&nbsp;Cather-<br>
ine,&nbsp;who allowed me&nbsp;time&nbsp;off from&nbsp;family duties&nbsp;to write this&nbsp;book.&nbsp;<br>
Steve Furber&nbsp;<br>
March 2000&nbsp;<br>
<hr>
<A name=6></a><IMG src="index-6_1.png"><br>
<IMG src="index-6_2.png"><br>
<IMG src="index-6_3.png"><br>
<IMG src="index-6_4.png"><br>
Contents&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<i>Preface in</i>&nbsp;<br>
&nbsp;&nbsp;An Introduction to Processor Design<br>
&nbsp;<br>
1&nbsp;<br>
1.1&nbsp;&nbsp;Processor architecture&nbsp;and organization&nbsp;<br>
2&nbsp;<br>
1.2&nbsp;&nbsp;Abstraction in&nbsp;hardware design&nbsp;<br>
3&nbsp;<br>
1.3&nbsp;&nbsp;MU0 - a simple&nbsp;processor&nbsp;<br>
7&nbsp;<br>
1.4&nbsp;&nbsp;Instruction set&nbsp;design&nbsp;<br>
14&nbsp;<br>
1.5&nbsp;&nbsp;Processor&nbsp;design trade-offs&nbsp;<br>
19&nbsp;<br>
1.6&nbsp;&nbsp;The&nbsp;Reduced&nbsp;Instruction Set&nbsp;Computer&nbsp;<br>
24&nbsp;<br>
1.7&nbsp;&nbsp;Design&nbsp;for&nbsp;low&nbsp;power&nbsp;consumption&nbsp;<br>
28&nbsp;<br>
1.8&nbsp;&nbsp;Examples&nbsp;and&nbsp;exercises&nbsp;<br>
32&nbsp;<br>
&nbsp;&nbsp;The ARM Architecture&nbsp;<br>
35&nbsp;<br>
2.1&nbsp;&nbsp;The&nbsp;Acorn RISC Machine&nbsp;<br>
36&nbsp;<br>
2.2&nbsp;&nbsp;Architectural&nbsp;inheritance&nbsp;<br>
37&nbsp;<br>
2.3&nbsp;&nbsp;The ARM&nbsp;programmer's&nbsp;model&nbsp;<br>
39&nbsp;<br>
2.4&nbsp;&nbsp;ARM&nbsp;development&nbsp;tools&nbsp;<br>
43&nbsp;<br>
2.5&nbsp;&nbsp;Example and exercises&nbsp;<br>
47&nbsp;<br>
ARM Assembly Langua<br>
&nbsp;<br>
ge Programming&nbsp;<br>
49&nbsp;<br>
3.1&nbsp;&nbsp;Data processing&nbsp;instructions&nbsp;<br>
50&nbsp;<br>
3.2&nbsp;&nbsp;Data transfer instructions&nbsp;<br>
55&nbsp;<br>
3.3&nbsp;&nbsp;Control flow&nbsp;instructions&nbsp;<br>
63&nbsp;<br>
3.4&nbsp;&nbsp;Writing simple assembly language&nbsp;programs&nbsp;<br>
69&nbsp;<br>
3.5&nbsp;&nbsp;Examples and&nbsp;exercises&nbsp;<br>
72&nbsp;<br>
ARM Organization and Implementation&nbsp;<br>
&nbsp;<br>
74&nbsp;<br>
4.1&nbsp;&nbsp;3-stage pipeline ARM&nbsp;organization&nbsp;<br>
75&nbsp;<br>
4.2&nbsp;&nbsp;5-stage pipeline ARM&nbsp;organization&nbsp;<br>
78&nbsp;<br>
4.3&nbsp;&nbsp;ARM instruction execution&nbsp;<br>
82&nbsp;<br>
4.4&nbsp;&nbsp;ARM implementation&nbsp;<br>
86&nbsp;<br>
<hr>
<A name=7></a><IMG src="index-7_1.png"><br>
<IMG src="index-7_2.png"><br>
<b>viii&nbsp;</b><br>
<b>Contents</b>&nbsp;<br>
4.5&nbsp;&nbsp;The&nbsp;ARM&nbsp;coprocessor&nbsp;interface&nbsp;<br>
101&nbsp;<br>
4.6&nbsp;&nbsp;Examples&nbsp;and&nbsp;exercises&nbsp;<br>
103&nbsp;<br>
&nbsp;&nbsp;The ARM&nbsp;Instruction Set&nbsp;<br>
105&nbsp;<br>
5.1&nbsp;<br>
Introduction&nbsp;106&nbsp;<br>
5.2&nbsp;&nbsp;Exceptions&nbsp;108&nbsp;<br>
5.3&nbsp;<br>
Conditional execution&nbsp;<br>
111&nbsp;<br>
5.4&nbsp;&nbsp;Branch&nbsp;and&nbsp;Branch with Link (B,&nbsp;BL)&nbsp;<br>
113&nbsp;<br>
5.5&nbsp;<br>
Branch, Branch&nbsp;with&nbsp;Link and&nbsp;eXchange&nbsp;(BX,&nbsp;BLX)&nbsp;<br>
115&nbsp;<br>
5.6&nbsp;&nbsp;Software&nbsp;Interrupt (SWI)&nbsp;<br>
117&nbsp;<br>
5.7&nbsp;&nbsp;Data processing&nbsp;instructions&nbsp;<br>
119&nbsp;<br>
5.8&nbsp;&nbsp;Multiply instructions&nbsp;<br>
122&nbsp;<br>
5.9&nbsp;&nbsp;Count leading&nbsp;zeros&nbsp;(CLZ&nbsp;-&nbsp;architecture v5T only)&nbsp;<br>
124&nbsp;<br>
5.10&nbsp;&nbsp;Single&nbsp;word&nbsp;and&nbsp;unsigned&nbsp;byte&nbsp;data&nbsp;transfer&nbsp;instructions&nbsp;<br>
125&nbsp;<br>
5.11&nbsp;&nbsp;Half-word&nbsp;and&nbsp;signed&nbsp;byte&nbsp;data&nbsp;transfer&nbsp;instructions&nbsp;<br>
128&nbsp;<br>
5.12&nbsp;&nbsp;Multiple&nbsp;register&nbsp;transfer&nbsp;instructions&nbsp;<br>
130&nbsp;<br>
5.13&nbsp;&nbsp;Swap&nbsp;memory&nbsp;and&nbsp;register&nbsp;instructions&nbsp;(SWP)&nbsp;<br>
132&nbsp;<br>
5.14&nbsp;&nbsp;Status&nbsp;register&nbsp;to&nbsp;general&nbsp;register&nbsp;transfer&nbsp;instructions&nbsp;<br>
133&nbsp;<br>
5.15&nbsp;&nbsp;General&nbsp;register&nbsp;to&nbsp;status&nbsp;register&nbsp;transfer&nbsp;instructions&nbsp;<br>
134&nbsp;<br>
5.16&nbsp;&nbsp;Coprocessor&nbsp;instructions&nbsp;<br>
136&nbsp;<br>
5.17&nbsp;&nbsp;Coprocessor data&nbsp;operations&nbsp;<br>
137&nbsp;<br>
5.18&nbsp;&nbsp;Coprocessor&nbsp;data&nbsp;transfers&nbsp;<br>
138&nbsp;<br>
5.19&nbsp;&nbsp;Coprocessor&nbsp;register&nbsp;transfers&nbsp;<br>
139&nbsp;<br>
5.20&nbsp;&nbsp;Breakpoint&nbsp;instruction&nbsp;(BRK&nbsp;-&nbsp;architecture&nbsp;v5T only)&nbsp;<br>
141&nbsp;<br>
5.21&nbsp;&nbsp;Unused&nbsp;instruction&nbsp;space&nbsp;<br>
142&nbsp;<br>
5.22&nbsp;&nbsp;Memory&nbsp;faults&nbsp;<br>
143&nbsp;<br>
5.23&nbsp;&nbsp;ARM&nbsp;architecture&nbsp;variants&nbsp;<br>
147&nbsp;<br>
5.24&nbsp;&nbsp;Example&nbsp;and&nbsp;exercises&nbsp;<br>
149&nbsp;<br>
&nbsp;&nbsp;Architectural Support&nbsp;for High-Level Languages<br>
&nbsp;15<br>
1&nbsp;<br>
6.1&nbsp;<br>
Abstraction&nbsp;in software design&nbsp;<br>
152&nbsp;<br>
6.2&nbsp;&nbsp;Data&nbsp;types&nbsp;<br>
153&nbsp;<br>
6.3&nbsp;<br>
Floating-point data types&nbsp;<br>
158&nbsp;<br>
6.4&nbsp;&nbsp;The ARM&nbsp;floating-point architecture&nbsp;<br>
163&nbsp;<br>
6.5&nbsp;&nbsp;Expressions 168&nbsp;<br>
6.6&nbsp;&nbsp;Conditional&nbsp;statements&nbsp;<br>
170&nbsp;<br>
6.7&nbsp;&nbsp;Loops&nbsp;173&nbsp;<br>
6.8&nbsp;&nbsp;Functions and&nbsp;procedures&nbsp;<br>
175&nbsp;<br>
<hr>
<A name=8></a><IMG src="index-8_1.png"><br>
<IMG src="index-8_2.png"><br>
<IMG src="index-8_3.png"><br>
<b>Contents</b>&nbsp;<br>
<b>ix</b>&nbsp;<br>
6.9&nbsp;&nbsp;Use&nbsp;of&nbsp;memory&nbsp;<br>
180&nbsp;<br>
6.10&nbsp;&nbsp;Run-time&nbsp;environment&nbsp;<br>
185&nbsp;<br>
6.11&nbsp;&nbsp;Examples&nbsp;and&nbsp;exercises&nbsp;<br>
186&nbsp;<br>
&nbsp;&nbsp;The&nbsp;Thumb&nbsp;&nbsp;Instruction&nbsp;&nbsp;Set<br>
&nbsp;188&nbsp;<br>
7.1&nbsp;<br>
The&nbsp;Thumb bit&nbsp;in&nbsp;the&nbsp;CPSR&nbsp;<br>
189&nbsp;<br>
7.2&nbsp;<br>
The&nbsp;Thumb programmer's&nbsp;model&nbsp;<br>
190&nbsp;<br>
7.3&nbsp;<br>
Thumb branch&nbsp;instructions&nbsp;<br>
191&nbsp;<br>
7.4&nbsp;&nbsp;Thumb&nbsp;software&nbsp;interrupt&nbsp;instruction&nbsp;<br>
194&nbsp;<br>
7.5&nbsp;<br>
Thumb data&nbsp;processing&nbsp;instructions&nbsp;<br>
195&nbsp;<br>
7.6&nbsp;&nbsp;Thumb&nbsp;single register&nbsp;data&nbsp;transfer&nbsp;instructions&nbsp;<br>
198&nbsp;<br>
7.7&nbsp;&nbsp;Thumb&nbsp;multiple&nbsp;register&nbsp;data&nbsp;transfer instructions&nbsp;<br>
199&nbsp;<br>
7.8&nbsp;&nbsp;Thumb&nbsp;breakpoint&nbsp;instruction&nbsp;<br>
200&nbsp;<br>
7.9&nbsp;&nbsp;Thumb&nbsp;implementation&nbsp;<br>
201&nbsp;<br>
7.10&nbsp;&nbsp;Thumb applications&nbsp;<br>
203&nbsp;<br>
7.11&nbsp;&nbsp;Example and&nbsp;exercises&nbsp;<br>
204&nbsp;<br>
Architectural Support for System Development&nbsp;<br>
207&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
8.1&nbsp;<br>
The&nbsp;ARM&nbsp;memory&nbsp;interface&nbsp;<br>
208&nbsp;<br>
8.2&nbsp;&nbsp;The&nbsp;Advanced&nbsp;Microcontroller&nbsp;Bus&nbsp;Architecture&nbsp;(AMBA)&nbsp;<br>
216&nbsp;<br>
8.3&nbsp;<br>
The&nbsp;ARM reference&nbsp;peripheral&nbsp;specification&nbsp;<br>
220&nbsp;<br>
8.4&nbsp;&nbsp;Hardware&nbsp;system&nbsp;prototyping tools&nbsp;<br>
223&nbsp;<br>
8.5&nbsp;&nbsp;The&nbsp;ARMulator&nbsp;<br>
225&nbsp;<br>
8.6&nbsp;&nbsp;The JTAG&nbsp;boundary scan&nbsp;test&nbsp;architecture&nbsp;<br>
226&nbsp;<br>
8.7&nbsp;&nbsp;The&nbsp;ARM&nbsp;debug architecture&nbsp;<br>
232&nbsp;<br>
8.8&nbsp;&nbsp;Embedded Trace&nbsp;<br>
237&nbsp;<br>
8.9&nbsp;&nbsp;Signal processing&nbsp;support&nbsp;<br>
239&nbsp;<br>
8.10&nbsp;&nbsp;Example and&nbsp;exercises&nbsp;<br>
245&nbsp;<br>
ARM Processor Cores&nbsp;<br>
247&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
9.1&nbsp;<br>
ARM7TDMI&nbsp;248&nbsp;<br>
9.2&nbsp;&nbsp;ARM8&nbsp;256&nbsp;<br>
9.3&nbsp;<br>
ARM9TDMI 260&nbsp;<br>
9.4&nbsp;&nbsp;ARM10TDMI 263&nbsp;<br>
9.5&nbsp;&nbsp;Discussion 266&nbsp;<br>
9.6&nbsp;&nbsp;Example and&nbsp;exercises&nbsp;<br>
267&nbsp;<br>
<hr>
<A name=9></a><IMG src="index-9_1.png"><br>
<IMG src="index-9_2.png"><br>
<IMG src="index-9_3.png"><br>
<IMG src="index-9_4.png"><br>
X&nbsp;<br>
<b>Contents</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Memory Hierarchy&nbsp;<br>
269&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
10.1&nbsp;&nbsp;Memory&nbsp;size and speed&nbsp;<br>
270 271&nbsp;<br>
10.2&nbsp;&nbsp;On-chip&nbsp;memory&nbsp;<br>
272 279&nbsp;<br>
10.3&nbsp;&nbsp;Caches&nbsp;<br>
283 289&nbsp;<br>
10.4&nbsp;&nbsp;Cache design&nbsp;- an example&nbsp;<br>
10.5&nbsp;&nbsp;Memory&nbsp;management&nbsp;<br>
290&nbsp;<br>
10.6&nbsp;&nbsp;Examples&nbsp;and exercises&nbsp;<br>
&nbsp;&nbsp;Architectural Support&nbsp;for Operating Systems&nbsp;<br>
&nbsp;&nbsp;&nbsp;11.1&nbsp;&nbsp;An introduction to operating&nbsp;systems&nbsp;<br>
291&nbsp;&nbsp;293&nbsp;<br>
11.2&nbsp;&nbsp;The ARM system&nbsp;control coprocessor&nbsp;<br>
294 297&nbsp;<br>
11.3&nbsp;&nbsp;CP15 protection unit&nbsp;registers&nbsp;<br>
298 302&nbsp;<br>
11.4&nbsp;&nbsp;ARM protection unit&nbsp;<br>
309 310&nbsp;<br>
11.5&nbsp;&nbsp;CP15 MMU&nbsp;registers&nbsp;<br>
312 316&nbsp;<br>
11.6&nbsp;&nbsp;ARM MMU&nbsp;architecture&nbsp;<br>
11.7&nbsp;&nbsp;Synchronization&nbsp;<br>
317&nbsp;<br>
11.8&nbsp;&nbsp;Context switching&nbsp;<br>
11.9&nbsp;&nbsp;Input/Output&nbsp;<br>
11.10&nbsp;Example and exercises&nbsp;<br>
&nbsp;&nbsp;ARM CPU Cores&nbsp;<br>
&nbsp;&nbsp;&nbsp;12.1&nbsp;&nbsp;The ARM710T, ARM720T&nbsp;and&nbsp;<br>
318 323&nbsp;<br>
ARM740T&nbsp;<br>
327 335&nbsp;<br>
12.2&nbsp;&nbsp;The ARM810&nbsp;<br>
339 341&nbsp;<br>
12.3&nbsp;&nbsp;The StrongARM&nbsp;SA-110&nbsp;<br>
344 346&nbsp;<br>
12.4&nbsp;&nbsp;The ARM920T and ARM940T&nbsp;<br>
12.5&nbsp;&nbsp;The ARM946E-S and ARM966E-S&nbsp;<br>
347&nbsp;<br>
12.6&nbsp;&nbsp;The ARM1020E&nbsp;<br>
12.7&nbsp;&nbsp;Discussion&nbsp;<br>
12.8&nbsp;&nbsp;Example and exercises&nbsp;<br>
&nbsp;&nbsp;Embedded ARM Applications&nbsp;<br>
&nbsp;&nbsp;&nbsp;13.1&nbsp;&nbsp;The VLSI&nbsp;Ruby II Advanced&nbsp;Communication&nbsp;Processor&nbsp;<br>
348 349&nbsp;<br>
13.2&nbsp;&nbsp;The VLSI ISDN Subscriber&nbsp;Processor&nbsp;<br>
352 355&nbsp;<br>
13.3&nbsp;&nbsp;The OneC™&nbsp;VWS22100&nbsp;GSM&nbsp;chip&nbsp;<br>
360&nbsp;<br>
13.4&nbsp;&nbsp;The Ericsson-VLSI Bluetooth Baseband Controller&nbsp;<br>
13.5&nbsp;&nbsp;The ARM7500 and ARM7500FE&nbsp;<br>
<hr>
<A name=10></a><IMG src="index-10_1.png"><br>
<b>Contents</b>&nbsp;<br>
xi&nbsp;<br>
13.6&nbsp;&nbsp;The ARM7100&nbsp;<br>
364&nbsp;<br>
13.7&nbsp;&nbsp;The SA-1100&nbsp;<br>
368&nbsp;<br>
13.8&nbsp;&nbsp;Examples&nbsp;and&nbsp;exercises&nbsp;<br>
371&nbsp;<br>
&nbsp;&nbsp;The AMULET Asynchronous&nbsp;ARM Processors&nbsp;<br>
374&nbsp;<br>
14.1&nbsp;&nbsp;Self-timed design&nbsp;<br>
375&nbsp;<br>
14.2&nbsp;&nbsp;AMULET1 377&nbsp;<br>
14.3&nbsp;&nbsp;AMULET2&nbsp;381&nbsp;<br>
14.4&nbsp;&nbsp;AMULET2e&nbsp;384&nbsp;<br>
14.5&nbsp;&nbsp;AMULET3&nbsp;387&nbsp;<br>
14.6&nbsp;&nbsp;The&nbsp;DRACO&nbsp;telecommunications&nbsp;controller&nbsp;<br>
390&nbsp;<br>
14.7&nbsp;&nbsp;A self-timed future?&nbsp;<br>
396&nbsp;<br>
14.8&nbsp;&nbsp;Example and&nbsp;exercises&nbsp;<br>
397&nbsp;<br>
<i>Appendix: Computer&nbsp;Logic&nbsp;</i><br>
399&nbsp;<br>
<i>Glossary&nbsp;</i><br>
405&nbsp;<br>
<i>Bibliography&nbsp;</i><br>
410&nbsp;<br>
<i>Index&nbsp;</i><br>
413&nbsp;<br>
<hr>
<A name=11></a><IMG src="index-11_1.png"><br>
An Introduction to&nbsp;<br>
Processor Design&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Summary of chapter contents&nbsp;<br>
The design of&nbsp;a general-purpose processor, in common with most&nbsp;engineering&nbsp;<br>
endeavours, requires the careful consideration of many&nbsp;trade-offs&nbsp;and compro-<br>
mises. In this&nbsp;chapter we&nbsp;will look at the basic principles&nbsp;of processor instruction&nbsp;<br>
set and logic&nbsp;design and the techniques&nbsp;available to the designer to help achieve&nbsp;<br>
the design&nbsp;objectives.&nbsp;<br>
Abstraction is&nbsp;fundamental&nbsp;to&nbsp;understanding&nbsp;complex computers.&nbsp;This&nbsp;chapter&nbsp;<br>
introduces&nbsp;the&nbsp;abstractions which are employed&nbsp;by&nbsp;computer hardware&nbsp;designers,&nbsp;<br>
of which the most important&nbsp;is the&nbsp;logic&nbsp;gate. The design&nbsp;of a&nbsp;simple processor is&nbsp;<br>
presented, from&nbsp;the instruction set,&nbsp;through&nbsp;a register transfer&nbsp;level description,&nbsp;<br>
down&nbsp;to&nbsp;logic&nbsp;gates.&nbsp;<br>
The ideas behind the&nbsp;<i>Reduced&nbsp;Instruction Set Computer&nbsp;</i>(RISC) originated&nbsp;in proc-<br>
essor research&nbsp;programmes at&nbsp;Stanford&nbsp;and&nbsp;Berkeley&nbsp;universities&nbsp;around&nbsp;1980,&nbsp;though&nbsp;<br>
some&nbsp;of&nbsp;the&nbsp;central&nbsp;ideas&nbsp;can be&nbsp;traced&nbsp;back&nbsp;to&nbsp;earlier&nbsp;machines.&nbsp;In&nbsp;this&nbsp;chapter we&nbsp;look&nbsp;<br>
at&nbsp;the&nbsp;thinking&nbsp;that&nbsp;led to&nbsp;the RISC&nbsp;movement&nbsp;and consequently influenced&nbsp;the design&nbsp;of&nbsp;<br>
the&nbsp;ARM processor&nbsp;which&nbsp;is&nbsp;the subject of&nbsp;the&nbsp;following&nbsp;chapters.&nbsp;<br>
With&nbsp;the rapid&nbsp;development&nbsp;of markets&nbsp;for&nbsp;portable&nbsp;computer-based&nbsp;products,&nbsp;<br>
the&nbsp;power&nbsp;consumption&nbsp;of&nbsp;digital circuits&nbsp;is&nbsp;of&nbsp;increasing&nbsp;importance.&nbsp;At&nbsp;the&nbsp;end&nbsp;of&nbsp;<br>
the&nbsp;chapter&nbsp;we&nbsp;will look&nbsp;at&nbsp;the&nbsp;principles&nbsp;of&nbsp;low-power&nbsp;high-performance&nbsp;design.&nbsp;<br>
1&nbsp;<br>
<hr>
<A name=12></a>2&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
1.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Processor architecture&nbsp;and organization&nbsp;<br>
All modern&nbsp;general-purpose&nbsp;computers&nbsp;employ&nbsp;the&nbsp;principles&nbsp;of the&nbsp;<i>stored-program&nbsp;</i><br>
<i>digital computer.&nbsp;</i>The&nbsp;stored-program&nbsp;concept&nbsp;originated from&nbsp;the&nbsp;Princeton Insti-<br>
tute of Advanced Studies in&nbsp;the 1940s and was first implemented in the 'Baby'&nbsp;<br>
machine which first&nbsp;ran in&nbsp;June 1948 at the University&nbsp;of&nbsp;Manchester&nbsp;in England.&nbsp;<br>
Fifty years&nbsp;of&nbsp;development&nbsp;have resulted&nbsp;in&nbsp;a spectacular increase in&nbsp;the&nbsp;perform-<br>
ance&nbsp;of processors and an&nbsp;equally&nbsp;spectacular reduction&nbsp;in&nbsp;their&nbsp;cost.&nbsp;Over&nbsp;this&nbsp;period&nbsp;<br>
of&nbsp;relentless progress in&nbsp;the&nbsp;cost-effectiveness of&nbsp;computers,&nbsp;the&nbsp;principles of&nbsp;oper-<br>
ation have&nbsp;changed&nbsp;remarkably&nbsp;little.&nbsp;Most&nbsp;of&nbsp;the&nbsp;improvements have&nbsp;resulted&nbsp;from&nbsp;<br>
advances&nbsp;in&nbsp;the&nbsp;technology&nbsp;of&nbsp;electronics,&nbsp;moving&nbsp;from&nbsp;valves (vacuum&nbsp;tubes) to&nbsp;indi-<br>
vidual&nbsp;transistors,&nbsp;to&nbsp;integrated&nbsp;circuits&nbsp;(ICs) incorporating&nbsp;several bipolar&nbsp;transistors&nbsp;<br>
and&nbsp;then&nbsp;through&nbsp;generations&nbsp;of IC technology&nbsp;leading&nbsp;to&nbsp;today's very&nbsp;large scale&nbsp;inte-<br>
grated&nbsp;(VLSI) circuits&nbsp;delivering&nbsp;millions&nbsp;of&nbsp;field-effect&nbsp;transistors on&nbsp;a&nbsp;single&nbsp;chip.&nbsp;<br>
As&nbsp;transistors&nbsp;get&nbsp;smaller&nbsp;they&nbsp;get cheaper,&nbsp;faster,&nbsp;and&nbsp;consume&nbsp;less&nbsp;power.&nbsp;This&nbsp;<br>
win-win scenario has&nbsp;carried the&nbsp;computer&nbsp;industry&nbsp;forward&nbsp;for the&nbsp;past&nbsp;three&nbsp;decades,&nbsp;<br>
and&nbsp;will&nbsp;continue&nbsp;to&nbsp;do so&nbsp;at&nbsp;least for the&nbsp;next few&nbsp;years.&nbsp;<br>
However,&nbsp;not&nbsp;all&nbsp;of&nbsp;the&nbsp;progress&nbsp;over&nbsp;the&nbsp;past&nbsp;50&nbsp;years&nbsp;has&nbsp;come&nbsp;from&nbsp;advances&nbsp;in&nbsp;<br>
electronics technology.&nbsp;There&nbsp;have also&nbsp;been occasions&nbsp;when a&nbsp;new insight into&nbsp;the&nbsp;<br>
way that technology&nbsp;is&nbsp;employed has&nbsp;made&nbsp;a&nbsp;significant contribution.&nbsp;These insights&nbsp;<br>
are described&nbsp;under&nbsp;the&nbsp;headings&nbsp;of&nbsp;computer architecture&nbsp;and computer&nbsp;organization,&nbsp;<br>
where&nbsp;we&nbsp;will&nbsp;work&nbsp;with&nbsp;the&nbsp;following&nbsp;interpretations of&nbsp;these&nbsp;terms:&nbsp;<br>
Computer&nbsp;<br>
•&nbsp;&nbsp;Computer&nbsp;architecture describes the&nbsp;user's view of&nbsp;the computer.&nbsp;The&nbsp;instruction&nbsp;<br>
architecture&nbsp;<br>
set, visible registers,&nbsp;memory&nbsp;management table structures and exception han&nbsp;<br>
dling&nbsp;model&nbsp;are all part of&nbsp;the&nbsp;architecture.&nbsp;<br>
Computer&nbsp;<br>
•&nbsp;&nbsp;Computer &nbsp;organization &nbsp;describes &nbsp;the&nbsp;&nbsp;user-invisible&nbsp; &nbsp;implementation &nbsp;<br>
organization&nbsp;<br>
of the&nbsp;<br>
architecture. The pipeline structure,&nbsp;&nbsp;&nbsp; transparent&nbsp;cache,&nbsp;table-walking&nbsp;<br>
hardware&nbsp;<br>
and translation&nbsp;look-aside buffer are&nbsp;all aspects of&nbsp;the organization.&nbsp;<br>
Amongst the advances&nbsp;in&nbsp;these aspects&nbsp;of&nbsp;the&nbsp;design&nbsp;of&nbsp;computers, the&nbsp;introduction&nbsp;<br>
of virtual&nbsp;memory&nbsp;in the early&nbsp;1960s, of&nbsp;transparent&nbsp;cache memories, of&nbsp;pipelining&nbsp;<br>
and so&nbsp;on, have&nbsp;all been&nbsp;milestones&nbsp;in the&nbsp;evolution of&nbsp;computers.&nbsp;The RISC idea&nbsp;<br>
ranks amongst these advances, offering&nbsp;a significant shift&nbsp;in the balance&nbsp;of&nbsp;forces&nbsp;<br>
What is a&nbsp;<br>
which determines the&nbsp;cost-effectiveness&nbsp;of computer technology.&nbsp;<br>
processor?&nbsp;<br>
A general-purpose&nbsp;processor&nbsp;is&nbsp;a finite-state&nbsp;automaton that&nbsp;executes instructions held&nbsp;<br>
in a memory. The state&nbsp;of the system&nbsp;is defined by the&nbsp;values&nbsp;held&nbsp;in&nbsp;the memory loca-<br>
tions&nbsp;together&nbsp;with&nbsp;the&nbsp;values&nbsp;held&nbsp;in&nbsp;certain&nbsp;registers&nbsp;within&nbsp;the&nbsp;processor&nbsp;itself&nbsp;(see&nbsp;<br>
Figure&nbsp;1.1&nbsp;on&nbsp;page&nbsp;3;&nbsp;the&nbsp;hexadecimal notation for the memory&nbsp;addresses&nbsp;is&nbsp;explained&nbsp;<br>
in&nbsp;Section&nbsp;6.2&nbsp;on&nbsp;page 153).&nbsp;Each&nbsp;instruction&nbsp;defines&nbsp;a&nbsp;particular&nbsp;way the&nbsp;total&nbsp;state&nbsp;<br>
should&nbsp;change&nbsp;and it&nbsp;also&nbsp;defines&nbsp;which&nbsp;instruction&nbsp;should&nbsp;be executed next.&nbsp;<br>
<hr>
<A name=13></a><IMG src="index-13_1.png"><br>
<b>Abstraction in&nbsp;hardware design</b>&nbsp;<br>
3&nbsp;<br>
&nbsp;<br>
Figure&nbsp;1.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;state in&nbsp;a&nbsp;stored-program&nbsp;digital computer.&nbsp;<br>
The Stored-&nbsp;<br>
The&nbsp;<b>stored-program&nbsp;</b>digital computer&nbsp;keeps&nbsp;its&nbsp;instructions&nbsp;and&nbsp;data&nbsp;in&nbsp;the&nbsp;same&nbsp;<br>
program&nbsp;<br>
memory system, allowing&nbsp;the instructions to&nbsp;be&nbsp;treated&nbsp;as&nbsp;data when&nbsp;necessary. This&nbsp;<br>
Computer&nbsp;<br>
enables&nbsp;the processor itself to&nbsp;generate&nbsp;instructions&nbsp;which&nbsp;it&nbsp;can&nbsp;subsequently&nbsp;execute.&nbsp;<br>
Although&nbsp;programs&nbsp;that&nbsp;do this&nbsp;at&nbsp;a fine&nbsp;granularity&nbsp;<b>(self-modifying&nbsp;</b>code) are&nbsp;gener-<br>
ally&nbsp;considered&nbsp;bad&nbsp;form&nbsp;these days&nbsp;since&nbsp;they are&nbsp;very&nbsp;difficult to debug,&nbsp;use&nbsp;at a&nbsp;<br>
coarser granularity is fundamental to&nbsp;the&nbsp;way most computers operate.&nbsp;Whenever a&nbsp;<br>
computer loads in&nbsp;a new program&nbsp;from&nbsp;disk (overwriting an old program)&nbsp;and then&nbsp;<br>
executes&nbsp;it&nbsp;the&nbsp;computer&nbsp;is&nbsp;employing this&nbsp;ability&nbsp;to&nbsp;change&nbsp;its own program.&nbsp;<br>
C&nbsp;o&nbsp;mp&nbsp;u&nbsp;t&nbsp;e&nbsp;r&nbsp;&nbsp;<br>
Because of its programmability&nbsp;a stored-program&nbsp;digital computer is&nbsp;<b>universal,</b>&nbsp;<br>
applications&nbsp;<br>
which means&nbsp;that&nbsp;it&nbsp;can&nbsp;undertake any&nbsp;task&nbsp;that&nbsp;can&nbsp;be&nbsp;described&nbsp;by&nbsp;a&nbsp;suitable&nbsp;algo-&nbsp;<br>
rithm.&nbsp;Sometimes this is&nbsp;reflected&nbsp;by&nbsp;its&nbsp;configuration as&nbsp;a&nbsp;desktop machine&nbsp;where&nbsp;<br>
the&nbsp;user runs&nbsp;different&nbsp;programs&nbsp;at different&nbsp;times, but sometimes it is reflected&nbsp;by&nbsp;<br>
the same&nbsp;processor&nbsp;being&nbsp;used&nbsp;in&nbsp;a&nbsp;range&nbsp;of&nbsp;different applications, each&nbsp;with a&nbsp;fixed&nbsp;<br>
program. Such&nbsp;applications are characteristically embedded&nbsp;into&nbsp;products such&nbsp;as&nbsp;<br>
mobile telephones,&nbsp;automotive engine-management systems,&nbsp;and so&nbsp;on.&nbsp;<br>
1.2 &nbsp; Abstraction&nbsp;in&nbsp;hardware&nbsp;design&nbsp;<br>
Computers are&nbsp;very complex pieces of equipment that operate at very high speeds.&nbsp;A&nbsp;<br>
modern microprocessor may&nbsp;be&nbsp;built from&nbsp;several&nbsp;million&nbsp;transistors each&nbsp;of&nbsp;which&nbsp;<br>
can switch a&nbsp;hundred million times a second.&nbsp;Watch&nbsp;a document&nbsp;scroll up&nbsp;the&nbsp;screen&nbsp;<br>
<hr>
<A name=14></a><IMG src="index-14_1.png"><br>
4&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
on&nbsp;a&nbsp;desktop PC or&nbsp;workstation&nbsp;and try&nbsp;to&nbsp;imagine how a hundred&nbsp;million&nbsp;million&nbsp;<br>
transistor&nbsp;switching&nbsp;actions are&nbsp;used&nbsp;in&nbsp;each second&nbsp;of&nbsp;that&nbsp;movement.&nbsp;Now&nbsp;consider&nbsp;<br>
that&nbsp;every&nbsp;one&nbsp;of&nbsp;those&nbsp;switching actions is, in&nbsp;some&nbsp;sense,&nbsp;the consequence of a&nbsp;<br>
deliberate&nbsp;design&nbsp;decision. None&nbsp;of&nbsp;them&nbsp;is random&nbsp;or&nbsp;uncontrolled;&nbsp;indeed,&nbsp;a&nbsp;single&nbsp;<br>
error amongst those&nbsp;transitions is likely&nbsp;to&nbsp;cause the machine&nbsp;to&nbsp;collapse&nbsp;into&nbsp;a&nbsp;useless&nbsp;<br>
state.&nbsp;How&nbsp;can&nbsp;such&nbsp;complex systems be&nbsp;designed to&nbsp;operate&nbsp;so reliably?&nbsp;<br>
Transistors&nbsp;<br>
A clue&nbsp;to&nbsp;the&nbsp;answer may be&nbsp;found&nbsp;in the question itself. We have&nbsp;described&nbsp;the&nbsp;oper-&nbsp;<br>
ation of&nbsp;the&nbsp;computer&nbsp;in terms of&nbsp;transistors,&nbsp;but&nbsp;what is&nbsp;a transistor?&nbsp;It is a curious&nbsp;<br>
structure composed from&nbsp;carefully&nbsp;chosen chemical&nbsp;substances&nbsp;with&nbsp;complex electri-<br>
cal properties that can only be&nbsp;understood&nbsp;by&nbsp;reference to&nbsp;the theory of&nbsp;quantum&nbsp;<br>
mechanics,&nbsp;where strange&nbsp;subatomic particles sometimes behave&nbsp;like&nbsp;waves&nbsp;and&nbsp;can&nbsp;<br>
only be described&nbsp;in&nbsp;terms&nbsp;of probabilities.&nbsp;Yet&nbsp;the gross behaviour&nbsp;of a&nbsp;transistor&nbsp;can&nbsp;<br>
be&nbsp;described,&nbsp;without&nbsp;reference to&nbsp;quantum&nbsp;mechanics,&nbsp;as a&nbsp;set of equations that&nbsp;relate&nbsp;<br>
the voltages on&nbsp;its terminals to the current that&nbsp;flows though it. These equations&nbsp;<br>
<b>abstract&nbsp;</b>the essential behaviour&nbsp;of&nbsp;the&nbsp;device from&nbsp;its&nbsp;underlying&nbsp;physics.&nbsp;<br>
Logic&nbsp;gates&nbsp;<br>
The equations&nbsp;that&nbsp;describe&nbsp;the&nbsp;behaviour&nbsp;of a transistor&nbsp;are still fairly&nbsp;complex.&nbsp;<br>
When a group&nbsp;of transistors&nbsp;is wired together in a particular&nbsp;structure,&nbsp;such as the&nbsp;<br>
CMOS&nbsp;(Complementary&nbsp;Metal Oxide&nbsp;Semiconductor)&nbsp;NAND gate shown&nbsp;in&nbsp;<br>
Figure 1.2,&nbsp;the behaviour of&nbsp;the group&nbsp;has a particularly&nbsp;simple&nbsp;description.&nbsp;<br>
If each&nbsp;of&nbsp;the input wires&nbsp;<i>(A&nbsp;</i>and&nbsp;B)&nbsp;is&nbsp;held&nbsp;at&nbsp;a&nbsp;voltage&nbsp;which&nbsp;is&nbsp;either&nbsp;near&nbsp;to&nbsp;<i>Vdd&nbsp;</i><br>
or near to&nbsp;<i>Vss,&nbsp;</i>the&nbsp;output&nbsp;will&nbsp;will&nbsp;also&nbsp;be&nbsp;near&nbsp;to&nbsp;<i>Vdd&nbsp;</i>or&nbsp;<i>Vss&nbsp;</i>according to&nbsp;the follow-<br>
ing rules:&nbsp;<br>
•&nbsp;&nbsp;If&nbsp;<i>A&nbsp;</i>and&nbsp;<i>B&nbsp;</i>are&nbsp;both&nbsp;near&nbsp;to&nbsp;<i>Vdd,&nbsp;</i>the&nbsp;output will be&nbsp;near&nbsp;to&nbsp;<i>Vss.</i>&nbsp;<br>
•&nbsp;&nbsp;If either&nbsp;<i>A</i>&nbsp;or&nbsp;<i>B&nbsp;</i>(or both)&nbsp;is near to&nbsp;<i>Vss,&nbsp;</i>the output will be near to&nbsp;<i>Vdd.</i>&nbsp;<br>
&nbsp;<br>
<b>Figure 1.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The&nbsp;transistor&nbsp;circuit of a static&nbsp;2-input CMOS NAND gate.&nbsp;<br>
<hr>
<A name=15></a><IMG src="index-15_1.png"><br>
<b>Abstraction in&nbsp;hardware design</b>&nbsp;<br>
5&nbsp;<br>
With&nbsp;a&nbsp;bit&nbsp;of&nbsp;care we&nbsp;can&nbsp;define what&nbsp;is&nbsp;meant&nbsp;by&nbsp;'near&nbsp;to'&nbsp;in&nbsp;these rules,&nbsp;and&nbsp;then&nbsp;<br>
associate&nbsp;the&nbsp;meaning&nbsp;<b>true&nbsp;</b>with&nbsp;a value near to&nbsp;<i>Vdd&nbsp;</i>and&nbsp;<b>false&nbsp;</b>with&nbsp;a value near&nbsp;to&nbsp;<br>
<i>Vss.&nbsp;</i>The circuit is then an implementation of the NAND Boolean&nbsp;logic function:&nbsp;<br>
<i>output = —(A^B)</i>&nbsp;<br>
Equation 1&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Although&nbsp;there is a lot of engineering&nbsp;design involved&nbsp;in&nbsp;turning&nbsp;four&nbsp;transistors&nbsp;<br>
into&nbsp;a reliable&nbsp;implementation of this equation, it&nbsp;can&nbsp;be&nbsp;done with sufficient reliability&nbsp;<br>
that&nbsp;the logic&nbsp;designer&nbsp;can think almost exclusively in&nbsp;terms of logic&nbsp;gates.&nbsp;The con-<br>
cepts&nbsp;that&nbsp;the logic designer&nbsp;works with are&nbsp;illustrated&nbsp;in&nbsp;Figure&nbsp;1.3,&nbsp;and&nbsp;consist&nbsp;of the&nbsp;<br>
following 'views'&nbsp;of the&nbsp;logic&nbsp;gate:&nbsp;<br>
Logic symbol&nbsp;<br>
•&nbsp;&nbsp;A logic symbol.&nbsp;<br>
This is a&nbsp;symbol that represents a&nbsp;NAND&nbsp;gate function in&nbsp;a circuit&nbsp;schematic;&nbsp;<br>
there&nbsp;are&nbsp;similar symbols for other&nbsp;logic&nbsp;gates&nbsp;(for&nbsp;instance,&nbsp;removing&nbsp;the bubble&nbsp;<br>
from&nbsp;the output leaves an&nbsp;AND gate&nbsp;which generates the&nbsp;opposite output func-<br>
tion; further examples are given in&nbsp;'Appendix: Computer Logic'&nbsp;on page 399).&nbsp;<br>
Truth table&nbsp;<br>
•&nbsp;A&nbsp;truth&nbsp;table.&nbsp;<br>
This describes the logic&nbsp;function&nbsp;of&nbsp;the gate,&nbsp;and&nbsp;encompasses everything&nbsp;that&nbsp;the&nbsp;<br>
logic designer needs to&nbsp;know&nbsp;about the&nbsp;gate for most&nbsp;purposes. The significance&nbsp;<br>
here&nbsp;is&nbsp;that it&nbsp;is&nbsp;a lot simpler&nbsp;than four&nbsp;sets&nbsp;of transistor equations.&nbsp;<br>
(In this truth&nbsp;table&nbsp;we have represented&nbsp;'true'&nbsp;by&nbsp;'1' and&nbsp;'false' by&nbsp;'0',&nbsp;as&nbsp;is&nbsp;<br>
common&nbsp;practice when dealing with&nbsp;Boolean variables.)&nbsp;<br>
The gate&nbsp;<br>
The point&nbsp;about the gate&nbsp;abstraction&nbsp;is&nbsp;that&nbsp;not only does it&nbsp;greatly&nbsp;simplify the&nbsp;<br>
abstraction&nbsp;<br>
process of&nbsp;designing circuits with great&nbsp;numbers of&nbsp;transistors, but it actually&nbsp;<br>
&nbsp;<br>
<b>Figure 1.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The&nbsp;logic symbol and truth&nbsp;table for a NAND&nbsp;gate.&nbsp;<br>
<hr>
<A name=16></a>6&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
removes the&nbsp;need&nbsp;to&nbsp;know that&nbsp;the&nbsp;gate&nbsp;is&nbsp;built from&nbsp;transistors. A logic&nbsp;circuit&nbsp;<br>
should have the same&nbsp;logical behaviour&nbsp;whether the gates are implemented using&nbsp;<br>
field-effect&nbsp;transistors&nbsp;(the transistors that&nbsp;are available on&nbsp;a CMOS process), bipo-<br>
lar transistors, electrical relays,&nbsp;fluid logic or any&nbsp;other&nbsp;form&nbsp;of logic.&nbsp;The imple-<br>
mentation technology will affect the&nbsp;<i>performance&nbsp;</i>of the circuit, but it should have&nbsp;<br>
no effect on&nbsp;<i>its function.&nbsp;</i>It&nbsp;is the duty of&nbsp;the transistor-level circuit&nbsp;designer to&nbsp;sup-<br>
port the gate abstraction as near perfectly&nbsp;as&nbsp;is possible in&nbsp;order to isolate the logic&nbsp;<br>
circuit designer&nbsp;from&nbsp;the need to&nbsp;understand&nbsp;the transistor&nbsp;equations.&nbsp;<br>
Levels of&nbsp;<br>
It&nbsp;may&nbsp;appear&nbsp;that this point is being somewhat laboured, particularly&nbsp;to those read-<br>
abstraction&nbsp;<br>
ers who&nbsp;have&nbsp;worked with&nbsp;logic gates for many&nbsp;years. However,&nbsp;the principle that&nbsp;is&nbsp;<br>
illustrated&nbsp;in the gate&nbsp;level&nbsp;abstraction&nbsp;is repeated&nbsp;many&nbsp;times&nbsp;at different levels&nbsp;in&nbsp;<br>
computer science&nbsp;and is&nbsp;absolutely fundamental to&nbsp;the process&nbsp;which&nbsp;we&nbsp;began con-<br>
sidering at&nbsp;the&nbsp;start of&nbsp;this&nbsp;section,&nbsp;which is the&nbsp;management of&nbsp;complexity.&nbsp;<br>
The process of&nbsp;gathering&nbsp;together a&nbsp;few components at&nbsp;one&nbsp;level to&nbsp;extract their&nbsp;<br>
essential joint behaviour and hide all the unnecessary detail&nbsp;at the next level enables&nbsp;<br>
us to&nbsp;scale&nbsp;orders of&nbsp;complexity&nbsp;in&nbsp;a&nbsp;few&nbsp;steps. For&nbsp;instance,&nbsp;if&nbsp;each level&nbsp;encompasses&nbsp;<br>
four&nbsp;components&nbsp;of&nbsp;the&nbsp;next lower level as&nbsp;our&nbsp;gate model&nbsp;does, we&nbsp;can get&nbsp;from&nbsp;a&nbsp;<br>
transistor to&nbsp;a&nbsp;microprocessor comprising a&nbsp;million transistors&nbsp;in just&nbsp;ten steps.&nbsp;In&nbsp;<br>
many&nbsp;cases we work with more than four&nbsp;components, so the number of steps is&nbsp;<br>
greatly reduced.&nbsp;<br>
A typical&nbsp;hierarchy&nbsp;of&nbsp;abstraction&nbsp;at&nbsp;the&nbsp;hardware&nbsp;level might&nbsp;be:&nbsp;<br>
1.&nbsp;transistors;&nbsp;<br>
2.&nbsp;logic gates,&nbsp;memory cells,&nbsp;special circuits;&nbsp;<br>
3.&nbsp;single-bit adders, multiplexers, decoders, flip-flops;&nbsp;<br>
4.&nbsp;word-wide adders,&nbsp;multiplexers, decoders,&nbsp;registers, buses;&nbsp;<br>
5.&nbsp;ALUs (Arithmetic-Logic Units),&nbsp;barrel shifters,&nbsp;register banks,&nbsp;memory blocks;&nbsp;<br>
6.&nbsp;processor, cache and&nbsp;memory&nbsp;management&nbsp;organizations;&nbsp;<br>
7.&nbsp;processors, peripheral cells,&nbsp;cache&nbsp;memories,&nbsp;memory&nbsp;management&nbsp;units;&nbsp;<br>
8.&nbsp;integrated&nbsp;system&nbsp;chips;&nbsp;<br>
9.&nbsp;printed&nbsp;circuit&nbsp;boards;&nbsp;<br>
10. mobile&nbsp;telephones, PCs,&nbsp;engine&nbsp;controllers.&nbsp;<br>
The&nbsp;process of&nbsp;understanding&nbsp;a design&nbsp;in&nbsp;terms of levels&nbsp;of&nbsp;abstraction is&nbsp;reasona-<br>
bly concrete&nbsp;when the design&nbsp;is expressed in&nbsp;hardware.&nbsp;But the process doesn't&nbsp;stop&nbsp;<br>
with&nbsp;the&nbsp;hardware;&nbsp;if&nbsp;anything, it&nbsp;is&nbsp;even&nbsp;more&nbsp;fundamental&nbsp;to&nbsp;the understanding&nbsp;of&nbsp;<br>
software&nbsp;and we&nbsp;will&nbsp;return&nbsp;to&nbsp;look at&nbsp;abstraction&nbsp;in software design&nbsp;in due&nbsp;course.&nbsp;<br>
Gate-level&nbsp;<br>
The&nbsp;next&nbsp;step&nbsp;up&nbsp;from&nbsp;the&nbsp;logic&nbsp;gate&nbsp;is&nbsp;to&nbsp;assemble&nbsp;a library of&nbsp;useful&nbsp;functions&nbsp;each&nbsp;<br>
design&nbsp;<br>
composed&nbsp;of several gates.&nbsp;Typical functions are,&nbsp;as&nbsp;listed&nbsp;above,&nbsp;adders,&nbsp;multiplex-<br>
ers, decoders and flip-flops, each 1-bit&nbsp;wide. This book is not intended to&nbsp;be a gen-&nbsp;<br>
<hr>
<A name=17></a><b>MU0 - a simple&nbsp;processor</b>&nbsp;<br>
7&nbsp;<br>
eral introduction to logic design since its&nbsp;principal subject&nbsp;material&nbsp;relates to the&nbsp;<br>
design&nbsp;and use of processor&nbsp;cores and&nbsp;any reader&nbsp;who is considering&nbsp;applying&nbsp;this&nbsp;<br>
information&nbsp;should already&nbsp;be&nbsp;familiar&nbsp;with&nbsp;conventional logic design.&nbsp;<br>
For those&nbsp;who&nbsp;are&nbsp;not&nbsp;so&nbsp;familiar with&nbsp;logic&nbsp;design&nbsp;or&nbsp;who&nbsp;need&nbsp;their&nbsp;knowledge&nbsp;<br>
refreshing,&nbsp;'Appendix:&nbsp;Computer Logic'&nbsp;on&nbsp;page&nbsp;399 describes the essentials&nbsp;which&nbsp;<br>
will&nbsp;be&nbsp;assumed&nbsp;in the&nbsp;next&nbsp;section.&nbsp;It&nbsp;includes&nbsp;brief&nbsp;details&nbsp;on:&nbsp;<br>
•&nbsp;&nbsp;Boolean algebra and&nbsp;notation;&nbsp;<br>
•&nbsp;&nbsp;binary&nbsp;numbers;&nbsp;<br>
•&nbsp;&nbsp;binary addition;&nbsp;<br>
•&nbsp;&nbsp;multiplexers;&nbsp;<br>
•&nbsp;&nbsp;clocks;&nbsp;<br>
•&nbsp;&nbsp;sequential&nbsp;circuits;&nbsp;<br>
•&nbsp;&nbsp;latches and&nbsp;flip-flops;&nbsp;<br>
•&nbsp;&nbsp;registers.&nbsp;<br>
If any of these&nbsp;terms is unfamiliar,&nbsp;a brief&nbsp;look at the appendix may yield sufficient&nbsp;<br>
information for&nbsp;what follows.&nbsp;<br>
Note that although&nbsp;the&nbsp;appendix&nbsp;describes these circuit functions in&nbsp;terms of simple&nbsp;<br>
logic&nbsp;gates,&nbsp;there are&nbsp;often more efficient&nbsp;CMOS implementations&nbsp;based&nbsp;on&nbsp;alternative&nbsp;<br>
transistor circuits.&nbsp;There&nbsp;are&nbsp;many&nbsp;ways to&nbsp;satisfy the basic&nbsp;requirements of&nbsp;logic&nbsp;<br>
design&nbsp;using the complementary transistors available&nbsp;on a&nbsp;CMOS chip,&nbsp;and new&nbsp;tran-<br>
sistor circuits are published regularly.&nbsp;<br>
For further information consult a&nbsp;text on&nbsp;logic design;&nbsp;a suitable&nbsp;reference&nbsp;is sug-<br>
gested&nbsp;in the 'Bibliography'&nbsp;on page&nbsp;410.&nbsp;<br>
1.3 &nbsp; MU0&nbsp;-&nbsp;a&nbsp;simple&nbsp;processor&nbsp;<br>
A&nbsp;simple&nbsp;form of processor can be&nbsp;built from&nbsp;a&nbsp;few basic&nbsp;components:&nbsp;<br>
•&nbsp;&nbsp;<b>a program&nbsp;counter&nbsp;</b>(PC)&nbsp;register that&nbsp;is used to hold the&nbsp;address of the&nbsp;current&nbsp;<br>
instruction;<b>&nbsp;</b><br>
•&nbsp;&nbsp;a single register called an&nbsp;<b>accumulator&nbsp;</b>(ACC) that holds&nbsp;a&nbsp;data value&nbsp;while it is&nbsp;<br>
worked upon;&nbsp;<br>
•&nbsp;&nbsp;<b>an arithmetic-logic&nbsp;unit&nbsp;</b>(ALU) that&nbsp;can&nbsp;perform&nbsp;a number of operations&nbsp;on&nbsp;<br>
binary&nbsp;operands,&nbsp;such as add,&nbsp;subtract,&nbsp;increment,&nbsp;and so&nbsp;on;<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>an instruction&nbsp;register&nbsp;</b>(IR) that&nbsp;holds&nbsp;the&nbsp;current&nbsp;instruction while&nbsp;it&nbsp;is&nbsp;executed;<b>&nbsp;</b><br>
•&nbsp;&nbsp;instruction decode and control logic that employs the above&nbsp;components to&nbsp;<br>
achieve the&nbsp;desired&nbsp;results from&nbsp;each&nbsp;instruction.&nbsp;<br>
<hr>
<A name=18></a><IMG src="index-18_1.png"><br>
<IMG src="index-18_2.png"><br>
8&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
This&nbsp;limited set of&nbsp;components allows&nbsp;a restricted&nbsp;set&nbsp;of instructions&nbsp;to&nbsp;be&nbsp;imple-<br>
mented.&nbsp;Such&nbsp;a design&nbsp;has&nbsp;been&nbsp;employed&nbsp;at&nbsp;the&nbsp;University&nbsp;of Manchester&nbsp;for&nbsp;many&nbsp;<br>
years to&nbsp;illustrate the principles&nbsp;of&nbsp;processor design. Manchester-designed&nbsp;machines&nbsp;<br>
are often referred to by&nbsp;the&nbsp;names MUn for 1 &lt;&nbsp;<i>n &lt;&nbsp;</i>6,&nbsp;so this simple&nbsp;machine is&nbsp;<br>
known&nbsp;as&nbsp;MU0. It&nbsp;is a&nbsp;design&nbsp;developed&nbsp;only&nbsp;for&nbsp;teaching and&nbsp;was&nbsp;not&nbsp;one&nbsp;of&nbsp;the&nbsp;<br>
large-scale&nbsp;machines&nbsp;built at&nbsp;the&nbsp;university as&nbsp;research&nbsp;vehicles,&nbsp;though it&nbsp;is&nbsp;similar to&nbsp;<br>
the very&nbsp;first&nbsp;Manchester&nbsp;machine&nbsp;and has&nbsp;been&nbsp;implemented in&nbsp;various&nbsp;forms&nbsp;by&nbsp;<br>
undergraduate students.&nbsp;<br>
The MU0&nbsp;<br>
MU0 is a&nbsp;16-bit machine with a&nbsp;12-bit address space, so&nbsp;it&nbsp;can address up to&nbsp;8&nbsp;<br>
instruction&nbsp;set&nbsp;<br>
Kbytes&nbsp;of&nbsp;memory arranged&nbsp;as 4,096&nbsp;individually addressable 16-bit&nbsp;locations.&nbsp;<br>
Instructions are 16 bits long, with&nbsp;a 4-bit operation&nbsp;code&nbsp;(or&nbsp;<b>opcode)&nbsp;</b>and a 12-bit&nbsp;<br>
address field&nbsp;(S) as&nbsp;shown&nbsp;in&nbsp;Figure&nbsp;1.4.&nbsp;The simplest&nbsp;instruction&nbsp;set&nbsp;uses only&nbsp;eight&nbsp;<br>
of the 16 available opcodes&nbsp;and is&nbsp;summarized in&nbsp;Table&nbsp;1.1.&nbsp;<br>
An&nbsp;instruction&nbsp;such as&nbsp;'ACC&nbsp;:=&nbsp;ACC + mem16[S]'&nbsp;means 'add&nbsp;the&nbsp;contents&nbsp;of&nbsp;the&nbsp;<br>
(16-bit&nbsp;wide) memory location whose address is&nbsp;S to the accumulator'.&nbsp;Instructions&nbsp;<br>
are fetched from&nbsp;consecutive&nbsp;memory&nbsp;addresses, starting&nbsp;from&nbsp;address&nbsp;zero,&nbsp;until&nbsp;an&nbsp;<br>
instruction which modifies the&nbsp;PC is executed,&nbsp;whereupon fetching&nbsp;starts from&nbsp;the new&nbsp;<br>
address&nbsp;given in&nbsp;the 'jump'&nbsp;instruction.&nbsp;<br>
<b>Table&nbsp;1.1 &nbsp;&nbsp;&nbsp;</b>The&nbsp;MU0 instruction set.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
MU0&nbsp;logic&nbsp;<br>
To understand&nbsp;how this instruction&nbsp;set&nbsp;might&nbsp;be implemented&nbsp;we&nbsp;will&nbsp;go through the&nbsp;<br>
design&nbsp;<br>
design process in a logical order. The&nbsp;approach taken here will be&nbsp;to separate&nbsp;the&nbsp;<br>
design&nbsp;into&nbsp;two&nbsp;components:&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;1.4 &nbsp;&nbsp;</b>The MU0 instruction format.&nbsp;<br>
<hr>
<A name=19></a><IMG src="index-19_1.png"><br>
<b>MU0 - a simple&nbsp;processor</b>&nbsp;<br>
9&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
•&nbsp;The&nbsp;datapath.&nbsp;<br>
All&nbsp;the components carrying, storing or&nbsp;processing&nbsp;many&nbsp;bits in parallel&nbsp;will&nbsp;be&nbsp;<br>
considered&nbsp;part of the&nbsp;datapath,&nbsp;including&nbsp;the&nbsp;accumulator, program&nbsp;counter,&nbsp;<br>
ALU and instruction&nbsp;register. For&nbsp;these&nbsp;components we will&nbsp;use&nbsp;a register&nbsp;trans-<br>
fer level&nbsp;<b>(RTL)&nbsp;</b>design&nbsp;style based on&nbsp;registers,&nbsp;multiplexers, and so on.&nbsp;<br>
•&nbsp;&nbsp;The control logic.&nbsp;<br>
Everything&nbsp;that does not&nbsp;fit&nbsp;comfortably into&nbsp;the datapath&nbsp;will&nbsp;be&nbsp;considered&nbsp;part&nbsp;<br>
of the control&nbsp;logic and will be designed using a finite&nbsp;state&nbsp;machine&nbsp;(FSM)&nbsp;<br>
approach.&nbsp;<br>
Datapath design&nbsp;<br>
There are&nbsp;many&nbsp;ways&nbsp;to connect the basic components needed to implement the&nbsp;<br>
MU0&nbsp;instruction&nbsp;set.&nbsp;Where there&nbsp;are&nbsp;choices to&nbsp;be&nbsp;made&nbsp;we&nbsp;need&nbsp;a guiding princi-<br>
ple to help us&nbsp;make the right choices. Here we&nbsp;will follow the principle that the&nbsp;<br>
memory&nbsp;will be&nbsp;the limiting&nbsp;factor in our design, and a&nbsp;memory access&nbsp;will always&nbsp;<br>
take&nbsp;a&nbsp;clock cycle.&nbsp;Hence we&nbsp;will&nbsp;aim&nbsp;for&nbsp;an&nbsp;implementation where:&nbsp;<br>
•&nbsp;&nbsp;Each instruction takes exactly&nbsp;the number of clock cycles defined by&nbsp;the number&nbsp;<br>
of&nbsp;memory&nbsp;accesses&nbsp;it&nbsp;must&nbsp;make.&nbsp;<br>
Referring&nbsp;back&nbsp;to Table 1.1&nbsp;we can see that&nbsp;the first four&nbsp;instructions&nbsp;each require&nbsp;<br>
two&nbsp;memory accesses&nbsp;(one&nbsp;to fetch&nbsp;the&nbsp;instruction&nbsp;itself&nbsp;and one to fetch&nbsp;or&nbsp;store&nbsp;the&nbsp;<br>
operand) whereas&nbsp;the last&nbsp;four&nbsp;instructions can execute in&nbsp;one cycle&nbsp;since they&nbsp;do not&nbsp;<br>
require an operand.&nbsp;(In practice&nbsp;we&nbsp;would&nbsp;probably&nbsp;not&nbsp;worry about&nbsp;the&nbsp;efficiency&nbsp;of&nbsp;<br>
the STP instruction since&nbsp;it halts the&nbsp;processor&nbsp;for ever.) Therefore we need&nbsp;a datapath&nbsp;<br>
design&nbsp;which has sufficient&nbsp;resource&nbsp;to&nbsp;allow these instructions&nbsp;to&nbsp;complete&nbsp;in&nbsp;two&nbsp;or&nbsp;<br>
one&nbsp;clock cycles. A suitable&nbsp;datapath&nbsp;is shown&nbsp;in Figure&nbsp;1.5.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;1.5 &nbsp;&nbsp;</b>MU0 datapath&nbsp;example.&nbsp;<br>
<hr>
<A name=20></a><b>10</b>&nbsp;<br>
<b>An&nbsp;Introduction&nbsp;to Processor Design</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
(Readers&nbsp;who&nbsp;might expect to&nbsp;see a dedicated PC incrementer in&nbsp;this datapath&nbsp;<br>
should note&nbsp;that&nbsp;all&nbsp;instructions that&nbsp;do&nbsp;not&nbsp;change&nbsp;the&nbsp;PC&nbsp;take&nbsp;two cycles,&nbsp;so the&nbsp;main&nbsp;<br>
ALU&nbsp;is available during one of&nbsp;these&nbsp;cycles to&nbsp;increment the&nbsp;PC.)&nbsp;<br>
Datapath&nbsp;<br>
The design&nbsp;we will develop assumes that&nbsp;each instruction&nbsp;starts&nbsp;when&nbsp;it&nbsp;has arrived&nbsp;<br>
operation&nbsp;<br>
in the instruction register. After all, until it&nbsp;is in the instruction register&nbsp;we cannot&nbsp;<br>
know which instruction&nbsp;we&nbsp;are dealing&nbsp;with. Therefore an instruction&nbsp;executes&nbsp;in&nbsp;<br>
two&nbsp;stages,&nbsp;possibly&nbsp;omitting the&nbsp;first of&nbsp;these:&nbsp;<br>
1.&nbsp;&nbsp;Access the&nbsp;memory operand&nbsp;and perform&nbsp;the desired&nbsp;operation.&nbsp;<br>
The address in&nbsp;the instruction register is&nbsp;issued and&nbsp;either an operand is read&nbsp;<br>
from&nbsp;memory, combined with the accumulator&nbsp;in&nbsp;the&nbsp;ALU and written&nbsp;back into&nbsp;<br>
the accumulator,&nbsp;or&nbsp;the&nbsp;accumulator&nbsp;is&nbsp;stored out to memory.&nbsp;<br>
2.&nbsp;&nbsp;Fetch&nbsp;the&nbsp;next instruction&nbsp;to be&nbsp;executed.&nbsp;<br>
Either&nbsp;the&nbsp;PC&nbsp;or the address&nbsp;in the&nbsp;instruction register is&nbsp;issued&nbsp;to&nbsp;fetch&nbsp;the next&nbsp;<br>
instruction, and in either case the address is incremented&nbsp;in the ALU and the&nbsp;<br>
incremented&nbsp;value&nbsp;saved&nbsp;into&nbsp;the&nbsp;PC.&nbsp;<br>
Initialization&nbsp;<br>
The&nbsp;processor&nbsp;must&nbsp;start&nbsp;in&nbsp;a&nbsp;known&nbsp;state.&nbsp;Usually&nbsp;this&nbsp;requires&nbsp;a&nbsp;<i>reset&nbsp;</i>input&nbsp;to&nbsp;cause&nbsp;it&nbsp;<br>
to start executing instructions from&nbsp;a known&nbsp;address.&nbsp;We will design MU0 to start exe-<br>
cuting from&nbsp;address 00016. There are several ways&nbsp;to achieve this, one of which is to use&nbsp;<br>
the reset signal&nbsp;to zero the ALU&nbsp;output&nbsp;and then clock this into&nbsp;the PC register.&nbsp;<br>
Register transfer&nbsp;<br>
The next step&nbsp;is to determine exactly the&nbsp;control signals&nbsp;that are&nbsp;required to cause&nbsp;<br>
level design&nbsp;<br>
the datapath&nbsp;to&nbsp;carry out&nbsp;the&nbsp;full&nbsp;set of&nbsp;operations.&nbsp;We&nbsp;assume&nbsp;that&nbsp;all&nbsp;the&nbsp;registers&nbsp;<br>
change state on the falling edge of the input clock, and&nbsp;where necessary&nbsp;have con-<br>
trol signals that&nbsp;may&nbsp;be used to prevent them&nbsp;from&nbsp;changing on a particular clock&nbsp;<br>
edge. The PC,&nbsp;for example, will change at&nbsp;the end&nbsp;of a clock cycle where&nbsp;<i>PCce&nbsp;</i><br>
is&nbsp;'&nbsp;1'&nbsp;but&nbsp;will&nbsp;not change when&nbsp;<i>PCce&nbsp;</i>is '0'.&nbsp;<br>
A&nbsp;suitable register organization&nbsp;is&nbsp;shown in&nbsp;Figure 1.6&nbsp;on page 11. This&nbsp;shows enables&nbsp;<br>
on all of the&nbsp;registers, function&nbsp;select&nbsp;lines to&nbsp;the ALU&nbsp;(the precise number&nbsp;and interpreta-<br>
tion to be determined later), the select control&nbsp;lines for two&nbsp;multiplexers, the&nbsp;control for a&nbsp;<br>
tri-state driver to&nbsp;send&nbsp;the ACC value to&nbsp;memory&nbsp;and&nbsp;memory&nbsp;request&nbsp;<i>(MEMrq)&nbsp;</i>and&nbsp;<br>
read/write&nbsp;<i>(RnW)&nbsp;</i>control lines. The other signals shown are&nbsp;outputs from&nbsp;the datapath to&nbsp;<br>
the control logic, including the&nbsp;opcode bits&nbsp;and&nbsp;signals&nbsp;indicating whether&nbsp;ACC is zero or&nbsp;<br>
negative which control the respective conditional jump&nbsp;instructions.&nbsp;<br>
Control&nbsp;logic&nbsp;<br>
The control logic simply&nbsp;has to&nbsp;decode the current instruction and generate the appropri-&nbsp;<br>
ate levels&nbsp;on&nbsp;the&nbsp;datapath&nbsp;control&nbsp;signals,&nbsp;using the control&nbsp;inputs&nbsp;from&nbsp;the&nbsp;datapath&nbsp;<br>
where&nbsp;necessary. Although the control&nbsp;logic&nbsp;is a&nbsp;finite&nbsp;state&nbsp;machine,&nbsp;and therefore&nbsp;in&nbsp;<br>
principle&nbsp;the&nbsp;design should start from&nbsp;a state&nbsp;transition diagram,&nbsp;in this case the FSM is&nbsp;<br>
trivial and the diagram&nbsp;not worth drawing. The implementation requires only&nbsp;two&nbsp;states,&nbsp;<br>
'fetch'&nbsp;and 'execute',&nbsp;and one&nbsp;bit of state&nbsp;<i>(Ex/ft)&nbsp;</i>is therefore&nbsp;sufficient.&nbsp;<br>
<hr>
<A name=21></a><IMG src="index-21_1.png"><br>
<b>MU0 - a simple&nbsp;processor</b>&nbsp;<br>
<b>11</b>&nbsp;<br>
The control&nbsp;logic&nbsp;can&nbsp;be&nbsp;presented&nbsp;in&nbsp;tabular&nbsp;form&nbsp;as shown&nbsp;in&nbsp;Table 1.2&nbsp;on page 12.&nbsp;<br>
In&nbsp;this&nbsp;table&nbsp;an&nbsp;'x' indicates&nbsp;a&nbsp;<i>don't&nbsp;care&nbsp;</i>condition. Once the&nbsp;ALU function&nbsp;select codes&nbsp;<br>
have been assigned the table may be implemented directly as a PLA (programmable&nbsp;<br>
logic array)&nbsp;or&nbsp;translated into&nbsp;combinatorial logic and&nbsp;implemented&nbsp;using standard&nbsp;gates.&nbsp;<br>
A quick scrutiny&nbsp;of Table&nbsp;1.2 reveals a few easy&nbsp;simplifications. The&nbsp;program&nbsp;<br>
counter and instruction register clock enables&nbsp;<i>(PCce&nbsp;</i>and&nbsp;<i>IRce)&nbsp;</i>are always the same.&nbsp;<br>
This&nbsp;makes&nbsp;sense, since whenever a new&nbsp;instruction is being fetched&nbsp;the ALU is&nbsp;com-<br>
puting the next&nbsp;program&nbsp;counter value, and this&nbsp;should be latched too. Therefore these&nbsp;<br>
control signals&nbsp;may be&nbsp;merged&nbsp;into&nbsp;one. Similarly, whenever the accumulator is driv-<br>
ing the data&nbsp;bus&nbsp;<i>(ACCoe&nbsp;</i>is&nbsp;high) the memory&nbsp;should perform&nbsp;a write operation&nbsp;<i>(Rn&nbsp;W&nbsp;</i><br>
is&nbsp;low), so one of these signals&nbsp;can be generated from&nbsp;the other using an inverter.&nbsp;<br>
After these&nbsp;simplifications the control&nbsp;logic&nbsp;design is almost complete.&nbsp;It&nbsp;only&nbsp;<br>
remains to&nbsp;determine the encodings&nbsp;of the&nbsp;ALU functions.&nbsp;<br>
&nbsp;<br>
Figure 1.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MU0 register transfer level organization.<br>
<hr>
<A name=22></a><IMG src="index-22_1.png"><br>
<b>MU0 - a simple&nbsp;processor</b>&nbsp;<br>
11&nbsp;<br>
The&nbsp;control&nbsp;logic can&nbsp;be&nbsp;presented in&nbsp;tabular&nbsp;form&nbsp;as shown&nbsp;in&nbsp;Table 1.2&nbsp;on page 12.&nbsp;<br>
In this table an&nbsp;'x'&nbsp;indicates a&nbsp;<i>don't&nbsp;care&nbsp;</i>condition. Once&nbsp;the&nbsp;ALU function select&nbsp;codes&nbsp;<br>
have&nbsp;been assigned&nbsp;the table&nbsp;may&nbsp;be implemented directly&nbsp;as a PLA&nbsp;(programmable&nbsp;<br>
logic array)&nbsp;or&nbsp;translated into&nbsp;combinatorial logic and&nbsp;implemented&nbsp;using standard&nbsp;gates.&nbsp;<br>
A quick scrutiny&nbsp;of Table&nbsp;1.2 reveals&nbsp;a&nbsp;few easy&nbsp;simplifications. The&nbsp;program&nbsp;<br>
counter and instruction register clock enables&nbsp;<i>(PCce&nbsp;</i>and&nbsp;<i>IRce)&nbsp;</i>are always the same.&nbsp;<br>
This&nbsp;makes sense, since whenever a new instruction is&nbsp;being fetched the ALU is&nbsp;com-<br>
puting the next&nbsp;program&nbsp;counter value,&nbsp;and this&nbsp;should be&nbsp;latched too. Therefore these&nbsp;<br>
control signals may be&nbsp;merged&nbsp;into one. Similarly, whenever the accumulator is driv-<br>
ing the&nbsp;data&nbsp;bus&nbsp;<i>(ACCoe&nbsp;</i>is&nbsp;high) the memory&nbsp;should&nbsp;perform&nbsp;a write&nbsp;operation&nbsp;<i>(RnW&nbsp;</i><br>
is&nbsp;low), so one of these signals&nbsp;can be generated from&nbsp;the other using an inverter.&nbsp;<br>
After these simplifications&nbsp;the control logic design&nbsp;is almost complete. It only&nbsp;<br>
remains to&nbsp;determine the encodings&nbsp;of the&nbsp;ALU functions.&nbsp;<br>
&nbsp;<br>
Figure 1.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MU0 register transfer level organization.<br>
<hr>
<A name=23></a><IMG src="index-23_1.png"><br>
<b>12</b>&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
ALU&nbsp;design&nbsp;<br>
Most&nbsp;of&nbsp;the register&nbsp;transfer&nbsp;level&nbsp;functions&nbsp;in Figure 1.6 have straightforward logic&nbsp;<br>
implementations (readers&nbsp;who are in&nbsp;doubt should refer to&nbsp;'Appendix: Computer&nbsp;<br>
Logic'&nbsp;on page 399).&nbsp;The MU0&nbsp;ALU is a&nbsp;little&nbsp;more&nbsp;complex than&nbsp;the&nbsp;simple&nbsp;adder&nbsp;<br>
described&nbsp;in&nbsp;the appendix,&nbsp;however.&nbsp;<br>
The&nbsp;ALU&nbsp;functions&nbsp;that&nbsp;are required are&nbsp;listed in&nbsp;Table&nbsp;1.2. There&nbsp;are&nbsp;five&nbsp;of&nbsp;them&nbsp;<br>
<i>(A&nbsp;+ B,&nbsp;A —&nbsp;B,&nbsp;B,&nbsp;B&nbsp;+&nbsp;</i>1,0),&nbsp;the last&nbsp;of&nbsp;which is only&nbsp;used&nbsp;while&nbsp;reset is active.&nbsp;There-<br>
fore the&nbsp;reset&nbsp;signal&nbsp;can&nbsp;control this&nbsp;function&nbsp;directly and the&nbsp;control logic need only&nbsp;<br>
generate&nbsp;a&nbsp;2-bit function&nbsp;select&nbsp;code&nbsp;to&nbsp;choose&nbsp;between&nbsp;the&nbsp;other&nbsp;four. If&nbsp;the principal&nbsp;<br>
ALU inputs are the&nbsp;<i>A&nbsp;</i>and&nbsp;<i>B&nbsp;</i>operands,&nbsp;all&nbsp;the&nbsp;functions&nbsp;may be&nbsp;produced&nbsp;by&nbsp;augment-<br>
ing&nbsp;a conventional binary&nbsp;adder:&nbsp;<br>
•&nbsp;&nbsp;<i>A +&nbsp;B&nbsp;</i>is the normal adder output (assuming&nbsp;that the carry-in is zero).&nbsp;<br>
•&nbsp;&nbsp;<i>A — B&nbsp;</i>may&nbsp;be&nbsp;implemented&nbsp;as&nbsp;<i>A +&nbsp;B +&nbsp;</i>1, requiring&nbsp;the&nbsp;<i>B&nbsp;</i>inputs to&nbsp;be inverted&nbsp;and&nbsp;<br>
the carry-in&nbsp;to&nbsp;be forced&nbsp;to a&nbsp;one.&nbsp;<br>
•&nbsp;&nbsp;<i>B&nbsp;</i>is implemented by&nbsp;forcing&nbsp;the&nbsp;<i>A&nbsp;</i>inputs and the carry-in to zero.&nbsp;<br>
•&nbsp;&nbsp;<i>B +&nbsp;</i>1 is implemented by&nbsp;forcing&nbsp;<i>A</i>&nbsp;to zero and the carry-in to one.&nbsp;<br>
<b>Table&nbsp;1.2 &nbsp;&nbsp;&nbsp;</b>MU0 control logic.&nbsp;<br>
&nbsp;<br>
<hr>
<A name=24></a><IMG src="index-24_1.png"><br>
<b>MU0 - a simple&nbsp;processor</b>&nbsp;<br>
<b>13</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The&nbsp;gate-level&nbsp;logic for&nbsp;the ALU is shown in&nbsp;Figure&nbsp;1.7.&nbsp;<i>Aen&nbsp;</i>enables the&nbsp;<i>A&nbsp;</i>operand&nbsp;<br>
or&nbsp;forces it to&nbsp;zero;&nbsp;<i>Binv&nbsp;&nbsp;</i>controls whether&nbsp;or not&nbsp;the&nbsp;<i>B&nbsp;&nbsp;</i>operand&nbsp;is&nbsp;inverted.&nbsp;The&nbsp;<br>
carry-out&nbsp;&nbsp;<i>(Cout)&nbsp;&nbsp;</i>from&nbsp;one&nbsp;bit&nbsp;is connected to the&nbsp;carry-in&nbsp;<i>(Cin)&nbsp;&nbsp;</i>of&nbsp;the next;&nbsp;the&nbsp;<br>
carry-in&nbsp;to the&nbsp;first bit is&nbsp;controlled by&nbsp;the ALU function&nbsp;selects (as are&nbsp;<i>Aen&nbsp;</i>and&nbsp;<i>Binv),&nbsp;</i><br>
and&nbsp;the&nbsp;carry-out from&nbsp;the last&nbsp;bit is&nbsp;unused&nbsp;Together with&nbsp;the multiplexers, registers,&nbsp;<br>
control&nbsp;logic and&nbsp;a&nbsp;bus&nbsp;buffer&nbsp;(which&nbsp;is used&nbsp;to&nbsp;put the&nbsp;accumulator value onto&nbsp;the&nbsp;<br>
data&nbsp;bus),&nbsp;the&nbsp;processor is complete. Add a standard&nbsp;memory&nbsp;and you have a&nbsp;workable&nbsp;<br>
computer.&nbsp;<br>
MU0 extensions&nbsp;<br>
Although&nbsp;MU0&nbsp;is a very&nbsp;simple processor&nbsp;and would&nbsp;not make&nbsp;a&nbsp;good target for a&nbsp;<br>
high-level language compiler, it serves&nbsp;to illustrate the basic&nbsp;principles&nbsp;of&nbsp;processor&nbsp;<br>
design. The design&nbsp;process&nbsp;used to&nbsp;develop&nbsp;the first&nbsp;ARM processors differed&nbsp;<br>
mainly&nbsp;in&nbsp;complexity&nbsp;and not&nbsp;in&nbsp;principle.&nbsp;MU0 designs based on&nbsp;microcoded&nbsp;con-<br>
trol logic have&nbsp;also been developed, as&nbsp;have extensions to incorporate indexed&nbsp;<br>
addressing. Like&nbsp;any good&nbsp;processor, MU0 has&nbsp;spaces&nbsp;left&nbsp;in&nbsp;the&nbsp;instruction&nbsp;space&nbsp;<br>
which&nbsp;allow&nbsp;future&nbsp;expansion&nbsp;of the instruction set.&nbsp;<br>
To turn&nbsp;MU0&nbsp;into&nbsp;a useful&nbsp;processor takes&nbsp;quite a&nbsp;lot&nbsp;of work. The&nbsp;following exten-<br>
sions seem&nbsp;most important:&nbsp;<br>
•&nbsp;&nbsp;Extending the address&nbsp;space.&nbsp;<br>
•&nbsp;&nbsp;Adding more&nbsp;addressing modes.&nbsp;<br>
•&nbsp;&nbsp;Allowing the&nbsp;PC to&nbsp;be&nbsp;saved&nbsp;in order to&nbsp;support a subroutine&nbsp;mechanism.&nbsp;<br>
•&nbsp;&nbsp;Adding&nbsp;more registers, supporting interrupts, and&nbsp;so on...&nbsp;<br>
Overall,&nbsp;this&nbsp;doesn't seem&nbsp;to be the&nbsp;place&nbsp;to&nbsp;start&nbsp;from&nbsp;if&nbsp;the objective is to design a&nbsp;<br>
high-performance processor which&nbsp;is&nbsp;a good&nbsp;compiler&nbsp;target.&nbsp;<br>
&nbsp;<br>
<b>Figure 1.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>MU0 ALU&nbsp;logic&nbsp;for one bit.&nbsp;<br>
<hr>
<A name=25></a><IMG src="index-25_1.png"><br>
<IMG src="index-25_2.png"><br>
<b>14</b>&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
1.4 &nbsp; Instruction&nbsp;set&nbsp;design&nbsp;<br>
If the MU0 instruction set is&nbsp;not a good choice for a high-performance processor,&nbsp;<br>
what other choices&nbsp;are&nbsp;there?&nbsp;<br>
Starting&nbsp;from&nbsp;first principles,&nbsp;let us look at a&nbsp;basic&nbsp;machine&nbsp;operation&nbsp;such&nbsp;as an&nbsp;<br>
instruction&nbsp;to&nbsp;add&nbsp;two&nbsp;numbers&nbsp;to&nbsp;produce a&nbsp;result.&nbsp;<br>
4-addreSS&nbsp;<br>
In its&nbsp;most general form, this&nbsp;instruction requires some&nbsp;bits&nbsp;to differentiate it from&nbsp;<br>
instructions&nbsp;<br>
other instructions, some&nbsp;bits&nbsp;to specify&nbsp;the&nbsp;operand addresses,&nbsp;some&nbsp;bits to specify&nbsp;<br>
where&nbsp;the&nbsp;result&nbsp;should&nbsp;be&nbsp;placed&nbsp;(the&nbsp;<b>destination),&nbsp;</b>and&nbsp;some&nbsp;bits to specify the&nbsp;<br>
address&nbsp;of&nbsp;the&nbsp;next&nbsp;instruction to&nbsp;be executed. An&nbsp;assembly language format for&nbsp;<br>
such&nbsp;an&nbsp;instruction&nbsp;might&nbsp;be:&nbsp;<br>
ADD&nbsp;<br>
d, &nbsp; s1, &nbsp; s2, &nbsp; next_i &nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
s2&nbsp;<br>
Such an instruction&nbsp;might be represented in&nbsp;memory&nbsp;by&nbsp;a&nbsp;binary&nbsp;format&nbsp;such as&nbsp;<br>
that shown&nbsp;in Figure&nbsp;1.8. This format requires&nbsp;<i>4n&nbsp;</i>+<i>f&nbsp;</i>bits&nbsp;per instruction where each&nbsp;<br>
operand&nbsp;requires&nbsp;<i>n&nbsp;</i>bits and the opcode that&nbsp;specifies 'ADD' requires/bits.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;1.8&nbsp; &nbsp;</b>A 4-address instruction&nbsp;format.&nbsp;<br>
3-addresS&nbsp;<br>
The first&nbsp;way&nbsp;to&nbsp;reduce the number of bits&nbsp;required for each instruction is to&nbsp;make&nbsp;<br>
instructions&nbsp;<br>
the address of the next instruction implicit (except for branch instructions, whose&nbsp;<br>
role is to modify&nbsp;the instruction sequence explicitly). If we assume&nbsp;that the default&nbsp;<br>
next instruction can be found by&nbsp;adding the size of the instruction to the PC,&nbsp;we get&nbsp;<br>
a 3-address instruction&nbsp;with an&nbsp;assembly&nbsp;language format&nbsp;like this:&nbsp;<br>
ADD&nbsp;<br>
<b>d,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s1,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s2&nbsp;</b><br>
<b>;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s2</b>&nbsp;<br>
<b>A binary&nbsp;representation&nbsp;of&nbsp;such&nbsp;an instruction is&nbsp;shown in&nbsp;Figure&nbsp;1.9.</b>&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;1.9&nbsp; &nbsp;</b>A 3-address instruction&nbsp;format.&nbsp;<br>
2-addreSS&nbsp;<br>
A further&nbsp;saving in the number of&nbsp;bits&nbsp;required to store an instruction can be&nbsp;<br>
instructions&nbsp;<br>
achieved by&nbsp;making the destination&nbsp;register&nbsp;the&nbsp;same&nbsp;as&nbsp;one&nbsp;of the source&nbsp;registers.&nbsp;<br>
The assembly language&nbsp;format could be:&nbsp;<br>
<hr>
<A name=26></a><IMG src="index-26_1.png"><br>
<IMG src="index-26_2.png"><br>
<IMG src="index-26_3.png"><br>
<b>Instruction set&nbsp;design</b>&nbsp;<br>
15&nbsp;<br>
ADD &nbsp; &nbsp;&nbsp;d,&nbsp;s1&nbsp; &nbsp;;&nbsp;&nbsp;d&nbsp;&nbsp;:=&nbsp;d&nbsp;+&nbsp;&nbsp;s1&nbsp;<br>
<b>The binary&nbsp;representation&nbsp;now&nbsp;reduces&nbsp;to&nbsp;that shown&nbsp;in&nbsp;Figure&nbsp;1.10.</b>&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;1.10 &nbsp;&nbsp;</b>A 2-address instruction&nbsp;format.&nbsp;<br>
1-address&nbsp;<br>
If the destination register is&nbsp;made implicit&nbsp;it is often called the&nbsp;<b>accumulator&nbsp;</b>(see,&nbsp;<br>
instructions&nbsp;<br>
for example,&nbsp;MU0&nbsp;in&nbsp;the&nbsp;previous&nbsp;section);&nbsp;an&nbsp;instruction need&nbsp;only&nbsp;specify&nbsp;one&nbsp;<br>
operand:&nbsp;<br>
ADD&nbsp;&nbsp;&nbsp; s1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;accumulator&nbsp;:=&nbsp;accumulator&nbsp;+&nbsp;s1&nbsp;<br>
The&nbsp;binary&nbsp;representation&nbsp;simplifies further&nbsp;to&nbsp;that&nbsp;shown in&nbsp;Figure&nbsp;1.11.&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 1.11&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>A 1-address (accumulator)&nbsp;instruction format.&nbsp;<br>
0-address&nbsp;<br>
Finally,&nbsp;an&nbsp;architecture&nbsp;may&nbsp;make all operand&nbsp;references&nbsp;implicit&nbsp;by&nbsp;using an&nbsp;evalu-<br>
instructions&nbsp;<br>
ation stack. The assembly language&nbsp;format is:&nbsp;<br>
ADD&nbsp;<br>
; &nbsp;&nbsp;top_of_stack &nbsp; := &nbsp;top_of_stack&nbsp;+&nbsp;<br>
next_on_stack&nbsp;<br>
The binary representation&nbsp;is&nbsp;as shown in&nbsp;Figure&nbsp;1.12.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;1.12 &nbsp;&nbsp;</b>A 0-address instruction&nbsp;format.&nbsp;<br>
Examples of&nbsp;<br>
All these forms of&nbsp;instruction have been&nbsp;used in&nbsp;processor instruction sets apart&nbsp;<br>
n-address use&nbsp;<br>
from&nbsp;the&nbsp;4-address form&nbsp;which, although&nbsp;it&nbsp;is used&nbsp;internally in&nbsp;some&nbsp;microcode&nbsp;<br>
designs,&nbsp;is unnecessarily expensive&nbsp;for a&nbsp;machine-level instruction&nbsp;set. For example:&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;Inmos transputer&nbsp;uses a&nbsp;0-address&nbsp;evaluation stack architecture.&nbsp;<br>
•&nbsp;&nbsp;The MU0 example in the previous section illustrates a&nbsp;simple&nbsp;1&nbsp;-address architecture.&nbsp;<br>
<hr>
<A name=27></a>16&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
•&nbsp;&nbsp;The Thumb instruction set used&nbsp;for high code&nbsp;density&nbsp;on some&nbsp;ARM processors uses&nbsp;<br>
an architecture&nbsp;which is predominantly&nbsp;of the 2-address form&nbsp;(see Chapter 7).&nbsp;<br>
•&nbsp;&nbsp;The standard&nbsp;ARM&nbsp;instruction set uses&nbsp;a 3-address&nbsp;architecture.&nbsp;<br>
Addresses&nbsp;<br>
An&nbsp;address&nbsp;in&nbsp;the MU0 architecture is the&nbsp;straightforward&nbsp;'absolute'&nbsp;address of&nbsp;the&nbsp;<br>
memory location which&nbsp;contains the desired operand.&nbsp;However,&nbsp;the&nbsp;three addresses&nbsp;<br>
in the ARM&nbsp;3-address instruction format&nbsp;are register&nbsp;specifiers, not memory&nbsp;<br>
addresses. In&nbsp;general, the term&nbsp;'3-address&nbsp;architecture'&nbsp;refers to an instruction set&nbsp;<br>
where&nbsp;the&nbsp;two&nbsp;source&nbsp;operands&nbsp;and&nbsp;the&nbsp;destination can&nbsp;be specified&nbsp;independently&nbsp;of&nbsp;<br>
each other, but&nbsp;often&nbsp;only&nbsp;within a&nbsp;restricted&nbsp;set of&nbsp;possible&nbsp;values.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Instruction types&nbsp;&nbsp;We have just&nbsp;looked at a number of&nbsp;ways&nbsp;of&nbsp;specifying&nbsp;an&nbsp;'ADD'&nbsp;instruction.&nbsp;A&nbsp;<br>
complete&nbsp;instruction&nbsp;set&nbsp;needs to&nbsp;do&nbsp;more&nbsp;than&nbsp;perform&nbsp;arithmetic&nbsp;operations&nbsp;on&nbsp;<br>
operands in&nbsp;memory.&nbsp;A general-purpose instruction&nbsp;set&nbsp;can be expected to include&nbsp;<br>
instructions&nbsp;in&nbsp;the&nbsp;following&nbsp;categories:&nbsp;<br>
•&nbsp;&nbsp;Data&nbsp;processing&nbsp;instructions&nbsp;such as&nbsp;add,&nbsp;subtract&nbsp;and&nbsp;multiply.&nbsp;<br>
•&nbsp;&nbsp;Data movement&nbsp;instructions&nbsp;that copy&nbsp;data&nbsp;from&nbsp;one&nbsp;place in memory to&nbsp;another,&nbsp;<br>
or&nbsp;from&nbsp;memory&nbsp;to&nbsp;the processor's&nbsp;registers, and so&nbsp;on.&nbsp;<br>
•&nbsp;&nbsp;Control flow instructions that switch execution from&nbsp;one&nbsp;part of the program&nbsp;to&nbsp;<br>
another, possibly depending on&nbsp;data values.&nbsp;<br>
•&nbsp;&nbsp;Special&nbsp;instructions&nbsp;to&nbsp;control&nbsp;the&nbsp;processor's execution state, for&nbsp;instance&nbsp;to&nbsp;<br>
switch into&nbsp;a privileged&nbsp;mode&nbsp;to carry&nbsp;out an&nbsp;operating system&nbsp;function.&nbsp;<br>
Sometimes an instruction will&nbsp;fit into more&nbsp;than&nbsp;one of these categories. For exam-<br>
ple,&nbsp;a 'decrement&nbsp;and&nbsp;branch&nbsp;if&nbsp;non-zero'&nbsp;instruction,&nbsp;which&nbsp;is&nbsp;useful&nbsp;for&nbsp;controlling&nbsp;<br>
program&nbsp;loops,&nbsp;does&nbsp;some&nbsp;data&nbsp;processing&nbsp;on&nbsp;the&nbsp;loop&nbsp;variable&nbsp;and&nbsp;also&nbsp;performs&nbsp;a&nbsp;<br>
control&nbsp;flow&nbsp;function.&nbsp;Similarly,&nbsp;a&nbsp;data&nbsp;processing instruction&nbsp;which&nbsp;fetches an&nbsp;oper-<br>
and from&nbsp;an address in memory and places&nbsp;its&nbsp;result in&nbsp;a register can&nbsp;be viewed as per-<br>
forming a data&nbsp;movement function.&nbsp;<br>
Orthogonal&nbsp;<br>
An instruction&nbsp;set is said to&nbsp;be&nbsp;<b>orthogonal&nbsp;&nbsp;</b>if each choice in the building of an&nbsp;<br>
instructions&nbsp;<br>
instruction&nbsp;is independent of&nbsp;the other&nbsp;choices.&nbsp;Since&nbsp;add&nbsp;and&nbsp;subtract&nbsp;are&nbsp;similar&nbsp;<br>
operations, one would expect to be able to&nbsp;use them&nbsp;in similar contexts. If add uses&nbsp;<br>
a&nbsp;3-address format with register&nbsp;addresses,&nbsp;so&nbsp;should&nbsp;subtract, and&nbsp;in neither case&nbsp;<br>
should there be&nbsp;any peculiar&nbsp;restrictions&nbsp;on&nbsp;the&nbsp;registers&nbsp;which&nbsp;may&nbsp;be&nbsp;used.&nbsp;<br>
An&nbsp;orthogonal instruction set&nbsp;is easier for&nbsp;the assembly language&nbsp;programmer to&nbsp;<br>
learn and&nbsp;easier&nbsp;for the compiler&nbsp;writer to&nbsp;target. The hardware implementation&nbsp;will&nbsp;<br>
usually&nbsp;be&nbsp;more efficient too.&nbsp;<br>
<hr>
<A name=28></a><IMG src="index-28_1.png"><br>
<b>Instruction set&nbsp;design</b>&nbsp;<br>
17&nbsp;<br>
&nbsp;&nbsp;&nbsp;Addressing&nbsp;<br>
When&nbsp;accessing an&nbsp;operand&nbsp;for a&nbsp;data&nbsp;processing&nbsp;or&nbsp;movement instruction,&nbsp;there are&nbsp;<br>
modes&nbsp;<br>
several&nbsp;standard techniques used&nbsp;to specify the desired&nbsp;location. Most processors&nbsp;<br>
support several of&nbsp;these&nbsp;<b>addressing&nbsp;modes&nbsp;</b>(though&nbsp;few&nbsp;support&nbsp;all of&nbsp;them):&nbsp;<br>
1.&nbsp;&nbsp;Immediate addressing:&nbsp;the desired&nbsp;value&nbsp;is&nbsp;presented as&nbsp;a binary&nbsp;value&nbsp;in&nbsp;the&nbsp;<br>
instruction.&nbsp;<br>
2.&nbsp;&nbsp;Absolute addressing: the&nbsp;instruction contains&nbsp;the&nbsp;full binary&nbsp;address of&nbsp;the&nbsp;<br>
desired value in&nbsp;memory.&nbsp;<br>
3.&nbsp;&nbsp;Indirect&nbsp;addressing:&nbsp;the instruction&nbsp;contains the binary&nbsp;address&nbsp;of&nbsp;a&nbsp;memory&nbsp;<br>
location that contains the binary&nbsp;address of&nbsp;the desired&nbsp;value.&nbsp;<br>
4.&nbsp;&nbsp;Register&nbsp;addressing:&nbsp;the&nbsp;desired&nbsp;value&nbsp;is&nbsp;in&nbsp;a&nbsp;register,&nbsp;and&nbsp;the&nbsp;instruction&nbsp;contains&nbsp;<br>
the register&nbsp;number.&nbsp;<br>
5.&nbsp;&nbsp;Register indirect&nbsp;addressing:&nbsp;the instruction contains the&nbsp;number of a register&nbsp;<br>
which&nbsp;contains&nbsp;the&nbsp;address of&nbsp;the value in&nbsp;memory.&nbsp;<br>
6.&nbsp;&nbsp;Base plus offset addressing:&nbsp;the instruction specifies a&nbsp;register&nbsp;(the&nbsp;<b>base)&nbsp;</b>and a&nbsp;<br>
binary&nbsp;offset to be added to&nbsp;the base to&nbsp;form&nbsp;the&nbsp;memory address.&nbsp;<br>
7.&nbsp;&nbsp;Base plus&nbsp;index addressing: the instruction&nbsp;specifies a base register and&nbsp;another&nbsp;<br>
register&nbsp;(the&nbsp;<b>index)&nbsp;</b>which&nbsp;is&nbsp;added to the&nbsp;base to&nbsp;form&nbsp;the&nbsp;memory address.&nbsp;<br>
8.&nbsp;&nbsp;Base&nbsp;plus&nbsp;scaled&nbsp;index&nbsp;addressing:&nbsp;as&nbsp;above,&nbsp;but the index&nbsp;is&nbsp;multiplied&nbsp;by&nbsp;a&nbsp;con&nbsp;<br>
stant&nbsp;(usually&nbsp;the&nbsp;size&nbsp;of&nbsp;the&nbsp;data&nbsp;item,&nbsp;and usually&nbsp;a power&nbsp;of&nbsp;two)&nbsp;before&nbsp;being&nbsp;<br>
added&nbsp;to&nbsp;the base.&nbsp;<br>
9.&nbsp;&nbsp;Stack&nbsp;addressing:&nbsp;an&nbsp;implicit&nbsp;or specified register (the&nbsp;<b>stack pointer)&nbsp;</b>points&nbsp;to&nbsp;an&nbsp;<br>
area&nbsp;of&nbsp;memory&nbsp;(the&nbsp;<b>stack)&nbsp;</b>where data items&nbsp;are&nbsp;written&nbsp;<b>(pushed)&nbsp;</b>or&nbsp;read&nbsp;<br>
<b>(popped)&nbsp;</b>on a&nbsp;last-in-first-out basis.&nbsp;<br>
Note that&nbsp;the naming conventions used for&nbsp;these&nbsp;modes by different&nbsp;processor&nbsp;man-<br>
ufacturers are not necessarily as above. The list can be extended almost indefinitely by&nbsp;<br>
adding&nbsp;more levels&nbsp;of&nbsp;indirection,&nbsp;adding&nbsp;base&nbsp;plus&nbsp;index&nbsp;plus offset, and&nbsp;so&nbsp;on.&nbsp;How-<br>
ever, most of the common addressing&nbsp;modes&nbsp;are covered in&nbsp;the list&nbsp;above.&nbsp;<br>
Control&nbsp;flow&nbsp;<br>
Where the program&nbsp;must deviate from&nbsp;the&nbsp;default&nbsp;(normally&nbsp;sequential)&nbsp;instruction&nbsp;<br>
instructions&nbsp;<br>
sequence,&nbsp;a&nbsp;control&nbsp;flow&nbsp;instruction is&nbsp;used&nbsp;to&nbsp;modify&nbsp;the&nbsp;program&nbsp;counter&nbsp;(PC)&nbsp;<br>
explicitly. The&nbsp;simplest&nbsp;such instructions are usually called&nbsp;'branches'&nbsp;or&nbsp;'jumps'.&nbsp;<br>
Since&nbsp;most branches&nbsp;require a relatively short&nbsp;range, a common&nbsp;form&nbsp;is the&nbsp;<br>
'PC-relative'&nbsp;branch.&nbsp;A typical&nbsp;assembly&nbsp;language format&nbsp;is:&nbsp;<br>
&nbsp;<br>
Here the&nbsp;assembler works out&nbsp;the&nbsp;displacement which must&nbsp;be&nbsp;added&nbsp;to&nbsp;the value&nbsp;<br>
the&nbsp;PC&nbsp;has&nbsp;when&nbsp;the&nbsp;branch&nbsp;is&nbsp;executed&nbsp;in&nbsp;order to force&nbsp;the PC to point to LABEL.&nbsp;<br>
The&nbsp;maximum range&nbsp;of the branch&nbsp;is determined by&nbsp;the number of&nbsp;bits&nbsp;allocated to&nbsp;<br>
<hr>
<A name=29></a>18&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
the displacement in the binary&nbsp;format; the&nbsp;assembler&nbsp;should report&nbsp;an&nbsp;error&nbsp;if the&nbsp;<br>
required&nbsp;branch&nbsp;is out of&nbsp;range.&nbsp;<br>
Conditional&nbsp;<br>
A Digital Signal Processing&nbsp;(DSP) program&nbsp;may&nbsp;execute&nbsp;a&nbsp;fixed instruction&nbsp;<br>
branches&nbsp;<br>
sequence for ever, but a general-purpose processor is usually&nbsp;required to vary&nbsp;its&nbsp;<br>
program&nbsp;in&nbsp;response to data values.&nbsp;Some&nbsp;processors&nbsp;(including MU0)&nbsp;allow the&nbsp;<br>
values in the&nbsp;general registers to control whether or not a branch is taken through&nbsp;<br>
instructions&nbsp;such&nbsp;as:&nbsp;<br>
•&nbsp;&nbsp;Branch&nbsp;if a particular&nbsp;register&nbsp;is zero&nbsp;(or not&nbsp;zero, or negative, and&nbsp;so on).&nbsp;<br>
•&nbsp;&nbsp;Branch&nbsp;if&nbsp;two specified&nbsp;registers are equal (or not equal).&nbsp;<br>
&nbsp;&nbsp;&nbsp;Condition code&nbsp;&nbsp;However,&nbsp;the&nbsp;most frequently&nbsp;used&nbsp;mechanism&nbsp;is based&nbsp;on&nbsp;a condition code register,&nbsp;<br>
register&nbsp;<br>
which is&nbsp;a special-purpose&nbsp;register&nbsp;within&nbsp;the processor.&nbsp;Whenever&nbsp;a data process-<br>
ing instruction&nbsp;is executed&nbsp;(or possibly only for&nbsp;special&nbsp;instructions, or&nbsp;instructions&nbsp;<br>
that specifically&nbsp;enable&nbsp;the&nbsp;condition&nbsp;code&nbsp;register), the condition code register&nbsp;<br>
records whether&nbsp;the&nbsp;result&nbsp;was zero, negative, overflowed, produced&nbsp;a carry output,&nbsp;<br>
and so&nbsp;on. The conditional branch&nbsp;instructions&nbsp;are then&nbsp;controlled by&nbsp;the&nbsp;state of&nbsp;the&nbsp;<br>
condition&nbsp;code&nbsp;register when&nbsp;they&nbsp;execute.&nbsp;<br>
Subroutine&nbsp;calls&nbsp;<br>
Sometimes&nbsp;a&nbsp;branch&nbsp;is executed&nbsp;to&nbsp;call a&nbsp;subprogram&nbsp;where&nbsp;the&nbsp;instruction&nbsp;<br>
sequence should&nbsp;<b>return&nbsp;</b>to&nbsp;the calling sequence when the subprogram&nbsp;terminates.&nbsp;<br>
Since the subprogram&nbsp;may&nbsp;be called from&nbsp;many&nbsp;different places, a&nbsp;record of the&nbsp;<br>
calling&nbsp;address&nbsp;must be kept. There are&nbsp;many&nbsp;different&nbsp;ways&nbsp;to achieve this:&nbsp;<br>
•&nbsp;&nbsp;The calling&nbsp;routine could compute a&nbsp;suitable return&nbsp;address&nbsp;and put it&nbsp;in&nbsp;a stand&nbsp;<br>
ard&nbsp;memory&nbsp;location&nbsp;for use by&nbsp;the subprogram&nbsp;as a return address before exe&nbsp;<br>
cuting the&nbsp;branch.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;return address&nbsp;could be pushed onto&nbsp;a stack.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;return address&nbsp;could be placed in a&nbsp;register.&nbsp;<br>
Subprogram&nbsp;calls are&nbsp;sufficiently&nbsp;common that most architectures&nbsp;include&nbsp;specific&nbsp;<br>
instructions&nbsp;to&nbsp;make&nbsp;them&nbsp;efficient.&nbsp;They&nbsp;typically require&nbsp;to jump&nbsp;further&nbsp;across&nbsp;<br>
memory&nbsp;than&nbsp;simple branches,&nbsp;so&nbsp;it&nbsp;makes sense to&nbsp;treat&nbsp;them&nbsp;separately. Often they&nbsp;<br>
are not&nbsp;conditional; a conditional subprogram&nbsp;call&nbsp;is&nbsp;programmed, when&nbsp;required,&nbsp;by&nbsp;<br>
inserting&nbsp;an&nbsp;unconditional call and branching&nbsp;around&nbsp;it&nbsp;with&nbsp;the opposite&nbsp;condition.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Subprogram&nbsp;<br>
The return instruction&nbsp;moves the&nbsp;return address&nbsp;from&nbsp;wherever&nbsp;it&nbsp;was stored&nbsp;(in&nbsp;<br>
return&nbsp;<br>
memory,&nbsp;possibly&nbsp;on&nbsp;a&nbsp;stack, or&nbsp;in&nbsp;a&nbsp;register)&nbsp;back&nbsp;into&nbsp;the&nbsp;PC.&nbsp;<br>
System calls&nbsp;<br>
Another category&nbsp;of&nbsp;control flow instruction&nbsp;is the system&nbsp;call.&nbsp;This is a branch to&nbsp;<br>
an operating&nbsp;system&nbsp;routine,&nbsp;often&nbsp;associated&nbsp;with&nbsp;a&nbsp;change&nbsp;in&nbsp;the&nbsp;privilege level of&nbsp;<br>
the executing&nbsp;program.&nbsp;Some functions in the processor,&nbsp;possibly&nbsp;including all the&nbsp;<br>
<hr>
<A name=30></a><b>Processor design trade-offs&nbsp;</b><br>
<b>19</b>&nbsp;<br>
input and output peripherals, are&nbsp;protected&nbsp;from&nbsp;access by&nbsp;user code. Therefore a&nbsp;<br>
user&nbsp;program&nbsp;that needs to access these&nbsp;functions&nbsp;must&nbsp;make a system&nbsp;call.&nbsp;<br>
System&nbsp;calls&nbsp;pass through&nbsp;protection&nbsp;barriers&nbsp;in a controlled&nbsp;way. A well-designed&nbsp;<br>
processor&nbsp;will ensure that it&nbsp;is possible&nbsp;to&nbsp;write a&nbsp;multi-user operating system&nbsp;where&nbsp;<br>
one&nbsp;user's&nbsp;program&nbsp;is protected from&nbsp;assaults&nbsp;from&nbsp;other,&nbsp;possibly&nbsp;malicious,&nbsp;users.&nbsp;<br>
This requires&nbsp;that&nbsp;a&nbsp;malicious&nbsp;user cannot&nbsp;change the system&nbsp;code and, when&nbsp;access to&nbsp;<br>
protected functions&nbsp;is required,&nbsp;the system&nbsp;code&nbsp;must&nbsp;make thorough&nbsp;checks&nbsp;that&nbsp;the&nbsp;<br>
requested&nbsp;function&nbsp;is authorized.&nbsp;<br>
This&nbsp;is&nbsp;a complex&nbsp;area of hardware&nbsp;and&nbsp;software design.&nbsp;Most&nbsp;embedded&nbsp;systems&nbsp;<br>
(and&nbsp;many&nbsp;desktop systems) do&nbsp;not&nbsp;use&nbsp;the full&nbsp;protection capabilities of the&nbsp;hard-<br>
ware, but a processor which&nbsp;does not support a protected system&nbsp;mode will be&nbsp;<br>
excluded&nbsp;from&nbsp;consideration for&nbsp;those&nbsp;applications&nbsp;that&nbsp;demand this&nbsp;facility,&nbsp;so&nbsp;most&nbsp;<br>
microprocessors now&nbsp;include&nbsp;such&nbsp;support. Whilst it&nbsp;is&nbsp;not necessary&nbsp;to&nbsp;understand&nbsp;<br>
the&nbsp;full implications&nbsp;of&nbsp;supporting&nbsp;a secure operating&nbsp;system&nbsp;to&nbsp;appreciate&nbsp;the basic&nbsp;<br>
design of&nbsp;an&nbsp;instruction&nbsp;set, even the less&nbsp;well-informed reader should&nbsp;have an aware-<br>
ness of&nbsp;the issues since some features&nbsp;of&nbsp;commercial processor architectures&nbsp;make&nbsp;<br>
little&nbsp;sense&nbsp;unless this&nbsp;objective&nbsp;of&nbsp;potentially&nbsp;secure&nbsp;protection is&nbsp;borne&nbsp;in&nbsp;mind.&nbsp;<br>
Exceptions&nbsp;<br>
The&nbsp;final category of&nbsp;control&nbsp;flow&nbsp;instruction comprises&nbsp;cases&nbsp;where&nbsp;the change&nbsp;in&nbsp;<br>
the&nbsp;flow&nbsp;of&nbsp;control is&nbsp;not the primary&nbsp;intent of&nbsp;the programmer&nbsp;but is a consequence&nbsp;<br>
of&nbsp;some&nbsp;unexpected (and possibly&nbsp;unwanted)&nbsp;side-effect of&nbsp;the program.&nbsp;An attempt&nbsp;<br>
to&nbsp;access&nbsp;a memory location&nbsp;may fail, for&nbsp;instance,&nbsp;because a fault is detected&nbsp;in the&nbsp;<br>
memory&nbsp;subsystem.&nbsp;The program&nbsp;must&nbsp;therefore&nbsp;deviate from&nbsp;its&nbsp;planned&nbsp;course&nbsp;in&nbsp;<br>
order&nbsp;to&nbsp;attempt&nbsp;to&nbsp;recover from&nbsp;the problem.&nbsp;<br>
These&nbsp;unplanned changes&nbsp;in&nbsp;the flow&nbsp;of&nbsp;control are termed&nbsp;<b>exceptions.</b>&nbsp;<br>
1.5 &nbsp; Processor&nbsp;design&nbsp;trade-offs&nbsp;<br>
The&nbsp;art of&nbsp;processor design is to define an&nbsp;instruction&nbsp;set that supports the functions&nbsp;<br>
that&nbsp;are&nbsp;useful to&nbsp;the programmer&nbsp;whilst&nbsp;allowing&nbsp;an&nbsp;implementation&nbsp;that&nbsp;is&nbsp;as effi-<br>
cient as possible. Preferably,&nbsp;the&nbsp;same&nbsp;instruction&nbsp;set&nbsp;should&nbsp;also&nbsp;allow future, more&nbsp;<br>
sophisticated&nbsp;implementations to&nbsp;be&nbsp;equally&nbsp;efficient.&nbsp;<br>
The&nbsp;programmer generally&nbsp;wants&nbsp;to&nbsp;express&nbsp;his or&nbsp;her program&nbsp;in as&nbsp;abstract&nbsp;a&nbsp;way&nbsp;<br>
as possible, using a high-level language&nbsp;which supports&nbsp;ways of handling concepts&nbsp;<br>
that&nbsp;are&nbsp;appropriate to the problem.&nbsp;Modern trends towards functional&nbsp;and object-ori-<br>
ented languages&nbsp;move the&nbsp;level of abstraction higher than&nbsp;older imperative&nbsp;languages&nbsp;<br>
such&nbsp;as&nbsp;C,&nbsp;and&nbsp;even&nbsp;the&nbsp;older languages&nbsp;were quite a long&nbsp;way removed from&nbsp;typical&nbsp;<br>
machine&nbsp;instructions.&nbsp;<br>
The&nbsp;<b>semantic&nbsp;gap&nbsp;</b>between a&nbsp;high-level&nbsp;language&nbsp;construct&nbsp;and&nbsp;a machine&nbsp;instruc-<br>
tion is bridged&nbsp;by&nbsp;a&nbsp;<b>compiler,&nbsp;</b>which&nbsp;is a&nbsp;(usually complex)&nbsp;computer&nbsp;program&nbsp;that&nbsp;<br>
<hr>
<A name=31></a><b>20</b>&nbsp;<br>
<b>An&nbsp;Introduction&nbsp;to Processor Design</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
translates&nbsp;a high-level language&nbsp;program&nbsp;into a sequence&nbsp;of&nbsp;machine&nbsp;instructions.&nbsp;<br>
Therefore&nbsp;the processor designer&nbsp;should define&nbsp;his or her instruction set to be&nbsp;a good&nbsp;<br>
compiler target&nbsp;rather&nbsp;than&nbsp;something&nbsp;that&nbsp;the programmer&nbsp;will&nbsp;use&nbsp;directly&nbsp;to&nbsp;solve&nbsp;<br>
the&nbsp;problem&nbsp;by&nbsp;hand. So, what sort&nbsp;of&nbsp;instruction set&nbsp;makes a&nbsp;good compiler&nbsp;target?&nbsp;<br>
Complex&nbsp;<br>
Prior to 1980, the principal&nbsp;trend&nbsp;in instruction set design&nbsp;was&nbsp;towards increasing&nbsp;<br>
Instruction Set&nbsp;<br>
complexity in an&nbsp;attempt to&nbsp;reduce&nbsp;the&nbsp;semantic&nbsp;gap that&nbsp;the&nbsp;compiler had to&nbsp;bridge.&nbsp;<br>
Computers&nbsp;<br>
Single&nbsp;instruction&nbsp;procedure&nbsp;entries and&nbsp;exits&nbsp;were&nbsp;incorporated&nbsp;into&nbsp;the&nbsp;instruction&nbsp;<br>
set,&nbsp;each&nbsp;performing a&nbsp;complex&nbsp;sequence&nbsp;of operations&nbsp;over&nbsp;many&nbsp;clock cycles.&nbsp;<br>
Processors were sold&nbsp;on&nbsp;the sophistication&nbsp;and&nbsp;number&nbsp;of their addressing&nbsp;modes,&nbsp;<br>
data&nbsp;types, and so&nbsp;on.&nbsp;<br>
The&nbsp;origins&nbsp;of&nbsp;this&nbsp;trend were in&nbsp;the&nbsp;minicomputers&nbsp;developed&nbsp;during&nbsp;the&nbsp;1970s.&nbsp;<br>
These&nbsp;computers had relatively&nbsp;slow main memories coupled to&nbsp;processors&nbsp;built&nbsp;using&nbsp;<br>
many simple integrated&nbsp;circuits. The processors were controlled&nbsp;by&nbsp;microcode ROMs&nbsp;<br>
(Read Only Memories) that&nbsp;were faster than&nbsp;main&nbsp;memory, so it made sense to&nbsp;imple-<br>
ment frequently&nbsp;used&nbsp;operations&nbsp;as&nbsp;microcode&nbsp;sequences&nbsp;rather&nbsp;than&nbsp;them&nbsp;requiring&nbsp;<br>
several&nbsp;instructions&nbsp;to&nbsp;be&nbsp;fetched from&nbsp;main memory.&nbsp;<br>
Throughout the 1970s microprocessors were&nbsp;advancing in their capabilities. These&nbsp;<br>
single&nbsp;chip&nbsp;processors&nbsp;were&nbsp;dependent on&nbsp;state-of-the-art semiconductor&nbsp;technology&nbsp;<br>
to&nbsp;achieve&nbsp;the&nbsp;highest&nbsp;possible number of transistors on&nbsp;a single&nbsp;chip,&nbsp;so&nbsp;their&nbsp;develop-<br>
ment&nbsp;took&nbsp;place&nbsp;within&nbsp;the&nbsp;semiconductor&nbsp;industry&nbsp;rather&nbsp;than&nbsp;within&nbsp;the&nbsp;computer&nbsp;<br>
industry. As a&nbsp;result, microprocessor designs displayed a&nbsp;lack of&nbsp;original thought at&nbsp;<br>
the&nbsp;architectural&nbsp;level,&nbsp;particularly&nbsp;with respect to&nbsp;the&nbsp;demands&nbsp;of the technology&nbsp;that&nbsp;<br>
was&nbsp;used&nbsp;in&nbsp;their&nbsp;implementation.&nbsp;Their&nbsp;designers,&nbsp;at&nbsp;best,&nbsp;took&nbsp;ideas from&nbsp;the&nbsp;mini-<br>
computer industry&nbsp;where the&nbsp;implementation&nbsp;technology&nbsp;was very&nbsp;different.&nbsp;In&nbsp;partic-<br>
ular,&nbsp;the microcode ROM which was&nbsp;needed&nbsp;for all&nbsp;the complex routines&nbsp;absorbed an&nbsp;<br>
unreasonable&nbsp;proportion&nbsp;of the area&nbsp;of a single chip, leaving&nbsp;little room&nbsp;for other&nbsp;per-<br>
formance-enhancing features.&nbsp;<br>
This&nbsp;approach&nbsp;led&nbsp;to&nbsp;the&nbsp;single-chip&nbsp;Complex&nbsp;Instruction&nbsp;Set&nbsp;Computers&nbsp;(CISCs)&nbsp;<br>
of the&nbsp;late&nbsp;1970s, which were&nbsp;microprocessors with&nbsp;minicomputer instruction sets that&nbsp;<br>
were severely&nbsp;compromised by&nbsp;the&nbsp;limited available&nbsp;silicon resource.&nbsp;<br>
The RISC&nbsp;<br>
Into&nbsp;this&nbsp;world of&nbsp;increasingly complex&nbsp;instruction&nbsp;sets&nbsp;the&nbsp;Reduced&nbsp;Instruction&nbsp;Set&nbsp;<br>
revolution&nbsp;<br>
Computer&nbsp;<b>(RISC)&nbsp;</b>was&nbsp;born.&nbsp;The RISC concept was&nbsp;a major influence&nbsp;on the&nbsp;design&nbsp;<br>
of the ARM processor; indeed,&nbsp;RISC&nbsp;was the ARM's&nbsp;middle name. But before&nbsp;we&nbsp;<br>
look at either&nbsp;RISC or&nbsp;the&nbsp;ARM in&nbsp;more detail&nbsp;we need&nbsp;a bit&nbsp;more background on&nbsp;<br>
what processors do&nbsp;and how they&nbsp;can&nbsp;be&nbsp;designed&nbsp;to&nbsp;do&nbsp;it quickly.&nbsp;<br>
If&nbsp;reducing&nbsp;the&nbsp;semantic gap between the&nbsp;processor instruction set and the&nbsp;<br>
high-level&nbsp;language&nbsp;is&nbsp;not the&nbsp;right&nbsp;way&nbsp;to&nbsp;make an&nbsp;efficient computer,&nbsp;what&nbsp;other&nbsp;<br>
options are open&nbsp;to&nbsp;the&nbsp;designer?&nbsp;<br>
<hr>
<A name=32></a><IMG src="index-32_1.png"><br>
<b>Processor design trade-offs</b>&nbsp;<br>
<b>21</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;What processors&nbsp;&nbsp;If&nbsp;we&nbsp;want to&nbsp;make a processor go fast,&nbsp;we&nbsp;must first understand&nbsp;what&nbsp;it spends its&nbsp;<br>
do&nbsp;<br>
time doing.&nbsp;It&nbsp;is a common&nbsp;misconception that computers spend their time&nbsp;comput-<br>
ing, that is,&nbsp;carrying out arithmetic operations on&nbsp;user&nbsp;data. In&nbsp;practice&nbsp;they&nbsp;spend&nbsp;<br>
very&nbsp;little&nbsp;time&nbsp;'computing'&nbsp;in&nbsp;this sense.&nbsp;Although they do a fair amount of arith-<br>
metic,&nbsp;most of&nbsp;this is&nbsp;with addresses in order to locate&nbsp;the relevant data items&nbsp;and&nbsp;<br>
program&nbsp;routines. Then,&nbsp;having&nbsp;found&nbsp;the user's&nbsp;data, most&nbsp;of&nbsp;the work&nbsp;is in&nbsp;moving&nbsp;<br>
it around&nbsp;rather than&nbsp;processing it&nbsp;in any transformational&nbsp;sense.&nbsp;<br>
At the&nbsp;instruction set level,&nbsp;it&nbsp;is&nbsp;possible&nbsp;to measure the frequency&nbsp;of use&nbsp;of the&nbsp;var-<br>
ious different&nbsp;instructions.&nbsp;It&nbsp;is&nbsp;very important&nbsp;to&nbsp;obtain&nbsp;dynamic&nbsp;measurements, that&nbsp;<br>
is,&nbsp;to&nbsp;measure&nbsp;the frequency&nbsp;of&nbsp;instructions that&nbsp;are&nbsp;executed,&nbsp;rather&nbsp;than&nbsp;the static&nbsp;<br>
frequency,&nbsp;which is just a count of the various instruction types in the&nbsp;binary&nbsp;image. A&nbsp;<br>
typical set&nbsp;of statistics is&nbsp;shown in&nbsp;Table&nbsp;1.3;&nbsp;these statistics were&nbsp;gathered running&nbsp;a&nbsp;<br>
print preview&nbsp;program&nbsp;on&nbsp;an&nbsp;ARM&nbsp;instruction emulator,&nbsp;but are broadly typical of&nbsp;<br>
what may&nbsp;be expected&nbsp;from&nbsp;other&nbsp;programs and&nbsp;instruction sets.&nbsp;<br>
<b>Table&nbsp;1.3 &nbsp; &nbsp;</b>Typical dynamic instruction usage.<br>
&nbsp;<br>
These sample statistics suggest&nbsp;that&nbsp;the most&nbsp;important&nbsp;instructions to&nbsp;optimise are&nbsp;<br>
those concerned&nbsp;with&nbsp;data&nbsp;movement,&nbsp;either between&nbsp;the processor registers and&nbsp;<br>
memory or from&nbsp;register&nbsp;to&nbsp;register.&nbsp;These&nbsp;account&nbsp;for&nbsp;almost half&nbsp;of&nbsp;all&nbsp;instructions&nbsp;<br>
executed. Second most frequent are&nbsp;the control flow instructions such&nbsp;as&nbsp;branches and&nbsp;<br>
procedure calls, which account&nbsp;for another quarter. Arithmetic operations are down at&nbsp;<br>
15%, as are comparisons.&nbsp;<br>
Now&nbsp;we have&nbsp;a feel&nbsp;for&nbsp;what&nbsp;processors&nbsp;spend their time&nbsp;doing, we can&nbsp;look at&nbsp;<br>
ways&nbsp;of&nbsp;making&nbsp;them&nbsp;go&nbsp;faster. The most important&nbsp;of these is pipelining.&nbsp;<br>
Another important&nbsp;technique is the use of&nbsp;a cache memory, which will&nbsp;be&nbsp;cov-<br>
ered in&nbsp;Section 10.3 on page 272. A third technique, super-scalar instruction exe-<br>
cution, is very&nbsp;complex, has not&nbsp;been&nbsp;used on&nbsp;ARM processors and is&nbsp;not&nbsp;<br>
covered in&nbsp;this&nbsp;book.&nbsp;<br>
<hr>
<A name=33></a><IMG src="index-33_1.png"><br>
<b>Processor design&nbsp;trade-offs</b>&nbsp;<br>
21&nbsp;<br>
&nbsp;&nbsp;&nbsp;What processors&nbsp;&nbsp;If&nbsp;we&nbsp;want to&nbsp;make a processor go fast,&nbsp;we&nbsp;must first understand&nbsp;what&nbsp;it spends its&nbsp;<br>
do&nbsp;<br>
time doing.&nbsp;It&nbsp;is a common&nbsp;misconception that computers spend their time&nbsp;comput-<br>
ing, that is, carrying out arithmetic operations on user data. In practice&nbsp;they&nbsp;spend&nbsp;<br>
very&nbsp;little&nbsp;time&nbsp;'computing'&nbsp;in&nbsp;this sense.&nbsp;Although they do a fair amount of arith-<br>
metic,&nbsp;most&nbsp;of this is with addresses in&nbsp;order to&nbsp;locate the relevant&nbsp;data&nbsp;items&nbsp;and&nbsp;<br>
program&nbsp;routines. Then,&nbsp;having&nbsp;found&nbsp;the user's&nbsp;data, most&nbsp;of&nbsp;the work&nbsp;is in&nbsp;moving&nbsp;<br>
it around&nbsp;rather than&nbsp;processing it&nbsp;in any transformational&nbsp;sense.&nbsp;<br>
At the&nbsp;instruction set level,&nbsp;it&nbsp;is&nbsp;possible&nbsp;to measure the frequency of use&nbsp;of the&nbsp;var-<br>
ious&nbsp;different&nbsp;instructions.&nbsp;It&nbsp;is&nbsp;very&nbsp;important&nbsp;to&nbsp;obtain&nbsp;dynamic measurements,&nbsp;that&nbsp;<br>
is, to&nbsp;measure&nbsp;the frequency&nbsp;of instructions that are executed, rather&nbsp;than&nbsp;the static&nbsp;<br>
frequency,&nbsp;which is just a count of the various instruction types in the&nbsp;binary&nbsp;image. A&nbsp;<br>
typical set&nbsp;of statistics is&nbsp;shown in&nbsp;Table&nbsp;1.3;&nbsp;these statistics were&nbsp;gathered running&nbsp;a&nbsp;<br>
print preview&nbsp;program&nbsp;on&nbsp;an&nbsp;ARM&nbsp;instruction emulator,&nbsp;but are broadly typical of&nbsp;<br>
what&nbsp;may&nbsp;be&nbsp;expected&nbsp;from&nbsp;other&nbsp;programs&nbsp;and&nbsp;instruction&nbsp;sets.&nbsp;<br>
<b>Table&nbsp;1.3 &nbsp;&nbsp;&nbsp;</b>Typical&nbsp;dynamic instruction usage.<br>
&nbsp;<br>
These&nbsp;sample&nbsp;statistics&nbsp;suggest&nbsp;that&nbsp;the&nbsp;most&nbsp;important&nbsp;instructions&nbsp;to&nbsp;optimise are&nbsp;<br>
those&nbsp;concerned with data&nbsp;movement, either between&nbsp;the processor&nbsp;registers and&nbsp;<br>
memory or from&nbsp;register to&nbsp;register. These&nbsp;account for almost half&nbsp;of all instructions&nbsp;<br>
executed.&nbsp;Second most frequent&nbsp;are the&nbsp;control flow instructions&nbsp;such&nbsp;as&nbsp;branches&nbsp;and&nbsp;<br>
procedure&nbsp;calls,&nbsp;which&nbsp;account&nbsp;for another quarter.&nbsp;Arithmetic&nbsp;operations are down at&nbsp;<br>
15%, as are comparisons.&nbsp;<br>
Now&nbsp;we have&nbsp;a feel for what&nbsp;processors spend their time&nbsp;doing, we can look at&nbsp;<br>
ways&nbsp;of&nbsp;making&nbsp;them&nbsp;go&nbsp;faster. The most important&nbsp;of these is pipelining.&nbsp;<br>
Another important&nbsp;technique is the use&nbsp;of&nbsp;a cache memory, which will&nbsp;be&nbsp;cov-<br>
ered in&nbsp;Section 10.3 on page 272. A third technique, super-scalar instruction exe-<br>
cution, is very&nbsp;complex, has not&nbsp;been&nbsp;used on&nbsp;ARM processors and is&nbsp;not&nbsp;<br>
covered in&nbsp;this&nbsp;book.&nbsp;<br>
<hr>
<A name=34></a><IMG src="index-34_1.png"><br>
<b>22</b>&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Pipelines&nbsp;<br>
A processor executes an individual instruction in a sequence of steps. A typical&nbsp;<br>
sequence might&nbsp;be:&nbsp;<br>
1.&nbsp;&nbsp;Fetch&nbsp;the instruction&nbsp;from&nbsp;memory&nbsp;(fetch).&nbsp;<br>
2.&nbsp;&nbsp;Decode&nbsp;it to&nbsp;see what&nbsp;sort&nbsp;of&nbsp;instruction it&nbsp;is&nbsp;(dec).&nbsp;<br>
3.&nbsp;&nbsp;Access any&nbsp;operands that&nbsp;may&nbsp;be required from&nbsp;the register bank&nbsp;(reg).&nbsp;<br>
4.&nbsp;&nbsp;Combine the&nbsp;operands&nbsp;to form&nbsp;the result&nbsp;or a memory&nbsp;address (ALU).&nbsp;<br>
5.&nbsp;&nbsp;Access&nbsp;memory&nbsp;for a data operand,&nbsp;if&nbsp;necessary&nbsp;(mem).&nbsp;<br>
6.&nbsp;&nbsp;Write the&nbsp;result&nbsp;back to&nbsp;the&nbsp;register&nbsp;bank&nbsp;(res).&nbsp;<br>
Not&nbsp;all&nbsp;instructions will&nbsp;require every&nbsp;step,&nbsp;but&nbsp;most&nbsp;instructions&nbsp;will&nbsp;require most&nbsp;<br>
of&nbsp;them. These steps tend&nbsp;to&nbsp;use&nbsp;different hardware&nbsp;functions, for instance&nbsp;the&nbsp;ALU is&nbsp;<br>
probably&nbsp;only&nbsp;used in&nbsp;step 4.&nbsp;Therefore,&nbsp;if an&nbsp;instruction does not start before its pred-<br>
ecessor&nbsp;has&nbsp;finished,&nbsp;only&nbsp;a&nbsp;small&nbsp;proportion&nbsp;of&nbsp;the&nbsp;processor&nbsp;hardware&nbsp;will&nbsp;be&nbsp;in&nbsp;use&nbsp;<br>
in any step.&nbsp;<br>
An&nbsp;obvious&nbsp;way&nbsp;to improve the utilization&nbsp;of&nbsp;the hardware&nbsp;resources, and also&nbsp;the&nbsp;<br>
processor throughput, would&nbsp;be&nbsp;to start the next&nbsp;instruction&nbsp;before the&nbsp;current&nbsp;one&nbsp;has&nbsp;<br>
finished. This technique is called&nbsp;<b>pipelining,&nbsp;</b>and is a very effective way&nbsp;of exploiting&nbsp;<br>
concurrency&nbsp;in&nbsp;a general-purpose&nbsp;processor.&nbsp;<br>
Taking&nbsp;the&nbsp;above sequence&nbsp;of&nbsp;operations,&nbsp;the&nbsp;processor is organized so&nbsp;that&nbsp;as soon&nbsp;<br>
as one&nbsp;instruction&nbsp;has&nbsp;completed step&nbsp;1 and&nbsp;moved on&nbsp;to&nbsp;step&nbsp;2,&nbsp;the&nbsp;next&nbsp;instruction&nbsp;<br>
begins&nbsp;step 1.&nbsp;This is&nbsp;illustrated in&nbsp;Figure&nbsp;1.13. In&nbsp;principle such&nbsp;a pipeline should&nbsp;<br>
deliver&nbsp;a&nbsp;six&nbsp;times speed-up&nbsp;compared&nbsp;with&nbsp;non-overlapped&nbsp;instruction&nbsp;execution;&nbsp;in&nbsp;<br>
practice things do not&nbsp;work&nbsp;out&nbsp;quite&nbsp;so well for reasons we&nbsp;will see below.&nbsp;<br>
Pipeline hazards&nbsp;<br>
It is relatively&nbsp;frequent in typical computer programs that the result&nbsp;from&nbsp;one&nbsp;<br>
instruction is used&nbsp;as an&nbsp;operand by&nbsp;the next&nbsp;instruction.&nbsp;When&nbsp;this&nbsp;occurs the pipe-<br>
line&nbsp;operation&nbsp;shown in Figure 1.13&nbsp;breaks&nbsp;down,&nbsp;since&nbsp;the&nbsp;result&nbsp;of&nbsp;instruction&nbsp;1 is&nbsp;<br>
not available&nbsp;at&nbsp;the&nbsp;time&nbsp;that&nbsp;instruction&nbsp;2&nbsp;collects its operands. Instruction 2&nbsp;must&nbsp;<br>
therefore&nbsp;stall&nbsp;until&nbsp;the&nbsp;result&nbsp;is&nbsp;available,&nbsp;giving&nbsp;the&nbsp;behaviour&nbsp;shown in&nbsp;Figure&nbsp;1.14&nbsp;<br>
on&nbsp;page&nbsp;23.&nbsp;This&nbsp;is&nbsp;a&nbsp;<b>read-after-write&nbsp;</b>pipeline&nbsp;hazard.&nbsp;<br>
&nbsp;<br>
<b>Figure 1.13&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Pipelined&nbsp;instruction execution.&nbsp;<br>
<hr>
<A name=35></a><IMG src="index-35_1.png"><br>
<IMG src="index-35_2.png"><br>
<b>Processor&nbsp;design&nbsp;trade-offs</b>&nbsp;<br>
<b>23</b>&nbsp;<br>
Branch instructions result&nbsp;in&nbsp;even&nbsp;worse&nbsp;pipeline behaviour&nbsp;since the fetch step of&nbsp;<br>
the following instruction is affected by&nbsp;the branch target&nbsp;computation and must there-<br>
fore&nbsp;be&nbsp;deferred.&nbsp;Unfortunately, subsequent fetches&nbsp;will be&nbsp;taking&nbsp;place while the&nbsp;<br>
branch&nbsp;is&nbsp;being decoded and before it&nbsp;has been recognized as a&nbsp;branch,&nbsp;so&nbsp;the&nbsp;fetched&nbsp;<br>
instructions&nbsp;may&nbsp;have to&nbsp;be discarded. If, for example,&nbsp;the branch target&nbsp;calculation is&nbsp;<br>
performed&nbsp;in&nbsp;the ALU stage&nbsp;of the pipeline&nbsp;in&nbsp;Figure 1.13,&nbsp;three&nbsp;instructions will&nbsp;have&nbsp;<br>
been fetched&nbsp;from&nbsp;the old stream&nbsp;before&nbsp;the&nbsp;branch&nbsp;target&nbsp;is&nbsp;available&nbsp;(see&nbsp;<br>
Figure 1.15). It&nbsp;is&nbsp;better&nbsp;to&nbsp;compute&nbsp;the branch&nbsp;target&nbsp;earlier&nbsp;in&nbsp;the pipeline if possible,&nbsp;<br>
even though this&nbsp;will&nbsp;probably&nbsp;require dedicated hardware.&nbsp;If branch instructions have&nbsp;<br>
a fixed format,&nbsp;the target&nbsp;may be computed&nbsp;<b>speculatively&nbsp;</b>(that is,&nbsp;before it has been&nbsp;<br>
determined that the instruction&nbsp;<i>is a&nbsp;</i>branch)&nbsp;during the 'dec' stage, thereby reducing&nbsp;<br>
the&nbsp;branch latency&nbsp;to&nbsp;a&nbsp;single cycle,&nbsp;though&nbsp;note that&nbsp;in&nbsp;this&nbsp;pipeline there may&nbsp;still&nbsp;be&nbsp;<br>
hazards on&nbsp;a&nbsp;conditional branch due&nbsp;to dependencies&nbsp;on the condition code result&nbsp;of&nbsp;<br>
the instruction preceding the&nbsp;branch.&nbsp;Some&nbsp;RISC architectures (though not the ARM)&nbsp;<br>
<b>Figure 1.14&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Read-after-write&nbsp;pipeline hazard.<br>
<b>Figure&nbsp;1.15 &nbsp;&nbsp;</b>Pipelined branch behaviour.<br>
<hr>
<A name=36></a><b>24&nbsp;</b><br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
define&nbsp;that&nbsp;the instruction&nbsp;following the branch is&nbsp;executed whether&nbsp;or not the&nbsp;branch&nbsp;<br>
is taken. This technique&nbsp;is known as the&nbsp;<b>delayed branch.</b>&nbsp;<br>
Pipeline&nbsp;<br>
Though there are techniques which reduce the impact of these pipeline problems,&nbsp;<br>
efficiency&nbsp;<br>
they&nbsp;cannot remove the difficulties altogether.&nbsp;The deeper the pipeline (that is, the&nbsp;<br>
more pipeline&nbsp;stages&nbsp;there are),&nbsp;the&nbsp;worse&nbsp;the problems get.&nbsp;For&nbsp;reasonably simple&nbsp;<br>
processors, there are&nbsp;significant benefits in introducing pipelines&nbsp;from&nbsp;three to five&nbsp;<br>
stages long, but beyond this the law of&nbsp;diminishing returns begins&nbsp;to apply&nbsp;and the&nbsp;<br>
added costs&nbsp;and complexity&nbsp;outweigh the&nbsp;benefits.&nbsp;<br>
Pipelines clearly benefit from&nbsp;all&nbsp;instructions&nbsp;going&nbsp;through a similar sequence&nbsp;of&nbsp;<br>
steps. Processors with&nbsp;very&nbsp;complex instructions&nbsp;where&nbsp;every instruction&nbsp;behaves&nbsp;dif-<br>
ferently&nbsp;from&nbsp;the&nbsp;next&nbsp;are&nbsp;hard&nbsp;to&nbsp;pipeline.&nbsp;In&nbsp;1980&nbsp;the&nbsp;complex&nbsp;instruction&nbsp;set&nbsp;micro-<br>
processor of&nbsp;the day&nbsp;was not&nbsp;pipelined&nbsp;due&nbsp;to&nbsp;the limited&nbsp;silicon&nbsp;resource,&nbsp;the&nbsp;limited&nbsp;<br>
design resource and the high complexity&nbsp;of designing&nbsp;a pipeline for a complex&nbsp;<br>
instruction set.&nbsp;<br>
1.6 &nbsp; The&nbsp;Reduced&nbsp;Instruction&nbsp;Set&nbsp;Computer&nbsp;<br>
In 1980&nbsp;Patterson and&nbsp;Ditzel&nbsp;published a paper entitled&nbsp;'The Case&nbsp;for the Reduced&nbsp;<br>
Instruction Set Computer'&nbsp;(a full&nbsp;reference&nbsp;is&nbsp;given&nbsp;in&nbsp;the&nbsp;bibliography&nbsp;on&nbsp;<br>
page 410).&nbsp;In this&nbsp;seminal&nbsp;work they expounded the view that the optimal architec-<br>
ture for a single-chip processor need not&nbsp;be&nbsp;the same&nbsp;as the optimal architecture for&nbsp;<br>
a&nbsp;multi-chip&nbsp;processor. Their&nbsp;argument&nbsp;was&nbsp;subsequently&nbsp;supported by&nbsp;the results of&nbsp;<br>
a processor design&nbsp;project undertaken&nbsp;by&nbsp;a&nbsp;postgraduate&nbsp;class&nbsp;at&nbsp;Berkeley which&nbsp;<br>
incorporated&nbsp;a Reduced&nbsp;Instruction&nbsp;Set&nbsp;Computer&nbsp;(RISC)&nbsp;architecture.&nbsp;This&nbsp;design,&nbsp;<br>
the Berkeley RISC I,&nbsp;was&nbsp;much simpler&nbsp;than the commercial CISC&nbsp;processors of&nbsp;<br>
the day&nbsp;and had taken an order of&nbsp;magnitude&nbsp;less design effort&nbsp;to develop, but nev-<br>
ertheless delivered&nbsp;a very&nbsp;similar performance.&nbsp;<br>
The RISC&nbsp;I&nbsp;instruction set&nbsp;differed from&nbsp;the minicomputer-like CISC instruction&nbsp;<br>
sets&nbsp;used&nbsp;on commercial&nbsp;microprocessors&nbsp;in&nbsp;a number of&nbsp;ways.&nbsp;It had&nbsp;the following&nbsp;<br>
key features:&nbsp;<br>
RISC&nbsp;<br>
•&nbsp;&nbsp;A fixed (32-bit)&nbsp;instruction&nbsp;size&nbsp;with&nbsp;few&nbsp;formats;&nbsp;CISC&nbsp;processors&nbsp;typically&nbsp;had&nbsp;<br>
architecture&nbsp;<br>
variable&nbsp;length&nbsp;instruction&nbsp;sets&nbsp;with&nbsp;many&nbsp;formats.&nbsp;<br>
•&nbsp;&nbsp;A load-store&nbsp;architecture where instructions&nbsp;that&nbsp;process data&nbsp;operate only&nbsp;on&nbsp;<br>
registers&nbsp;and are separate&nbsp;from&nbsp;instructions&nbsp;that access memory;&nbsp;CISC&nbsp;processors&nbsp;<br>
typically&nbsp;allowed values in&nbsp;memory&nbsp;to be&nbsp;used&nbsp;as operands&nbsp;in&nbsp;data&nbsp;processing&nbsp;<br>
instructions.&nbsp;<br>
<hr>
<A name=37></a><b>The Reduced Instruction&nbsp;Set&nbsp;Computer</b>&nbsp;<br>
<b>25</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
•&nbsp;&nbsp;A large&nbsp;register&nbsp;bank&nbsp;of&nbsp;thirty-two&nbsp;32-bit&nbsp;registers, all&nbsp;of&nbsp;which could&nbsp;be&nbsp;used for&nbsp;<br>
any purpose,&nbsp;to&nbsp;allow&nbsp;the&nbsp;load-store&nbsp;architecture to&nbsp;operate&nbsp;efficiently;&nbsp;CISC&nbsp;<br>
register sets were getting larger, but&nbsp;none&nbsp;was this large&nbsp;and most had different&nbsp;<br>
registers&nbsp;for different purposes&nbsp;(for example, the&nbsp;<i>data&nbsp;</i>and&nbsp;<i>address&nbsp;</i>registers on&nbsp;the&nbsp;<br>
Motorola MC68000).&nbsp;<br>
These&nbsp;differences&nbsp;greatly&nbsp;simplified&nbsp;the&nbsp;design&nbsp;of&nbsp;the&nbsp;processor&nbsp;and allowed&nbsp;the&nbsp;<br>
designers to&nbsp;implement the&nbsp;architecture&nbsp;using&nbsp;organizational features&nbsp;that&nbsp;contributed&nbsp;<br>
to&nbsp;the&nbsp;performance of&nbsp;the prototype devices:&nbsp;<br>
<b>RISC</b>&nbsp;<br>
•&nbsp;&nbsp;Hard-wired instruction decode&nbsp;logic;&nbsp;CISC&nbsp;processors used&nbsp;large&nbsp;microcode&nbsp;<br>
organization&nbsp;<br>
ROMs to&nbsp;decode&nbsp;their&nbsp;instructions.&nbsp;<br>
•&nbsp;&nbsp;Pipelined&nbsp;execution; CISC processors allowed little,&nbsp;if&nbsp;any,&nbsp;overlap between con&nbsp;<br>
secutive instructions&nbsp;(though&nbsp;they&nbsp;do now).&nbsp;<br>
•&nbsp;&nbsp;Single-cycle&nbsp;execution; CISC&nbsp;processors&nbsp;typically took&nbsp;many clock cycles&nbsp;to&nbsp;<br>
complete&nbsp;a&nbsp;single instruction.&nbsp;<br>
By&nbsp;incorporating all these architectural and organizational changes at&nbsp;once, the&nbsp;<br>
Berkeley&nbsp;RISC&nbsp;microprocessor&nbsp;effectively escaped from&nbsp;the problem&nbsp;that haunts&nbsp;<br>
progress by&nbsp;incremental&nbsp;improvement,&nbsp;which is&nbsp;the&nbsp;risk&nbsp;of&nbsp;getting&nbsp;stuck&nbsp;in&nbsp;a&nbsp;local&nbsp;<br>
maximum&nbsp;of&nbsp;the performance function.&nbsp;<br>
RISC&nbsp;<br>
Patterson&nbsp;and&nbsp;Ditzel&nbsp;argued&nbsp;that&nbsp;RISC&nbsp;offered three&nbsp;principal&nbsp;advantages:&nbsp;<br>
advantages&nbsp;<br>
•&nbsp;&nbsp;A smaller&nbsp;die size.&nbsp;<br>
A simple processor should require&nbsp;fewer transistors and less&nbsp;silicon area. There-<br>
fore a&nbsp;whole&nbsp;CPU will&nbsp;fit&nbsp;on a chip at&nbsp;an earlier&nbsp;stage in process technol-<br>
ogy&nbsp;development,&nbsp;and once the&nbsp;technology&nbsp;has&nbsp;developed beyond&nbsp;the&nbsp;point&nbsp;<br>
where either CPU&nbsp;will&nbsp;fit on&nbsp;a&nbsp;chip, a RISC&nbsp;CPU&nbsp;leaves&nbsp;more&nbsp;die area&nbsp;free&nbsp;for&nbsp;<br>
performance-enhancing features&nbsp;such&nbsp;as&nbsp;cache&nbsp;memory,&nbsp;memory&nbsp;management&nbsp;<br>
functions,&nbsp;floating-point hardware, and&nbsp;so on.&nbsp;<br>
•&nbsp;&nbsp;A shorter development&nbsp;time.&nbsp;<br>
A&nbsp;simple processor should take&nbsp;less design effort and therefore have a lower design&nbsp;<br>
cost and be better&nbsp;matched to the process technology&nbsp;when it is launched (since proc-<br>
ess technology&nbsp;developments need be predicted over a shorter development period).&nbsp;<br>
•&nbsp;A&nbsp;higher&nbsp;performance.&nbsp;<br>
This is&nbsp;the&nbsp;tricky one!&nbsp;The previous&nbsp;two advantages&nbsp;are easy to accept,&nbsp;but in&nbsp;a&nbsp;<br>
world&nbsp;where higher performance had&nbsp;been&nbsp;sought&nbsp;through&nbsp;ever-increasing&nbsp;com-<br>
plexity, this&nbsp;was a&nbsp;bit hard to&nbsp;swallow.&nbsp;<br>
The argument goes&nbsp;something like this: smaller things have&nbsp;higher&nbsp;natural fre-<br>
quencies (insects flap their&nbsp;wings faster&nbsp;than&nbsp;small birds,&nbsp;small birds faster than&nbsp;<br>
<hr>
<A name=38></a><b>26</b>&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
large birds, and&nbsp;so&nbsp;on)&nbsp;so&nbsp;a simple&nbsp;processor ought to&nbsp;allow&nbsp;a high&nbsp;clock&nbsp;rate.&nbsp;So&nbsp;<br>
let's design&nbsp;our complex&nbsp;processor by&nbsp;starting with a&nbsp;simple one, then&nbsp;add com-<br>
plex instructions one at&nbsp;a time. When&nbsp;we add a complex&nbsp;instruction it&nbsp;will&nbsp;make&nbsp;<br>
some&nbsp;high-level function&nbsp;more&nbsp;efficient,&nbsp;but&nbsp;it&nbsp;will&nbsp;also&nbsp;slow&nbsp;the&nbsp;clock&nbsp;down&nbsp;a&nbsp;bit&nbsp;<br>
for all instructions.&nbsp;We can measure the overall&nbsp;benefit on&nbsp;typical programs,&nbsp;and&nbsp;<br>
when we do, all complex instructions&nbsp;make the program&nbsp;run slower.&nbsp;Hence we&nbsp;<br>
stick to&nbsp;the&nbsp;simple processor&nbsp;we&nbsp;started&nbsp;with.&nbsp;<br>
These&nbsp;arguments were backed&nbsp;up&nbsp;by&nbsp;experimental&nbsp;results&nbsp;and the&nbsp;prototype&nbsp;proces-<br>
sors (the&nbsp;Berkeley&nbsp;RISC&nbsp;II&nbsp;came shortly&nbsp;after&nbsp;RISC&nbsp;I).&nbsp;The&nbsp;commercial&nbsp;processor&nbsp;<br>
companies were&nbsp;sceptical at&nbsp;first,&nbsp;but&nbsp;most&nbsp;new companies designing&nbsp;processors for&nbsp;<br>
their&nbsp;own&nbsp;purposes&nbsp;saw an&nbsp;opportunity&nbsp;to&nbsp;reduce&nbsp;development costs&nbsp;and get&nbsp;ahead&nbsp;of&nbsp;<br>
the game.&nbsp;These&nbsp;commercial&nbsp;RISC designs,&nbsp;of which&nbsp;the ARM was&nbsp;the first, showed&nbsp;<br>
that&nbsp;the idea worked, and since 1980&nbsp;all new&nbsp;general-purpose processor architectures&nbsp;<br>
have&nbsp;embraced&nbsp;the concepts&nbsp;of&nbsp;the RISC to&nbsp;a&nbsp;greater or lesser&nbsp;degree.&nbsp;<br>
RISC&nbsp;in&nbsp;<br>
Since the RISC&nbsp;is now&nbsp;well established in commercial use it is possible to look back and&nbsp;<br>
retrospect&nbsp;<br>
see&nbsp;more&nbsp;clearly&nbsp;what its contribution to the&nbsp;evolution&nbsp;of&nbsp;the microprocessor really&nbsp;was.&nbsp;<br>
Early&nbsp;RISCs achieved&nbsp;their&nbsp;performance through:&nbsp;<br>
•&nbsp;Pipelining.&nbsp;<br>
Pipelining is the simplest&nbsp;form&nbsp;of&nbsp;concurrency to implement in a processor and&nbsp;<br>
delivers around two&nbsp;to three&nbsp;times&nbsp;speed-up.&nbsp;A&nbsp;simple instruction&nbsp;set greatly&nbsp;sim-<br>
plifies the&nbsp;design&nbsp;of&nbsp;the&nbsp;pipeline.&nbsp;<br>
•&nbsp;&nbsp;A high&nbsp;clock rate with&nbsp;single-cycle&nbsp;execution.&nbsp;<br>
In 1980 standard&nbsp;semiconductor&nbsp;memories&nbsp;(DRAMs&nbsp;-&nbsp;Dynamic&nbsp;Random&nbsp;Access&nbsp;<br>
Memories) could operate at around 3&nbsp;MHz for random&nbsp;accesses and at&nbsp;6&nbsp;MHz for&nbsp;<br>
sequential (page&nbsp;mode) accesses.&nbsp;The CISC&nbsp;microprocessors of the time&nbsp;could&nbsp;<br>
access&nbsp;memory&nbsp;at&nbsp;most&nbsp;at&nbsp;2&nbsp;MHz,&nbsp;so&nbsp;memory bandwidth&nbsp;was not&nbsp;being exploited&nbsp;<br>
to&nbsp;the&nbsp;full.&nbsp;RISC&nbsp;processors, being&nbsp;rather&nbsp;simpler, could&nbsp;be&nbsp;designed&nbsp;to&nbsp;operate&nbsp;at&nbsp;<br>
clock rates&nbsp;that&nbsp;would&nbsp;use&nbsp;all&nbsp;the&nbsp;available memory bandwidth.&nbsp;<br>
Neither&nbsp;of&nbsp;these properties&nbsp;is a&nbsp;feature&nbsp;of&nbsp;the architecture,&nbsp;but&nbsp;both&nbsp;depend&nbsp;on&nbsp;the&nbsp;<br>
architecture being simple enough to allow the implementation to&nbsp;incorporate it. RISC&nbsp;<br>
architectures succeeded&nbsp;because they were&nbsp;simple enough&nbsp;to&nbsp;enable the designers to&nbsp;<br>
exploit these organizational&nbsp;techniques. It&nbsp;was&nbsp;entirely&nbsp;feasible&nbsp;to&nbsp;implement a&nbsp;<br>
fixed-length&nbsp;instruction load-store&nbsp;architecture&nbsp;using microcode,&nbsp;multi-cycle&nbsp;<br>
execution&nbsp;and&nbsp;no&nbsp;pipeline,&nbsp;but such&nbsp;an&nbsp;implementation&nbsp;would&nbsp;exhibit&nbsp;no&nbsp;advantage&nbsp;<br>
over&nbsp;an&nbsp;off-the-shelf&nbsp;CISC. It was&nbsp;<i>not&nbsp;&nbsp;</i>possible,&nbsp;at&nbsp;that&nbsp;time, to&nbsp;implement a&nbsp;<br>
hard-wired,&nbsp;single-cycle&nbsp;execution&nbsp;pipelined&nbsp;CISC. But it&nbsp;is&nbsp;now!&nbsp;<br>
Clock rates&nbsp;<br>
As&nbsp;footnotes to&nbsp;the&nbsp;above&nbsp;analysis,&nbsp;there&nbsp;are&nbsp;two&nbsp;aspects of&nbsp;the clock&nbsp;rate&nbsp;discussion&nbsp;<br>
that require further explanation:&nbsp;<br>
<hr>
<A name=39></a><b>The Reduced Instruction Set Computer</b>&nbsp;<br>
<b>27</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
•&nbsp;&nbsp;1980s CISC processors&nbsp;often&nbsp;had higher&nbsp;clock&nbsp;rates than&nbsp;the&nbsp;early&nbsp;RISCs, but&nbsp;they&nbsp;<br>
took&nbsp;several&nbsp;clock cycles to&nbsp;perform&nbsp;a&nbsp;single&nbsp;memory&nbsp;access,&nbsp;so they&nbsp;had&nbsp;a&nbsp;lower&nbsp;<br>
memory access rate. Beware of&nbsp;evaluating processors on their clock rate alone!&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;mismatch&nbsp;between the&nbsp;CISC memory access&nbsp;rate&nbsp;and the available&nbsp;bandwidth&nbsp;<br>
appears to conflict&nbsp;with&nbsp;the&nbsp;comments&nbsp;in 'Complex&nbsp;Instruction&nbsp;Set&nbsp;Computers'&nbsp;on&nbsp;<br>
page 20 where microcode&nbsp;is&nbsp;justified in an&nbsp;early 1970s minicomputer&nbsp;on the&nbsp;<br>
grounds&nbsp;of&nbsp;the&nbsp;slow&nbsp;main memory&nbsp;speed relative&nbsp;to&nbsp;the&nbsp;processor speed.&nbsp;The&nbsp;<br>
resolution of&nbsp;the conflict lies in observing&nbsp;that in the&nbsp;intervening decade&nbsp;memory&nbsp;<br>
technology&nbsp;had become&nbsp;significantly&nbsp;faster&nbsp;while&nbsp;early&nbsp;CISC&nbsp;microprocessors&nbsp;<br>
were&nbsp;slower&nbsp;than typical&nbsp;minicomputer processors. This loss of processor speed&nbsp;<br>
was due to&nbsp;the&nbsp;necessity&nbsp;to&nbsp;switch from&nbsp;fast&nbsp;bipolar&nbsp;technologies to&nbsp;much&nbsp;slower&nbsp;<br>
NMOS technologies to&nbsp;achieve the logic&nbsp;density&nbsp;required to&nbsp;fit the complete&nbsp;<br>
processor onto&nbsp;a single chip.&nbsp;<br>
RISC&nbsp;drawbacks&nbsp;<br>
RISC processors have clearly&nbsp;won the performance battle and&nbsp;should&nbsp;cost less to&nbsp;<br>
design,&nbsp;so&nbsp;is a RISC all&nbsp;good&nbsp;news?&nbsp;With&nbsp;the&nbsp;passage of&nbsp;time,&nbsp;two&nbsp;drawbacks have&nbsp;<br>
come&nbsp;to light:&nbsp;<br>
•&nbsp;&nbsp;RISCs generally&nbsp;have&nbsp;poor code&nbsp;density compared&nbsp;with&nbsp;CISCs.&nbsp;<br>
•&nbsp;&nbsp;RISCs don't&nbsp;execute x86 code.&nbsp;<br>
The&nbsp;second&nbsp;of&nbsp;these&nbsp;is&nbsp;hard&nbsp;to&nbsp;fix,&nbsp;though&nbsp;PC&nbsp;emulation&nbsp;software&nbsp;is&nbsp;available&nbsp;for&nbsp;<br>
many&nbsp;RISC platforms. It is only&nbsp;a&nbsp;problem,&nbsp;however, if you&nbsp;want&nbsp;to&nbsp;build&nbsp;an IBM PC&nbsp;<br>
compatible; for other&nbsp;applications&nbsp;it&nbsp;can safely&nbsp;be&nbsp;ignored.&nbsp;<br>
The&nbsp;poor&nbsp;code&nbsp;density&nbsp;is&nbsp;a&nbsp;consequence&nbsp;of&nbsp;the fixed-length&nbsp;instruction set and is&nbsp;<br>
rather&nbsp;more&nbsp;serious for&nbsp;a&nbsp;wide range&nbsp;of&nbsp;applications. In&nbsp;the&nbsp;absence&nbsp;of&nbsp;a cache,&nbsp;poor&nbsp;<br>
code density leads to&nbsp;more&nbsp;main&nbsp;memory&nbsp;bandwidth&nbsp;being&nbsp;used&nbsp;for&nbsp;instruction&nbsp;fetch-<br>
ing, resulting&nbsp;in&nbsp;a&nbsp;higher memory&nbsp;power consumption.&nbsp;When&nbsp;the&nbsp;processor&nbsp;incorpo-<br>
rates&nbsp;an&nbsp;on-chip&nbsp;cache of&nbsp;a&nbsp;particular size, poor&nbsp;code&nbsp;density&nbsp;results&nbsp;in a smaller&nbsp;<br>
proportion&nbsp;of&nbsp;the working&nbsp;set&nbsp;being&nbsp;held&nbsp;in&nbsp;the&nbsp;cache&nbsp;at&nbsp;any time, increasing&nbsp;the&nbsp;cache&nbsp;<br>
miss&nbsp;rate,&nbsp;resulting in an even greater increase in the&nbsp;main&nbsp;memory bandwidth&nbsp;<br>
requirement and consequent&nbsp;power consumption.&nbsp;<br>
ARM code&nbsp;<br>
The&nbsp;ARM&nbsp;processor design&nbsp;is&nbsp;based&nbsp;on&nbsp;RISC&nbsp;principles, but&nbsp;for various&nbsp;reasons&nbsp;suf-<br>
density and&nbsp;<br>
fers less&nbsp;from&nbsp;poor&nbsp;code density&nbsp;than&nbsp;most other&nbsp;RISCs.&nbsp;Its code density&nbsp;is&nbsp;still,&nbsp;<br>
Thumb&nbsp;<br>
however, not as good as&nbsp;some&nbsp;CISC processors. Where code density&nbsp;is&nbsp;of&nbsp;prime&nbsp;<br>
importance,&nbsp;ARM Limited has&nbsp;incorporated a novel&nbsp;mechanism,&nbsp;called&nbsp;the Thumb&nbsp;<br>
architecture, into&nbsp;some&nbsp;versions&nbsp;of&nbsp;the&nbsp;ARM&nbsp;processor.&nbsp;The Thumb instruction&nbsp;set is&nbsp;<br>
a 16-bit&nbsp;compressed&nbsp;form&nbsp;of&nbsp;the original&nbsp;32-bit&nbsp;ARM instruction&nbsp;set, and employs&nbsp;<br>
dynamic decompression&nbsp;hardware in&nbsp;the&nbsp;instruction pipeline. Thumb&nbsp;code&nbsp;density&nbsp;is&nbsp;<br>
better than that achieved by&nbsp;most CISC processors.&nbsp;The&nbsp;Thumb&nbsp;architecture&nbsp;is&nbsp;<br>
described&nbsp;in&nbsp;Chapter&nbsp;7.&nbsp;<br>
<hr>
<A name=40></a><b>28&nbsp;</b><br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
Beyond&nbsp;RISC&nbsp;<br>
It&nbsp;seems unlikely&nbsp;that RISC&nbsp;represents the last&nbsp;word on computer&nbsp;architecture, so&nbsp;is&nbsp;<br>
there any&nbsp;sign of&nbsp;another breakthrough which&nbsp;will render the&nbsp;RISC approach&nbsp;obsolete?&nbsp;<br>
There is&nbsp;no&nbsp;development&nbsp;visible&nbsp;at&nbsp;the time&nbsp;of&nbsp;writing which suggests&nbsp;a&nbsp;change&nbsp;on&nbsp;<br>
the&nbsp;same&nbsp;scale&nbsp;as&nbsp;RISC, but instruction&nbsp;sets&nbsp;continue&nbsp;to&nbsp;evolve&nbsp;to&nbsp;give&nbsp;better&nbsp;support&nbsp;<br>
for efficient&nbsp;implementations&nbsp;and for new applications such&nbsp;as&nbsp;multimedia.&nbsp;<br>
1.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Design for low power consumption&nbsp;<br>
Since the introduction of digital computers 50 years&nbsp;ago&nbsp;there has been&nbsp;sustained&nbsp;<br>
improvement in&nbsp;their&nbsp;cost-effectiveness at&nbsp;a&nbsp;rate unparalleled in&nbsp;any&nbsp;other&nbsp;technical&nbsp;<br>
endeavour. As a side-effect&nbsp;of the route taken to increased performance, the power&nbsp;<br>
consumption&nbsp;of the machines has reduced&nbsp;equally dramatically.&nbsp;Only very&nbsp;recently,&nbsp;<br>
however, has the drive for&nbsp;minimum&nbsp;power&nbsp;consumption&nbsp;become&nbsp;as important as,&nbsp;<br>
and in&nbsp;some&nbsp;application areas&nbsp;more important than,&nbsp;the drive&nbsp;for increased perform-<br>
ance. This change has come&nbsp;about as a result of&nbsp;the growing&nbsp;market&nbsp;for&nbsp;<br>
battery-powered&nbsp;portable equipment, such&nbsp;as digital mobile&nbsp;telephones&nbsp;and&nbsp;lap-top&nbsp;<br>
computers,&nbsp;which incorporate high-performance computing&nbsp;components.&nbsp;<br>
Following&nbsp;the&nbsp;introduction&nbsp;of the&nbsp;integrated circuit the&nbsp;computer business has&nbsp;<br>
been&nbsp;driven&nbsp;by the&nbsp;win-win scenario whereby smaller&nbsp;transistors yield lower cost,&nbsp;<br>
higher performance and&nbsp;lower power consumption.&nbsp;Now, though, designers&nbsp;are&nbsp;<br>
beginning to&nbsp;design specifically&nbsp;for low&nbsp;power, even,&nbsp;in&nbsp;some&nbsp;cases, sacrificing per-<br>
formance&nbsp;to&nbsp;achieve&nbsp;it.&nbsp;<br>
The&nbsp;ARM&nbsp;processor&nbsp;is&nbsp;at&nbsp;the&nbsp;centre&nbsp;of&nbsp;this&nbsp;drive for&nbsp;power-efficient processing.&nbsp;It&nbsp;<br>
therefore&nbsp;seems appropriate&nbsp;to consider the issues around&nbsp;design&nbsp;for low power.&nbsp;<br>
Where does&nbsp;the&nbsp;<br>
The starting&nbsp;point for low-power&nbsp;design&nbsp;is&nbsp;to understand&nbsp;where&nbsp;the power goes in&nbsp;<br>
power go?&nbsp;<br>
existing circuits. CMOS is the dominant&nbsp;technology&nbsp;for&nbsp;modern&nbsp;high-performance&nbsp;<br>
digital electronics, and&nbsp;has&nbsp;itself some&nbsp;good&nbsp;properties for low-power&nbsp;design, so we&nbsp;<br>
start by&nbsp;looking&nbsp;at&nbsp;where the power goes in&nbsp;a&nbsp;CMOS circuit.&nbsp;<br>
A typical CMOS circuit is the static&nbsp;NAND gate, illustrated&nbsp;in&nbsp;Figure 1.2&nbsp;on&nbsp;<br>
page&nbsp;4.&nbsp;All&nbsp;signals&nbsp;swing&nbsp;between&nbsp;the&nbsp;voltages&nbsp;of&nbsp;the&nbsp;power and&nbsp;ground&nbsp;rails,&nbsp;<i>Vdd&nbsp;</i>and&nbsp;<br>
<i>Vss,&nbsp;</i>Until&nbsp;recently&nbsp;a&nbsp;5&nbsp;volt&nbsp;supply&nbsp;was&nbsp;standard,&nbsp;but&nbsp;many&nbsp;modern&nbsp;CMOS&nbsp;processes&nbsp;<br>
require a lower&nbsp;supply voltage&nbsp;of&nbsp;around 3&nbsp;volts and the&nbsp;latest&nbsp;technologies&nbsp;operate&nbsp;<br>
with&nbsp;supplies of&nbsp;between&nbsp;1&nbsp;and 2 volts, and&nbsp;this&nbsp;will&nbsp;reduce&nbsp;further in&nbsp;the&nbsp;future.&nbsp;<br>
The gate&nbsp;operates&nbsp;by&nbsp;connecting the&nbsp;output&nbsp;either&nbsp;to&nbsp;<i>Vdd&nbsp;</i>through a pull-up&nbsp;network&nbsp;<br>
of p-type transistors, or to&nbsp;<i>Vss&nbsp;</i>through&nbsp;a pull-down network&nbsp;of&nbsp;n-type transistors. When&nbsp;<br>
the inputs&nbsp;are both close to&nbsp;one&nbsp;rail or the other, then&nbsp;one&nbsp;of&nbsp;these networks is conduct-<br>
ing and the other is effectively not conducting, so there is no path through the gate from&nbsp;<br>
<i>Vdd&nbsp;</i>to&nbsp;<i>Vss.&nbsp;</i>Furthermore, the output&nbsp;is normally&nbsp;connected&nbsp;to the inputs of similar gates&nbsp;<br>
<hr>
<A name=41></a><IMG src="index-41_1.png"><br>
<b>Design&nbsp;for low&nbsp;power consumption</b>&nbsp;<br>
<b>29</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
and therefore sees only capacitive&nbsp;load. Once&nbsp;the output has&nbsp;been driven close&nbsp;to either&nbsp;<br>
rail, it takes&nbsp;no&nbsp;current to&nbsp;hold&nbsp;it there. Therefore a&nbsp;short time&nbsp;after the&nbsp;gate&nbsp;has switched&nbsp;<br>
the circuit&nbsp;reaches a stable&nbsp;condition and&nbsp;no&nbsp;further current is taken&nbsp;from&nbsp;the&nbsp;supply.&nbsp;<br>
This&nbsp;characteristic of consuming power only&nbsp;when switching&nbsp;is&nbsp;not shared&nbsp;by&nbsp;many&nbsp;<br>
other logic&nbsp;technologies and has been a&nbsp;major factor in&nbsp;making CMOS the technology&nbsp;<br>
of choice for&nbsp;high-density&nbsp;integrated circuits.&nbsp;<br>
CMOS power&nbsp;<br>
The total&nbsp;power consumption&nbsp;of a CMOS circuit comprises&nbsp;three components:&nbsp;<br>
components&nbsp;<br>
• Switching&nbsp;power.&nbsp;<br>
This&nbsp;is&nbsp;the&nbsp;power&nbsp;dissipated&nbsp;by&nbsp;charging&nbsp;and&nbsp;discharging the&nbsp;gate&nbsp;output&nbsp;capaci-<br>
tance&nbsp;<i>CL,&nbsp;</i>and&nbsp;represents&nbsp;the&nbsp;useful&nbsp;work&nbsp;performed by&nbsp;the&nbsp;gate.&nbsp;<br>
The energy&nbsp;per output&nbsp;transition is:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
•&nbsp;Short-circuit&nbsp;<br>
power.&nbsp;<br>
When&nbsp;the gate&nbsp;inputs&nbsp;are&nbsp;at&nbsp;an&nbsp;intermediate&nbsp;level both&nbsp;the p-&nbsp;and n-type&nbsp;networks&nbsp;can&nbsp;<br>
conduct.&nbsp;This&nbsp;results in&nbsp;a transitory&nbsp;conducting&nbsp;path&nbsp;from&nbsp;<i>Vdd&nbsp;</i>to&nbsp;<i>Vss.&nbsp;</i>With a&nbsp;correctly&nbsp;<br>
designed circuit&nbsp;(which generally&nbsp;means one&nbsp;that&nbsp;avoids slow signal&nbsp;transitions) the&nbsp;<br>
short-circuit&nbsp;power should&nbsp;be&nbsp;a small&nbsp;fraction&nbsp;of the switching&nbsp;power.&nbsp;<br>
• Leakage&nbsp;current.&nbsp;<br>
The transistor&nbsp;networks&nbsp;do conduct&nbsp;a&nbsp;very&nbsp;small current&nbsp;when they&nbsp;are in&nbsp;their&nbsp;<br>
'off'&nbsp;state; though&nbsp;on&nbsp;a&nbsp;conventional process this&nbsp;current&nbsp;is very&nbsp;small (a&nbsp;small&nbsp;<br>
fraction&nbsp;of a nanoamp&nbsp;per&nbsp;gate), it is the only dissipation&nbsp;in&nbsp;a circuit that is pow-<br>
ered but&nbsp;inactive, and can drain a&nbsp;supply&nbsp;battery&nbsp;over&nbsp;a long&nbsp;period&nbsp;of&nbsp;time. It&nbsp;is&nbsp;<br>
generally negligible in an active circuit.&nbsp;<br>
In a&nbsp;well-designed&nbsp;active&nbsp;circuit the switching&nbsp;power dominates, with&nbsp;the&nbsp;<br>
short-circuit power adding&nbsp;perhaps&nbsp;10%&nbsp;to 20%&nbsp;to&nbsp;the total power, and the leakage&nbsp;<br>
current&nbsp;being significant&nbsp;only&nbsp;when the circuit is&nbsp;inactive. However, the trend&nbsp;to&nbsp;lower&nbsp;<br>
voltage&nbsp;operation does lead to a trade-off&nbsp;between performance and leakage current as&nbsp;<br>
discussed further below, and leakage&nbsp;is&nbsp;an increasing concern for future low-power&nbsp;<br>
high-performance designs.&nbsp;<br>
CMOS circuit&nbsp;<br>
The total power dissipation,&nbsp;<i>Pc,&nbsp;</i>of a CMOS&nbsp;circuit,&nbsp;neglecting the short-circuit&nbsp;and&nbsp;<br>
power&nbsp;<br>
leakage components, is therefore&nbsp;given by&nbsp;summing&nbsp;the dissipation of every&nbsp;gate&nbsp;<i>g&nbsp;</i><br>
in&nbsp;the circuit C:&nbsp;<br>
<hr>
<A name=42></a><IMG src="index-42_1.png"><br>
<IMG src="index-42_2.png"><br>
<b>30</b>&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
where/is&nbsp;the clock frequency,&nbsp;<i>Ag&nbsp;</i>is the&nbsp;gate&nbsp;<b>activity factor&nbsp;</b>(reflecting&nbsp;the&nbsp;fact&nbsp;that&nbsp;<br>
not&nbsp;all gates switch every clock cycle)&nbsp;and&nbsp;C/&nbsp;is&nbsp;the gate&nbsp;load&nbsp;capacitance.&nbsp;Note&nbsp;<br>
that&nbsp;within&nbsp;this&nbsp;summation&nbsp;clock lines,&nbsp;which&nbsp;make&nbsp;two transitions&nbsp;per clock&nbsp;cycle,&nbsp;<br>
have&nbsp;an&nbsp;activity&nbsp;factor&nbsp;of&nbsp;2.&nbsp;<br>
Low-power&nbsp;<br>
The typical gate load&nbsp;capacitance is a&nbsp;function of the process technology and there-<br>
circuit design&nbsp;<br>
fore not under the&nbsp;direct&nbsp;control&nbsp;of the&nbsp;designer. The remaining parameters in&nbsp;<br>
Equation&nbsp;3 suggest&nbsp;various approaches&nbsp;to&nbsp;low-power&nbsp;design.&nbsp;These&nbsp;are&nbsp;listed below&nbsp;<br>
with the most&nbsp;important&nbsp;first:&nbsp;<br>
1.&nbsp;&nbsp;Minimize the power&nbsp;supply voltage,&nbsp;<i>Vdd.</i>&nbsp;<br>
The quadratic contribution of&nbsp;the&nbsp;supply voltage to&nbsp;the power dissipation&nbsp;makes&nbsp;<br>
this an&nbsp;obvious&nbsp;target. This is discussed&nbsp;further below.&nbsp;<br>
2.&nbsp;&nbsp;Minimize the circuit&nbsp;activity,&nbsp;<i>A.</i>&nbsp;<br>
Techniques such as clock gating fall under this heading. Whenever a circuit&nbsp;<br>
function is&nbsp;not needed,&nbsp;activity&nbsp;should&nbsp;be eliminated.&nbsp;<br>
3.&nbsp;&nbsp;Minimize&nbsp;the number of&nbsp;gates.&nbsp;<br>
Simple circuits&nbsp;use less power than complex ones, all other things&nbsp;being equal,&nbsp;<br>
since the&nbsp;sum&nbsp;is&nbsp;over a smaller number of&nbsp;gate&nbsp;contributions.&nbsp;<br>
4.&nbsp;&nbsp;Minimize the clock frequency,&nbsp;<i>f</i>.&nbsp;<br>
Avoiding&nbsp;unnecessarily&nbsp;high&nbsp;clock rates is clearly&nbsp;desirable,&nbsp;but although&nbsp;a lower&nbsp;<br>
clock rate reduces the power consumption it also reduces performance, having a neu-<br>
tral&nbsp;effect&nbsp;on power-efficiency&nbsp;(measured,&nbsp;for&nbsp;example,&nbsp;in&nbsp;MIPS -&nbsp;Millions&nbsp;of&nbsp;<br>
Instructions Per Second - per&nbsp;watt). If,&nbsp;however, a reduced&nbsp;clock frequency&nbsp;allows&nbsp;<br>
operation at a reduced&nbsp;<i>Vdd,&nbsp;</i>this will be highly&nbsp;beneficial to the power-efficiency.&nbsp;<br>
Reducing&nbsp;<i>Vdd</i>&nbsp;<br>
As the&nbsp;feature size&nbsp;on CMOS&nbsp;processes&nbsp;gets&nbsp;smaller,&nbsp;there&nbsp;is&nbsp;pressure&nbsp;to&nbsp;reduce the&nbsp;<br>
supply&nbsp;voltage. This is because&nbsp;the&nbsp;materials used&nbsp;to&nbsp;form&nbsp;the transistors cannot&nbsp;<br>
withstand an&nbsp;electric&nbsp;field of&nbsp;unlimited strength, and as transistors get&nbsp;smaller the&nbsp;<br>
field&nbsp;strength increases&nbsp;if&nbsp;the supply&nbsp;voltage is&nbsp;held&nbsp;constant.&nbsp;<br>
However, with&nbsp;increasing interest in&nbsp;design specifically for low power, it&nbsp;may be&nbsp;<br>
desirable&nbsp;for&nbsp;the supply&nbsp;voltage to&nbsp;be reduced&nbsp;faster than&nbsp;is necessary&nbsp;solely&nbsp;to&nbsp;prevent&nbsp;<br>
electrical&nbsp;breakdown.&nbsp;What&nbsp;prevents&nbsp;very&nbsp;low supply&nbsp;voltages from&nbsp;being&nbsp;used&nbsp;now?&nbsp;<br>
The problem&nbsp;with reducing&nbsp;<i>Vdd&nbsp;</i>is that&nbsp;this&nbsp;also reduces the&nbsp;performance of&nbsp;the cir-<br>
cuit.&nbsp;The&nbsp;saturated transistor current is&nbsp;given by:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<hr>
<A name=43></a><IMG src="index-43_1.png"><br>
<IMG src="index-43_2.png"><br>
<b>Design&nbsp;for low&nbsp;power consumption&nbsp;</b><br>
<b>31</b>&nbsp;<br>
where&nbsp;<i>Vt&nbsp;</i>is&nbsp;the transistor threshold. The charge on a circuit node is proportional to&nbsp;<br>
<i>Vdd,&nbsp;</i>so&nbsp;the&nbsp;maximum&nbsp;operating&nbsp;frequency&nbsp;is&nbsp;given&nbsp;by:&nbsp;<br>
&nbsp;<br>
Therefore the maximum&nbsp;operating frequency&nbsp;is reduced as&nbsp;<i>Vdd&nbsp;</i>is reduced.&nbsp;The per-<br>
formance&nbsp;loss&nbsp;on&nbsp;a&nbsp;sub-micron&nbsp;process&nbsp;may&nbsp;not&nbsp;be&nbsp;as&nbsp;severe as&nbsp;Equation&nbsp;5 suggests&nbsp;<br>
since&nbsp;the&nbsp;current&nbsp;at&nbsp;high&nbsp;voltage may&nbsp;be limited&nbsp;by&nbsp;velocity&nbsp;saturation&nbsp;effects,&nbsp;but&nbsp;per-<br>
formance&nbsp;will&nbsp;be&nbsp;lost&nbsp;to&nbsp;some&nbsp;extent.&nbsp;Equation&nbsp;5 suggests&nbsp;that&nbsp;an&nbsp;obvious&nbsp;way&nbsp;to&nbsp;<br>
ameliorate&nbsp;the&nbsp;performance&nbsp;loss would&nbsp;be&nbsp;to reduce&nbsp;<i>Vt.&nbsp;</i>However&nbsp;the leakage current&nbsp;<br>
depends strongly on&nbsp;<i>Vt:</i>&nbsp;<br>
&nbsp;<br>
Even a small&nbsp;reduction in&nbsp;<i>Vt&nbsp;&nbsp;</i>can significantly increase the leakage&nbsp;current,&nbsp;<br>
increasing&nbsp;the&nbsp;battery drain&nbsp;through&nbsp;an inactive&nbsp;circuit.&nbsp;There is&nbsp;therefore&nbsp;a&nbsp;trade-off&nbsp;<br>
to&nbsp;be&nbsp;struck between&nbsp;maximizing performance and&nbsp;minimizing&nbsp;standby power,&nbsp;and&nbsp;<br>
this issue&nbsp;must&nbsp;be considered&nbsp;carefully by&nbsp;designers of&nbsp;systems&nbsp;where both charac-<br>
teristics are&nbsp;important.&nbsp;<br>
Even where standby&nbsp;power is&nbsp;not important&nbsp;designers&nbsp;must be&nbsp;aware that&nbsp;maximizing&nbsp;<br>
performance by&nbsp;using&nbsp;very&nbsp;low threshold&nbsp;transistors can&nbsp;increase the leakage power to&nbsp;<br>
Low-power&nbsp;<br>
the point where&nbsp;is becomes comparable&nbsp;with the&nbsp;dynamic&nbsp;power,&nbsp;and&nbsp;therefore&nbsp;leakage&nbsp;<br>
strategies&nbsp;<br>
power&nbsp;must be taken into consideration when selecting packaging and cooling&nbsp;systems.&nbsp;<br>
To&nbsp;conclude this introduction&nbsp;to&nbsp;design&nbsp;techniques&nbsp;for low power consumption, here&nbsp;<br>
are some&nbsp;suggested strategies&nbsp;for&nbsp;low-power&nbsp;applications.&nbsp;<br>
•&nbsp;Minimize&nbsp;<br>
<i>Vdd.</i>&nbsp;<br>
Choose the lowest clock frequency&nbsp;that delivers the required performance, then&nbsp;<br>
set the power&nbsp;supply&nbsp;voltage as&nbsp;low as&nbsp;is&nbsp;practical&nbsp;given the&nbsp;clock frequency&nbsp;and&nbsp;<br>
the requirements of the various system&nbsp;components. Be wary&nbsp;of reducing the&nbsp;<br>
supply&nbsp;voltage so&nbsp;far that leakage compromises standby&nbsp;power.&nbsp;<br>
•&nbsp;&nbsp;Minimize&nbsp;off-chip&nbsp;activity.&nbsp;<br>
Off-chip&nbsp;capacitances are much&nbsp;higher than&nbsp;on-chip loads, so&nbsp;always minimize&nbsp;<br>
off-chip activity.&nbsp;Avoid allowing transients to&nbsp;drive&nbsp;off-chip loads and&nbsp;use caches&nbsp;<br>
to&nbsp;minimize&nbsp;accesses to&nbsp;off-chip&nbsp;memories.&nbsp;<br>
•&nbsp;&nbsp;Minimize on-chip activity.&nbsp;<br>
Lower priority&nbsp;than&nbsp;minimizing off-chip activity, it is&nbsp;still important to&nbsp;avoid&nbsp;<br>
clocking unnecessary&nbsp;circuit&nbsp;functions (for example, by&nbsp;using gated clocks) and&nbsp;<br>
to&nbsp;employ&nbsp;sleep&nbsp;modes where possible.&nbsp;<br>
<hr>
<A name=44></a><IMG src="index-44_1.png"><br>
<b>32</b>&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
• Exploit parallelism.&nbsp;<br>
Where&nbsp;the&nbsp;power&nbsp;supply&nbsp;voltage is a free variable&nbsp;parallelism&nbsp;can&nbsp;be exploited&nbsp;to&nbsp;<br>
improve&nbsp;power-efficiency. Duplicating a circuit&nbsp;allows the two&nbsp;circuits&nbsp;to sustain&nbsp;<br>
the same&nbsp;performance at half the&nbsp;clock&nbsp;frequency&nbsp;of the original circuit, which&nbsp;<br>
allows the&nbsp;required&nbsp;performance&nbsp;to&nbsp;be&nbsp;delivered&nbsp;with a&nbsp;lower supply&nbsp;voltage.&nbsp;<br>
Design for low power&nbsp;is an&nbsp;active research&nbsp;area and one where new&nbsp;ideas are being&nbsp;<br>
generated&nbsp;at&nbsp;a&nbsp;high&nbsp;rate. It&nbsp;is&nbsp;expected&nbsp;that&nbsp;a&nbsp;combination&nbsp;of&nbsp;process and&nbsp;design&nbsp;tech-<br>
nology&nbsp;improvements will yield&nbsp;considerable further improvement&nbsp;in&nbsp;the&nbsp;<br>
power-efficiency&nbsp;of high-speed digital&nbsp;circuits&nbsp;over&nbsp;the next&nbsp;decade.&nbsp;<br>
1.8 &nbsp; Examples&nbsp;and&nbsp;exercises&nbsp;<br>
(The more&nbsp;practical&nbsp;exercises will require you&nbsp;to have access to&nbsp;some&nbsp;form&nbsp;of&nbsp;hard-<br>
ware&nbsp;simulation&nbsp;environment.)&nbsp;<br>
<b>Example 1.1</b>&nbsp;<br>
<b>Design&nbsp;a 4-bit&nbsp;binary&nbsp;counter&nbsp;using&nbsp;logic gates and&nbsp;a 4-bit register.</b>&nbsp;<br>
If the register&nbsp;inputs are denoted by&nbsp;<i>D[0]&nbsp;</i>to&nbsp;<i>D[3]&nbsp;</i>and its outputs are denoted&nbsp;by&nbsp;<br>
<i>Q[0]&nbsp;</i>to&nbsp;<i>Q[3],&nbsp;</i>the counter may be implemented by&nbsp;building&nbsp;combinatorial logic that&nbsp;<br>
generates&nbsp;<i>D[3:0]&nbsp;</i>=&nbsp;<i>Q[3:0]&nbsp;+&nbsp;</i>1. The logic&nbsp;equations&nbsp;for a&nbsp;binary adder are given&nbsp;in&nbsp;<br>
the Appendix&nbsp;(Equation 20&nbsp;on page 401 gives the&nbsp;sum&nbsp;and Equation 21&nbsp;the carry).&nbsp;<br>
When the second operand&nbsp;is&nbsp;a constant these equations&nbsp;simplify&nbsp;to:&nbsp;<br>
&nbsp;<br>
for&nbsp;1 &lt; i&nbsp;&lt; 3&nbsp;, and&nbsp;<i>C[0]&nbsp;</i>= 1.&nbsp;<i>(C[3]&nbsp;</i>is not needed.) These&nbsp;equations&nbsp;may be&nbsp;drawn as&nbsp;<br>
the&nbsp;logic circuit shown&nbsp;on page 33,&nbsp;which&nbsp;also&nbsp;includes the&nbsp;register.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Exercise 1.1.1</b>&nbsp;<br>
Modify&nbsp;the binary&nbsp;counter to&nbsp;count&nbsp;from&nbsp;0&nbsp;to 9, and&nbsp;then,&nbsp;on the next&nbsp;clock edge, to&nbsp;<br>
start&nbsp;again at&nbsp;zero.&nbsp;(This is&nbsp;a&nbsp;<b>modulo 10&nbsp;</b>counter.)&nbsp;<br>
<b>Exercise&nbsp;1.1.2</b>&nbsp;<br>
Modify the binary counter to include a&nbsp;<b>synchronous clear&nbsp;</b>function.&nbsp;This means&nbsp;<br>
adding&nbsp;a new input ('clear')&nbsp;which, if active, causes the counter output&nbsp;to be zero&nbsp;<br>
after&nbsp;the&nbsp;next&nbsp;clock edge whatever&nbsp;its&nbsp;current&nbsp;value&nbsp;is.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Exercise&nbsp;1.1.3</b>&nbsp;<br>
Modify the binary&nbsp;counter to&nbsp;include an&nbsp;<b>up/down&nbsp;</b>input. When&nbsp;this input&nbsp;is high&nbsp;the&nbsp;<br>
counter should behave&nbsp;as&nbsp;described&nbsp;in&nbsp;the&nbsp;example&nbsp;above; when&nbsp;it&nbsp;is&nbsp;low the counter&nbsp;<br>
should count down&nbsp;(in&nbsp;the&nbsp;reverse&nbsp;sequence to&nbsp;the&nbsp;<i>up&nbsp;</i>mode).&nbsp;<br>
<hr>
<A name=45></a><IMG src="index-45_1.png"><br>
<b>Examples and exercises</b>&nbsp;<br>
<b>33</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Example 1.2</b>&nbsp;<br>
<b>Add indexed addressing&nbsp;to the&nbsp;MU0 instruction set.</b>&nbsp;<br>
The&nbsp;minimum extension&nbsp;that&nbsp;<i>is&nbsp;</i>useful here is to introduce&nbsp;a new 12-bit index regis-<br>
ter&nbsp;(X) and&nbsp;some&nbsp;new instructions&nbsp;that&nbsp;allow it&nbsp;to&nbsp;be initialized and used&nbsp;in load and&nbsp;<br>
store instructions. Referring to Table 1.1&nbsp;on&nbsp;page 8, there&nbsp;are eight unused opcodes&nbsp;<br>
in the original design, so we&nbsp;could add up&nbsp;to eight new instructions before&nbsp;we run&nbsp;<br>
out of&nbsp;space. The basic set of&nbsp;indexing operations is:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
LDX&nbsp;S&nbsp;LDA&nbsp;<br>
; X := mem16[S]&nbsp;<br>
S,&nbsp;X&nbsp;STA&nbsp;S,&nbsp;<br>
; ACC := mem16[S+X]&nbsp;<br>
X&nbsp;<br>
; mem16[S+X]&nbsp;:= ACC&nbsp;<br>
An&nbsp;index register&nbsp;is&nbsp;much&nbsp;more useful&nbsp;if&nbsp;there&nbsp;is&nbsp;some&nbsp;way&nbsp;to&nbsp;modify&nbsp;it,&nbsp;for&nbsp;<br>
instance&nbsp;to step through a&nbsp;table:&nbsp;<br>
INX DEX&nbsp;<br>
; &nbsp;&nbsp;X&nbsp;&nbsp;&nbsp;:= &nbsp;&nbsp;X&nbsp;&nbsp;&nbsp;<br>
+ &nbsp; 1&nbsp;;&nbsp;&nbsp;&nbsp;<br>
X&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
1&nbsp;<br>
This gives&nbsp;the&nbsp;basic functionality of an&nbsp;index register. It would&nbsp;increase the useful-<br>
ness&nbsp;of&nbsp;X&nbsp;to&nbsp;include a&nbsp;way&nbsp;to&nbsp;store it&nbsp;in&nbsp;memory, then&nbsp;it&nbsp;could&nbsp;be&nbsp;used&nbsp;as&nbsp;a&nbsp;temporary&nbsp;<br>
register,&nbsp;but&nbsp;for&nbsp;simplicity we&nbsp;will&nbsp;stop&nbsp;here.&nbsp;<br>
<b>Exercise 1.2.1</b>&nbsp;<br>
Modify&nbsp;the RTL organization&nbsp;shown in&nbsp;Figure 1.6&nbsp;on page&nbsp;11 to include the X reg-<br>
ister, indicating the new control&nbsp;signals&nbsp;required.&nbsp;<br>
<hr>
<A name=46></a><b>34</b>&nbsp;<br>
<b>An&nbsp;Introduction to Processor Design</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Exercise&nbsp;1.2.2</b>&nbsp;<br>
Modify&nbsp;the control logic in Table 1.2 on page 12 to support indexed addressing.&nbsp;If&nbsp;<br>
you&nbsp;have&nbsp;access to a hardware&nbsp;simulator,&nbsp;test your design.&nbsp;(This is&nbsp;non-trivial!)&nbsp;<br>
&nbsp;&nbsp;&nbsp;<b>Example 1.3</b>&nbsp;<br>
<b>Estimate&nbsp;the performance&nbsp;benefit&nbsp;of&nbsp;a&nbsp;single-cycle&nbsp;delayed&nbsp;branch.</b>&nbsp;<br>
A delayed branch&nbsp;allows&nbsp;the instruction following the&nbsp;branch&nbsp;to&nbsp;be&nbsp;executed&nbsp;<br>
whether or not&nbsp;the branch is&nbsp;taken.&nbsp;The&nbsp;instruction&nbsp;after&nbsp;the branch&nbsp;is in&nbsp;the&nbsp;'delay&nbsp;<br>
slot'.&nbsp;Assume&nbsp;the dynamic instruction frequencies shown in Table 1.3&nbsp;on page 21&nbsp;<br>
and the pipeline structure&nbsp;shown&nbsp;in&nbsp;Figure&nbsp;1.13 on&nbsp;page&nbsp;22; ignore&nbsp;register hazards;&nbsp;<br>
assume&nbsp;all&nbsp;delay slots can&nbsp;be&nbsp;filled&nbsp;(most single&nbsp;delay slots&nbsp;can&nbsp;be&nbsp;filled).&nbsp;<br>
If there&nbsp;is a dedicated&nbsp;branch&nbsp;target&nbsp;adder in&nbsp;the decode&nbsp;stage,&nbsp;a branch has&nbsp;a&nbsp;<br>
1-cycle&nbsp;delayed effect,&nbsp;so a&nbsp;single&nbsp;delay slot removes&nbsp;all&nbsp;wasted&nbsp;cycles.&nbsp;One&nbsp;instruc-<br>
tion in four&nbsp;is&nbsp;a&nbsp;branch, so&nbsp;four&nbsp;instructions&nbsp;take&nbsp;five clock&nbsp;cycles&nbsp;without the delay&nbsp;<br>
slot&nbsp;and&nbsp;four&nbsp;with&nbsp;it, giving&nbsp;25%&nbsp;higher performance.&nbsp;<br>
If there is&nbsp;no&nbsp;dedicated branch&nbsp;target&nbsp;adder&nbsp;and the&nbsp;main&nbsp;ALU stage&nbsp;is&nbsp;used&nbsp;to com-<br>
pute&nbsp;the target, a&nbsp;branch&nbsp;will&nbsp;incur&nbsp;three wasted cycles. Therefore&nbsp;four instructions on&nbsp;<br>
average&nbsp;include&nbsp;one&nbsp;branch&nbsp;and&nbsp;take&nbsp;seven&nbsp;clock cycles,&nbsp;or&nbsp;six with&nbsp;a&nbsp;single&nbsp;delay&nbsp;slot.&nbsp;<br>
The delay&nbsp;slot&nbsp;therefore gives 17% higher&nbsp;performance (but the dedicated branch&nbsp;<br>
adder does&nbsp;better even&nbsp;without&nbsp;the&nbsp;delay&nbsp;slot).&nbsp;<br>
<b>Exercise&nbsp;1.3.1</b>&nbsp;<br>
Estimate&nbsp;the&nbsp;performance benefit&nbsp;of&nbsp;a&nbsp;2-cycle delayed branch assuming&nbsp;that&nbsp;all&nbsp;the&nbsp;<br>
first delay&nbsp;slots&nbsp;can&nbsp;be&nbsp;filled, but only&nbsp;50% of&nbsp;the&nbsp;second delay slots&nbsp;can&nbsp;be&nbsp;filled.&nbsp;<br>
Why&nbsp;is the 2-cycle delayed branch&nbsp;only&nbsp;relevant&nbsp;if&nbsp;there is&nbsp;no&nbsp;dedicated&nbsp;branch&nbsp;<br>
target&nbsp;adder?&nbsp;<br>
<b>Exercise&nbsp;1.3.2</b>&nbsp;<br>
What is the effect on code size of the 1-&nbsp;and 2-cycle delayed branches suggested&nbsp;<br>
above?&nbsp;(All unfilled&nbsp;branch&nbsp;delay slots must be filled with&nbsp;no-ops.)&nbsp;<br>
<hr>
<A name=47></a><IMG src="index-47_1.png"><br>
The ARM Architecture&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Summary of chapter contents&nbsp;<br>
The&nbsp;ARM processor is&nbsp;a&nbsp;<i>Reduced&nbsp;Instruction Set&nbsp;Computer&nbsp;</i>(RISC).&nbsp;The&nbsp;RISC con-<br>
cept,&nbsp;as&nbsp;we&nbsp;saw in&nbsp;the&nbsp;previous&nbsp;chapter,&nbsp;originated&nbsp;in&nbsp;processor&nbsp;research&nbsp;pro-<br>
grammes at&nbsp;Stanford&nbsp;and&nbsp;Berkeley&nbsp;universities around&nbsp;1980.&nbsp;<br>
In&nbsp;this chapter&nbsp;we&nbsp;see&nbsp;how&nbsp;the&nbsp;RISC ideas helped shape the&nbsp;ARM&nbsp;processors.&nbsp;<br>
The&nbsp;ARM&nbsp;was originally&nbsp;developed&nbsp;at&nbsp;Acorn&nbsp;Computers Limited&nbsp;of&nbsp;Cambridge,&nbsp;<br>
England, between 1983 and&nbsp;1985. It&nbsp;was the first&nbsp;RISC&nbsp;microprocessor&nbsp;developed&nbsp;<br>
for commercial&nbsp;use&nbsp;and has some significant&nbsp;differences&nbsp;from subsequent&nbsp;RISC&nbsp;<br>
architectures.&nbsp;The principal&nbsp;features&nbsp;of&nbsp;the&nbsp;ARM architecture are presented&nbsp;here in&nbsp;<br>
overview&nbsp;form;&nbsp;the&nbsp;details are&nbsp;postponed to&nbsp;subsequent&nbsp;chapters.&nbsp;<br>
In 1990&nbsp;ARM&nbsp;Limited&nbsp;was established&nbsp;as&nbsp;a separate company specifically&nbsp;to&nbsp;<br>
widen&nbsp;the exploitation&nbsp;of&nbsp;ARM technology, since when&nbsp;the ARM has been licensed&nbsp;<br>
to many semiconductor manufacturers around the world. It has become estab-<br>
lished&nbsp;as&nbsp;a market-leader for&nbsp;low-power&nbsp;and&nbsp;cost-sensitive&nbsp;embedded applications.&nbsp;<br>
No processor is&nbsp;particularly useful&nbsp;without the support&nbsp;of&nbsp;hardware and software&nbsp;<br>
development&nbsp;tools.&nbsp;The&nbsp;ARM is&nbsp;supported by&nbsp;a toolkit&nbsp;which includes&nbsp;an&nbsp;instruction&nbsp;<br>
set emulator&nbsp;for hardware&nbsp;model&nbsp;ing and software&nbsp;testing&nbsp;and&nbsp;benchmarking,&nbsp;an&nbsp;<br>
assembler,&nbsp;C&nbsp;and&nbsp;C++&nbsp;compilers,&nbsp;a&nbsp;linker&nbsp;and&nbsp;a&nbsp;symbolic&nbsp;debugger.&nbsp;<br>
35&nbsp;<br>
<hr>
<A name=48></a><b>36&nbsp;</b><br>
<b>The ARM Architecture</b>&nbsp;<br>
2.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The Acorn RISC Machine&nbsp;<br>
The first&nbsp;ARM processor&nbsp;was developed at Acorn Computers&nbsp;Limited, of Cam-<br>
bridge, England, between&nbsp;October 1983 and April&nbsp;1985.&nbsp;At&nbsp;that time, and until the&nbsp;<br>
formation of&nbsp;Advanced&nbsp;RISC&nbsp;Machines&nbsp;Limited (which&nbsp;later was&nbsp;renamed simply&nbsp;<br>
ARM Limited)&nbsp;in&nbsp;1990, ARM stood for Acorn&nbsp;<b>RISC&nbsp;Machine.</b>&nbsp;<br>
Acorn had&nbsp;developed a&nbsp;strong&nbsp;position&nbsp;in the UK personal computer&nbsp;market&nbsp;due&nbsp;<br>
to&nbsp;the&nbsp;success of the BBC&nbsp;(British Broadcasting Corporation) microcomputer.&nbsp;The&nbsp;<br>
BBC&nbsp;micro&nbsp;was&nbsp;a&nbsp;machine&nbsp;powered&nbsp;by&nbsp;the 8-bit 6502&nbsp;microprocessor&nbsp;and&nbsp;rapidly&nbsp;<br>
became&nbsp;established as the dominant&nbsp;machine in&nbsp;UK schools&nbsp;following its introduc-<br>
tion in January&nbsp;1982 in support of a series&nbsp;of television&nbsp;programmes&nbsp;broadcast by&nbsp;<br>
the BBC.&nbsp;It also enjoyed enthusiastic support in the hobbyist&nbsp;market and found its&nbsp;<br>
way&nbsp;into a&nbsp;number of&nbsp;research&nbsp;laboratories&nbsp;and higher&nbsp;education&nbsp;establishments.&nbsp;<br>
Following the&nbsp;success of&nbsp;the BBC&nbsp;micro, Acorn's engineers looked at&nbsp;various&nbsp;<br>
microprocessors&nbsp;to&nbsp;build a successor machine&nbsp;around, but found all the&nbsp;commercial&nbsp;<br>
offerings lacking. The 16-bit&nbsp;CISC&nbsp;microprocessors that were available in 1983&nbsp;<br>
were slower&nbsp;than standard&nbsp;memory parts. They&nbsp;also had instructions that took&nbsp;many&nbsp;<br>
clock cycles to&nbsp;complete&nbsp;(in&nbsp;some&nbsp;cases,&nbsp;many&nbsp;hundreds of clock cycles), giving&nbsp;<br>
them&nbsp;very long&nbsp;interrupt&nbsp;latencies. The BBC micro&nbsp;benefited&nbsp;greatly from&nbsp;the&nbsp;<br>
6502's rapid interrupt&nbsp;response,&nbsp;so&nbsp;Acorn's&nbsp;designers were&nbsp;unwilling&nbsp;to&nbsp;accept&nbsp;a&nbsp;ret-<br>
rograde&nbsp;step in&nbsp;this&nbsp;aspect of&nbsp;the processor's&nbsp;performance.&nbsp;<br>
As a result of&nbsp;these frustrations with&nbsp;the commercial&nbsp;microprocessor offerings,&nbsp;<br>
the design of&nbsp;a proprietary&nbsp;microprocessor&nbsp;was considered. The&nbsp;major stumbling&nbsp;<br>
block&nbsp;was that the&nbsp;Acorn team&nbsp;knew that&nbsp;commercial&nbsp;microprocessor projects&nbsp;had&nbsp;<br>
absorbed hundreds of&nbsp;man-years of design&nbsp;effort.&nbsp;Acorn&nbsp;could not contemplate an&nbsp;<br>
investment&nbsp;on&nbsp;that&nbsp;scale since it&nbsp;was&nbsp;a&nbsp;company of&nbsp;only&nbsp;just over 400&nbsp;employees in&nbsp;<br>
total. It had&nbsp;to&nbsp;produce a better design&nbsp;with&nbsp;a&nbsp;fraction&nbsp;of&nbsp;the design&nbsp;effort, and&nbsp;with&nbsp;<br>
no experience&nbsp;in custom&nbsp;chip&nbsp;design&nbsp;beyond a few small gate arrays&nbsp;designed for&nbsp;<br>
the BBC&nbsp;micro.&nbsp;<br>
Into this&nbsp;apparently&nbsp;impossible scenario, the papers on the Berkeley&nbsp;RISC&nbsp;I fell&nbsp;<br>
like a&nbsp;bolt from&nbsp;the&nbsp;blue. Here was a&nbsp;processor which&nbsp;had been&nbsp;designed by&nbsp;a few&nbsp;<br>
postgraduate&nbsp;students&nbsp;in under&nbsp;a&nbsp;year,&nbsp;yet&nbsp;was competitive with the&nbsp;leading com-<br>
mercial&nbsp;offerings. It&nbsp;was inherently simple,&nbsp;so there&nbsp;were no&nbsp;complex instructions to&nbsp;<br>
ruin the interrupt latency.&nbsp;It&nbsp;also came&nbsp;with supporting arguments that&nbsp;suggested it&nbsp;<br>
could&nbsp;point&nbsp;the way to&nbsp;the future, though&nbsp;technical merit, however well supported&nbsp;by&nbsp;<br>
academic argument,&nbsp;is&nbsp;no guarantee&nbsp;of&nbsp;commercial&nbsp;success.&nbsp;<br>
The ARM, then, was born through a serendipitous combination of factors, and&nbsp;<br>
became&nbsp;the core component&nbsp;in Acorn's product line. Later, after a judicious&nbsp;mod-<br>
ification of the acronym&nbsp;expansion to&nbsp;<b>Advanced RISC Machine,&nbsp;</b>it lent its name&nbsp;<br>
to&nbsp;the&nbsp;company formed&nbsp;to broaden&nbsp;its&nbsp;market&nbsp;beyond&nbsp;Acorn's product range.&nbsp;<br>
Despite the&nbsp;change of&nbsp;name, the architecture still remains close to&nbsp;the original&nbsp;<br>
Acorn design.&nbsp;<br>
<hr>
<A name=49></a><b>Architectural&nbsp;inheritance</b>&nbsp;<br>
<b>37</b>&nbsp;<br>
2.2 &nbsp; Architectural&nbsp;inheritance&nbsp;<br>
At the time&nbsp;the&nbsp;first&nbsp;ARM&nbsp;chip&nbsp;was&nbsp;designed,&nbsp;the&nbsp;only&nbsp;examples&nbsp;of&nbsp;RISC&nbsp;architec-<br>
tures were the Berkeley&nbsp;RISC&nbsp;I&nbsp;and II and the Stanford&nbsp;MIPS (which stands&nbsp;for&nbsp;<br>
<b>Microprocessor&nbsp;without Interlocking Pipeline&nbsp;</b>Stages), although some&nbsp;earlier&nbsp;<br>
machines such&nbsp;as the&nbsp;Digital&nbsp;PDP-8, the Cray-1&nbsp;and the IBM 801, which predated&nbsp;<br>
the RISC&nbsp;concept,&nbsp;shared&nbsp;many of the&nbsp;characteristics&nbsp;which later came&nbsp;to&nbsp;be associ-<br>
ated&nbsp;with&nbsp;RISCs.&nbsp;<br>
Features used&nbsp;<br>
The&nbsp;ARM&nbsp;architecture incorporated&nbsp;a number of&nbsp;features from&nbsp;the&nbsp;Berkeley&nbsp;RISC&nbsp;<br>
design, but a number of&nbsp;other&nbsp;features&nbsp;were&nbsp;rejected. Those that&nbsp;were&nbsp;used were:&nbsp;<br>
•&nbsp;&nbsp;a load-store&nbsp;architecture;&nbsp;<br>
•&nbsp;&nbsp;fixed-length&nbsp;32-bit&nbsp;instructions;&nbsp;<br>
•&nbsp;&nbsp;3-address instruction formats.&nbsp;<br>
Features&nbsp;<br>
The&nbsp;features that&nbsp;were employed on&nbsp;the Berkeley&nbsp;RISC&nbsp;designs which&nbsp;were rejected&nbsp;<br>
rejected&nbsp;<br>
by&nbsp;the&nbsp;ARM&nbsp;designers were:&nbsp;<br>
•&nbsp;Register&nbsp;windows.&nbsp;<br>
The&nbsp;register&nbsp;banks on&nbsp;the Berkeley RISC&nbsp;processors incorporated&nbsp;a large&nbsp;number&nbsp;<br>
of registers, 32&nbsp;of which were visible at&nbsp;any&nbsp;time.&nbsp;Procedure entry&nbsp;and exit&nbsp;<br>
instructions&nbsp;moved the visible&nbsp;'window'&nbsp;to&nbsp;give each&nbsp;procedure&nbsp;access to new&nbsp;<br>
registers, thereby reducing&nbsp;the data traffic between&nbsp;the&nbsp;processor and&nbsp;memory&nbsp;<br>
resulting from&nbsp;register saving&nbsp;and&nbsp;restoring.&nbsp;<br>
The&nbsp;principal problem&nbsp;with register&nbsp;windows is&nbsp;the large&nbsp;chip area occupied by&nbsp;<br>
the&nbsp;large number of&nbsp;registers.&nbsp;This&nbsp;feature was therefore rejected&nbsp;on&nbsp;cost grounds,&nbsp;<br>
although the shadow&nbsp;registers used&nbsp;to handle&nbsp;exceptions&nbsp;on&nbsp;the&nbsp;ARM are&nbsp;not too&nbsp;<br>
different&nbsp;in&nbsp;concept.&nbsp;<br>
In the&nbsp;early days of&nbsp;RISC the register window&nbsp;mechanism&nbsp;was strongly&nbsp;associ-<br>
ated with the&nbsp;RISC idea&nbsp;due&nbsp;to its inclusion in the Berkeley prototypes,&nbsp;but sub-<br>
sequently&nbsp;only&nbsp;the&nbsp;Sun&nbsp;SPARC&nbsp;architecture has adopted&nbsp;it&nbsp;in&nbsp;its&nbsp;original&nbsp;form&nbsp;<br>
•&nbsp;Delayed&nbsp;branches.&nbsp;<br>
Branches&nbsp;cause&nbsp;pipelines&nbsp;problems&nbsp;since&nbsp;they&nbsp;interrupt&nbsp;the smooth flow&nbsp;of&nbsp;instruc-<br>
tions.&nbsp;Most&nbsp;RISC processors&nbsp;ameliorate&nbsp;the problem&nbsp;by&nbsp;using&nbsp;delayed branches&nbsp;<br>
where the&nbsp;branch&nbsp;takes&nbsp;effect&nbsp;<i>after&nbsp;</i>the&nbsp;following&nbsp;instruction has&nbsp;executed.&nbsp;<br>
The problem&nbsp;with&nbsp;delayed branches is&nbsp;that&nbsp;they remove the atomicity&nbsp;of&nbsp;individ-<br>
ual&nbsp;instructions. They&nbsp;work&nbsp;well&nbsp;on&nbsp;single&nbsp;issue&nbsp;pipelined&nbsp;processors,&nbsp;but&nbsp;they&nbsp;do&nbsp;<br>
not scale&nbsp;well&nbsp;to super-scalar&nbsp;implementations and can interact&nbsp;badly&nbsp;with&nbsp;branch&nbsp;<br>
prediction&nbsp;mechanisms.&nbsp;<br>
<hr>
<A name=50></a><b>38&nbsp;</b><br>
<b>The ARM Architecture</b>&nbsp;<br>
On&nbsp;the original&nbsp;ARM&nbsp;delayed branches&nbsp;were&nbsp;not&nbsp;used&nbsp;because they&nbsp;made&nbsp;<br>
exception&nbsp;handling&nbsp;more&nbsp;complex; in the long&nbsp;run this&nbsp;has&nbsp;turned&nbsp;out&nbsp;to be&nbsp;a&nbsp;<br>
good decision since it&nbsp;simplifies re-implementing the architecture&nbsp;with&nbsp;a differ-<br>
ent pipeline.&nbsp;<br>
• Single-cycle&nbsp;execution of&nbsp;all instructions.&nbsp;<br>
Although the&nbsp;ARM executes&nbsp;most data processing instructions in a single clock&nbsp;<br>
cycle,&nbsp;many&nbsp;other instructions&nbsp;take&nbsp;multiple&nbsp;clock cycles.&nbsp;<br>
The rationale here was based on the observation that&nbsp;with a single memory&nbsp;for&nbsp;<br>
both data and instructions, even&nbsp;a&nbsp;simple&nbsp;load&nbsp;or&nbsp;store instruction&nbsp;requires at&nbsp;least&nbsp;<br>
two&nbsp;memory accesses&nbsp;(one for the instruction and one for the data). Therefore&nbsp;<br>
single&nbsp;cycle&nbsp;operation&nbsp;of&nbsp;all&nbsp;instructions is&nbsp;only possible&nbsp;with&nbsp;separate&nbsp;data and&nbsp;<br>
instruction&nbsp;memories,&nbsp;which were considered too expensive for the intended&nbsp;<br>
ARM&nbsp;application areas.&nbsp;<br>
Instead of&nbsp;single-cycle execution&nbsp;of&nbsp;all&nbsp;instructions,&nbsp;the&nbsp;ARM was designed&nbsp;to&nbsp;<br>
use the minimum&nbsp;number of cycles required for&nbsp;memory accesses. Where this&nbsp;<br>
was greater than&nbsp;one, the extra cycles&nbsp;were&nbsp;used,&nbsp;where possible,&nbsp;to&nbsp;do something&nbsp;<br>
useful,&nbsp;such&nbsp;as&nbsp;support auto-indexing&nbsp;addressing&nbsp;modes.&nbsp;This reduces the&nbsp;total&nbsp;<br>
number of&nbsp;ARM instructions required to&nbsp;perform&nbsp;any&nbsp;sequence of operations,&nbsp;<br>
improving performance and code&nbsp;density.&nbsp;<br>
Simplicity&nbsp;<br>
An overriding&nbsp;concern&nbsp;of the original&nbsp;ARM design team&nbsp;was&nbsp;the need to keep the&nbsp;<br>
design&nbsp;simple.&nbsp;Before&nbsp;the&nbsp;first&nbsp;ARM&nbsp;chips,&nbsp;Acorn&nbsp;designers&nbsp;had&nbsp;experience&nbsp;only&nbsp;of&nbsp;<br>
gate arrays&nbsp;with complexities up to&nbsp;around&nbsp;2,000 gates, so the&nbsp;full-custom&nbsp;CMOS&nbsp;<br>
design&nbsp;medium&nbsp;was approached&nbsp;with some respect. When&nbsp;venturing&nbsp;into&nbsp;unknown&nbsp;<br>
territory&nbsp;it is advisable to&nbsp;minimize those&nbsp;risks&nbsp;which are under&nbsp;your control,&nbsp;since&nbsp;<br>
this&nbsp;still&nbsp;leaves significant&nbsp;risks from&nbsp;those factors&nbsp;which are&nbsp;not&nbsp;well understood&nbsp;or&nbsp;<br>
are&nbsp;fundamentally not controllable.&nbsp;<br>
The simplicity&nbsp;of the ARM&nbsp;may&nbsp;be more apparent&nbsp;in&nbsp;the&nbsp;hardware organization and&nbsp;<br>
implementation&nbsp;(described in Chapter 4)&nbsp;than&nbsp;it is&nbsp;in the instruction set architecture.&nbsp;<br>
From&nbsp;the&nbsp;programmer's perspective&nbsp;it&nbsp;is&nbsp;perhaps more visible as&nbsp;a&nbsp;conservatism&nbsp;in&nbsp;the&nbsp;<br>
ARM&nbsp;instruction set&nbsp;design&nbsp;which, while&nbsp;accepting the fundamental&nbsp;precepts&nbsp;of&nbsp;the&nbsp;<br>
RISC approach, is less radical&nbsp;than&nbsp;many&nbsp;subsequent&nbsp;RISC designs.&nbsp;<br>
The combination of the simple hardware with&nbsp;an&nbsp;instruction set that&nbsp;is grounded&nbsp;in&nbsp;<br>
RISC&nbsp;ideas&nbsp;but&nbsp;retains&nbsp;a few&nbsp;key&nbsp;CISC&nbsp;features,&nbsp;and thereby&nbsp;achieves&nbsp;a&nbsp;significantly&nbsp;<br>
better code density&nbsp;than&nbsp;a pure&nbsp;RISC, has given the ARM its power-efficiency&nbsp;and its&nbsp;<br>
small core size.&nbsp;<br>
<hr>
<A name=51></a><IMG src="index-51_1.png"><br>
<b>The ARM&nbsp;programmer's&nbsp;model</b>&nbsp;<br>
<b>39</b>&nbsp;<br>
2.3 &nbsp; The&nbsp;ARM&nbsp;programmer's&nbsp;model&nbsp;<br>
A processor's instruction&nbsp;set&nbsp;defines the operations&nbsp;that the programmer&nbsp;can use to&nbsp;<br>
change the&nbsp;state of the system&nbsp;incorporating the processor.&nbsp;This&nbsp;state usually com-<br>
prises the values of the data items&nbsp;in the processor's visible registers and the sys-<br>
tem's&nbsp;memory. Each instruction can be viewed as performing&nbsp;a defined&nbsp;<br>
transformation&nbsp;from&nbsp;the state&nbsp;before the instruction is executed to the&nbsp;state after it&nbsp;<br>
has&nbsp;completed.&nbsp;Note that although&nbsp;a&nbsp;processor&nbsp;will typically have&nbsp;many&nbsp;invisible&nbsp;<br>
registers involved in executing an instruction, the values of these registers before&nbsp;<br>
and after&nbsp;the instruction&nbsp;is&nbsp;executed&nbsp;are not&nbsp;significant;&nbsp;only the values&nbsp;in&nbsp;the&nbsp;visible&nbsp;<br>
registers&nbsp;have&nbsp;any&nbsp;significance.&nbsp;The&nbsp;visible registers&nbsp;in&nbsp;an&nbsp;ARM&nbsp;processor are&nbsp;shown&nbsp;<br>
in&nbsp;Figure&nbsp;2.1.&nbsp;<br>
When writing&nbsp;user-level&nbsp;programs, only the&nbsp;15&nbsp;general-purpose&nbsp;32-bit&nbsp;registers (r0&nbsp;<br>
to r!4), the program&nbsp;counter (r15) and the current program&nbsp;status register (CPSR)&nbsp;<br>
need&nbsp;be&nbsp;considered.&nbsp;The&nbsp;remaining&nbsp;registers&nbsp;are&nbsp;used&nbsp;only for system-level&nbsp;program-<br>
ming&nbsp;and for&nbsp;handling exceptions&nbsp;(for&nbsp;example, interrupts).&nbsp;<br>
<b>Figure 2.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM's visible&nbsp;registers.<br>
<hr>
<A name=52></a><IMG src="index-52_1.png"><br>
<b>40</b>&nbsp;<br>
<b>The ARM Architecture</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 2.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM CPSR format.&nbsp;<br>
The Current&nbsp;<br>
The&nbsp;CPSR&nbsp;is&nbsp;used&nbsp;in user-level&nbsp;programs&nbsp;to&nbsp;store the condition code bits.&nbsp;These bits&nbsp;<br>
Program&nbsp;Status&nbsp;<br>
are&nbsp;used,&nbsp;for example,&nbsp;to&nbsp;record&nbsp;the&nbsp;result&nbsp;of&nbsp;a comparison&nbsp;operation&nbsp;and to&nbsp;control&nbsp;<br>
Register (CPSR)&nbsp;<br>
whether or&nbsp;not a conditional&nbsp;branch is taken. The user-level programmer need not&nbsp;<br>
usually&nbsp;be concerned&nbsp;with how this&nbsp;register&nbsp;is configured,&nbsp;but for completeness the&nbsp;<br>
register&nbsp;is illustrated&nbsp;in&nbsp;Figure 2.2. The&nbsp;bits&nbsp;at&nbsp;the bottom&nbsp;of the&nbsp;register&nbsp;control&nbsp;the&nbsp;<br>
processor&nbsp;mode&nbsp;(see&nbsp;Section 5.1 on page 106), instruction set ('T', see&nbsp;Section 7.1&nbsp;<br>
on&nbsp;page&nbsp;189)&nbsp;and&nbsp;interrupt&nbsp;enables&nbsp;('I'&nbsp;and 'F',&nbsp;see Section 5.2&nbsp;on page&nbsp;108)&nbsp;and&nbsp;<br>
are protected&nbsp;from&nbsp;change by the&nbsp;user-level&nbsp;program.&nbsp;The&nbsp;condition code&nbsp;flags are in&nbsp;<br>
the&nbsp;top&nbsp;four&nbsp;bits&nbsp;of&nbsp;the&nbsp;register&nbsp;and&nbsp;have&nbsp;the&nbsp;following&nbsp;meanings:&nbsp;<br>
•&nbsp;&nbsp;N: Negative;&nbsp;the last&nbsp;ALU&nbsp;operation which&nbsp;changed&nbsp;the flags produced&nbsp;a&nbsp;negative&nbsp;<br>
result&nbsp;(the top&nbsp;bit of the 32-bit&nbsp;result&nbsp;was a&nbsp;one).&nbsp;<br>
•&nbsp;&nbsp;Z: Zero; the last ALU operation which&nbsp;changed the flags produced a zero result&nbsp;<br>
(every bit&nbsp;of&nbsp;the&nbsp;32-bit&nbsp;result was zero).&nbsp;<br>
•&nbsp;&nbsp;C: Carry; the&nbsp;last&nbsp;ALU operation which changed the&nbsp;flags&nbsp;generated a carry-out,&nbsp;<br>
either&nbsp;as&nbsp;a result&nbsp;of&nbsp;an arithmetic&nbsp;operation&nbsp;in the&nbsp;ALU&nbsp;or&nbsp;from&nbsp;the&nbsp;shifter.&nbsp;<br>
•&nbsp;&nbsp;V: oVerflow;&nbsp;the last&nbsp;arithmetic ALU operation which changed&nbsp;the flags&nbsp;generated&nbsp;<br>
an overflow&nbsp;into&nbsp;the sign bit.&nbsp;<br>
Note that although&nbsp;the above definitions&nbsp;for C and&nbsp;V look&nbsp;quite complex,&nbsp;their use&nbsp;<br>
does&nbsp;not require a detailed&nbsp;understanding&nbsp;of&nbsp;their operation.&nbsp;In&nbsp;most cases&nbsp;there is a&nbsp;<br>
simple condition test which&nbsp;gives the desired&nbsp;result without&nbsp;the programmer having to&nbsp;<br>
work out&nbsp;the&nbsp;precise&nbsp;values&nbsp;of&nbsp;the&nbsp;condition&nbsp;code&nbsp;bits.&nbsp;<br>
The&nbsp;memory&nbsp;<br>
In addition&nbsp;to&nbsp;the&nbsp;processor register state, an ARM system&nbsp;has memory state.&nbsp;<br>
system&nbsp;<br>
Memory&nbsp;may&nbsp;be&nbsp;viewed&nbsp;as&nbsp;a&nbsp;linear array of&nbsp;bytes numbered&nbsp;from&nbsp;zero&nbsp;up&nbsp;to&nbsp;232-l.&nbsp;<br>
Data items&nbsp;may be 8-bit&nbsp;bytes,&nbsp;16-bit&nbsp;half-words&nbsp;or&nbsp;32-bit&nbsp;words. Words&nbsp;are&nbsp;always&nbsp;<br>
aligned on&nbsp;4-byte boundaries (that is, the&nbsp;two&nbsp;least significant&nbsp;address bits are zero)&nbsp;<br>
and half-words&nbsp;are&nbsp;aligned&nbsp;on&nbsp;even&nbsp;byte boundaries.&nbsp;<br>
The&nbsp;memory&nbsp;organization is illustrated in&nbsp;Figure 2.3 on&nbsp;page 41. This&nbsp;shows a&nbsp;<br>
small&nbsp;area&nbsp;of&nbsp;memory&nbsp;where each&nbsp;byte&nbsp;location has a unique number.&nbsp;A byte&nbsp;may&nbsp;<br>
occupy&nbsp;any&nbsp;of these&nbsp;locations,&nbsp;and&nbsp;a few&nbsp;examples are&nbsp;shown&nbsp;in&nbsp;the&nbsp;figure.&nbsp;A&nbsp;<br>
word-sized&nbsp;data item&nbsp;must occupy&nbsp;a group&nbsp;of&nbsp;four byte locations&nbsp;starting&nbsp;at a&nbsp;byte&nbsp;<br>
address&nbsp;which is&nbsp;a multiple&nbsp;of four, and&nbsp;again&nbsp;the figure&nbsp;contains&nbsp;a&nbsp;couple&nbsp;of&nbsp;<br>
examples. Half-words&nbsp;occupy&nbsp;two byte&nbsp;locations starting&nbsp;at&nbsp;an&nbsp;even&nbsp;byte&nbsp;address.&nbsp;<br>
<hr>
<A name=53></a><IMG src="index-53_1.png"><br>
<b>The&nbsp;ARM programmer's model</b>&nbsp;<br>
<b>41</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 2.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM memory&nbsp;organization.&nbsp;<br>
(This is&nbsp;the&nbsp;standard, 'little-endian',&nbsp;memory&nbsp;organization used&nbsp;by&nbsp;the ARM.&nbsp;ARM&nbsp;<br>
can&nbsp;also&nbsp;be configured&nbsp;to&nbsp;work with&nbsp;a 'big-endian'&nbsp;memory&nbsp;organization; we will&nbsp;<br>
return&nbsp;to&nbsp;this&nbsp;issue&nbsp;in&nbsp;Chapter 5.)&nbsp;<br>
Load-store&nbsp;<br>
In&nbsp;common with most RISC&nbsp;processors,&nbsp;ARM employs&nbsp;a load-store architecture.&nbsp;<br>
architecture&nbsp;<br>
This means that&nbsp;the&nbsp;instruction&nbsp;set will&nbsp;only&nbsp;process&nbsp;(add,&nbsp;subtract,&nbsp;and&nbsp;so&nbsp;on)&nbsp;<br>
values&nbsp;which are in&nbsp;registers&nbsp;(or specified directly&nbsp;within&nbsp;the instruction&nbsp;itself), and&nbsp;<br>
will&nbsp;always place the&nbsp;results of&nbsp;such&nbsp;processing&nbsp;into&nbsp;a&nbsp;register.&nbsp;The only&nbsp;operations&nbsp;<br>
which apply to&nbsp;memory state are ones which copy&nbsp;memory&nbsp;values into&nbsp;registers&nbsp;<br>
(load&nbsp;instructions) or copy&nbsp;register values into memory (store&nbsp;instructions).&nbsp;<br>
CISC processors&nbsp;typically allow&nbsp;a value&nbsp;from&nbsp;memory&nbsp;to&nbsp;be&nbsp;added to&nbsp;a&nbsp;value in&nbsp;a&nbsp;<br>
register,&nbsp;and sometimes allow&nbsp;a value in&nbsp;a register&nbsp;to&nbsp;be added to&nbsp;a&nbsp;value&nbsp;in memory.&nbsp;<br>
ARM&nbsp;does&nbsp;not support such 'memory-to-memory'&nbsp;operations. Therefore&nbsp;all ARM&nbsp;<br>
instructions&nbsp;fall&nbsp;into&nbsp;one&nbsp;of&nbsp;the following three&nbsp;categories:&nbsp;<br>
1.&nbsp;&nbsp;Data&nbsp;processing instructions. These&nbsp;use and change&nbsp;only&nbsp;register&nbsp;values. For&nbsp;<br>
example, an instruction&nbsp;can add&nbsp;two&nbsp;registers and&nbsp;place the result&nbsp;in&nbsp;a register.&nbsp;<br>
2.&nbsp;&nbsp;Data transfer&nbsp;instructions. These copy&nbsp;memory&nbsp;values into registers (load&nbsp;<br>
instructions) or copy&nbsp;register values into memory&nbsp;(store instructions).&nbsp;An addi&nbsp;<br>
tional form,&nbsp;useful&nbsp;only&nbsp;in systems code,&nbsp;exchanges a memory&nbsp;value with&nbsp;a reg&nbsp;<br>
ister value.&nbsp;<br>
3.&nbsp;&nbsp;Control flow instructions.&nbsp;Normal instruction execution uses instructions stored&nbsp;<br>
at consecutive memory addresses. Control flow instructions cause execution to&nbsp;<br>
switch to a different address, either permanently&nbsp;(branch instructions) or&nbsp;saving&nbsp;<br>
a return address to resume&nbsp;the original sequence (branch&nbsp;and link instructions)&nbsp;<br>
or trapping&nbsp;into&nbsp;system&nbsp;code (supervisor calls).&nbsp;<br>
<hr>
<A name=54></a><b>42</b>&nbsp;<br>
<b>The ARM Architecture</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Supervisor mode&nbsp;&nbsp;The ARM processor&nbsp;supports a protected&nbsp;supervisor&nbsp;mode. The protection&nbsp;mecha-<br>
nism&nbsp;ensures&nbsp;that&nbsp;user code cannot&nbsp;gain&nbsp;supervisor privileges&nbsp;without appropriate&nbsp;<br>
checks being carried out&nbsp;to ensure that&nbsp;the&nbsp;code is not attempting illegal operations.&nbsp;<br>
The upshot&nbsp;of&nbsp;this&nbsp;for the user-level&nbsp;programmer&nbsp;is that system-level functions can&nbsp;<br>
only&nbsp;be&nbsp;accessed through specified supervisor calls. These&nbsp;functions generally&nbsp;include&nbsp;<br>
any&nbsp;accesses&nbsp;to&nbsp;hardware&nbsp;peripheral&nbsp;registers, and&nbsp;to widely&nbsp;used&nbsp;operations&nbsp;such&nbsp;as&nbsp;<br>
character&nbsp;input&nbsp;and output.&nbsp;User-level&nbsp;programmers are&nbsp;principally&nbsp;concerned with&nbsp;<br>
devising&nbsp;algorithms&nbsp;to&nbsp;operate on&nbsp;the&nbsp;data 'owned'&nbsp;by&nbsp;their&nbsp;programs, and&nbsp;rely&nbsp;on&nbsp;the&nbsp;<br>
operating system&nbsp;to handle all&nbsp;transactions with the world outside their&nbsp;programs. The&nbsp;<br>
instructions&nbsp;which request operating system&nbsp;functions are covered in&nbsp;'Supervisor&nbsp;<br>
calls'&nbsp;on&nbsp;page&nbsp;67.&nbsp;<br>
The ARM&nbsp;<br>
All ARM instructions are 32&nbsp;bits wide (except the compressed 16-bit Thumb&nbsp;<br>
instruction set&nbsp;<br>
instructions&nbsp;which are described in&nbsp;Chapter 7)&nbsp;and&nbsp;are aligned on&nbsp;4-byte&nbsp;boundaries&nbsp;<br>
in&nbsp;memory.&nbsp;Basic&nbsp;use&nbsp;of&nbsp;the&nbsp;instruction&nbsp;set&nbsp;is&nbsp;described&nbsp;in&nbsp;Chapter&nbsp;3&nbsp;and&nbsp;full&nbsp;details,&nbsp;<br>
including the&nbsp;binary&nbsp;instruction formats, are given in Chapter 5.&nbsp;The&nbsp;most notable&nbsp;<br>
features&nbsp;of&nbsp;the ARM instruction&nbsp;set&nbsp;are:&nbsp;<br>
•&nbsp;&nbsp;The load-store&nbsp;architecture;&nbsp;<br>
•&nbsp;&nbsp;3-address data processing instructions&nbsp;(that&nbsp;is, the two source operand registers&nbsp;<br>
and the&nbsp;result&nbsp;register are all independently&nbsp;specified);&nbsp;<br>
•&nbsp;&nbsp;conditional execution of&nbsp;every&nbsp;instruction;&nbsp;<br>
•&nbsp;&nbsp;the inclusion of&nbsp;very powerful&nbsp;load and&nbsp;store&nbsp;multiple&nbsp;register&nbsp;instructions;&nbsp;<br>
•&nbsp;&nbsp;the ability&nbsp;to perform&nbsp;a general shift operation and a general ALU operation in a&nbsp;<br>
single instruction that executes in a&nbsp;single clock cycle;&nbsp;<br>
•&nbsp;&nbsp;open instruction set extension through the coprocessor instruction set, including&nbsp;<br>
adding&nbsp;new&nbsp;registers and data types to&nbsp;the programmer's&nbsp;model;&nbsp;<br>
•&nbsp;&nbsp;a&nbsp;very&nbsp;dense&nbsp;16-bit compressed&nbsp;representation&nbsp;of&nbsp;the instruction&nbsp;set in the&nbsp;Thumb&nbsp;<br>
architecture.&nbsp;<br>
To&nbsp;those readers familiar with&nbsp;modern&nbsp;RISC&nbsp;instruction sets,&nbsp;the ARM&nbsp;instruction&nbsp;<br>
set may appear&nbsp;to have rather&nbsp;more formats than other commercial&nbsp;RISC&nbsp;processors.&nbsp;<br>
While&nbsp;this&nbsp;is&nbsp;certainly the&nbsp;case&nbsp;and&nbsp;it&nbsp;does&nbsp;lead&nbsp;to&nbsp;more&nbsp;complex&nbsp;instruction decoding,&nbsp;<br>
it&nbsp;also&nbsp;leads&nbsp;to&nbsp;higher code&nbsp;density. For the small embedded&nbsp;systems that&nbsp;most ARM&nbsp;<br>
processors are&nbsp;used in,&nbsp;this&nbsp;code&nbsp;density&nbsp;advantage&nbsp;outweighs the small performance&nbsp;<br>
penalty&nbsp;incurred by&nbsp;the decode complexity. Thumb&nbsp;code&nbsp;extends&nbsp;this advantage to&nbsp;<br>
give&nbsp;ARM&nbsp;better code&nbsp;density&nbsp;than&nbsp;most CISC processors.&nbsp;<br>
The&nbsp;I/O&nbsp;system&nbsp;<br>
The ARM handles&nbsp;I/O (input/output) peripherals (such as&nbsp;disk controllers, network&nbsp;<br>
interfaces, and so&nbsp;on)&nbsp;as memory-mapped&nbsp;devices&nbsp;with&nbsp;interrupt support. The inter-<br>
nal registers&nbsp;in&nbsp;these&nbsp;devices appear&nbsp;as&nbsp;addressable&nbsp;locations&nbsp;within&nbsp;the&nbsp;ARM's&nbsp;<br>
<hr>
<A name=55></a><b>ARM&nbsp;development tools&nbsp;</b><br>
<b>43</b>&nbsp;<br>
memory&nbsp;map&nbsp;and&nbsp;may be&nbsp;read and written using the same (load-store)&nbsp;instructions&nbsp;<br>
as any other&nbsp;memory&nbsp;locations.&nbsp;<br>
Peripherals&nbsp;may&nbsp;attract the processor's attention by&nbsp;making an interrupt request&nbsp;<br>
using either the&nbsp;normal interrupt&nbsp;<i>(IRQ)&nbsp;&nbsp;</i>or the fast&nbsp;interrupt&nbsp;<i>(FIQ)&nbsp;&nbsp;</i>input. Both&nbsp;<br>
interrupt&nbsp;inputs are level-sensitive and&nbsp;maskable.&nbsp;Normally&nbsp;most&nbsp;interrupt sources&nbsp;<br>
share the&nbsp;IRQ input, with just one or two time-critical&nbsp;sources connected to the&nbsp;<br>
higher-priority FIQ input.&nbsp;<br>
Some&nbsp;systems&nbsp;may include&nbsp;direct memory&nbsp;access (DMA) hardware external to&nbsp;the&nbsp;<br>
processor to handle high-bandwidth&nbsp;I/O traffic. This&nbsp;is discussed&nbsp;further in&nbsp;<br>
Section 11.9 on&nbsp;page 312.&nbsp;<br>
Interrupts are a form&nbsp;<i>of&nbsp;exception&nbsp;</i>and are handled as outlined&nbsp;below.&nbsp;<br>
ARM exceptions&nbsp;<br>
The&nbsp;ARM&nbsp;architecture&nbsp;supports a&nbsp;range of&nbsp;interrupts, traps and&nbsp;supervisor calls,&nbsp;all&nbsp;<br>
grouped under the general heading of exceptions.&nbsp;The general&nbsp;way these are handled&nbsp;<br>
is&nbsp;the&nbsp;same&nbsp;in&nbsp;all cases:&nbsp;<br>
1.&nbsp;&nbsp;The current&nbsp;state is saved by copying the&nbsp;PC into&nbsp;<i>rl4_exc&nbsp;</i>and the CPSR&nbsp;into&nbsp;<br>
SPSR_exc (where&nbsp;<i>exc&nbsp;</i>stands&nbsp;for the&nbsp;exception&nbsp;type).&nbsp;<br>
2.&nbsp;&nbsp;The processor&nbsp;operating&nbsp;mode&nbsp;is changed to the appropriate&nbsp;exception&nbsp;mode.&nbsp;<br>
3.&nbsp;&nbsp;The PC is forced to a&nbsp;value&nbsp;between 0016&nbsp;and&nbsp;1C16, the&nbsp;particular value&nbsp;depending&nbsp;<br>
on&nbsp;the type&nbsp;of&nbsp;exception.&nbsp;<br>
The&nbsp;instruction at&nbsp;the&nbsp;location the PC&nbsp;is&nbsp;forced&nbsp;to (the&nbsp;<i>vector&nbsp;address)&nbsp;</i>will&nbsp;usually&nbsp;<br>
contain&nbsp;a branch to the&nbsp;exception&nbsp;handler.&nbsp;The exception&nbsp;handler&nbsp;will use&nbsp;rl3_exc,&nbsp;<br>
which&nbsp;will&nbsp;normally&nbsp;have been&nbsp;initialized to&nbsp;point to&nbsp;a dedicated&nbsp;stack&nbsp;in&nbsp;memory,&nbsp;to&nbsp;<br>
save some&nbsp;user registers for use as work registers.&nbsp;<br>
The&nbsp;return&nbsp;to the&nbsp;user&nbsp;program&nbsp;is achieved&nbsp;by restoring&nbsp;the user registers&nbsp;and&nbsp;then&nbsp;<br>
using an&nbsp;instruction to&nbsp;restore the&nbsp;PC&nbsp;and&nbsp;the CPSR atomically.&nbsp;This&nbsp;may involve&nbsp;<br>
some&nbsp;adjustment&nbsp;of&nbsp;the PC&nbsp;value saved&nbsp;in&nbsp;<i>rl4_exc&nbsp;</i>to&nbsp;compensate&nbsp;for&nbsp;the state of&nbsp;the&nbsp;<br>
pipeline&nbsp;when&nbsp;the exception&nbsp;arose.&nbsp;This&nbsp;is&nbsp;described&nbsp;in&nbsp;more detail&nbsp;in&nbsp;Section&nbsp;5.2&nbsp;on&nbsp;<br>
page 108.&nbsp;<br>
2.4 &nbsp; ARM&nbsp;development&nbsp;tools&nbsp;<br>
Software&nbsp;development for the&nbsp;ARM&nbsp;is&nbsp;supported&nbsp;by&nbsp;a coherent&nbsp;range of&nbsp;tools&nbsp;devel-<br>
oped&nbsp;by&nbsp;ARM&nbsp;Limited, and&nbsp;there are also&nbsp;many&nbsp;third&nbsp;party&nbsp;and&nbsp;public domain&nbsp;tools&nbsp;<br>
available,&nbsp;such&nbsp;as&nbsp;an&nbsp;ARM back-end&nbsp;for the&nbsp;<i>gcc C&nbsp;</i>compiler.&nbsp;<br>
Since the&nbsp;ARM is&nbsp;widely used&nbsp;as&nbsp;an&nbsp;embedded&nbsp;controller&nbsp;where the&nbsp;target&nbsp;hard-<br>
ware will&nbsp;not make&nbsp;a&nbsp;good environment for&nbsp;software development,&nbsp;the tools are&nbsp;<br>
intended&nbsp;for&nbsp;<b>cross-development&nbsp;</b>(that&nbsp;is, they run on a&nbsp;different architecture&nbsp;from&nbsp;the&nbsp;<br>
<hr>
<A name=56></a><IMG src="index-56_1.png"><br>
<b>44</b>&nbsp;<br>
<b>The ARM Architecture</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
one for which&nbsp;they&nbsp;produce code) from&nbsp;a platform&nbsp;such as a PC running Windows or a&nbsp;<br>
suitable&nbsp;UNIX workstation.&nbsp;The overall&nbsp;structure of&nbsp;the&nbsp;ARM cross-development&nbsp;<br>
toolkit&nbsp;is&nbsp;shown&nbsp;in&nbsp;Figure&nbsp;2.4.&nbsp;C&nbsp;or&nbsp;assembler source&nbsp;files&nbsp;are&nbsp;compiled&nbsp;or&nbsp;assembled&nbsp;<br>
into&nbsp;ARM&nbsp;object&nbsp;format&nbsp;<i>(.aof)&nbsp;</i>files, which&nbsp;are then&nbsp;linked into&nbsp;ARM image format&nbsp;<br>
<i>(.aif)&nbsp;</i>files.&nbsp;The&nbsp;image&nbsp;format&nbsp;files&nbsp;can be&nbsp;built&nbsp;to&nbsp;include&nbsp;the debug tables required by&nbsp;<br>
the ARM symbolic debugger (ARMsd which can load, run and debug&nbsp;programs&nbsp;<br>
either on&nbsp;hardware such&nbsp;as&nbsp;the ARM Development Board or using&nbsp;a software emula-<br>
tion&nbsp;of&nbsp;the&nbsp;ARM&nbsp;(the&nbsp;ARMulator). The&nbsp;ARMulator has been&nbsp;designed&nbsp;to&nbsp;allow easy&nbsp;<br>
extension of the&nbsp;software&nbsp;model to&nbsp;include system&nbsp;features&nbsp;such as&nbsp;caches,&nbsp;particular&nbsp;<br>
memory&nbsp;timing&nbsp;characteristics, and so&nbsp;on.&nbsp;<br>
The ARM C&nbsp;<br>
The ARM&nbsp;C&nbsp;compiler&nbsp;is&nbsp;compliant&nbsp;with&nbsp;the ANSI (American National Standards&nbsp;<br>
compiler&nbsp;<br>
Institute)&nbsp;standard for C and is supported&nbsp;by&nbsp;the appropriate library&nbsp;of standard&nbsp;<br>
functions. It&nbsp;uses the ARM Procedure&nbsp;Call&nbsp;Standard&nbsp;(see Section 6.8 on&nbsp;page 175)&nbsp;<br>
for all externally&nbsp;available functions. It can be told&nbsp;to&nbsp;produce assembly&nbsp;source&nbsp;<br>
output instead&nbsp;of&nbsp;ARM&nbsp;object&nbsp;format,&nbsp;so&nbsp;the code&nbsp;can&nbsp;be&nbsp;inspected, or&nbsp;even&nbsp;hand&nbsp;<br>
optimized, and then assembled&nbsp;subsequently.&nbsp;The&nbsp;compiler&nbsp;can&nbsp;also&nbsp;produce&nbsp;Thumb&nbsp;<br>
code.&nbsp;<br>
&nbsp;<br>
Figure&nbsp;2.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;structure of&nbsp;the ARM&nbsp;cross-development&nbsp;toolkit.&nbsp;<br>
<hr>
<A name=57></a><b>ARM development&nbsp;tools</b>&nbsp;<br>
<b>45</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;The ARM&nbsp;<br>
The ARM&nbsp;assembler&nbsp;is&nbsp;a&nbsp;full&nbsp;macro assembler&nbsp;which&nbsp;produces&nbsp;ARM&nbsp;object&nbsp;format&nbsp;<br>
assembler&nbsp;<br>
output&nbsp;that can be linked with&nbsp;output from&nbsp;the&nbsp;C&nbsp;compiler.&nbsp;<br>
Assembly&nbsp;source language is&nbsp;near machine-level,&nbsp;with&nbsp;most assembly&nbsp;instructions&nbsp;<br>
translating&nbsp;into&nbsp;single&nbsp;ARM (or Thumb) instructions. ARM&nbsp;assembly language&nbsp;pro-<br>
gramming is introduced&nbsp;in&nbsp;the next&nbsp;chapter,&nbsp;and&nbsp;the full&nbsp;details of&nbsp;the ARM&nbsp;instruc-<br>
tion&nbsp;set, including&nbsp;assembly language&nbsp;formats, are given in&nbsp;Chapter&nbsp;<i>5.&nbsp;</i>The Thumb&nbsp;<br>
instruction&nbsp;set and assembly&nbsp;language&nbsp;formats are given&nbsp;in&nbsp;Chapter&nbsp;7.&nbsp;<br>
The&nbsp;linker&nbsp;<br>
The&nbsp;linker takes&nbsp;one&nbsp;or&nbsp;more&nbsp;object&nbsp;files and combines them&nbsp;into an&nbsp;executable&nbsp;pro-<br>
gram. It resolves symbolic references&nbsp;between&nbsp;the object files and&nbsp;extracts object&nbsp;<br>
modules&nbsp;from&nbsp;libraries&nbsp;as&nbsp;needed&nbsp;by&nbsp;the&nbsp;program.&nbsp;It&nbsp;can&nbsp;assemble&nbsp;the&nbsp;various&nbsp;com-<br>
ponents of the program&nbsp;in&nbsp;a&nbsp;number of&nbsp;different&nbsp;ways, depending on whether the&nbsp;<br>
code&nbsp;is to run&nbsp;in&nbsp;RAM&nbsp;(Random&nbsp;Access&nbsp;Memory,&nbsp;which&nbsp;can&nbsp;be&nbsp;read&nbsp;and written) or&nbsp;<br>
ROM (Read Only&nbsp;Memory),&nbsp;whether&nbsp;overlays are required,&nbsp;and so&nbsp;on.&nbsp;<br>
Normally the linker includes debug tables&nbsp;in the output file. If&nbsp;the object files were&nbsp;<br>
compiled&nbsp;with full&nbsp;debug information,&nbsp;this&nbsp;will&nbsp;include&nbsp;full symbolic debug&nbsp;tables&nbsp;(so&nbsp;<br>
the&nbsp;program&nbsp;can&nbsp;be&nbsp;debugged&nbsp;using&nbsp;the&nbsp;variable&nbsp;names in&nbsp;the source&nbsp;program). The&nbsp;<br>
linker can&nbsp;also&nbsp;produce object library&nbsp;modules&nbsp;that are not&nbsp;executable but are ready&nbsp;<br>
for efficient linking&nbsp;with&nbsp;object&nbsp;files&nbsp;in&nbsp;the&nbsp;future.&nbsp;<br>
ARMsd&nbsp;<br>
The ARM&nbsp;symbolic debugger is a&nbsp;front-end interface to&nbsp;assist in debugging pro-<br>
grams&nbsp;running&nbsp;either under emulation&nbsp;(on the ARMulator) or&nbsp;remotely&nbsp;on a target&nbsp;<br>
system&nbsp;such&nbsp;as the&nbsp;ARM development board.&nbsp;The&nbsp;remote system&nbsp;must support the&nbsp;<br>
appropriate remote debug&nbsp;protocols&nbsp;either&nbsp;via a serial&nbsp;line or&nbsp;through&nbsp;a&nbsp;JTAG test&nbsp;<br>
interface (see&nbsp;Section 8.6 on&nbsp;page 226).&nbsp;Debugging a system&nbsp;where the processor&nbsp;<br>
core&nbsp;is&nbsp;embedded within an&nbsp;application-specific system&nbsp;chip&nbsp;is&nbsp;a complex issue&nbsp;that&nbsp;<br>
we will&nbsp;return to&nbsp;in&nbsp;Chapter&nbsp;8.&nbsp;<br>
At&nbsp;its&nbsp;most&nbsp;basic,&nbsp;ARMsd allows an executable&nbsp;program&nbsp;to&nbsp;be&nbsp;loaded&nbsp;into the&nbsp;<br>
ARMulator or a development board and&nbsp;run. It allows the setting of breakpoints,&nbsp;<br>
which are addresses in&nbsp;the code&nbsp;that, if&nbsp;executed,&nbsp;cause execution&nbsp;to&nbsp;halt&nbsp;so&nbsp;that&nbsp;the&nbsp;<br>
processor&nbsp;state can be examined.&nbsp;In the&nbsp;ARMulator,&nbsp;or&nbsp;when running&nbsp;on&nbsp;hardware&nbsp;<br>
with appropriate support,&nbsp;it also&nbsp;allows&nbsp;the setting of watchpoints. These are&nbsp;memory&nbsp;<br>
addresses that,&nbsp;if accessed&nbsp;as data&nbsp;addresses,&nbsp;cause&nbsp;execution&nbsp;to&nbsp;halt&nbsp;in&nbsp;a&nbsp;similar way.&nbsp;<br>
At a more sophisticated&nbsp;level&nbsp;ARMsd supports full&nbsp;source&nbsp;level&nbsp;debugging,&nbsp;allow-<br>
ing&nbsp;the C programmer to debug&nbsp;a program&nbsp;using&nbsp;the source&nbsp;file to&nbsp;specify&nbsp;breakpoints&nbsp;<br>
and using variable&nbsp;names&nbsp;from&nbsp;the&nbsp;original&nbsp;program.&nbsp;<br>
ARMulator&nbsp;<br>
The ARMulator&nbsp;<i>(ARM&nbsp;emulator)&nbsp;</i>is&nbsp;a&nbsp;suite&nbsp;of&nbsp;programs&nbsp;that&nbsp;models&nbsp;the&nbsp;behaviour&nbsp;of&nbsp;<br>
various ARM&nbsp;processor&nbsp;cores in software&nbsp;on&nbsp;a&nbsp;host system.&nbsp;It&nbsp;can&nbsp;operate at various&nbsp;<br>
levels of accuracy:&nbsp;<br>
<hr>
<A name=58></a>46&nbsp;<br>
<b>The ARM Architecture</b>&nbsp;<br>
•&nbsp;&nbsp;<i>Instruction-accurate&nbsp;</i>modelling gives the exact behaviour of the&nbsp;system&nbsp;state&nbsp;<br>
without&nbsp;regard&nbsp;to the precise&nbsp;timing characteristics of&nbsp;the&nbsp;processor.&nbsp;<br>
•&nbsp;&nbsp;<i>Cycle-accurate&nbsp;</i>modelling gives the exact behaviour&nbsp;of the processor on a cycle-&nbsp;<br>
by-cycle&nbsp;basis,&nbsp;allowing&nbsp;the&nbsp;exact&nbsp;number&nbsp;of&nbsp;clock cycles that&nbsp;a program&nbsp;requires&nbsp;<br>
to&nbsp;be established.&nbsp;<br>
•&nbsp;&nbsp;<i>Timing-accurate&nbsp;</i>modelling&nbsp;presents signals at&nbsp;the correct time&nbsp;within&nbsp;a cycle,&nbsp;<br>
allowing logic delays&nbsp;to be accounted for.&nbsp;<br>
All these&nbsp;approaches run&nbsp;considerably&nbsp;slower&nbsp;than&nbsp;the real hardware,&nbsp;but the&nbsp;first&nbsp;<br>
incurs&nbsp;the&nbsp;smallest&nbsp;speed penalty&nbsp;and&nbsp;is&nbsp;best&nbsp;suited&nbsp;to software development.&nbsp;<br>
At its simplest, the ARMulator allows&nbsp;an ARM program developed&nbsp;using&nbsp;the&nbsp;C&nbsp;<br>
compiler or&nbsp;assembler to&nbsp;be tested and debugged on a host&nbsp;machine&nbsp;with no ARM&nbsp;<br>
processor connected. It allows the&nbsp;number&nbsp;of&nbsp;clock&nbsp;cycles the&nbsp;program&nbsp;takes to&nbsp;exe-<br>
cute to be measured exactly, so the performance of the target&nbsp;system&nbsp;can be evaluated.&nbsp;<br>
At&nbsp;its&nbsp;most complex,&nbsp;the&nbsp;ARMulator can be&nbsp;used as&nbsp;the centre of&nbsp;a&nbsp;complete,&nbsp;<br>
timing-accurate, C&nbsp;model of the target system, with&nbsp;full&nbsp;details of the&nbsp;cache and&nbsp;<br>
memory&nbsp;management functions added, running&nbsp;an&nbsp;operating&nbsp;system.&nbsp;<br>
In between these two&nbsp;extremes the ARMulator comes with&nbsp;a set&nbsp;of&nbsp;model&nbsp;prototyp-<br>
ing&nbsp;modules&nbsp;including&nbsp;a rapid&nbsp;prototype&nbsp;memory&nbsp;model&nbsp;and&nbsp;coprocessor&nbsp;interfacing&nbsp;<br>
support. (There&nbsp;is more&nbsp;detail&nbsp;on&nbsp;this&nbsp;in&nbsp;Section&nbsp;8.5&nbsp;on&nbsp;page&nbsp;225.)&nbsp;<br>
The ARMulator can also be used as the core of a timing-accurate ARM&nbsp;behav-<br>
ioural&nbsp;model in&nbsp;a hardware simulation environment based around a language such&nbsp;<br>
as&nbsp;VHDL.&nbsp;(VHDL is a standard,&nbsp;widely supported&nbsp;hardware description language.)&nbsp;<br>
A&nbsp;VHDL&nbsp;'wrapper'&nbsp;must&nbsp;be&nbsp;generated to interface&nbsp;the&nbsp;ARMulator C code to the&nbsp;<br>
VHDL environment.&nbsp;<br>
ARM&nbsp;<br>
The&nbsp;ARM&nbsp;Development&nbsp;Board is&nbsp;a circuit&nbsp;board&nbsp;incorporating&nbsp;a&nbsp;range&nbsp;of compo-<br>
development&nbsp;<br>
nents&nbsp;and interfaces&nbsp;to support the&nbsp;development&nbsp;of&nbsp;ARM-based systems. It&nbsp;includes&nbsp;<br>
board&nbsp;<br>
an&nbsp;ARM&nbsp;core&nbsp;(for example,&nbsp;an&nbsp;ARM7TDMI),&nbsp;memory&nbsp;components&nbsp;which&nbsp;can&nbsp;be&nbsp;<br>
configured to match the performance and bus-width of&nbsp;the&nbsp;memory in&nbsp;the&nbsp;target&nbsp;sys-<br>
tem,&nbsp;and electrically&nbsp;programmable devices&nbsp;which can&nbsp;be configured&nbsp;to emulate&nbsp;<br>
application-specific&nbsp;peripherals. It can support both hardware&nbsp;and software&nbsp;develop-<br>
ment&nbsp;before the&nbsp;final application-specific&nbsp;hardware is&nbsp;available.&nbsp;<br>
Software&nbsp;Toolkit&nbsp;<br>
ARM Limited&nbsp;supplies the&nbsp;complete set&nbsp;of tools&nbsp;described&nbsp;above, with&nbsp;some&nbsp;support&nbsp;<br>
utility programs&nbsp;and documentation,&nbsp;as the&nbsp;'ARM&nbsp;Software&nbsp;Development Toolkit'.&nbsp;<br>
The&nbsp;Toolkit CD-ROM includes a&nbsp;PC&nbsp;version of the&nbsp;toolset&nbsp;that&nbsp;runs under&nbsp;most ver-<br>
sions&nbsp;of&nbsp;the Windows&nbsp;operating system&nbsp;and includes&nbsp;a full Windows-based&nbsp;project&nbsp;<br>
manager. The&nbsp;toolkit is&nbsp;updated as&nbsp;new versions of&nbsp;the&nbsp;ARM&nbsp;become&nbsp;available.&nbsp;<br>
The ARM&nbsp;Project&nbsp;Manager&nbsp;is&nbsp;a graphical front-end&nbsp;for the&nbsp;tools&nbsp;described&nbsp;above. It&nbsp;<br>
supports&nbsp;the&nbsp;building of a single&nbsp;library&nbsp;or&nbsp;executable&nbsp;image from&nbsp;a list&nbsp;of&nbsp;files that&nbsp;<br>
make up&nbsp;a&nbsp;particular&nbsp;project. These files may&nbsp;be:&nbsp;<br>
<hr>
<A name=59></a><b>exercises</b>&nbsp;<br>
<b>47</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
•&nbsp;&nbsp;source files&nbsp;(C, assembler,&nbsp;and&nbsp;so&nbsp;on);&nbsp;<br>
•&nbsp;&nbsp;object&nbsp;files;&nbsp;<br>
•&nbsp;&nbsp;library files.&nbsp;<br>
The&nbsp;source&nbsp;files may be&nbsp;edited&nbsp;within&nbsp;the&nbsp;Project&nbsp;Manager,&nbsp;a&nbsp;dependency&nbsp;list&nbsp;cre-<br>
ated&nbsp;and&nbsp;the&nbsp;output&nbsp;library or&nbsp;executable&nbsp;image&nbsp;built.&nbsp;There&nbsp;are&nbsp;many options&nbsp;which&nbsp;<br>
may&nbsp;be chosen&nbsp;for the&nbsp;build, such as:&nbsp;<br>
•&nbsp;&nbsp;Whether the output should be&nbsp;optimized&nbsp;for code size or&nbsp;execution time.&nbsp;<br>
•&nbsp;&nbsp;Whether the output should be&nbsp;in debug or&nbsp;release form.&nbsp;<br>
(Code compiled for source-level debugging&nbsp;cannot be&nbsp;fully&nbsp;optimized since the&nbsp;<br>
mapping&nbsp;from&nbsp;the source to&nbsp;fully optimized output is too&nbsp;obscure&nbsp;for debugging&nbsp;<br>
purposes.)&nbsp;<br>
•&nbsp;&nbsp;Which ARM&nbsp;processor is&nbsp;the target (and,&nbsp;particularly, whether it&nbsp;supports the&nbsp;<br>
Thumb instruction set).&nbsp;<br>
The&nbsp;CD-ROM&nbsp;also&nbsp;contains&nbsp;versions&nbsp;of&nbsp;the&nbsp;tools&nbsp;that run&nbsp;on&nbsp;a&nbsp;Sun&nbsp;or HP&nbsp;UNIX&nbsp;<br>
host, where a command-line interface is used. All versions have on-line help&nbsp;available.&nbsp;<br>
JumpStart&nbsp;<br>
The JumpStart&nbsp;tools from&nbsp;VLSI Technology,&nbsp;Inc.,&nbsp;include the same&nbsp;basic&nbsp;set&nbsp;of&nbsp;<br>
development tools but present a&nbsp;full&nbsp;X-windows interface&nbsp;on a suitable&nbsp;workstation&nbsp;<br>
rather&nbsp;than the&nbsp;command-line&nbsp;interface of&nbsp;the&nbsp;standard&nbsp;ARM toolkit. There&nbsp;are&nbsp;many&nbsp;<br>
other suppliers&nbsp;of tools&nbsp;that support ARM&nbsp;development.&nbsp;<br>
2.5 &nbsp; Example&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example&nbsp;2.1&nbsp;</b><br>
<b>Describe&nbsp;the&nbsp;principal&nbsp;features&nbsp;of the ARM&nbsp;architecture.</b>&nbsp;<br>
The main&nbsp;features&nbsp;of&nbsp;the&nbsp;ARM&nbsp;architecture&nbsp;are:&nbsp;<br>
•&nbsp;&nbsp;a large&nbsp;set of&nbsp;registers, all&nbsp;of&nbsp;which&nbsp;can be used&nbsp;for&nbsp;most purposes;&nbsp;<br>
•&nbsp;&nbsp;a load-store&nbsp;architecture;&nbsp;<br>
•&nbsp;&nbsp;3-address&nbsp;instructions (that&nbsp;is,&nbsp;the&nbsp;two&nbsp;source&nbsp;operand&nbsp;registers&nbsp;and&nbsp;the result&nbsp;reg&nbsp;<br>
ister are all&nbsp;independently specified);&nbsp;<br>
•&nbsp;&nbsp;conditional execution of&nbsp;every&nbsp;instruction;&nbsp;<br>
•&nbsp;&nbsp;the inclusion of&nbsp;very powerful&nbsp;load and&nbsp;store&nbsp;multiple&nbsp;register&nbsp;instructions;&nbsp;<br>
•&nbsp;&nbsp;the ability&nbsp;to perform&nbsp;a general shift operation and a general ALU operation in a&nbsp;<br>
single instruction that executes in a&nbsp;single clock cycle;&nbsp;<br>
•&nbsp;&nbsp;open instruction set extension through the coprocessor instruction set, including&nbsp;<br>
adding new&nbsp;registers and data types to the programmer's&nbsp;model.&nbsp;<br>
<hr>
<A name=60></a><b>48</b>&nbsp;<br>
<b>The ARM Architecture</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
If the&nbsp;Thumb&nbsp;instruction set&nbsp;is considered&nbsp;part&nbsp;of&nbsp;the&nbsp;ARM&nbsp;architecture, we could&nbsp;<br>
also add:&nbsp;<br>
•&nbsp;a very dense 16-bit&nbsp;compressed&nbsp;representation of&nbsp;the&nbsp;instruction&nbsp;set&nbsp;in&nbsp;the&nbsp;Thumb&nbsp;<br>
architecture.&nbsp;<br>
<b>Exercise 2.1.1&nbsp;</b><br>
Which features&nbsp;does&nbsp;ARM&nbsp;have&nbsp;in&nbsp;common with&nbsp;many other RISC&nbsp;architectures?&nbsp;<br>
<b>Exercise 2.1.2&nbsp;</b><br>
Which features of&nbsp;the ARM architecture&nbsp;are&nbsp;not shared&nbsp;by&nbsp;most&nbsp;other&nbsp;RISCs?&nbsp;Which&nbsp;<br>
<b>Exercise&nbsp;2.1.3</b>&nbsp;<br>
features of&nbsp;most&nbsp;other RISC&nbsp;architectures&nbsp;are not&nbsp;shared by&nbsp;the&nbsp;ARM?&nbsp;<br>
<hr>
<A name=61></a><IMG src="index-61_1.png"><br>
ARM Assembly Language&nbsp;<br>
Programming&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Summary of chapter contents&nbsp;<br>
The&nbsp;ARM&nbsp;processor is&nbsp;very&nbsp;easy&nbsp;to&nbsp;program at&nbsp;the&nbsp;assembly&nbsp;level, though&nbsp;for&nbsp;most&nbsp;<br>
applications&nbsp;it&nbsp;is&nbsp;more&nbsp;appropriate&nbsp;to&nbsp;program&nbsp;in&nbsp;a&nbsp;high-level&nbsp;language&nbsp;such&nbsp;as&nbsp;C&nbsp;or&nbsp;<br>
C++.&nbsp;<br>
Assembly language programming requires&nbsp;the programmer&nbsp;to&nbsp;think at&nbsp;the level of&nbsp;<br>
the&nbsp;individual&nbsp;machine&nbsp;instruction.&nbsp;An ARM instruction is&nbsp;32 bits&nbsp;long, so&nbsp;there are&nbsp;<br>
around 4 billion&nbsp;different binary machine instructions. Fortunately there is considerable&nbsp;<br>
structure within the instruction space, so&nbsp;the&nbsp;programmer does not have to be familiar&nbsp;<br>
with each of the 4 billion binary encodings on&nbsp;an individual&nbsp;basis. Even so, there is a&nbsp;<br>
considerable&nbsp;amount of&nbsp;detail&nbsp;to be&nbsp;got&nbsp;right&nbsp;in each instruction.&nbsp;The assembler is&nbsp;a&nbsp;<br>
computer program which handles most of&nbsp;this&nbsp;detail for the&nbsp;programmer.&nbsp;<br>
In&nbsp;this&nbsp;chapter we&nbsp;will&nbsp;look&nbsp;at ARM assembly&nbsp;language&nbsp;programming at&nbsp;the user&nbsp;<br>
level and&nbsp;see how&nbsp;to write&nbsp;simple&nbsp;programs which will&nbsp;run&nbsp;on&nbsp;an ARM development&nbsp;<br>
board&nbsp;or&nbsp;an&nbsp;ARM&nbsp;emulator&nbsp;(for example,&nbsp;the ARMulator which&nbsp;comes&nbsp;as&nbsp;part&nbsp;of&nbsp;the&nbsp;<br>
ARM&nbsp;development toolkit).&nbsp;Once the basic instruction set is&nbsp;familiar&nbsp;we&nbsp;will move&nbsp;<br>
on, in Chapter 5, to look at system-level programming&nbsp;and at some of the finer&nbsp;<br>
details of the&nbsp;ARM instruction&nbsp;set, including the binary-level&nbsp;instruction encoding.&nbsp;<br>
Some&nbsp;ARM processors&nbsp;support a form of&nbsp;the instruction&nbsp;set that has&nbsp;been com-<br>
pressed&nbsp;into&nbsp;16-bit&nbsp;Thumb'&nbsp;instructions. These are discussed in Chapter 7.&nbsp;<br>
<b>49</b>&nbsp;<br>
<hr>
<A name=62></a><b>50</b>&nbsp;<br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
3.1 &nbsp; &nbsp;Data&nbsp;processing&nbsp;instructions&nbsp;<br>
ARM&nbsp;data&nbsp;processing&nbsp;instructions&nbsp;enable&nbsp;the&nbsp;programmer&nbsp;to&nbsp;perform&nbsp;arithmetic&nbsp;and&nbsp;<br>
logical operations on data values&nbsp;in&nbsp;registers.&nbsp;All other instructions&nbsp;just&nbsp;move data&nbsp;<br>
around and control the sequence of program&nbsp;execution, so the data&nbsp;processing&nbsp;<br>
instructions are the only instructions which&nbsp;modify&nbsp;data values. These instructions&nbsp;<br>
typically&nbsp;require two operands and produce a single&nbsp;result, though there are excep-<br>
tions to both of these rules.&nbsp;A characteristic operation is to add two values together&nbsp;<br>
to produce a&nbsp;single result&nbsp;which is&nbsp;the&nbsp;sum.&nbsp;<br>
Here&nbsp;are some&nbsp;rules which&nbsp;apply&nbsp;to&nbsp;ARM&nbsp;data&nbsp;processing&nbsp;instructions:&nbsp;<br>
•&nbsp;&nbsp;All operands&nbsp;are 32 bits wide&nbsp;and come&nbsp;from&nbsp;registers or&nbsp;are&nbsp;specified as&nbsp;literals&nbsp;<br>
in the instruction itself.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;result, if&nbsp;there is&nbsp;one, is&nbsp;32 bits&nbsp;wide&nbsp;and is placed in&nbsp;a register.&nbsp;<br>
(There is an exception here: long multiply&nbsp;instructions produce&nbsp;a 64-bit&nbsp;result;&nbsp;<br>
they are discussed in&nbsp;Section&nbsp;5.8 on page 122.)&nbsp;<br>
•&nbsp;&nbsp;Each&nbsp;of&nbsp;the operand&nbsp;registers and the&nbsp;result register&nbsp;are&nbsp;independently&nbsp;specified in&nbsp;<br>
the instruction.&nbsp;That is,&nbsp;the&nbsp;ARM uses&nbsp;a&nbsp;'3-address'&nbsp;format&nbsp;for these instructions.&nbsp;<br>
Simple register&nbsp;<br>
A typical&nbsp;ARM data processing&nbsp;instruction is&nbsp;written&nbsp;in assembly&nbsp;language&nbsp;as&nbsp;<br>
operands&nbsp;<br>
shown below:&nbsp;<br>
r0, &nbsp;&nbsp;r1, &nbsp;&nbsp;r2&nbsp;ADD&nbsp;<br>
r0, &nbsp;&nbsp;r1, &nbsp;&nbsp;<br>
r2&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
r1&nbsp;&nbsp;&nbsp;+&nbsp;&nbsp;&nbsp;r2&nbsp;<br>
The semicolon in&nbsp;this&nbsp;line indicates that&nbsp;everything&nbsp;to&nbsp;the right of&nbsp;it&nbsp;is&nbsp;a com-<br>
ment and should be ignored&nbsp;by&nbsp;the assembler. Comments are put into&nbsp;the assem-<br>
bly&nbsp;source code to&nbsp;make&nbsp;reading and understanding it easier.&nbsp;<br>
This example simply&nbsp;takes the values in&nbsp;two registers (r1 and r2), adds them&nbsp;<br>
together, and&nbsp;places&nbsp;the&nbsp;result in a third&nbsp;register&nbsp;(r0). The values in the&nbsp;source&nbsp;reg-<br>
isters are&nbsp;32&nbsp;bits wide&nbsp;and&nbsp;may&nbsp;be considered&nbsp;to&nbsp;be&nbsp;either&nbsp;unsigned&nbsp;integers&nbsp;or&nbsp;<br>
signed 2's-complement integers. The addition may&nbsp;produce a carry-out&nbsp;or, in the&nbsp;<br>
case&nbsp;of&nbsp;signed&nbsp;2's-complement values, an&nbsp;internal&nbsp;overflow&nbsp;into the&nbsp;sign&nbsp;bit, but in&nbsp;<br>
either case this&nbsp;is ignored.&nbsp;<br>
Note that in writing the assembly&nbsp;language source code, care&nbsp;must be&nbsp;taken to&nbsp;<br>
write the operands in the correct order,&nbsp;which is result register first, then the first&nbsp;<br>
operand&nbsp;and lastly&nbsp;the second operand (though for commutative&nbsp;operations the&nbsp;<br>
order of&nbsp;the&nbsp;first and&nbsp;second operands is not significant&nbsp;when they are both regis-<br>
ters). When this instruction is&nbsp;executed the&nbsp;only&nbsp;change to&nbsp;the system&nbsp;state is the&nbsp;<br>
value of the destination register&nbsp;r0&nbsp;(and, optionally, the&nbsp;N, Z, C and&nbsp;V flags in&nbsp;the&nbsp;<br>
CPSR, as&nbsp;we shall see later).&nbsp;<br>
<hr>
<A name=63></a><IMG src="index-63_1.png"><br>
<IMG src="index-63_2.png"><br>
<IMG src="index-63_3.png"><br>
<b>Data processing&nbsp;instructions</b>&nbsp;<br>
<b>51</b>&nbsp;<br>
The&nbsp;different instructions available&nbsp;in&nbsp;this form&nbsp;are listed below in their classes:&nbsp;<br>
• Arithmetic operations.&nbsp;<br>
These instructions perform&nbsp;binary&nbsp;arithmetic (addition, subtraction and&nbsp;reverse&nbsp;<br>
subtraction, which is subtraction&nbsp;with&nbsp;the&nbsp;operand&nbsp;order reversed)&nbsp;on two&nbsp;32-bit&nbsp;<br>
operands. The operands&nbsp;may&nbsp;be&nbsp;unsigned&nbsp;or&nbsp;2's-complement&nbsp;signed integers; the&nbsp;<br>
carry-in,&nbsp;when&nbsp;used,&nbsp;is&nbsp;the current value of&nbsp;the C bit&nbsp;in the&nbsp;CPSR.&nbsp;<br>
&nbsp;<br>
'ADD'&nbsp;is simple addition,&nbsp;'ADC'&nbsp;is&nbsp;add&nbsp;with&nbsp;carry, 'SUB'&nbsp;is&nbsp;subtract, 'SBC'&nbsp;is sub-<br>
tract&nbsp;with&nbsp;carry, 'RSB'&nbsp;is&nbsp;reverse subtraction and 'RSC'&nbsp;reverse subtract with&nbsp;carry.&nbsp;<br>
• Bit-wise logical operations.&nbsp;<br>
These instructions&nbsp;perform&nbsp;the&nbsp;specified Boolean&nbsp;logic operation on each bit pair&nbsp;<br>
of&nbsp;the&nbsp;input operands, so&nbsp;in&nbsp;the&nbsp;first case&nbsp;<i>r0[i]:= r1[i]&nbsp;</i>AND&nbsp;<i>r2[i]&nbsp;</i>for&nbsp;each value&nbsp;<br>
of&nbsp;<i>i</i>&nbsp;from&nbsp;0 to&nbsp;31 inclusive, where&nbsp;<i>r0[i]&nbsp;</i>is the&nbsp;<i>i</i>th&nbsp;bit&nbsp;of r0.&nbsp;<br>
&nbsp;<br>
We&nbsp;have met&nbsp;AND, OR&nbsp;and XOR (here called EOR)&nbsp;logical&nbsp;operations at the&nbsp;<br>
hardware gate level in&nbsp;Section&nbsp;1.2&nbsp;on&nbsp;page 3; the&nbsp;final&nbsp;mnemonic,&nbsp;BIC,&nbsp;stands&nbsp;for&nbsp;<br>
'bit clear'&nbsp;where every&nbsp;'&nbsp;1'&nbsp;in&nbsp;the second operand clears the corresponding bit in&nbsp;<br>
the first.&nbsp;(The&nbsp;'not'&nbsp;operation&nbsp;in the assembly&nbsp;language comment inverts each bit&nbsp;<br>
of the&nbsp;following operand.)&nbsp;<br>
• Register&nbsp;movement operations.&nbsp;<br>
These&nbsp;instructions ignore the&nbsp;first operand,&nbsp;which&nbsp;is omitted from&nbsp;the&nbsp;assembly&nbsp;<br>
language&nbsp;format, and simply&nbsp;move&nbsp;the&nbsp;second&nbsp;operand (possibly&nbsp;bit-wise&nbsp;<br>
inverted) to the&nbsp;destination.&nbsp;<br>
&nbsp;<br>
The 'MVN'&nbsp;mnemonic&nbsp;stands&nbsp;for&nbsp;'move negated';&nbsp;it leaves the result&nbsp;register&nbsp;set to&nbsp;<br>
the value obtained by&nbsp;inverting&nbsp;every bit&nbsp;in the&nbsp;source&nbsp;operand.&nbsp;<br>
<hr>
<A name=64></a><IMG src="index-64_1.png"><br>
<b>52</b>&nbsp;<br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
• Comparison&nbsp;operations.&nbsp;<br>
These&nbsp;instructions do not produce a&nbsp;result&nbsp;(which is&nbsp;therefore omitted&nbsp;from&nbsp;the&nbsp;<br>
assembly&nbsp;language&nbsp;format)&nbsp;but&nbsp;just&nbsp;set&nbsp;the&nbsp;condition&nbsp;code&nbsp;bits&nbsp;(N, Z,&nbsp;C and&nbsp;V) in&nbsp;<br>
the CPSR according to&nbsp;the&nbsp;selected operation.&nbsp;<br>
CMP CMN&nbsp;&nbsp;r1, r2&nbsp;<br>
,•&nbsp;set&nbsp;&nbsp;cc&nbsp;&nbsp;on r1&nbsp;-&nbsp;r2&nbsp;<br>
TST&nbsp;TEQ&nbsp;&nbsp;r1, r2&nbsp;<br>
;&nbsp;set&nbsp;cc&nbsp;&nbsp;on r1 + r2&nbsp;<br>
r1, r2&nbsp;<br>
;&nbsp;set&nbsp;&nbsp;cc&nbsp;&nbsp;on&nbsp;r1&nbsp;and&nbsp;r2&nbsp;<br>
r1, r2&nbsp;<br>
;&nbsp;set&nbsp;cc&nbsp;&nbsp;on&nbsp;r1&nbsp;xor&nbsp;r2&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The mnemonics stand for 'compare'&nbsp;(CMP),&nbsp;'compare negated'&nbsp;(CMN),&nbsp;'(bit) test'&nbsp;<br>
(TST)&nbsp;and 'test equal'&nbsp;(TEQ).&nbsp;<br>
Immediate&nbsp;<br>
If,&nbsp;instead&nbsp;of&nbsp;adding two registers, we simply&nbsp;wish&nbsp;to&nbsp;add&nbsp;a&nbsp;constant&nbsp;to&nbsp;a&nbsp;register&nbsp;we&nbsp;<br>
operands&nbsp;<br>
can replace the second source operand&nbsp;with an immediate value, which is a literal&nbsp;<br>
constant, preceded by&nbsp;'#':&nbsp;<br>
&nbsp;&nbsp;&nbsp;ADD&nbsp;<br>
r3, &nbsp;&nbsp;r3, &nbsp;&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
#1&nbsp;<br>
+ &nbsp;&nbsp;1&nbsp;<br>
AND&nbsp;<br>
r8, &nbsp; r7, &nbsp;&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
#&amp;ff&nbsp;<br>
r7[7:0]&nbsp;<br>
The&nbsp;first example also&nbsp;illustrates&nbsp;that&nbsp;although the&nbsp;3-address&nbsp;format allows&nbsp;source&nbsp;<br>
and destination operands&nbsp;to be specified&nbsp;separately,&nbsp;they are&nbsp;not&nbsp;required&nbsp;to be distinct&nbsp;<br>
registers. The second example&nbsp;shows that&nbsp;the immediate value&nbsp;may&nbsp;be specified in&nbsp;<br>
hexadecimal (base&nbsp;16)&nbsp;notation&nbsp;by&nbsp;putting&nbsp;'&amp;'&nbsp;after&nbsp;the '#'.&nbsp;<br>
Since the immediate value is&nbsp;coded&nbsp;within&nbsp;the 32 bits of the instruction, it is not&nbsp;<br>
possible&nbsp;to&nbsp;enter every&nbsp;possible 32-bit&nbsp;value&nbsp;as&nbsp;an immediate.&nbsp;The&nbsp;values&nbsp;which&nbsp;can be&nbsp;<br>
entered correspond&nbsp;to&nbsp;any&nbsp;32-bit&nbsp;binary&nbsp;number&nbsp;where&nbsp;all the binary&nbsp;ones fall&nbsp;within&nbsp;a&nbsp;<br>
group of&nbsp;eight&nbsp;adjacent bit positions&nbsp;on a&nbsp;2-bit&nbsp;boundary. Most valid&nbsp;immediate values&nbsp;<br>
are given by:&nbsp;<br>
&nbsp;<br>
Equation&nbsp;10&nbsp;<br>
where 0 &lt;&nbsp;<i>n &lt;&nbsp;</i>12 . The assembler will also replace&nbsp;MOV&nbsp;with&nbsp;MVN,&nbsp;ADD&nbsp;with&nbsp;SUB, and&nbsp;<br>
so&nbsp;on, where&nbsp;this&nbsp;can&nbsp;bring&nbsp;the immediate&nbsp;within&nbsp;range.&nbsp;<br>
This&nbsp;may&nbsp;appear a complex constraint on the immediate values, but it&nbsp;does, in&nbsp;<br>
practice, cover all the&nbsp;most common cases&nbsp;such as a byte&nbsp;value at any of the four&nbsp;<br>
byte positions within a 32-bit word, any&nbsp;power of&nbsp;2, and so on. In any&nbsp;case the&nbsp;<br>
assembler&nbsp;will report any&nbsp;value which is requested that it cannot encode.&nbsp;<br>
(The&nbsp;reason&nbsp;for the constraint&nbsp;on immediate values is the&nbsp;way they&nbsp;are&nbsp;specified&nbsp;<br>
at the&nbsp;binary&nbsp;instruction&nbsp;level. This is&nbsp;described in&nbsp;the&nbsp;Chapter&nbsp;5, and the reader&nbsp;<br>
who wishes to understand&nbsp;this issue fully&nbsp;should look&nbsp;there for the&nbsp;complete&nbsp;<br>
explanation.)&nbsp;<br>
<hr>
<A name=65></a><b>Data&nbsp;processing instructions</b>&nbsp;<br>
<b>53</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Shifted register&nbsp;&nbsp;A third&nbsp;way to&nbsp;specify&nbsp;a data&nbsp;operation&nbsp;is&nbsp;similar to&nbsp;the&nbsp;first, but&nbsp;allows the&nbsp;second&nbsp;<br>
operands&nbsp;<br>
register&nbsp;operand&nbsp;to&nbsp;be&nbsp;subject&nbsp;to&nbsp;a&nbsp;shift&nbsp;operation&nbsp;before&nbsp;it is&nbsp;combined&nbsp;with&nbsp;the&nbsp;first&nbsp;<br>
operand. For&nbsp;example:&nbsp;<br>
ADD&nbsp;<br>
r3,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r2,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r1,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LSL&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#3&nbsp;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
x &nbsp;r1&nbsp;<br>
Note&nbsp;that&nbsp;this&nbsp;is&nbsp;still&nbsp;a&nbsp;single&nbsp;ARM&nbsp;instruction,&nbsp;executed&nbsp;in&nbsp;a&nbsp;single&nbsp;clock&nbsp;cycle.&nbsp;<br>
Most&nbsp;processors&nbsp;offer shift&nbsp;operations&nbsp;as&nbsp;separate&nbsp;instructions,&nbsp;but the&nbsp;ARM combines&nbsp;<br>
them&nbsp;with&nbsp;a&nbsp;general ALU operation&nbsp;in a&nbsp;single&nbsp;instruction.&nbsp;<br>
Here 'LSL'&nbsp;indicates 'logical shift left&nbsp;by the&nbsp;specified number of bits',&nbsp;which in&nbsp;<br>
this example is 3. Any&nbsp;number from&nbsp;0 to 31&nbsp;may be specified, though&nbsp;using 0 is equiv-<br>
alent&nbsp;to&nbsp;omitting&nbsp;the&nbsp;shift&nbsp;altogether.&nbsp;As before,&nbsp;'#'&nbsp;indicates an&nbsp;immediate&nbsp;quantity.&nbsp;<br>
The available&nbsp;shift&nbsp;operations&nbsp;are:&nbsp;<br>
•&nbsp;&nbsp;LSL:&nbsp;logical&nbsp;shift&nbsp;left&nbsp;by&nbsp;0&nbsp;to 31&nbsp;places;&nbsp;fill&nbsp;the&nbsp;vacated bits&nbsp;at&nbsp;the&nbsp;least&nbsp;significant&nbsp;<br>
end of&nbsp;the&nbsp;word&nbsp;with&nbsp;zeros.&nbsp;<br>
•&nbsp;&nbsp;LSR:&nbsp;logical shift right by 0 to 32 places; fill the vacated bits at the&nbsp;most&nbsp;signifi&nbsp;<br>
cant&nbsp;end&nbsp;of&nbsp;the&nbsp;word&nbsp;with&nbsp;zeros.&nbsp;<br>
•&nbsp;&nbsp;ASL:&nbsp;arithmetic shift left; this&nbsp;is a&nbsp;synonym&nbsp;for LSL.&nbsp;<br>
•&nbsp;&nbsp;ASR: arithmetic shift&nbsp;right&nbsp;by&nbsp;0&nbsp;to 32 places;&nbsp;fill the vacated bits at the&nbsp;most&nbsp;sig&nbsp;<br>
nificant end&nbsp;of the word with&nbsp;zeros if&nbsp;the source operand&nbsp;was positive,&nbsp;or with&nbsp;<br>
ones&nbsp;if&nbsp;the source&nbsp;operand&nbsp;was&nbsp;negative.&nbsp;<br>
•&nbsp;&nbsp;ROR:&nbsp;rotate&nbsp;right by 0 to 32 places;&nbsp;the bits&nbsp;which&nbsp;fall&nbsp;off the least significant end&nbsp;<br>
of&nbsp;the&nbsp;word&nbsp;are&nbsp;used, in&nbsp;order,&nbsp;to&nbsp;fill&nbsp;the&nbsp;vacated bits&nbsp;at&nbsp;the most&nbsp;significant&nbsp;end of&nbsp;<br>
the word.&nbsp;<br>
•&nbsp;&nbsp;RRX:&nbsp;rotate&nbsp;right&nbsp;extended by&nbsp;1 place; the&nbsp;vacated&nbsp;bit&nbsp;(bit&nbsp;31) is&nbsp;filled&nbsp;with&nbsp;the&nbsp;old&nbsp;<br>
value&nbsp;of the&nbsp;C flag and&nbsp;the operand&nbsp;is&nbsp;shifted one place to the right. With&nbsp;<br>
appropriate use of&nbsp;the condition codes&nbsp;(see&nbsp;below) a 33-bit rotate of&nbsp;the&nbsp;operand&nbsp;<br>
and&nbsp;the C flag&nbsp;is performed.&nbsp;<br>
These shift&nbsp;operations&nbsp;are&nbsp;illustrated in&nbsp;Figure&nbsp;3.1&nbsp;on&nbsp;page&nbsp;54. It&nbsp;is&nbsp;also&nbsp;possible&nbsp;to&nbsp;<br>
use a register&nbsp;value to specify&nbsp;the number&nbsp;of bits the second operand&nbsp;should&nbsp;be&nbsp;<br>
shifted by:&nbsp;<br>
ADD&nbsp;<br>
r5,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r5,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r3,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LSL&nbsp;&nbsp;&nbsp;&nbsp;r2&nbsp;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
x &nbsp;2r2&nbsp;<br>
This is&nbsp;a 4-address instruction. Only&nbsp;the bottom&nbsp;eight&nbsp;bits&nbsp;of r2&nbsp;are&nbsp;significant,&nbsp;but&nbsp;<br>
since&nbsp;shifts&nbsp;by&nbsp;more than&nbsp;32&nbsp;bits are&nbsp;not&nbsp;very&nbsp;useful&nbsp;this&nbsp;limitation&nbsp;is not&nbsp;important&nbsp;for&nbsp;<br>
most purposes.&nbsp;<br>
Setting the&nbsp;<br>
Any data processing instruction can set the&nbsp;condition codes (N, Z, C and V) if the&nbsp;<br>
condition&nbsp;codes&nbsp;<br>
programmer wishes it to. The comparison&nbsp;operations only&nbsp;set the condition codes,&nbsp;<br>
so there&nbsp;is&nbsp;no&nbsp;option&nbsp;with&nbsp;them, but for&nbsp;all other&nbsp;data processing instructions&nbsp;a&nbsp;<br>
<hr>
<A name=66></a><IMG src="index-66_1.png"><br>
<IMG src="index-66_2.png"><br>
54&nbsp;<br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;3.1 &nbsp; &nbsp;</b>ARM shift operations&nbsp;<br>
specific request must&nbsp;be made.&nbsp;At&nbsp;the&nbsp;assembly&nbsp;language&nbsp;level&nbsp;this&nbsp;request is&nbsp;indi-<br>
cated&nbsp;by&nbsp;adding an&nbsp;'s'&nbsp;to the opcode, standing for 'Set condition codes'. As&nbsp;an&nbsp;<br>
example, the&nbsp;following code&nbsp;performs&nbsp;a&nbsp;64-bit addition&nbsp;of two numbers held in&nbsp;<br>
r0-r1 and r2-r3, using the C condition code&nbsp;flag to store the intermediate&nbsp;carry:&nbsp;<br>
&nbsp;<br>
Since&nbsp;the s&nbsp;opcode&nbsp;extension&nbsp;gives the&nbsp;programmer control&nbsp;over&nbsp;whether&nbsp;or&nbsp;not an&nbsp;<br>
instruction modifies&nbsp;the condition codes,&nbsp;the&nbsp;codes can&nbsp;be&nbsp;preserved over&nbsp;long&nbsp;instruc-<br>
tion sequences&nbsp;when&nbsp;it&nbsp;is&nbsp;appropriate&nbsp;to&nbsp;do so.&nbsp;<br>
An arithmetic&nbsp;operation&nbsp;(which here includes&nbsp;CMP&nbsp;and&nbsp;&nbsp;CMN)&nbsp;sets&nbsp;all&nbsp;the flags&nbsp;<br>
according&nbsp;to&nbsp;the&nbsp;arithmetic result. A logical or move&nbsp;operation&nbsp;does not&nbsp;produce&nbsp;a&nbsp;<br>
meaningful&nbsp;value for C&nbsp;or&nbsp;V,&nbsp;so these operations&nbsp;set N&nbsp;and&nbsp;Z&nbsp;according to the result&nbsp;<br>
but&nbsp;preserve&nbsp;V, and&nbsp;either&nbsp;preserve&nbsp;C when&nbsp;there&nbsp;is&nbsp;no&nbsp;shift operation,&nbsp;or&nbsp;set&nbsp;C&nbsp;to&nbsp;the&nbsp;<br>
value of the last&nbsp;bit to&nbsp;fall off the&nbsp;end&nbsp;of&nbsp;the&nbsp;shift.&nbsp;This&nbsp;detail&nbsp;is&nbsp;not&nbsp;often significant.&nbsp;<br>
<hr>
<A name=67></a><b>Data&nbsp;transfer&nbsp;instructions</b>&nbsp;<br>
<b>55</b>&nbsp;<br>
Use&nbsp;Of&nbsp;the&nbsp;<br>
We have already&nbsp;seen the C&nbsp;flag used as an&nbsp;input to an arithmetic data processing&nbsp;<br>
Condition codes&nbsp;instruction. However we have not yet&nbsp;seen&nbsp;the most important&nbsp;use&nbsp;of&nbsp;the condition&nbsp;<br>
codes, which is&nbsp;to control the program&nbsp;flow&nbsp;through&nbsp;the&nbsp;conditional branch instruc-<br>
tions.&nbsp;These&nbsp;will be described in Section 3.3 on page 63.&nbsp;<br>
Multiplies&nbsp;<br>
A&nbsp;special&nbsp;form&nbsp;of&nbsp;the&nbsp;data&nbsp;processing&nbsp;instruction&nbsp;supports multiplication:&nbsp;<br>
MUL&nbsp;<br>
r4, &nbsp; r3, &nbsp;&nbsp;r2&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(r3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;&nbsp;&nbsp;&nbsp;r&nbsp;2&nbsp;)&nbsp;[&nbsp;31:0]&nbsp;<br>
There&nbsp;are&nbsp;some&nbsp;important&nbsp;differences from&nbsp;the&nbsp;other&nbsp;arithmetic&nbsp;instructions:&nbsp;<br>
•&nbsp;&nbsp;Immediate&nbsp;second operands&nbsp;are not supported.&nbsp;<br>
•&nbsp;&nbsp;The result&nbsp;register&nbsp;must&nbsp;not&nbsp;be&nbsp;the same&nbsp;as&nbsp;the first&nbsp;source&nbsp;register.&nbsp;<br>
•&nbsp;&nbsp;If the&nbsp;'&nbsp;s'&nbsp;bit is&nbsp;set the V&nbsp;flag is&nbsp;preserved (as for a logical instruction) and the C&nbsp;<br>
flag&nbsp;is&nbsp;rendered&nbsp;meaningless.&nbsp;<br>
Multiplying two 32-bit&nbsp;integers&nbsp;gives&nbsp;a&nbsp;64-bit&nbsp;result,&nbsp;the&nbsp;least&nbsp;significant&nbsp;32&nbsp;bits&nbsp;of&nbsp;<br>
which are placed in the result&nbsp;register&nbsp;and the rest&nbsp;are&nbsp;ignored.&nbsp;This&nbsp;can&nbsp;be&nbsp;viewed&nbsp;as&nbsp;<br>
multiplication in&nbsp;modulo 232&nbsp;arithmetic and&nbsp;gives the correct&nbsp;result whether the oper-<br>
ands are viewed&nbsp;as signed&nbsp;or&nbsp;unsigned&nbsp;integers. (ARMs&nbsp;also support&nbsp;long&nbsp;multiply&nbsp;<br>
instructions&nbsp;which place the&nbsp;most&nbsp;significant&nbsp;32&nbsp;bits&nbsp;into&nbsp;a second result&nbsp;register; these&nbsp;<br>
are&nbsp;described in&nbsp;Section 5.8&nbsp;on&nbsp;page&nbsp;122.)&nbsp;<br>
An&nbsp;alternative form,&nbsp;subject&nbsp;to&nbsp;the&nbsp;same&nbsp;restrictions,&nbsp;adds&nbsp;the product to&nbsp;a&nbsp;running&nbsp;<br>
total.&nbsp;This&nbsp;is&nbsp;the multiply-accumulate&nbsp;instruction:&nbsp;<br>
MLA&nbsp;<br>
r4,&nbsp;&nbsp;&nbsp;r3,&nbsp;&nbsp;&nbsp;r2,&nbsp;&nbsp;&nbsp;r1&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(r3&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;r2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;&nbsp;&nbsp;&nbsp;r1)[31:0]&nbsp;<br>
Multiplication by&nbsp;a constant&nbsp;can be&nbsp;implemented by&nbsp;loading&nbsp;the constant&nbsp;into a reg-<br>
ister&nbsp;and then&nbsp;using one of these instructions,&nbsp;but&nbsp;it&nbsp;is&nbsp;usually more efficient&nbsp;to use&nbsp;a&nbsp;<br>
short&nbsp;series&nbsp;of&nbsp;data&nbsp;processing&nbsp;instructions&nbsp;using&nbsp;shifts&nbsp;and&nbsp;adds&nbsp;or&nbsp;subtracts.&nbsp;For&nbsp;<br>
example, to&nbsp;multiply&nbsp;r0 by&nbsp;35:&nbsp;<br>
ADD RSB&nbsp;&nbsp;r0, r0,&nbsp;<br>
r0, r0,&nbsp;<br>
r0, r0,&nbsp;<br>
LSL &nbsp;&nbsp;<br>
r0':=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;&nbsp;&nbsp;<br>
#2;&nbsp;LSL &nbsp;&nbsp;r0&nbsp;r0&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;7&nbsp;&nbsp;&nbsp;&nbsp;(&nbsp;=&nbsp;&nbsp;&nbsp;3&nbsp;5&nbsp;&nbsp;&nbsp;x&nbsp;&nbsp;&nbsp;r&nbsp;0&nbsp;)&nbsp;&nbsp;<br>
#3;&nbsp;<br>
x &nbsp;r0'&nbsp;<br>
3.2 &nbsp; Data&nbsp;transfer&nbsp;instructions&nbsp;<br>
Data&nbsp;transfer instructions&nbsp;move data between&nbsp;ARM registers&nbsp;and memory. There are&nbsp;<br>
three&nbsp;basic&nbsp;forms of&nbsp;data transfer instruction&nbsp;in the&nbsp;ARM&nbsp;instruction&nbsp;set:&nbsp;<br>
• Single register load&nbsp;and&nbsp;store instructions.&nbsp;<br>
These instructions provide the&nbsp;most flexible&nbsp;way to transfer single&nbsp;data&nbsp;items&nbsp;<br>
between an ARM register and&nbsp;memory. The data item&nbsp;may&nbsp;be a byte, a 32-bit&nbsp;<br>
word, or&nbsp;a&nbsp;16-bit half-word.&nbsp;(Older&nbsp;ARM chips may not support&nbsp;half-words.)&nbsp;<br>
<hr>
<A name=68></a><b>56</b>&nbsp;<br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
•&nbsp;&nbsp;Multiple&nbsp;register load&nbsp;and&nbsp;store instructions.&nbsp;<br>
These instructions are less&nbsp;flexible than single register&nbsp;transfer instructions, but&nbsp;<br>
enable large quantities of data to be transferred&nbsp;more efficiently. They&nbsp;are used&nbsp;<br>
for procedure&nbsp;entry and exit,&nbsp;to&nbsp;save&nbsp;and restore workspace&nbsp;registers, and to copy&nbsp;<br>
blocks&nbsp;of&nbsp;data around&nbsp;memory.&nbsp;<br>
•&nbsp;&nbsp;Single&nbsp;register&nbsp;swap&nbsp;instructions.&nbsp;<br>
These&nbsp;instructions allow a&nbsp;value in&nbsp;a&nbsp;register to be&nbsp;exchanged&nbsp;with&nbsp;a&nbsp;value in&nbsp;<br>
memory, effectively&nbsp;doing both a load and a store operation in one instruction.&nbsp;<br>
They are little&nbsp;used in user-level programs,&nbsp;so they will not be discussed further&nbsp;<br>
in this section. Their principal use&nbsp;is to implement&nbsp;semaphores&nbsp;to&nbsp;ensure&nbsp;mutual&nbsp;<br>
exclusion on accesses to&nbsp;shared data structures in&nbsp;multi-processor systems, but&nbsp;<br>
don't&nbsp;worry if&nbsp;this explanation has little&nbsp;meaning for&nbsp;you&nbsp;at the&nbsp;moment.&nbsp;<br>
It is quite&nbsp;possible&nbsp;to write any&nbsp;program&nbsp;for the ARM&nbsp;using&nbsp;only&nbsp;the single&nbsp;register&nbsp;<br>
load and store&nbsp;instructions, but&nbsp;there are situations&nbsp;where&nbsp;the multiple register&nbsp;trans-<br>
fers are much&nbsp;more efficient,&nbsp;so&nbsp;the&nbsp;programmer should&nbsp;be&nbsp;familiar&nbsp;with them.&nbsp;<br>
Register-indirect&nbsp;<br>
Towards the&nbsp;end of Section 1.4&nbsp;on&nbsp;page&nbsp;14 there was a discussion&nbsp;of&nbsp;memory&nbsp;<br>
addressing&nbsp;<br>
addressing&nbsp;mechanisms&nbsp;that&nbsp;are&nbsp;available to&nbsp;the processor instruction&nbsp;set designer.&nbsp;<br>
The ARM&nbsp;data transfer instructions are&nbsp;all&nbsp;based around register-indirect address-<br>
ing, with&nbsp;modes that&nbsp;include base-plus-offset&nbsp;and&nbsp;base-plus-index addressing.&nbsp;<br>
Register-indirect&nbsp;addressing uses&nbsp;a&nbsp;value in&nbsp;one register&nbsp;(the&nbsp;<b>base&nbsp;</b>register) as&nbsp;a&nbsp;<br>
memory address and either&nbsp;<b>loads&nbsp;</b>the&nbsp;value from&nbsp;that&nbsp;address into&nbsp;another register&nbsp;or&nbsp;<br>
<b>stores&nbsp;</b>the&nbsp;value from&nbsp;another&nbsp;register into that memory address.&nbsp;<br>
These&nbsp;instructions are written&nbsp;in&nbsp;assembly&nbsp;language&nbsp;as follows:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
LDR &nbsp;&nbsp; &nbsp;r0,&nbsp;[r1]&nbsp;<br>
; r0 := mem32[r1] ;&nbsp;<br>
STR&nbsp;&nbsp; &nbsp;r0,&nbsp;[r1]&nbsp;<br>
mem32[r1] := r0&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Other&nbsp;forms of addressing&nbsp;all&nbsp;build&nbsp;on&nbsp;this&nbsp;form, adding&nbsp;immediate&nbsp;or register&nbsp;off-<br>
sets to&nbsp;the base&nbsp;address.&nbsp;In&nbsp;all&nbsp;cases it&nbsp;is necessary&nbsp;to&nbsp;have an&nbsp;ARM&nbsp;register&nbsp;loaded&nbsp;<br>
with an&nbsp;address&nbsp;which is&nbsp;near to&nbsp;the desired&nbsp;transfer address,&nbsp;so we will&nbsp;begin by&nbsp;look-<br>
ing&nbsp;at&nbsp;ways&nbsp;of&nbsp;getting memory&nbsp;addresses&nbsp;into&nbsp;a register.&nbsp;<br>
Initializing an&nbsp;<br>
To load or&nbsp;store from&nbsp;or&nbsp;to a&nbsp;particular&nbsp;memory location,&nbsp;an&nbsp;ARM&nbsp;register&nbsp;must&nbsp;be&nbsp;<br>
address pointer&nbsp;<br>
initialized&nbsp;to contain the address of&nbsp;that location, or,&nbsp;in the case of&nbsp;single register&nbsp;<br>
transfer&nbsp;instructions, an&nbsp;address&nbsp;within&nbsp;4&nbsp;Kbytes&nbsp;of&nbsp;that&nbsp;location&nbsp;(the&nbsp;4&nbsp;Kbyte&nbsp;range&nbsp;<br>
will be explained&nbsp;later).&nbsp;<br>
If the&nbsp;location&nbsp;is close&nbsp;to&nbsp;the&nbsp;code&nbsp;being executed&nbsp;it&nbsp;is often possible to&nbsp;exploit&nbsp;the&nbsp;<br>
fact that the&nbsp;program&nbsp;counter, r15,&nbsp;is close&nbsp;to&nbsp;the&nbsp;desired&nbsp;address.&nbsp;A data processing&nbsp;<br>
instruction&nbsp;can&nbsp;be&nbsp;employed&nbsp;to&nbsp;add&nbsp;a small offset to&nbsp;r15,&nbsp;but&nbsp;calculating&nbsp;the appropri-<br>
ate&nbsp;offset&nbsp;may&nbsp;not&nbsp;be&nbsp;that&nbsp;straightforward.&nbsp;However,&nbsp;this&nbsp;is&nbsp;the sort&nbsp;of tricky calcula-<br>
tion that assemblers&nbsp;are good at, and&nbsp;ARM assemblers have an inbuilt&nbsp;'pseudo&nbsp;<br>
instruction',&nbsp;ADR,&nbsp;which&nbsp;makes this easy.&nbsp;A pseudo instruction looks like a normal&nbsp;<br>
<hr>
<A name=69></a><IMG src="index-69_1.png"><br>
<IMG src="index-69_2.png"><br>
&nbsp;<br>
<b>Data&nbsp;transfer&nbsp;instructions</b>&nbsp;<br>
<b>57</b>&nbsp;<br>
instruction in&nbsp;the assembly&nbsp;source code but&nbsp;does&nbsp;not&nbsp;correspond&nbsp;directly&nbsp;to a particu-<br>
lar ARM&nbsp;instruction.&nbsp;Instead,&nbsp;the assembler has a&nbsp;set of&nbsp;rules which&nbsp;enable&nbsp;it&nbsp;to&nbsp;select&nbsp;<br>
the most appropriate&nbsp;ARM instruction&nbsp;or&nbsp;short instruction&nbsp;sequence for the situation&nbsp;<br>
in&nbsp;which&nbsp;the pseudo instruction is&nbsp;used. (In fact,&nbsp;ADR&nbsp;is&nbsp;always&nbsp;assembled&nbsp;into&nbsp;a single&nbsp;<br>
ADD&nbsp;or&nbsp;SUB&nbsp;instruction.)&nbsp;<br>
As&nbsp;an example, consider&nbsp;a program&nbsp;which&nbsp;must&nbsp;copy&nbsp;data from&nbsp;TABLE1&nbsp;to&nbsp;<br>
TABLE2, both of which&nbsp;are near&nbsp;to&nbsp;the&nbsp;code:&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Here&nbsp;we have&nbsp;introduced&nbsp;<b>labels&nbsp;</b>(COPY,&nbsp;TABLE1&nbsp;and TABLE2) which&nbsp;are&nbsp;simply&nbsp;<br>
names given to&nbsp;particular&nbsp;points in&nbsp;the assembly&nbsp;code. The first&nbsp;ADR&nbsp;pseudo&nbsp;instruc-<br>
tion causes r1 to&nbsp;contain the address&nbsp;of&nbsp;the&nbsp;data that follows&nbsp;TABLE1;&nbsp;the second&nbsp;ADR&nbsp;<br>
likewise causes r2 to&nbsp;hold the address of the&nbsp;memory&nbsp;starting at TABLE2.&nbsp;<br>
Of course any&nbsp;ARM&nbsp;instruction can&nbsp;be used&nbsp;to&nbsp;compute the address&nbsp;of a&nbsp;data&nbsp;item&nbsp;<br>
in&nbsp;memory, but for the purposes of small&nbsp;programs&nbsp;the&nbsp;ADR&nbsp;pseudo instruction will do&nbsp;<br>
what we require.&nbsp;<br>
Single register&nbsp;<br>
These instructions compute&nbsp;an&nbsp;address&nbsp;for the transfer&nbsp;using a&nbsp;base&nbsp;register,&nbsp;which&nbsp;<br>
load and&nbsp;store&nbsp;<br>
should&nbsp;contain an address&nbsp;near&nbsp;to the target address,&nbsp;and an&nbsp;offset&nbsp;which may be&nbsp;<br>
instructions&nbsp;<br>
another&nbsp;register&nbsp;or an&nbsp;immediate value.&nbsp;<br>
We&nbsp;have just&nbsp;seen the simplest&nbsp;form&nbsp;of these&nbsp;instructions, which does not&nbsp;use&nbsp;<br>
an offset:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
LDR&nbsp;<br>
r0, &nbsp; &nbsp;<br>
; r0 := mem32&nbsp;[r1]&nbsp;;&nbsp;<br>
[r1]&nbsp;<br>
mem32[r1] := r0&nbsp;<br>
STR&nbsp;<br>
r0, &nbsp; &nbsp;<br>
[r1]&nbsp;<br>
The notation&nbsp;used&nbsp;here indicates that the data&nbsp;quantity is the 32-bit&nbsp;memory word&nbsp;<br>
addressed by&nbsp;r1.&nbsp;The&nbsp;word&nbsp;address&nbsp;in&nbsp;r1&nbsp;should be&nbsp;aligned&nbsp;on&nbsp;a 4-byte boundary,&nbsp;so&nbsp;<br>
the&nbsp;two least significant bits&nbsp;of&nbsp;r1 should be zero. We&nbsp;can now copy&nbsp;the first word from&nbsp;<br>
one table&nbsp;to&nbsp;the other:&nbsp;<br>
&nbsp;<br>
<hr>
<A name=70></a><IMG src="index-70_1.png"><br>
<b>58</b>&nbsp;<br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
We&nbsp;could now use&nbsp;data&nbsp;processing&nbsp;instructions&nbsp;to&nbsp;modify&nbsp;both&nbsp;base&nbsp;registers&nbsp;ready&nbsp;<br>
for the next transfer:&nbsp;<br>
&nbsp;<br>
Note&nbsp;that&nbsp;the&nbsp;base registers&nbsp;are incremented&nbsp;by 4 (bytes), since this is&nbsp;the&nbsp;size&nbsp;of&nbsp;a&nbsp;<br>
word.&nbsp;If&nbsp;the&nbsp;base&nbsp;register&nbsp;was&nbsp;word-aligned&nbsp;before&nbsp;the increment,&nbsp;it&nbsp;will&nbsp;be&nbsp;<br>
word-aligned&nbsp;afterwards&nbsp;too.&nbsp;<br>
All load&nbsp;and&nbsp;store&nbsp;instructions could&nbsp;use&nbsp;just&nbsp;this&nbsp;simple&nbsp;form&nbsp;of&nbsp;register-indirect&nbsp;<br>
addressing.&nbsp;However, the&nbsp;ARM&nbsp;instruction&nbsp;set&nbsp;includes&nbsp;more&nbsp;addressing&nbsp;modes that&nbsp;<br>
can make the code&nbsp;more efficient.&nbsp;<br>
Base&nbsp;plus offset&nbsp;<br>
If&nbsp;the base&nbsp;register does not&nbsp;contain&nbsp;exactly&nbsp;the&nbsp;right&nbsp;address,&nbsp;an&nbsp;offset&nbsp;of up&nbsp;to&nbsp;<br>
addressing&nbsp;<br>
4 Kbytes&nbsp;may&nbsp;be added&nbsp;(or subtracted) to the base&nbsp;to compute the transfer address:&nbsp;<br>
&nbsp;&nbsp;&nbsp;LDR&nbsp;<br>
r0, &nbsp; &nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;men32[r1 &nbsp;&nbsp;<br>
[r1,#4]&nbsp;<br>
+ &nbsp; 4]&nbsp;<br>
This&nbsp;is&nbsp;a&nbsp;<b>pre-indexed&nbsp;</b>addressing&nbsp;mode. It allows one&nbsp;base&nbsp;register to&nbsp;be&nbsp;used&nbsp;to&nbsp;<br>
access&nbsp;a number of&nbsp;memory locations&nbsp;which are in&nbsp;the same&nbsp;area of memory.&nbsp;<br>
Sometimes&nbsp;it&nbsp;is useful&nbsp;to&nbsp;modify the base&nbsp;register&nbsp;to point to&nbsp;the transfer&nbsp;address.&nbsp;<br>
This can&nbsp;be&nbsp;achieved&nbsp;by&nbsp;using pre-indexed&nbsp;addressing&nbsp;with&nbsp;<b>auto-indexing,&nbsp;</b>and allows&nbsp;<br>
the&nbsp;program&nbsp;to walk through a&nbsp;table&nbsp;of values:&nbsp;<br>
LDR&nbsp;<br>
r0, &nbsp; &nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;mem32[r1 &nbsp;&nbsp;<br>
[r1,#4]!&nbsp;<br>
+&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4]&nbsp;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
+&nbsp;&nbsp; 4&nbsp;<br>
The exclamation&nbsp;mark indicates that the instruction should update the base reg-<br>
ister&nbsp;after initiating&nbsp;the&nbsp;data&nbsp;transfer. On the ARM&nbsp;this auto-indexing costs&nbsp;no&nbsp;<br>
extra time since it is&nbsp;performed on&nbsp;the processor's datapath while&nbsp;the&nbsp;data is being&nbsp;<br>
fetched from&nbsp;memory. It is&nbsp;exactly&nbsp;equivalent&nbsp;to&nbsp;preceding a simple&nbsp;<br>
register-indirect load with&nbsp;a data processing instruction that adds the offset&nbsp;(4&nbsp;<br>
bytes&nbsp;in&nbsp;this&nbsp;example) to&nbsp;the base&nbsp;register, but the&nbsp;time&nbsp;and code&nbsp;space cost&nbsp;of&nbsp;<br>
the&nbsp;extra&nbsp;instruction&nbsp;are&nbsp;avoided.&nbsp;<br>
<hr>
<A name=71></a><IMG src="index-71_1.png"><br>
<IMG src="index-71_2.png"><br>
<b>Data&nbsp;transfer&nbsp;instructions</b>&nbsp;<br>
59&nbsp;<br>
Another useful&nbsp;form&nbsp;of&nbsp;the instruction, called&nbsp;<b>post-indexed&nbsp;</b>addressing, allows&nbsp;<br>
the base to be&nbsp;used without an offset as&nbsp;the transfer&nbsp;address, after&nbsp;which it is&nbsp;<br>
auto-indexed:&nbsp;<br>
LDR&nbsp;<br>
r0,&nbsp;[r1], #4&nbsp;<br>
r0 := mem32&nbsp;[r1]&nbsp;<br>
r1 := r1&nbsp;+&nbsp;4&nbsp;<br>
Here the&nbsp;exclamation mark is not&nbsp;needed, since&nbsp;the&nbsp;only use of the immediate&nbsp;offset&nbsp;<br>
is as a base&nbsp;register&nbsp;modifier.&nbsp;Again, this&nbsp;form&nbsp;of&nbsp;the&nbsp;instruction is&nbsp;exactly&nbsp;equivalent&nbsp;<br>
to&nbsp;a simple&nbsp;register-indirect load followed&nbsp;by&nbsp;a&nbsp;data&nbsp;processing&nbsp;instruction,&nbsp;but&nbsp;it&nbsp;is&nbsp;<br>
faster&nbsp;and occupies less&nbsp;code space.&nbsp;<br>
Using&nbsp;the last&nbsp;of these&nbsp;forms we can&nbsp;now improve on&nbsp;the&nbsp;table&nbsp;copying&nbsp;program&nbsp;<br>
example introduced&nbsp;earlier:&nbsp;<br>
&nbsp;<br>
The load&nbsp;and store instructions&nbsp;are repeated&nbsp;until the required number of values&nbsp;has&nbsp;<br>
been copied into TABLE2, then the loop&nbsp;is exited. Control&nbsp;flow&nbsp;instructions&nbsp;are&nbsp;<br>
required&nbsp;to&nbsp;determine&nbsp;the&nbsp;loop&nbsp;exit;&nbsp;they&nbsp;will&nbsp;be&nbsp;introduced&nbsp;shortly.&nbsp;<br>
In&nbsp;the above examples&nbsp;the&nbsp;address offset&nbsp;from&nbsp;the base&nbsp;register&nbsp;was always an&nbsp;<br>
immediate value.&nbsp;It&nbsp;can&nbsp;equally&nbsp;be another&nbsp;register, optionally&nbsp;subject to&nbsp;a shift&nbsp;oper-<br>
ation&nbsp;before&nbsp;being&nbsp;added&nbsp;to&nbsp;the base, but&nbsp;such&nbsp;forms of the&nbsp;instruction are&nbsp;less&nbsp;useful&nbsp;<br>
than&nbsp;the&nbsp;immediate&nbsp;offset form. They are&nbsp;described fully in&nbsp;Section 5.10&nbsp;on&nbsp;page 125.&nbsp;<br>
As a final variation,&nbsp;the size&nbsp;of the&nbsp;data&nbsp;item&nbsp;which&nbsp;is transferred may be a single&nbsp;<br>
unsigned 8-bit byte instead of&nbsp;a 32-bit&nbsp;word.&nbsp;This&nbsp;option&nbsp;is&nbsp;selected&nbsp;by adding a letter&nbsp;<br>
B&nbsp;onto the&nbsp;opcode:&nbsp;<br>
&nbsp;<br>
In&nbsp;this case&nbsp;the&nbsp;transfer&nbsp;address can have&nbsp;any alignment&nbsp;and is&nbsp;not&nbsp;restricted&nbsp;to&nbsp;a&nbsp;<br>
4-byte boundary,&nbsp;since bytes&nbsp;may be stored&nbsp;at&nbsp;any&nbsp;byte address. The loaded byte is&nbsp;<br>
placed&nbsp;in&nbsp;the&nbsp;bottom&nbsp;byte of r0 and&nbsp;the&nbsp;remaining&nbsp;bytes in&nbsp;r0&nbsp;are filled&nbsp;with&nbsp;zeros.&nbsp;<br>
(All&nbsp;but&nbsp;the&nbsp;oldest&nbsp;ARM&nbsp;processors&nbsp;also&nbsp;support&nbsp;<b>signed&nbsp;</b>bytes, where&nbsp;the top bit&nbsp;of&nbsp;<br>
the byte indicates&nbsp;whether the value&nbsp;should&nbsp;be&nbsp;treated&nbsp;as positive or negative, and&nbsp;<br>
signed&nbsp;and unsigned 16-bit&nbsp;half-words;&nbsp;these&nbsp;variants&nbsp;will be&nbsp;described when&nbsp;we&nbsp;<br>
return to&nbsp;look&nbsp;at&nbsp;the&nbsp;instruction&nbsp;set in&nbsp;more&nbsp;detail&nbsp;in Section&nbsp;5.11&nbsp;on&nbsp;page&nbsp;128.)&nbsp;<br>
<hr>
<A name=72></a><IMG src="index-72_1.png"><br>
60&nbsp;<br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Multiple register&nbsp;&nbsp;Where considerable&nbsp;quantities&nbsp;of&nbsp;data&nbsp;are&nbsp;to&nbsp;be transferred,&nbsp;it is&nbsp;preferable&nbsp;to&nbsp;move&nbsp;<br>
data&nbsp;transfers&nbsp;<br>
several registers at&nbsp;a time.&nbsp;These instructions allow&nbsp;any&nbsp;subset&nbsp;(or&nbsp;all)&nbsp;of&nbsp;the&nbsp;16&nbsp;reg-<br>
isters to be&nbsp;transferred&nbsp;with&nbsp;a single&nbsp;instruction. The trade-off is that the available&nbsp;<br>
addressing modes&nbsp;are more restricted&nbsp;than&nbsp;with&nbsp;a&nbsp;single&nbsp;register&nbsp;transfer&nbsp;instruction.&nbsp;<br>
A&nbsp;simple&nbsp;example of this instruction&nbsp;class is:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Since the transferred data items&nbsp;are always 32-bit words, the base address&nbsp;(r1)&nbsp;<br>
should&nbsp;be&nbsp;word-aligned.&nbsp;<br>
The&nbsp;transfer&nbsp;list,&nbsp;within the curly&nbsp;brackets,&nbsp;may&nbsp;contain any&nbsp;or all of&nbsp;r0&nbsp;to&nbsp;r15.&nbsp;The&nbsp;<br>
order of&nbsp;the&nbsp;registers&nbsp;within the list is&nbsp;insignificant and does not affect the order&nbsp;of&nbsp;<br>
transfer&nbsp;or&nbsp;the values&nbsp;in the&nbsp;registers after the instruction has&nbsp;executed. It&nbsp;is&nbsp;normal&nbsp;<br>
practice,&nbsp;however, to&nbsp;specify the registers in&nbsp;increasing&nbsp;order within the list.&nbsp;<br>
Note&nbsp;that&nbsp;including&nbsp;r15&nbsp;in&nbsp;the&nbsp;list&nbsp;will&nbsp;cause&nbsp;a&nbsp;change&nbsp;in&nbsp;the&nbsp;control&nbsp;flow, since&nbsp;<br>
r15&nbsp;is&nbsp;the&nbsp;PC.&nbsp;We&nbsp;will&nbsp;return to&nbsp;this&nbsp;case&nbsp;when&nbsp;we&nbsp;discuss control&nbsp;flow&nbsp;instructions&nbsp;<br>
and&nbsp;will&nbsp;not&nbsp;consider&nbsp;it&nbsp;further until then.&nbsp;<br>
The above example illustrates a common&nbsp;feature of all forms of these instruc-<br>
tions: the lowest register&nbsp;is transferred to or from&nbsp;the lowest address, and then the&nbsp;<br>
other registers are transferred in order of&nbsp;register number to or from&nbsp;consecutive&nbsp;<br>
word addresses above&nbsp;the first. However&nbsp;there&nbsp;are&nbsp;several&nbsp;variations&nbsp;on&nbsp;how&nbsp;the&nbsp;<br>
first address is formed, and auto-indexing is&nbsp;also available (again&nbsp;by&nbsp;adding a '!'&nbsp;<br>
after the base register).&nbsp;<br>
Stack&nbsp;<br>
The addressing&nbsp;variations&nbsp;stem&nbsp;from&nbsp;the&nbsp;fact that one&nbsp;use of these&nbsp;instructions is&nbsp;to&nbsp;<br>
addressing&nbsp;<br>
implement&nbsp;stacks within&nbsp;memory. A&nbsp;stack&nbsp;is a form&nbsp;of&nbsp;last-in-first-out&nbsp;store which&nbsp;<br>
supports simple dynamic&nbsp;memory allocation, that is,&nbsp;memory allocation where the&nbsp;<br>
address to be used to store a data value is&nbsp;not known at&nbsp;the time&nbsp;the program&nbsp;is&nbsp;<br>
compiled&nbsp;or&nbsp;assembled. An&nbsp;example would&nbsp;be&nbsp;a recursive&nbsp;function, where the&nbsp;depth&nbsp;<br>
of recursion depends on the&nbsp;value of the&nbsp;argument. A stack is usually&nbsp;implemented&nbsp;<br>
as&nbsp;a&nbsp;linear&nbsp;data&nbsp;structure which&nbsp;grows&nbsp;up&nbsp;(an&nbsp;<b>ascending&nbsp;</b>stack) or&nbsp;down&nbsp;(a&nbsp;<b>descend-</b><br>
<b>ing&nbsp;</b>stack)&nbsp;memory&nbsp;as data is added to&nbsp;it and shrinks back&nbsp;as data is removed. A&nbsp;<br>
<b>stack pointer&nbsp;</b>holds the&nbsp;address of&nbsp;the&nbsp;current&nbsp;top&nbsp;of&nbsp;the&nbsp;stack, either&nbsp;by&nbsp;pointing&nbsp;to&nbsp;<br>
the last valid data item&nbsp;pushed onto the stack (a&nbsp;<b>full&nbsp;</b>stack), or by&nbsp;pointing to the&nbsp;<br>
vacant slot where the&nbsp;next&nbsp;data&nbsp;item&nbsp;will&nbsp;be placed (an&nbsp;<b>empty&nbsp;</b>stack).&nbsp;<br>
The&nbsp;above&nbsp;description&nbsp;suggests that&nbsp;there&nbsp;are&nbsp;four&nbsp;variations&nbsp;on&nbsp;a&nbsp;stack,&nbsp;represent-<br>
ing all the combinations of&nbsp;ascending and descending full and empty stacks. The&nbsp;<br>
ARM multiple&nbsp;register transfer&nbsp;instructions support&nbsp;all four&nbsp;forms of stack:&nbsp;<br>
• Full&nbsp;ascending: the&nbsp;stack grows up through increasing&nbsp;memory addresses and&nbsp;the&nbsp;<br>
base&nbsp;register points to&nbsp;the highest address containing a valid item.&nbsp;<br>
<hr>
<A name=73></a><b>Data&nbsp;transfer&nbsp;instructions</b>&nbsp;<br>
61&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
•&nbsp;&nbsp;Empty&nbsp;ascending: the&nbsp;stack grows up through increasing&nbsp;memory&nbsp;addresses and&nbsp;<br>
the base&nbsp;register points to&nbsp;the first empty&nbsp;location above&nbsp;the stack.&nbsp;<br>
•&nbsp;&nbsp;Full&nbsp;descending:&nbsp;the stack grows down&nbsp;through&nbsp;decreasing memory&nbsp;addresses&nbsp;<br>
and the base&nbsp;register points to&nbsp;the lowest address&nbsp;containing&nbsp;a valid item.&nbsp;<br>
•&nbsp;&nbsp;Empty&nbsp;descending: the&nbsp;stack&nbsp;grows down&nbsp;through decreasing&nbsp;memory&nbsp;addresses&nbsp;<br>
and the base&nbsp;register points to&nbsp;the&nbsp;first&nbsp;empty location below the&nbsp;stack.&nbsp;<br>
Block copy&nbsp;<br>
Although&nbsp;the&nbsp;stack&nbsp;view of&nbsp;multiple&nbsp;register transfer instructions&nbsp;is useful,&nbsp;there are&nbsp;<br>
addressing&nbsp;<br>
occasions&nbsp;when&nbsp;a different view&nbsp;is&nbsp;easier&nbsp;to understand. For example, when these&nbsp;<br>
instructions&nbsp;are used&nbsp;to&nbsp;copy&nbsp;a&nbsp;block&nbsp;of data&nbsp;from&nbsp;one place in&nbsp;memory to&nbsp;another&nbsp;a&nbsp;<br>
mechanistic view of&nbsp;the addressing process is&nbsp;more useful.&nbsp;Therefore&nbsp;the ARM&nbsp;<br>
assembler&nbsp;supports two&nbsp;different&nbsp;views&nbsp;of&nbsp;the addressing&nbsp;mechanism,&nbsp;both of&nbsp;which&nbsp;<br>
map&nbsp;onto&nbsp;the&nbsp;same&nbsp;basic&nbsp;instructions, and&nbsp;which&nbsp;can&nbsp;be&nbsp;used&nbsp;interchangeably.&nbsp;The&nbsp;<br>
block copy&nbsp;view is based on&nbsp;whether the data is to be stored above or below the&nbsp;<br>
address held&nbsp;in the base&nbsp;register and&nbsp;whether the address incrementing or decre-<br>
menting begins&nbsp;before&nbsp;or after storing the&nbsp;first value.&nbsp;The&nbsp;mapping&nbsp;between&nbsp;the&nbsp;two&nbsp;<br>
views&nbsp;depends&nbsp;on&nbsp;whether&nbsp;the operation is a load&nbsp;or&nbsp;a&nbsp;store,&nbsp;and is detailed in&nbsp;<br>
Table 3.1&nbsp;on&nbsp;page&nbsp;62.&nbsp;<br>
The block&nbsp;copy&nbsp;views&nbsp;are illustrated&nbsp;in&nbsp;Figure&nbsp;3.2 on&nbsp;page&nbsp;62,&nbsp;which shows how&nbsp;<br>
each variant stores three registers into memory&nbsp;and how the&nbsp;base register is&nbsp;modified&nbsp;if&nbsp;<br>
auto-indexing&nbsp;is&nbsp;enabled. The&nbsp;base&nbsp;register&nbsp;value before&nbsp;the instruction&nbsp;is&nbsp;r9,&nbsp;and after&nbsp;<br>
the&nbsp;auto-indexing&nbsp;it&nbsp;is&nbsp;r9'.&nbsp;<br>
To illustrate&nbsp;the use of these instructions,&nbsp;here are two instructions&nbsp;which copy&nbsp;<br>
eight&nbsp;words from the location&nbsp;r0&nbsp;points&nbsp;to&nbsp;to&nbsp;the location&nbsp;r1&nbsp;points&nbsp;to:&nbsp;<br>
LDMIA &nbsp;r0!,&nbsp;{r2-r9}&nbsp;<br>
STMIA &nbsp;r1, &nbsp;{r2-r9}&nbsp;<br>
After executing these&nbsp;instructions&nbsp;r0&nbsp;has&nbsp;increased&nbsp;by&nbsp;32&nbsp;since&nbsp;the&nbsp;'!'&nbsp;causes&nbsp;it&nbsp;to&nbsp;<br>
auto-index&nbsp;across&nbsp;eight words, whereas r1&nbsp;is&nbsp;unchanged. If&nbsp;r2&nbsp;to&nbsp;r9&nbsp;contained&nbsp;useful&nbsp;<br>
values,&nbsp;we&nbsp;could&nbsp;preserve&nbsp;them&nbsp;across&nbsp;this&nbsp;operation&nbsp;by&nbsp;pushing&nbsp;them&nbsp;onto&nbsp;a stack:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
STMFD&nbsp;r13!,&nbsp;{r2-r9}&nbsp;<br>
save&nbsp;regs onto stack&nbsp;<br>
LDMIA&nbsp;r0!,&nbsp;&nbsp;{r2-r9}&nbsp;<br>
STMIA&nbsp;r1,&nbsp;<br>
{r2-r9}&nbsp;<br>
LDMFD&nbsp;r13!,&nbsp;{r2-r9}&nbsp;<br>
; &nbsp; restore &nbsp; from&nbsp;<br>
stack&nbsp;<br>
Here the 'FD'&nbsp;postfix on&nbsp;the&nbsp;first and last instructions signifies the full&nbsp;descend-<br>
ing stack address&nbsp;mode&nbsp;as&nbsp;described earlier. Note&nbsp;that&nbsp;auto-indexing&nbsp;is almost&nbsp;<br>
always&nbsp;specified for&nbsp;stack&nbsp;operations&nbsp;in&nbsp;order to&nbsp;ensure&nbsp;that the&nbsp;stack&nbsp;pointer has a&nbsp;<br>
consistent behaviour.&nbsp;<br>
The&nbsp;load&nbsp;and store&nbsp;multiple&nbsp;register&nbsp;instructions&nbsp;are an efficient way to save&nbsp;and&nbsp;<br>
restore&nbsp;processor state&nbsp;and&nbsp;to&nbsp;move blocks&nbsp;of&nbsp;data&nbsp;around&nbsp;in&nbsp;memory. They&nbsp;save&nbsp;code&nbsp;<br>
space and operate up to&nbsp;four&nbsp;times faster&nbsp;than&nbsp;the equivalent&nbsp;sequence&nbsp;of&nbsp;single&nbsp;<br>
<hr>
<A name=74></a><IMG src="index-74_1.png"><br>
<IMG src="index-74_2.png"><br>
<IMG src="index-74_3.png"><br>
62&nbsp;<br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;3.2&nbsp; &nbsp;</b>Multiple&nbsp;register&nbsp;transfer addressing&nbsp;modes.&nbsp;<br>
<b>Table&nbsp;3.1 &nbsp; &nbsp;</b>The&nbsp;mapping between the stack and block copy&nbsp;views of the&nbsp;load and store&nbsp;<br>
multiple&nbsp;instructions.&nbsp;<br>
&nbsp;<br>
<hr>
<A name=75></a><IMG src="index-75_1.png"><br>
<b>Control flow&nbsp;instructions</b>&nbsp;<br>
<b>63</b>&nbsp;<br>
register&nbsp;load or&nbsp;store&nbsp;instructions&nbsp;(a&nbsp;factor&nbsp;of two due&nbsp;to&nbsp;improved sequential behav-<br>
iour and&nbsp;another&nbsp;factor&nbsp;of&nbsp;nearly&nbsp;two&nbsp;due to&nbsp;the&nbsp;reduced&nbsp;instruction count).&nbsp;This&nbsp;sig-<br>
nificant advantage&nbsp;suggests&nbsp;that it is&nbsp;worth thinking&nbsp;carefully&nbsp;about how data&nbsp;is&nbsp;<br>
organized in&nbsp;memory in order to&nbsp;maximize the potential for using&nbsp;multiple&nbsp;register&nbsp;<br>
data&nbsp;transfer instructions&nbsp;to&nbsp;access&nbsp;it.&nbsp;<br>
These&nbsp;instructions&nbsp;are,&nbsp;perhaps, not&nbsp;pure 'RISC'&nbsp;since&nbsp;they&nbsp;cannot&nbsp;be executed&nbsp;in&nbsp;a&nbsp;<br>
single&nbsp;clock cycle even&nbsp;with separate&nbsp;instruction&nbsp;and&nbsp;data&nbsp;caches,&nbsp;but&nbsp;other RISC&nbsp;<br>
architectures&nbsp;are&nbsp;beginning to&nbsp;adopt multiple&nbsp;register transfer instructions in&nbsp;order&nbsp;to&nbsp;<br>
increase the&nbsp;data&nbsp;bandwidth&nbsp;between the processor's&nbsp;registers&nbsp;and&nbsp;the&nbsp;memory.&nbsp;<br>
On the&nbsp;other side&nbsp;of the&nbsp;equation,&nbsp;load&nbsp;and store multiple&nbsp;instructions&nbsp;are&nbsp;complex&nbsp;<br>
to implement, as&nbsp;we shall see later.&nbsp;<br>
The&nbsp;ARM&nbsp;multiple register transfer instructions&nbsp;are uniquely flexible&nbsp;in&nbsp;being&nbsp;able&nbsp;<br>
to&nbsp;transfer&nbsp;any&nbsp;subset&nbsp;of&nbsp;the 16 currently visible&nbsp;registers,&nbsp;and this&nbsp;feature is&nbsp;power-<br>
fully&nbsp;exploited by&nbsp;the ARM&nbsp;procedure&nbsp;call mechanism&nbsp;which is&nbsp;described&nbsp;in&nbsp;<br>
Section 6.8&nbsp;on&nbsp;page&nbsp;175.&nbsp;<br>
3.3 &nbsp; Control&nbsp;flow&nbsp;instructions&nbsp;<br>
This third category&nbsp;of instructions&nbsp;neither&nbsp;processes data&nbsp;nor moves it&nbsp;around;&nbsp;it&nbsp;<br>
simply&nbsp;determines&nbsp;which&nbsp;instructions get executed next.&nbsp;<br>
Branch&nbsp;<br>
The most&nbsp;common way&nbsp;to&nbsp;switch&nbsp;program&nbsp;execution&nbsp;from&nbsp;one place to another&nbsp;is&nbsp;&nbsp;to&nbsp;<br>
instructions&nbsp;<br>
use the&nbsp;branch&nbsp;instruction:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
LABEL&nbsp;<br>
The processor normally&nbsp;executes&nbsp;instructions&nbsp;sequentially,&nbsp;but&nbsp;when&nbsp;it&nbsp;reaches the&nbsp;<br>
branch&nbsp;instruction it&nbsp;proceeds&nbsp;directly&nbsp;to&nbsp;the&nbsp;instruction&nbsp;at&nbsp;LABEL&nbsp;instead of&nbsp;executing&nbsp;<br>
the instruction&nbsp;immediately&nbsp;after the&nbsp;branch. In this&nbsp;example&nbsp;LABEL&nbsp;comes after&nbsp;the&nbsp;<br>
branch&nbsp;instruction&nbsp;in&nbsp;the&nbsp;program,&nbsp;so&nbsp;the instructions in&nbsp;between&nbsp;are&nbsp;skipped.&nbsp;How-<br>
ever,&nbsp;LABEL&nbsp;could equally well come&nbsp;before the&nbsp;branch, in&nbsp;which case&nbsp;the processor&nbsp;<br>
goes&nbsp;back&nbsp;to&nbsp;it&nbsp;and&nbsp;possibly&nbsp;repeats&nbsp;some&nbsp;instructions&nbsp;it&nbsp;has already&nbsp;executed.&nbsp;<br>
Conditional&nbsp;<br>
branches&nbsp;<br>
Sometimes&nbsp;you will&nbsp;want the&nbsp;processor&nbsp;to&nbsp;take a decision&nbsp;whether or&nbsp;not to branch.&nbsp;<br>
For example, to implement a loop a branch&nbsp;back to&nbsp;the&nbsp;start of the&nbsp;loop&nbsp;is&nbsp;required,&nbsp;<br>
but this branch&nbsp;should only&nbsp;be&nbsp;taken until the loop has been executed&nbsp;the&nbsp;required&nbsp;<br>
number of&nbsp;times, then the branch should be&nbsp;skipped.&nbsp;<br>
The&nbsp;mechanism&nbsp;used to control&nbsp;loop exit&nbsp;is&nbsp;conditional branching.&nbsp;Here the&nbsp;branch&nbsp;<br>
has&nbsp;a condition&nbsp;associated&nbsp;with it&nbsp;and&nbsp;it&nbsp;is only&nbsp;executed if&nbsp;the&nbsp;condition&nbsp;codes have&nbsp;<br>
the&nbsp;correct&nbsp;value. A&nbsp;typical&nbsp;loop&nbsp;control sequence&nbsp;might&nbsp;be:&nbsp;<br>
<hr>
<A name=76></a>64&nbsp;<br>
<b>ARM Assembly&nbsp;Language Programming</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
MOV&nbsp;<br>
r0, #0&nbsp;<br>
;&nbsp;initialize counter&nbsp;<br>
LOOP&nbsp;<br>
ADD&nbsp;<br>
r0,&nbsp;r0, #1&nbsp;<br>
;&nbsp;increment&nbsp;loop counter&nbsp;<br>
CMP BNE&nbsp;&nbsp;r0, #10&nbsp;<br>
;&nbsp;compare with limit&nbsp;<br>
LOOP&nbsp;<br>
;&nbsp;repeat if not equal&nbsp;<br>
;&nbsp;else fall through&nbsp;<br>
This&nbsp;example&nbsp;shows&nbsp;one sort&nbsp;of&nbsp;conditional&nbsp;branch,&nbsp;BNE,&nbsp;or 'branch if&nbsp;not&nbsp;equal'.&nbsp;<br>
There are many&nbsp;forms of the condition.&nbsp;All&nbsp;the forms are&nbsp;listed&nbsp;in&nbsp;Table 3.2,&nbsp;along&nbsp;<br>
with&nbsp;their normal&nbsp;interpretations. The pairs&nbsp;of&nbsp;conditions&nbsp;which&nbsp;are listed&nbsp;in&nbsp;the same&nbsp;<br>
row of the table (for&nbsp;instance BCC and&nbsp;BLO)&nbsp;are synonyms&nbsp;which result&nbsp;in&nbsp;identical&nbsp;<br>
binary&nbsp;code,&nbsp;but&nbsp;both are available&nbsp;because each makes&nbsp;the interpretation&nbsp;of the&nbsp;<br>
assembly source code easier in particular&nbsp;circumstances.&nbsp;Where the table refers to&nbsp;<br>
signed&nbsp;or&nbsp;unsigned comparisons this&nbsp;does&nbsp;not&nbsp;reflect&nbsp;a choice in&nbsp;the&nbsp;comparison&nbsp;<br>
instruction&nbsp;itself but supports alternative interpretations&nbsp;of&nbsp;the operands.&nbsp;<br>
<b>Table&nbsp;</b>3.2 &nbsp;&nbsp;&nbsp;Branch&nbsp;conditions.&nbsp;<br>
&nbsp;<br>
Branch&nbsp;&nbsp;&nbsp;Interpretation&nbsp;&nbsp;&nbsp;<br>
Normal uses&nbsp;&nbsp;&nbsp;<br>
B BAL&nbsp;&nbsp;&nbsp;<br>
Unconditional&nbsp;<br>
Always&nbsp;take&nbsp;this branch&nbsp;<br>
Always&nbsp;&nbsp;&nbsp;<br>
Always&nbsp;take&nbsp;this branch&nbsp;&nbsp;&nbsp;<br>
BEQ&nbsp;&nbsp;&nbsp;<br>
Equal&nbsp;&nbsp;&nbsp;<br>
Comparison equal or&nbsp;zero&nbsp;result&nbsp;&nbsp;&nbsp;<br>
BNE&nbsp;&nbsp;&nbsp;<br>
Not equal&nbsp;&nbsp;&nbsp;<br>
Comparison&nbsp;not equal or&nbsp;non-zero result&nbsp;&nbsp;&nbsp;<br>
BPL&nbsp;&nbsp;&nbsp;<br>
Plus&nbsp;&nbsp;&nbsp;<br>
Result positive or zero&nbsp;&nbsp;&nbsp;<br>
BMI&nbsp;&nbsp;&nbsp;<br>
Minus&nbsp;&nbsp;&nbsp;<br>
Result&nbsp;minus or negative&nbsp;&nbsp;&nbsp;<br>
BCC&nbsp;<br>
Carry clear&nbsp;<br>
Arithmetic&nbsp;operation did not give&nbsp;carry-out&nbsp;<br>
BLO&nbsp;&nbsp;&nbsp;<br>
Lower&nbsp;&nbsp;&nbsp;<br>
Unsigned&nbsp;comparison&nbsp;gave&nbsp;lower&nbsp;&nbsp;&nbsp;<br>
BCS&nbsp;<br>
Carry set&nbsp;Higher&nbsp;<br>
Arithmetic&nbsp;operation&nbsp;gave&nbsp;carry-out&nbsp;<br>
BHS&nbsp;&nbsp;&nbsp;<br>
or same&nbsp;&nbsp;&nbsp;<br>
Unsigned comparison gave higher or same&nbsp;&nbsp;&nbsp;<br>
BVC&nbsp;&nbsp;&nbsp;<br>
Overflow clear&nbsp;&nbsp;&nbsp;<br>
Signed integer operation; no&nbsp;overflow occurred&nbsp;&nbsp;&nbsp;<br>
BVS&nbsp;&nbsp;&nbsp;<br>
Overflow set&nbsp;&nbsp;&nbsp;<br>
Signed integer operation; overflow&nbsp;occurred&nbsp;&nbsp;&nbsp;<br>
BGT&nbsp;&nbsp;&nbsp;<br>
Greater than&nbsp;&nbsp;&nbsp;<br>
Signed integer comparison gave greater than&nbsp;&nbsp;&nbsp;<br>
BGE&nbsp;&nbsp;&nbsp;<br>
Greater or&nbsp;equal&nbsp;&nbsp;&nbsp;&nbsp;Signed integer comparison gave greater or&nbsp;equal&nbsp;&nbsp;&nbsp;<br>
BLT&nbsp;&nbsp;&nbsp;<br>
Less than&nbsp;&nbsp;&nbsp;<br>
Signed integer comparison gave less than&nbsp;&nbsp;&nbsp;<br>
BLE&nbsp;&nbsp;&nbsp;<br>
Less or equal&nbsp;&nbsp;&nbsp;<br>
Signed integer comparison gave less than or equal&nbsp;&nbsp;&nbsp;<br>
BHI&nbsp;&nbsp;&nbsp;<br>
Higher&nbsp;&nbsp;&nbsp;<br>
Unsigned comparison gave higher&nbsp;&nbsp;&nbsp;<br>
BLS&nbsp;&nbsp;&nbsp;<br>
Lower or&nbsp;same&nbsp;&nbsp;&nbsp;<br>
Unsigned comparison gave lower&nbsp;or same&nbsp;&nbsp;&nbsp;<br>
<hr>
<A name=77></a><IMG src="index-77_1.png"><br>
<IMG src="index-77_2.png"><br>
<b>Control flow&nbsp;instructions</b>&nbsp;<br>
65&nbsp;<br>
&nbsp;&nbsp;&nbsp;Conditional&nbsp;<br>
An&nbsp;unusual&nbsp;feature of&nbsp;the&nbsp;ARM instruction set&nbsp;is that&nbsp;conditional&nbsp;execution applies&nbsp;<br>
execution&nbsp;<br>
not only&nbsp;to branches but to&nbsp;all ARM&nbsp;instructions.&nbsp;A branch which is used to skip a&nbsp;<br>
small number&nbsp;of&nbsp;following&nbsp;instructions&nbsp;may be&nbsp;omitted altogether&nbsp;by&nbsp;giving those&nbsp;<br>
instructions&nbsp;the opposite condition. For example, consider&nbsp;the&nbsp;following&nbsp;sequence:&nbsp;<br>
This&nbsp;may be replaced&nbsp;by:<br>
The new&nbsp;sequence is both&nbsp;smaller and faster&nbsp;than&nbsp;the&nbsp;old one.&nbsp;Whenever&nbsp;the&nbsp;condi-<br>
tional&nbsp;sequence&nbsp;is three&nbsp;instructions&nbsp;or&nbsp;fewer it&nbsp;is&nbsp;better&nbsp;to&nbsp;exploit conditional&nbsp;execu-<br>
tion&nbsp;than&nbsp;to&nbsp;use a&nbsp;branch,&nbsp;provided&nbsp;that&nbsp;the&nbsp;skipped sequence&nbsp;is&nbsp;not&nbsp;doing anything&nbsp;<br>
complicated with the&nbsp;condition&nbsp;codes&nbsp;within&nbsp;itself.&nbsp;<br>
(The&nbsp;three instruction&nbsp;guideline is&nbsp;based&nbsp;on&nbsp;the&nbsp;fact&nbsp;that&nbsp;ARM branch&nbsp;instructions&nbsp;<br>
typically take three&nbsp;cycles&nbsp;to&nbsp;execute, and it&nbsp;is only&nbsp;a guideline.&nbsp;If the code is to be&nbsp;<br>
fully&nbsp;optimized then&nbsp;the decision on&nbsp;whether&nbsp;to use&nbsp;conditional execution or&nbsp;a branch&nbsp;<br>
must be based&nbsp;on measurements&nbsp;of the dynamic code&nbsp;behaviour.)&nbsp;<br>
Conditional&nbsp;execution&nbsp;is&nbsp;invoked&nbsp;by&nbsp;adding&nbsp;the&nbsp;2-letter&nbsp;condition&nbsp;after&nbsp;the&nbsp;3-letter&nbsp;<br>
opcode&nbsp;(and before any other instruction&nbsp;modifier&nbsp;letter&nbsp;such&nbsp;as&nbsp;the 's' that&nbsp;controls&nbsp;<br>
setting the condition codes&nbsp;in&nbsp;a data processing instruction&nbsp;or the&nbsp;'B'&nbsp;that specifies&nbsp;a&nbsp;<br>
byte&nbsp;load&nbsp;or store).&nbsp;<br>
Just to&nbsp;emphasize&nbsp;the&nbsp;scope of&nbsp;this&nbsp;technique,&nbsp;note&nbsp;that&nbsp;every&nbsp;ARM instruction,&nbsp;<br>
including supervisor calls and coprocessor instructions,&nbsp;may have a condition&nbsp;<br>
appended&nbsp;which&nbsp;causes&nbsp;it&nbsp;to&nbsp;be&nbsp;skipped&nbsp;if&nbsp;the&nbsp;condition&nbsp;is&nbsp;not&nbsp;met.&nbsp;<br>
It is sometimes possible&nbsp;to&nbsp;write&nbsp;very&nbsp;compact code&nbsp;by&nbsp;cunning&nbsp;use&nbsp;of&nbsp;conditionals,&nbsp;<br>
for example:&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;((a==b)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(c==d))&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;e++;&nbsp;<br>
CMP&nbsp;r0,&nbsp;r1&nbsp;CMPEQ&nbsp;r2,&nbsp;<br>
r3&nbsp;ADDEQ&nbsp;r4,&nbsp;r4,&nbsp;#1&nbsp;<br>
Note&nbsp;how&nbsp;if&nbsp;the first comparison&nbsp;finds&nbsp;unequal operands the&nbsp;second&nbsp;is&nbsp;skipped,&nbsp;<br>
causing&nbsp;the&nbsp;increment&nbsp;to be&nbsp;skipped&nbsp;also.&nbsp;The logical&nbsp;'and'&nbsp;in the&nbsp;if&nbsp;clause&nbsp;is&nbsp;imple-<br>
mented&nbsp;by&nbsp;making&nbsp;the second&nbsp;comparison&nbsp;conditional.&nbsp;<br>
<hr>
<A name=78></a><IMG src="index-78_1.png"><br>
<IMG src="index-78_2.png"><br>
<IMG src="index-78_3.png"><br>
<IMG src="index-78_4.png"><br>
66&nbsp;<br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Branch and link&nbsp;&nbsp;A common requirement in&nbsp;a&nbsp;program&nbsp;is to&nbsp;be&nbsp;able&nbsp;to&nbsp;branch&nbsp;to&nbsp;a&nbsp;subroutine&nbsp;in&nbsp;a way&nbsp;<br>
instructions&nbsp;<br>
which&nbsp;makes it possible to&nbsp;resume&nbsp;the original code sequence when the&nbsp;subroutine&nbsp;<br>
has&nbsp;completed. This requires&nbsp;that a&nbsp;record&nbsp;is kept of&nbsp;the value of&nbsp;the program&nbsp;coun-<br>
ter&nbsp;just before&nbsp;the branch is&nbsp;taken.&nbsp;<br>
ARM offers&nbsp;this&nbsp;functionality&nbsp;through the&nbsp;branch&nbsp;and link instruction&nbsp;which, as&nbsp;<br>
well as&nbsp;performing&nbsp;a branch in&nbsp;exactly&nbsp;the&nbsp;same&nbsp;way as&nbsp;the branch instruction,&nbsp;also&nbsp;<br>
saves&nbsp;the&nbsp;address of&nbsp;the instruction&nbsp;following&nbsp;the&nbsp;branch&nbsp;in&nbsp;the link&nbsp;register, r14:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
Note&nbsp;that&nbsp;since the return&nbsp;address&nbsp;is&nbsp;held&nbsp;in a&nbsp;register,&nbsp;the subroutine should&nbsp;not&nbsp;call&nbsp;<br>
a further,&nbsp;nested,&nbsp;subroutine&nbsp;without&nbsp;first&nbsp;saving&nbsp;r14,&nbsp;otherwise&nbsp;the&nbsp;new&nbsp;return&nbsp;address&nbsp;<br>
will overwrite the old one&nbsp;and&nbsp;it&nbsp;will not be possible to&nbsp;find the&nbsp;way&nbsp;back&nbsp;to&nbsp;the origi-<br>
nal caller. The normal&nbsp;mechanism&nbsp;used here is to push&nbsp;r14 onto a stack&nbsp;in&nbsp;memory.&nbsp;<br>
Since&nbsp;the&nbsp;subroutine&nbsp;will often also&nbsp;require some&nbsp;work&nbsp;registers, the old values in&nbsp;<br>
these&nbsp;registers&nbsp;can&nbsp;be&nbsp;saved&nbsp;at&nbsp;the&nbsp;same&nbsp;time using&nbsp;a store multiple&nbsp;instruction:&nbsp;<br>
BL&nbsp;<br>
SUB1&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
SUB1 &nbsp; &nbsp;STMFD&nbsp; &nbsp;r13!,&nbsp;{r0-r2,r14}&nbsp;BL&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
save&nbsp;work&nbsp;&amp;&nbsp;link regs&nbsp;<br>
SUB2&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
SUB2&nbsp;<br>
&nbsp;<br>
A subroutine&nbsp;that does&nbsp;not call&nbsp;another subroutine (a&nbsp;<b>leaf&nbsp;</b>subroutine) need&nbsp;not save&nbsp;<br>
r14 since&nbsp;it will not be&nbsp;overwritten.&nbsp;<br>
Subroutine&nbsp;<br>
To&nbsp;get&nbsp;back&nbsp;to&nbsp;the&nbsp;calling&nbsp;routine,&nbsp;the&nbsp;value&nbsp;saved&nbsp;by&nbsp;the&nbsp;branch&nbsp;and&nbsp;link&nbsp;instruction&nbsp;<br>
return&nbsp;<br>
in r14&nbsp;must be copied back into the program&nbsp;counter.&nbsp;In&nbsp;the simplest case of&nbsp;a leaf&nbsp;<br>
instructions&nbsp;<br>
subroutine&nbsp;(a subroutine&nbsp;that&nbsp;does&nbsp;not&nbsp;call another subroutine) a&nbsp;MOV instruction suf-<br>
fices,&nbsp;exploiting the visibility&nbsp;of the program counter as&nbsp;r15:&nbsp;<br>
SUB2&nbsp;<br>
MOV&nbsp;<br>
pc, r14 ;&nbsp;copy r14 into&nbsp;r15 to&nbsp;return&nbsp;<br>
In&nbsp;fact the availability of&nbsp;the&nbsp;program&nbsp;counter as r15&nbsp;means that any&nbsp;of&nbsp;the data&nbsp;<br>
processing&nbsp;instructions&nbsp;can&nbsp;be used&nbsp;to&nbsp;compute&nbsp;a&nbsp;return&nbsp;address, though&nbsp;the&nbsp;'MOV'&nbsp;<br>
form&nbsp;is by&nbsp;far the most commonly&nbsp;used.&nbsp;<br>
Where the&nbsp;return address has been&nbsp;pushed&nbsp;onto a stack,&nbsp;it can be&nbsp;restored along&nbsp;<br>
with&nbsp;any saved&nbsp;work&nbsp;registers&nbsp;using a&nbsp;load&nbsp;multiple&nbsp;instruction:&nbsp;<br>
SUB1&nbsp;&nbsp;&nbsp;&nbsp;STMFD&nbsp;&nbsp;r13!, {r0-r2,r14};&nbsp;save work&nbsp;regs&nbsp;&amp;&nbsp;link&nbsp;BL&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
SUB2&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
LDMFD&nbsp;<br>
r13!, {r0-r2,pc} ; restore work&nbsp;regs &amp; return&nbsp;<br>
<hr>
<A name=79></a><b>Control flow&nbsp;instructions</b>&nbsp;<br>
<b>67</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Note&nbsp;here how the return address&nbsp;is&nbsp;restored&nbsp;directly&nbsp;to&nbsp;the&nbsp;program&nbsp;counter, not&nbsp;to&nbsp;<br>
the link register. This&nbsp;single restore and&nbsp;return instruction is&nbsp;very&nbsp;powerful. Note&nbsp;also&nbsp;<br>
the use of the&nbsp;stack view of the&nbsp;multiple register&nbsp;transfer addressing&nbsp;modes.&nbsp;The same&nbsp;<br>
stack&nbsp;model&nbsp;(in this&nbsp;case 'full descending',&nbsp;which is&nbsp;the most&nbsp;common stack type for&nbsp;<br>
ARM&nbsp;code) is&nbsp;used for&nbsp;both&nbsp;the store and&nbsp;the load,&nbsp;ensuring that&nbsp;the&nbsp;correct&nbsp;values&nbsp;<br>
will&nbsp;be collected.&nbsp;It&nbsp;is important&nbsp;that&nbsp;for&nbsp;any&nbsp;particular&nbsp;stack&nbsp;the same&nbsp;addressing&nbsp;<br>
mode is&nbsp;used for every&nbsp;use of the stack, unless you really&nbsp;know what&nbsp;you are doing.&nbsp;<br>
Supervisor calls&nbsp;<br>
Whenever a program&nbsp;requires input&nbsp;or output, for instance&nbsp;to&nbsp;send some&nbsp;text to&nbsp;the dis-<br>
play, it&nbsp;is&nbsp;normal to&nbsp;call a&nbsp;supervisor&nbsp;routine.&nbsp;The supervisor&nbsp;is&nbsp;a program&nbsp;which operates&nbsp;<br>
at&nbsp;a privileged level, which&nbsp;means that&nbsp;it&nbsp;can&nbsp;do things&nbsp;that&nbsp;a user-level&nbsp;program&nbsp;cannot&nbsp;<br>
do directly.&nbsp;The&nbsp;limitations on the capabilities&nbsp;of a user-level&nbsp;program&nbsp;vary&nbsp;from&nbsp;system&nbsp;<br>
to system,&nbsp;but&nbsp;in&nbsp;many&nbsp;systems the&nbsp;user&nbsp;cannot&nbsp;access&nbsp;hardware&nbsp;facilities directly.&nbsp;<br>
The supervisor&nbsp;provides trusted ways&nbsp;to&nbsp;access system&nbsp;resources&nbsp;which appear&nbsp;to&nbsp;<br>
the user-level&nbsp;program&nbsp;rather&nbsp;like special&nbsp;subroutine&nbsp;accesses.&nbsp;The&nbsp;instruction set&nbsp;<br>
includes&nbsp;a&nbsp;special instruction, SWI, to&nbsp;call&nbsp;these functions, (SWI&nbsp;stands&nbsp;for&nbsp;<br>
'Software Interrupt', but&nbsp;is&nbsp;usually pronounced&nbsp;'Supervisor Call'.)&nbsp;<br>
Although the supervisor calls&nbsp;are implemented in&nbsp;system&nbsp;software, and could there-<br>
fore be totally&nbsp;different from&nbsp;one ARM&nbsp;system&nbsp;to&nbsp;another, most&nbsp;ARM&nbsp;systems imple-<br>
ment&nbsp;a common subset&nbsp;of calls in addition to any specific calls&nbsp;required&nbsp;by&nbsp;the&nbsp;<br>
particular&nbsp;application.&nbsp;The most&nbsp;useful&nbsp;of&nbsp;these is a&nbsp;routine&nbsp;which sends&nbsp;the character&nbsp;<br>
in&nbsp;the bottom&nbsp;byte&nbsp;of&nbsp;r0&nbsp;to&nbsp;the&nbsp;user display device:&nbsp;<br>
SWI&nbsp;<br>
SWI_WriteC&nbsp;<br>
; &nbsp; output &nbsp; r0[7:0]&nbsp;<br>
Another&nbsp;useful&nbsp;call&nbsp;returns&nbsp;control&nbsp;from&nbsp;a&nbsp;user&nbsp;program&nbsp;back&nbsp;to&nbsp;the&nbsp;monitor&nbsp;program:&nbsp;<br>
&nbsp;&nbsp;&nbsp;SWI&nbsp;&nbsp;SWI_Exit&nbsp;<br>
; return&nbsp;to&nbsp;monitor&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The operation&nbsp;of SWIs is&nbsp;described in&nbsp;more detail&nbsp;in&nbsp;Section 5.6&nbsp;on&nbsp;page&nbsp;117.&nbsp;<br>
Jump tables&nbsp;<br>
Jump&nbsp;tables&nbsp;are not&nbsp;normally used by&nbsp;less&nbsp;experienced programmers, so you can&nbsp;<br>
ignore this section&nbsp;if&nbsp;you&nbsp;are&nbsp;relatively new to&nbsp;programming&nbsp;at the assembly level.&nbsp;<br>
The idea of&nbsp;a jump&nbsp;table is that a programmer sometimes&nbsp;wants to&nbsp;call one&nbsp;of&nbsp;a set&nbsp;<br>
of subroutines, the choice depending on&nbsp;a value computed by&nbsp;the program. It&nbsp;is&nbsp;clearly&nbsp;<br>
possible to&nbsp;do&nbsp;this with&nbsp;the instructions&nbsp;we have&nbsp;seen&nbsp;already. Suppose the&nbsp;value is in&nbsp;<br>
r0.&nbsp;We can then write:&nbsp;<br>
&nbsp;&nbsp;&nbsp;BL&nbsp;<br>
JUMPTAB&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
JUMPTAB&nbsp;CMP&nbsp;<br>
r0, #0&nbsp;<br>
BEQ&nbsp;<br>
SUB0 r0,&nbsp;<br>
CMP&nbsp;<br>
#1 SUB1&nbsp;<br>
BEQ&nbsp;<br>
r0, #2&nbsp;<br>
CMP&nbsp;<br>
SUB2&nbsp;<br>
BEQ&nbsp;<br>
<hr>
<A name=80></a><IMG src="index-80_1.png"><br>
<b>68&nbsp;</b><br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
However, this&nbsp;solution becomes very&nbsp;slow&nbsp;when the list&nbsp;of subroutines is long&nbsp;<br>
unless there is&nbsp;some&nbsp;reason&nbsp;to think&nbsp;that&nbsp;the later choices will rarely&nbsp;be used. A&nbsp;<br>
solution&nbsp;which&nbsp;is&nbsp;more&nbsp;efficient in&nbsp;this&nbsp;case exploits the&nbsp;visibility of&nbsp;the program&nbsp;<br>
counter&nbsp;in the general register file:&nbsp;<br>
BL &nbsp; &nbsp; &nbsp;JUMPTAB&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
JUMPTAB&nbsp;ADR&nbsp;<br>
r1, SUBTAB&nbsp;<br>
r1 -&gt; SUBTAB&nbsp;<br>
CMP&nbsp;r0,&nbsp;<br>
#SUBMAX&nbsp;<br>
check&nbsp;for&nbsp;overrun..&nbsp;.&nbsp;.&nbsp;if&nbsp;OK,&nbsp;<br>
LDRLS&nbsp;pc,&nbsp;<br>
[r1,r0,LSL&nbsp;<br>
#2]&nbsp;<br>
table jump ..&nbsp;otherwise&nbsp;<br>
B&nbsp;ERROR&nbsp;<br>
signal&nbsp;error&nbsp;<br>
SUBTAB &nbsp;DCD&nbsp;<br>
SUB0&nbsp;<br>
table of&nbsp;subroutine&nbsp;<br>
DCD&nbsp;SUB1&nbsp;<br>
entry points&nbsp;<br>
DCD&nbsp;SUB2&nbsp;<br>
The 'DCD'&nbsp;directive instructs the&nbsp;assembler&nbsp;to&nbsp;reserve&nbsp;a&nbsp;word of&nbsp;store and to initial-<br>
ize it to&nbsp;the value of&nbsp;the expression to the right,&nbsp;which&nbsp;in&nbsp;these cases is&nbsp;just&nbsp;the&nbsp;address&nbsp;<br>
of the label.&nbsp;<br>
This approach has a&nbsp;constant performance however&nbsp;many&nbsp;subroutines are in&nbsp;the&nbsp;<br>
table and&nbsp;independent&nbsp;of&nbsp;the&nbsp;distribution&nbsp;of&nbsp;frequency&nbsp;of use.&nbsp;Note,&nbsp;however, that&nbsp;the&nbsp;<br>
consequences&nbsp;of&nbsp;reading beyond&nbsp;the&nbsp;end&nbsp;of&nbsp;the table&nbsp;are likely&nbsp;to&nbsp;be&nbsp;dire,&nbsp;so&nbsp;checking&nbsp;<br>
for&nbsp;overrun&nbsp;is essential!&nbsp;Here,&nbsp;note&nbsp;how the overrun check&nbsp;is&nbsp;implemented&nbsp;by&nbsp;making&nbsp;<br>
the&nbsp;load&nbsp;into&nbsp;the&nbsp;PC&nbsp;conditional, so&nbsp;the overrun&nbsp;case&nbsp;skips the load&nbsp;and&nbsp;falls into&nbsp;the&nbsp;<br>
branch&nbsp;to&nbsp;the error&nbsp;handler.&nbsp;The only performance cost of checking&nbsp;for overrun is the&nbsp;<br>
comparison with&nbsp;the maximum&nbsp;value.&nbsp;More&nbsp;obvious code&nbsp;might have&nbsp;been:&nbsp;<br>
CMP&nbsp;<br>
r0,&nbsp;&nbsp;&nbsp;#SUBMAX&nbsp;<br>
;&nbsp;&nbsp;&nbsp;check&nbsp;&nbsp;for&nbsp;overrun..&nbsp;<br>
BHI&nbsp;<br>
ERROR&nbsp;<br>
; &nbsp; &nbsp; &nbsp;.. &nbsp; if&nbsp;overrun&nbsp;call&nbsp;&nbsp;<br>
error&nbsp;<br>
LDR&nbsp;<br>
pc,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[r1,r0,LSL&nbsp;&nbsp;&nbsp;&nbsp;#2]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;..&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else&nbsp;&nbsp;&nbsp;&nbsp;table&nbsp;&nbsp;&nbsp;<br>
jump&nbsp;<br>
but note&nbsp;that&nbsp;here&nbsp;the&nbsp;cost&nbsp;of conditionally&nbsp;skipping&nbsp;the&nbsp;branch&nbsp;is&nbsp;borne&nbsp;every time&nbsp;<br>
the&nbsp;jump&nbsp;table is&nbsp;used.&nbsp;The&nbsp;original&nbsp;version&nbsp;is&nbsp;more&nbsp;efficient&nbsp;except&nbsp;when&nbsp;overrun&nbsp;is&nbsp;<br>
detected, which should be infrequent and, since it represents an error, performance&nbsp;<br>
in that case&nbsp;is&nbsp;not of great concern.&nbsp;<br>
An alternative,&nbsp;less obvious way&nbsp;to implement a jump&nbsp;table is discussed in&nbsp;<br>
'switches'on page 171.&nbsp;<br>
<hr>
<A name=81></a><IMG src="index-81_1.png"><br>
<b>Writing simple&nbsp;assembly&nbsp;language programs</b>&nbsp;<br>
<b>69</b>&nbsp;<br>
3.4 &nbsp; Writing&nbsp;simple&nbsp;assembly&nbsp;language programs&nbsp;<br>
We now have all the basic tools&nbsp;for&nbsp;writing simply&nbsp;assembly language programs.&nbsp;As&nbsp;<br>
with&nbsp;any programming&nbsp;task, it is&nbsp;important to have a&nbsp;clear&nbsp;idea&nbsp;of&nbsp;your&nbsp;algorithm&nbsp;<br>
before beginning to type instructions&nbsp;into&nbsp;the computer.&nbsp;Large programs are almost&nbsp;<br>
certainly&nbsp;better written in C or C++, so&nbsp;we will only&nbsp;look at small&nbsp;examples of&nbsp;<br>
assembly language&nbsp;programs.&nbsp;<br>
Even the most&nbsp;experienced programmers begin by checking&nbsp;that they can get a very&nbsp;<br>
simple&nbsp;program to&nbsp;run&nbsp;before&nbsp;moving&nbsp;on&nbsp;to&nbsp;whatever&nbsp;their&nbsp;real&nbsp;task&nbsp;is.&nbsp;There&nbsp;are so&nbsp;<br>
many&nbsp;complexities to do&nbsp;with&nbsp;learning to use&nbsp;a text editor,&nbsp;working out how to get the&nbsp;<br>
assembler to run, how to&nbsp;load&nbsp;the&nbsp;program&nbsp;into&nbsp;the machine,&nbsp;how to&nbsp;get it&nbsp;to start exe-<br>
cuting&nbsp;and so&nbsp;on.&nbsp;This&nbsp;sort&nbsp;of&nbsp;simple test&nbsp;program&nbsp;is&nbsp;often referred&nbsp;to&nbsp;as&nbsp;a&nbsp;<i>Hello World&nbsp;</i><br>
program&nbsp;because&nbsp;all&nbsp;it&nbsp;does&nbsp;is&nbsp;print 'Hello&nbsp;World'&nbsp;on&nbsp;the&nbsp;display&nbsp;before&nbsp;terminating.&nbsp;<br>
Here is an&nbsp;ARM assembly language version:&nbsp;<br>
&nbsp;<br>
This&nbsp;program&nbsp;illustrates&nbsp;a&nbsp;number of the&nbsp;features&nbsp;of&nbsp;the&nbsp;ARM&nbsp;assembly&nbsp;language&nbsp;<br>
and instruction set:&nbsp;<br>
•&nbsp;&nbsp;The declaration of the code&nbsp;'AREA',&nbsp;with appropriate attributes.&nbsp;<br>
•&nbsp;&nbsp;The definitions&nbsp;of&nbsp;the&nbsp;system&nbsp;calls&nbsp;which&nbsp;will be used in the routine.&nbsp;(In a&nbsp;larger&nbsp;<br>
program&nbsp;these&nbsp;would&nbsp;be&nbsp;defined&nbsp;in&nbsp;a file&nbsp;which other&nbsp;code files would reference.)&nbsp;<br>
•&nbsp;&nbsp;The use of&nbsp;the&nbsp;ADR&nbsp;pseudo instruction to&nbsp;get an address into a base&nbsp;register.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;use of&nbsp;auto-indexed addressing&nbsp;to&nbsp;move&nbsp;through&nbsp;a list of&nbsp;bytes.&nbsp;<br>
•&nbsp;&nbsp;Conditional execution of&nbsp;the&nbsp;SWI instruction to avoid an&nbsp;extra branch.&nbsp;<br>
Note also&nbsp;the use of a&nbsp;zero&nbsp;byte to&nbsp;mark the&nbsp;end of the&nbsp;string (following the line-<br>
feed and&nbsp;carriage&nbsp;return&nbsp;special characters). Whenever&nbsp;you use&nbsp;a looping&nbsp;structure,&nbsp;<br>
make&nbsp;sure it&nbsp;has a&nbsp;terminating&nbsp;condition.&nbsp;<br>
<hr>
<A name=82></a><IMG src="index-82_1.png"><br>
<b>70</b>&nbsp;<br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
In order to run&nbsp;this program&nbsp;you will need&nbsp;the following&nbsp;tools, all&nbsp;of which are&nbsp;<br>
available&nbsp;within&nbsp;the ARM software development toolkit:&nbsp;<br>
•&nbsp;&nbsp;A text&nbsp;editor to&nbsp;type&nbsp;the program&nbsp;into.&nbsp;<br>
•&nbsp;&nbsp;An&nbsp;assembler to&nbsp;turn&nbsp;the&nbsp;program&nbsp;into&nbsp;ARM&nbsp;binary code.&nbsp;<br>
•&nbsp;&nbsp;An ARM system&nbsp;or emulator to execute the binary&nbsp;on. The ARM system&nbsp;must&nbsp;<br>
have some&nbsp;text output capability. (The ARM development board,&nbsp;for example,&nbsp;<br>
sends text output back up to&nbsp;the host&nbsp;for output onto the host's&nbsp;display.)&nbsp;<br>
Once you&nbsp;have this&nbsp;program&nbsp;running&nbsp;you&nbsp;are ready to try something&nbsp;more useful.&nbsp;<br>
From&nbsp;now&nbsp;on,&nbsp;the&nbsp;only&nbsp;thing that&nbsp;changes is&nbsp;the program&nbsp;text. The use&nbsp;of&nbsp;the editor,&nbsp;<br>
the&nbsp;assembler,&nbsp;and&nbsp;the&nbsp;test&nbsp;system&nbsp;or emulator will&nbsp;remain&nbsp;pretty&nbsp;similar&nbsp;to&nbsp;what&nbsp;you&nbsp;<br>
have&nbsp;done&nbsp;already,&nbsp;at least&nbsp;up&nbsp;to&nbsp;the point where your&nbsp;program&nbsp;refuses to&nbsp;do&nbsp;what you&nbsp;<br>
want and&nbsp;you&nbsp;can't&nbsp;see&nbsp;why it&nbsp;refuses.&nbsp;Then&nbsp;you&nbsp;will need&nbsp;to use a debugger to see&nbsp;<br>
what&nbsp;is&nbsp;happening inside your program.&nbsp;This&nbsp;means learning&nbsp;how to&nbsp;use another&nbsp;com-<br>
plex&nbsp;tool, so&nbsp;we&nbsp;will&nbsp;put&nbsp;off that moment for&nbsp;as&nbsp;long&nbsp;as&nbsp;possible.&nbsp;<br>
For the next example, we&nbsp;can&nbsp;now&nbsp;complete the block copy&nbsp;program&nbsp;developed par-<br>
tially earlier&nbsp;in&nbsp;the&nbsp;text. To&nbsp;ensure that&nbsp;we&nbsp;know it&nbsp;has worked&nbsp;properly, we&nbsp;will&nbsp;use&nbsp;a&nbsp;<br>
text&nbsp;source&nbsp;string&nbsp;so&nbsp;that&nbsp;we&nbsp;can&nbsp;output&nbsp;it&nbsp;from&nbsp;the&nbsp;destination&nbsp;address,&nbsp;and&nbsp;we&nbsp;will&nbsp;<br>
initialize&nbsp;the&nbsp;destination&nbsp;area&nbsp;to&nbsp;something different:&nbsp;<br>
&nbsp;<br>
<hr>
<A name=83></a><b>Writing simple assembly&nbsp;language programs&nbsp;</b><br>
<b>71</b>&nbsp;<br>
This&nbsp;program&nbsp;uses word loads and stores to&nbsp;copy&nbsp;the table,&nbsp;which is&nbsp;why&nbsp;the tables&nbsp;<br>
must be&nbsp;word-aligned.&nbsp;It then&nbsp;uses&nbsp;byte loads to print&nbsp;out the&nbsp;result&nbsp;using a routine&nbsp;<br>
which&nbsp;is the same as that used&nbsp;in&nbsp;the 'Hello&nbsp;World'&nbsp;program.&nbsp;<br>
Note&nbsp;the use of&nbsp;'BLT'&nbsp;&nbsp;to&nbsp;control&nbsp;the loop termination.&nbsp;If&nbsp;TABLE1&nbsp;&nbsp;contains&nbsp;a&nbsp;<br>
number&nbsp;of bytes which&nbsp;is&nbsp;not&nbsp;a&nbsp;multiple&nbsp;of four,&nbsp;there is&nbsp;a danger&nbsp;that r1&nbsp;would&nbsp;<br>
step&nbsp;past&nbsp;T1END&nbsp;without ever exactly equalling it, so a termination condition based&nbsp;<br>
on 'BNE'&nbsp;might&nbsp;fail.&nbsp;<br>
If you&nbsp;have succeeded in&nbsp;getting this program&nbsp;running,&nbsp;you are&nbsp;well on the way to&nbsp;<br>
understanding the basic operation of the ARM&nbsp;instruction set.&nbsp;The&nbsp;examples and exer-<br>
cises which&nbsp;follow should&nbsp;be&nbsp;studied to&nbsp;reinforce this&nbsp;understanding.&nbsp;As&nbsp;you&nbsp;attempt&nbsp;<br>
more complex programming tasks, questions&nbsp;of detail will&nbsp;arise. These should be&nbsp;<br>
answered by&nbsp;the full&nbsp;instruction set&nbsp;description given in&nbsp;Chapter 5.&nbsp;<br>
Program design&nbsp;<br>
With&nbsp;a basic understanding of the instruction&nbsp;set, small programs&nbsp;can&nbsp;be&nbsp;written&nbsp;and&nbsp;<br>
debugged&nbsp;without&nbsp;too&nbsp;much&nbsp;trouble by&nbsp;just typing&nbsp;them&nbsp;into&nbsp;an&nbsp;editor and&nbsp;seeing&nbsp;if&nbsp;<br>
they work. However, it is dangerous&nbsp;to assume&nbsp;that this simple approach will scale to&nbsp;<br>
the successful&nbsp;development&nbsp;of complex programs which&nbsp;may&nbsp;be expected to work&nbsp;for&nbsp;<br>
many&nbsp;years,&nbsp;which may&nbsp;be changed&nbsp;by&nbsp;other&nbsp;programmers in&nbsp;the&nbsp;future,&nbsp;and&nbsp;which&nbsp;<br>
may&nbsp;end up in&nbsp;the hands of customers who will&nbsp;use use&nbsp;them&nbsp;in unexpected ways.&nbsp;<br>
This&nbsp;book&nbsp;is&nbsp;not&nbsp;a text&nbsp;on&nbsp;program&nbsp;design,&nbsp;but&nbsp;having&nbsp;offered an&nbsp;introduction to&nbsp;<br>
programming&nbsp;it&nbsp;would be a serious omission not&nbsp;to&nbsp;point&nbsp;out that there is&nbsp;a&nbsp;lot&nbsp;more&nbsp;to&nbsp;<br>
writing&nbsp;a useful program&nbsp;than&nbsp;just sitting&nbsp;down&nbsp;and&nbsp;typing&nbsp;code.&nbsp;<br>
Serious programming&nbsp;should&nbsp;start&nbsp;not&nbsp;with coding, but&nbsp;with&nbsp;careful&nbsp;design.&nbsp;The&nbsp;<br>
first&nbsp;step of the development&nbsp;process is&nbsp;to&nbsp;understand the requirements;&nbsp;it&nbsp;is surprising&nbsp;<br>
how&nbsp;often programs&nbsp;do not behave&nbsp;as expected because the&nbsp;requirements were&nbsp;not&nbsp;<br>
well&nbsp;understood by&nbsp;the programmer! Then the (often informal) requirements should be&nbsp;<br>
translated into&nbsp;an unambiguous specification.&nbsp;Now the design can&nbsp;begin,&nbsp;defining&nbsp;a&nbsp;<br>
program&nbsp;structure, the data structures that&nbsp;the program&nbsp;works with&nbsp;and the algorithms&nbsp;<br>
that&nbsp;are used to&nbsp;perform&nbsp;the required&nbsp;operations on&nbsp;the data. The algorithms&nbsp;may&nbsp;be&nbsp;<br>
expressed&nbsp;in&nbsp;<b>pseudo-code,&nbsp;</b>a program-like&nbsp;notation&nbsp;which&nbsp;does not&nbsp;follow&nbsp;the&nbsp;syntax&nbsp;<br>
of a&nbsp;particular programming language but&nbsp;which makes the&nbsp;meaning clear.&nbsp;<br>
Only&nbsp;when the&nbsp;design is&nbsp;developed should&nbsp;the coding&nbsp;begin. Individual&nbsp;modules&nbsp;<br>
should&nbsp;be coded,&nbsp;tested&nbsp;thoroughly&nbsp;(which&nbsp;may require&nbsp;special&nbsp;programs&nbsp;to&nbsp;be&nbsp;<br>
designed as 'test-harnesses') and documented, and the&nbsp;program built piece by&nbsp;piece.&nbsp;<br>
Today&nbsp;nearly&nbsp;all programming&nbsp;is&nbsp;based&nbsp;on high-level languages,&nbsp;so it is&nbsp;rare&nbsp;for&nbsp;<br>
large programs&nbsp;to&nbsp;be&nbsp;built&nbsp;using&nbsp;assembly&nbsp;programming&nbsp;as described&nbsp;here. Some-<br>
times, however, it&nbsp;may be necessary&nbsp;to&nbsp;develop small&nbsp;software components in&nbsp;assem-<br>
bly&nbsp;language to&nbsp;get&nbsp;the&nbsp;best&nbsp;performance for a&nbsp;critical&nbsp;application,&nbsp;so&nbsp;it&nbsp;is&nbsp;useful&nbsp;to&nbsp;<br>
know&nbsp;how to&nbsp;write&nbsp;assembly&nbsp;code for these&nbsp;purposes.&nbsp;<br>
<hr>
<A name=84></a>72&nbsp;<br>
<b>ARM&nbsp;Assembly&nbsp;Language&nbsp;Programming</b>&nbsp;<br>
3.5 &nbsp; Examples&nbsp;and&nbsp;exercises&nbsp;<br>
Once you&nbsp;have&nbsp;the&nbsp;basic flavour&nbsp;of&nbsp;an instruction set&nbsp;the&nbsp;easiest way&nbsp;to&nbsp;learn to&nbsp;write&nbsp;<br>
programs&nbsp;is to&nbsp;look&nbsp;at some&nbsp;examples, then&nbsp;attempt to&nbsp;write your&nbsp;own program&nbsp;to&nbsp;do&nbsp;<br>
something slightly&nbsp;different.&nbsp;To see&nbsp;whether&nbsp;or not your&nbsp;program&nbsp;works you will&nbsp;need&nbsp;<br>
an ARM assembler and either an ARM emulator or hardware with an&nbsp;ARM processor&nbsp;<br>
in&nbsp;it. The&nbsp;following&nbsp;sections&nbsp;contain&nbsp;example ARM&nbsp;programs&nbsp;and&nbsp;suggestions for&nbsp;<br>
modifications&nbsp;to&nbsp;them. You&nbsp;should get the&nbsp;original program working&nbsp;first,&nbsp;then see if&nbsp;<br>
you can edit&nbsp;it&nbsp;to&nbsp;perform&nbsp;the modified function suggested in&nbsp;the&nbsp;exercises.&nbsp;<br>
<b>Example 3.1</b>&nbsp;<br>
<b>Print&nbsp;out r1 in hexadecimal.</b>&nbsp;<br>
This&nbsp;is&nbsp;a useful&nbsp;little routine which dumps a register to&nbsp;the display&nbsp;in&nbsp;hexadecimal (base&nbsp;<br>
16) notation; it&nbsp;can be used&nbsp;to&nbsp;help&nbsp;debug a program&nbsp;by writing out&nbsp;register&nbsp;values&nbsp;and&nbsp;<br>
checking&nbsp;that&nbsp;algorithms are producing the expected results,&nbsp;though in&nbsp;most&nbsp;cases using&nbsp;<br>
a debugger&nbsp;is&nbsp;a&nbsp;better&nbsp;way&nbsp;of seeing what&nbsp;is&nbsp;going on inside&nbsp;a program.&nbsp;<br>
AREA&nbsp;<br>
Hex_Out,CODE,READONLY&nbsp;<br>
SWI_WriteC&nbsp;<br>
EQU &nbsp; &nbsp;&amp;0&nbsp;<br>
output character in r0&nbsp;<br>
SWI_Exit&nbsp;<br>
EQU &nbsp; &nbsp;&amp;11&nbsp;<br>
finish program&nbsp;<br>
ENTRY&nbsp;<br>
code entry point&nbsp;<br>
LDR r1,&nbsp;<br>
VALUE&nbsp;<br>
get value to print&nbsp;<br>
BL&nbsp;<br>
HexOut&nbsp;<br>
call&nbsp;hexadecimal output&nbsp;<br>
SWI&nbsp;SWI_Exit&nbsp;<br>
finish&nbsp;<br>
VALUE &nbsp;DCD&nbsp;<br>
&amp;12345678&nbsp;<br>
test value&nbsp;<br>
HexOut MOV&nbsp;<br>
r2, #8&nbsp;<br>
nibble count = 8&nbsp;<br>
LOOP&nbsp;&nbsp;&nbsp;MOV&nbsp;<br>
r0,&nbsp;r1,&nbsp;LSR&nbsp;#28&nbsp;<br>
get top nibble&nbsp;<br>
CMP r0,&nbsp;<br>
#9&nbsp;<br>
0-9 or A-F?&nbsp;<br>
ADDGT&nbsp;&nbsp;r0,&nbsp;r0,&nbsp;#&quot;A&quot;-10&nbsp;<br>
ASCII&nbsp;alphabetic&nbsp;<br>
ADDLE&nbsp;r0,&nbsp;<br>
r0,&nbsp;<br>
#&quot;0&quot;&nbsp;<br>
ASCII numeric&nbsp;<br>
SWI&nbsp;SWI_WriteC&nbsp;<br>
print&nbsp;<br>
character&nbsp;<br>
MOV&nbsp;<br>
r1,&nbsp;r1,&nbsp;LSL&nbsp;#4&nbsp;<br>
shift left one nibble&nbsp;<br>
SUBS&nbsp;<br>
r2,&nbsp;r2,&nbsp;#1&nbsp;<br>
decrement nibble count&nbsp;<br>
BNE&nbsp;LOOP&nbsp;<br>
if&nbsp;<br>
more do next nibble&nbsp;<br>
MOV&nbsp;<br>
pc, r14&nbsp;<br>
return&nbsp;<br>
END&nbsp;<br>
<b>Exercise&nbsp;3.1.1</b>&nbsp;<br>
Modify&nbsp;the&nbsp;above program&nbsp;to&nbsp;output&nbsp;r1&nbsp;in&nbsp;binary&nbsp;format. For&nbsp;the value loaded&nbsp;into&nbsp;<br>
r1&nbsp;in&nbsp;the example&nbsp;program&nbsp;you&nbsp;should&nbsp;get:&nbsp;<br>
00010010001101000101011001111000 Use&nbsp;HEXOUT&nbsp;as&nbsp;the basis of&nbsp;<br>
<b>Exercise&nbsp;3.1.2</b>&nbsp;<br>
a program&nbsp;to&nbsp;display&nbsp;the contents of an&nbsp;area of memory.&nbsp;<br>
<hr>
<A name=85></a><IMG src="index-85_1.png"><br>
<IMG src="index-85_2.png"><br>
<b>Examples and exercises</b>&nbsp;<br>
<b>73</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<b>Example 3.2</b>&nbsp;<br>
<b>Write&nbsp;a&nbsp;subroutine&nbsp;to&nbsp;output&nbsp;a text&nbsp;string&nbsp;immediately&nbsp;following&nbsp;the call.</b>&nbsp;<br>
It is&nbsp;often useful&nbsp;to&nbsp;be&nbsp;able&nbsp;to&nbsp;output&nbsp;a&nbsp;text&nbsp;string without&nbsp;having&nbsp;to&nbsp;set&nbsp;up a&nbsp;separate&nbsp;<br>
data&nbsp;area for&nbsp;the text (though&nbsp;this is inefficient&nbsp;if the processor has&nbsp;separate data&nbsp;and&nbsp;<br>
instruction&nbsp;caches, as&nbsp;does the StrongARM;&nbsp;in&nbsp;this case it&nbsp;is better to set up&nbsp;a sepa-<br>
rate&nbsp;data area).&nbsp;A call should look&nbsp;like:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
The issue&nbsp;here&nbsp;is that the&nbsp;return&nbsp;from&nbsp;the&nbsp;subroutine&nbsp;must not go directly&nbsp;to the&nbsp;<br>
value&nbsp;put&nbsp;in the link&nbsp;register&nbsp;by the&nbsp;call,&nbsp;since this would&nbsp;land the&nbsp;program&nbsp;in&nbsp;the&nbsp;text&nbsp;<br>
string. Here&nbsp;is&nbsp;a suitable&nbsp;subroutine&nbsp;and&nbsp;test&nbsp;harness:&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
This&nbsp;example shows r14 incrementing&nbsp;along&nbsp;the text&nbsp;string&nbsp;and&nbsp;then&nbsp;being adjusted&nbsp;<br>
to&nbsp;the next&nbsp;word&nbsp;boundary prior to&nbsp;the&nbsp;return.&nbsp;If the&nbsp;adjustment&nbsp;(add&nbsp;3,&nbsp;then&nbsp;clear&nbsp;the&nbsp;<br>
bottom&nbsp;two bits)&nbsp;looks like&nbsp;slight&nbsp;of hand,&nbsp;check it; there are&nbsp;only&nbsp;four&nbsp;cases.&nbsp;<br>
<b>Exercise 3.2.1</b>&nbsp;<br>
Using&nbsp;code&nbsp;from&nbsp;this&nbsp;and the&nbsp;previous&nbsp;examples, write&nbsp;a&nbsp;program&nbsp;to&nbsp;dump&nbsp;the&nbsp;ARM&nbsp;<br>
registers in hexadecimal&nbsp;with&nbsp;formatting&nbsp;such as:&nbsp;<br>
r0&nbsp;=&nbsp;12345678&nbsp;r1&nbsp;<br>
=&nbsp;9ABCDEF0&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Exercise 3.2.2</b>&nbsp;<br>
Now&nbsp;try&nbsp;to save the registers you need&nbsp;to&nbsp;work with before they are&nbsp;changed, for&nbsp;<br>
instance&nbsp;by&nbsp;saving&nbsp;them&nbsp;near&nbsp;the code&nbsp;using PC-relative&nbsp;addressing.&nbsp;<br>
<hr>
<A name=86></a><IMG src="index-86_1.png"><br>
ARM Organization and&nbsp;<br>
Implementation&nbsp;<br>
&nbsp;<br>
Summary of chapter contents&nbsp;<br>
The organization&nbsp;of the ARM integer&nbsp;processor core&nbsp;changed&nbsp;very&nbsp;little from&nbsp;the&nbsp;<br>
first 3&nbsp;micron&nbsp;devices&nbsp;developed&nbsp;at&nbsp;Acorn&nbsp;Computers between&nbsp;1983&nbsp;and&nbsp;1985&nbsp;to&nbsp;<br>
the&nbsp;ARM6&nbsp;and ARM7&nbsp;developed by&nbsp;ARM Limited&nbsp;between 1990 and&nbsp;1995.&nbsp;The&nbsp;<br>
3-stage&nbsp;pipeline used&nbsp;by&nbsp;these&nbsp;processors&nbsp;was&nbsp;steadily tightened&nbsp;up, and&nbsp;CMOS&nbsp;<br>
process&nbsp;technology&nbsp;reduced&nbsp;in&nbsp;feature&nbsp;size by&nbsp;almost an&nbsp;order&nbsp;of&nbsp;magnitude&nbsp;over&nbsp;<br>
this&nbsp;period, so&nbsp;the&nbsp;performance&nbsp;of&nbsp;the&nbsp;cores&nbsp;improved&nbsp;dramatically,&nbsp;but the&nbsp;basic&nbsp;<br>
principles of operation remained largely&nbsp;the&nbsp;same.&nbsp;<br>
Since 1995&nbsp;several new&nbsp;ARM cores have&nbsp;been introduced&nbsp;which deliver signifi-<br>
cantly&nbsp;higher&nbsp;performance&nbsp;through&nbsp;the&nbsp;use&nbsp;of&nbsp;5-stage&nbsp;pipelines and&nbsp;separate&nbsp;<br>
instruction and&nbsp;data&nbsp;memories&nbsp;(usually&nbsp;in&nbsp;the&nbsp;form&nbsp;of&nbsp;separate caches&nbsp;which&nbsp;are&nbsp;<br>
connected&nbsp;to&nbsp;a&nbsp;shared&nbsp;instruction and&nbsp;data&nbsp;main memory&nbsp;system).&nbsp;<br>
This&nbsp;chapter includes descriptions&nbsp;of&nbsp;the&nbsp;internal structures&nbsp;of these two&nbsp;basic&nbsp;<br>
styles of&nbsp;processor&nbsp;core&nbsp;and covers&nbsp;the&nbsp;general&nbsp;principles of&nbsp;operation of&nbsp;the&nbsp;<br>
3-stage&nbsp;and&nbsp;5-stage&nbsp;pipelines&nbsp;and&nbsp;<i>a&nbsp;</i>number of&nbsp;implementation&nbsp;details. Details on&nbsp;<br>
particular cores are presented&nbsp;in Chapter 9.&nbsp;<br>
<b>74</b>&nbsp;<br>
<hr>
<A name=87></a><b>3-stage pipeline&nbsp;ARM organization&nbsp;</b><br>
<b>75</b>&nbsp;<br>
4.1 &nbsp; 3-stage&nbsp;pipeline&nbsp;ARM&nbsp;organization&nbsp;<br>
The organization of an ARM&nbsp;with a 3-stage pipeline is illustrated in Figure 4.1 on&nbsp;<br>
page 76.&nbsp;The&nbsp;principal components&nbsp;are:&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;register bank, which&nbsp;stores the processor&nbsp;state. It has two&nbsp;read ports&nbsp;and one&nbsp;<br>
write port which can each be used to access any register, plus an additional read&nbsp;<br>
port and an&nbsp;additional&nbsp;write&nbsp;port that&nbsp;give&nbsp;special access&nbsp;to&nbsp;r15,&nbsp;the&nbsp;program&nbsp;<br>
counter. (The&nbsp;additional write port on r15 allows it to be updated as the instruc&nbsp;<br>
tion fetch&nbsp;address is incremented and&nbsp;the read&nbsp;port allows&nbsp;instruction fetch to&nbsp;<br>
resume&nbsp;after a&nbsp;data address has been&nbsp;issued.)&nbsp;<br>
•&nbsp;&nbsp;The barrel&nbsp;shifter, which can&nbsp;shift or&nbsp;rotate&nbsp;one operand by&nbsp;any number&nbsp;of bits.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;ALU,&nbsp;which&nbsp;performs&nbsp;the&nbsp;arithmetic&nbsp;and&nbsp;logic&nbsp;functions&nbsp;required&nbsp;by&nbsp;the&nbsp;<br>
instruction set.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;address register and&nbsp;incrementer,&nbsp;which &nbsp;select&nbsp;and&nbsp;hold&nbsp;all&nbsp;memory&nbsp;<br>
addresses and generate&nbsp;sequential addresses when&nbsp;required.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;data&nbsp;registers,&nbsp;which hold&nbsp;data passing to&nbsp;and&nbsp;from&nbsp;memory.&nbsp;<br>
•&nbsp;&nbsp;The instruction decoder and&nbsp;associated&nbsp;control logic.&nbsp;<br>
In&nbsp;a&nbsp;single-cycle data&nbsp;processing instruction,&nbsp;two&nbsp;register&nbsp;operands are&nbsp;accessed,&nbsp;<br>
the value on the B bus is&nbsp;shifted&nbsp;and combined with the&nbsp;value on the&nbsp;A bus in the&nbsp;<br>
ALU, then&nbsp;the&nbsp;result&nbsp;is&nbsp;written back&nbsp;into&nbsp;the&nbsp;register&nbsp;bank. The&nbsp;program&nbsp;counter&nbsp;value&nbsp;<br>
is&nbsp;in&nbsp;the address register, from&nbsp;where&nbsp;it is&nbsp;fed into the incrementer,&nbsp;then&nbsp;the&nbsp;incre-<br>
mented&nbsp;value&nbsp;is&nbsp;copied&nbsp;back&nbsp;into&nbsp;rl5&nbsp;in&nbsp;the register&nbsp;bank&nbsp;and&nbsp;also&nbsp;into&nbsp;the&nbsp;address reg-<br>
ister to be&nbsp;used as&nbsp;the&nbsp;address&nbsp;for the&nbsp;next&nbsp;instruction&nbsp;fetch.&nbsp;<br>
The 3-stage&nbsp;<br>
ARM processors up to&nbsp;the ARM?&nbsp;employ&nbsp;a simple&nbsp;3-stage pipeline&nbsp;with&nbsp;the follow-<br>
pipeline&nbsp;<br>
ing pipeline stages:&nbsp;<br>
• Fetch;&nbsp;<br>
the instruction&nbsp;is&nbsp;fetched&nbsp;from&nbsp;memory and placed in&nbsp;the instruction&nbsp;pipeline.&nbsp;<br>
•&nbsp;Decode;&nbsp;<br>
the instruction is decoded and the datapath control signals&nbsp;prepared for the next&nbsp;<br>
cycle.&nbsp;In this&nbsp;stage the instruction&nbsp;'owns'&nbsp;the&nbsp;decode logic&nbsp;but not the datapath.&nbsp;<br>
• Execute;&nbsp;<br>
the instruction 'owns'&nbsp;the datapath; the register bank is read, an operand shifted,&nbsp;<br>
the ALU result generated&nbsp;and&nbsp;written&nbsp;back&nbsp;into&nbsp;a&nbsp;destination register.&nbsp;<br>
At&nbsp;any one&nbsp;time,&nbsp;three&nbsp;different instructions&nbsp;may&nbsp;occupy&nbsp;each&nbsp;of&nbsp;these&nbsp;stages,&nbsp;so&nbsp;<br>
the hardware&nbsp;in&nbsp;each&nbsp;stage has&nbsp;to&nbsp;be&nbsp;capable&nbsp;of independent&nbsp;operation.&nbsp;<br>
<hr>
<A name=88></a><IMG src="index-88_1.png"><br>
<b>76</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
&nbsp;<br>
<b>D[31:&nbsp;Figure&nbsp;</b><br>
<b>4.1 &nbsp; &nbsp;&nbsp;</b>3-stage pipeline ARM organization.&nbsp;<br>
When&nbsp;the processor is&nbsp;executing&nbsp;simple&nbsp;data&nbsp;processing&nbsp;instructions&nbsp;the&nbsp;pipeline&nbsp;<br>
enables&nbsp;one instruction&nbsp;to&nbsp;be completed every clock cycle. An individual instruction&nbsp;<br>
takes three clock cycles&nbsp;to&nbsp;complete, so it has a&nbsp;three-cycle&nbsp;latency, but&nbsp;the through-<br>
put is one&nbsp;instruction&nbsp;per cycle. The 3-stage pipeline operation&nbsp;for&nbsp;single-cycle&nbsp;<br>
instructions&nbsp;is shown&nbsp;in&nbsp;Figure&nbsp;4.2 on&nbsp;page&nbsp;77.&nbsp;<br>
<hr>
<A name=89></a><IMG src="index-89_1.png"><br>
<IMG src="index-89_2.png"><br>
3-stage&nbsp;<b>pipeline ARM&nbsp;organization</b>&nbsp;<br>
77&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;4.2 &nbsp;&nbsp;</b>ARM&nbsp;single-cycle&nbsp;instruction&nbsp;3-stage&nbsp;pipeline&nbsp;operation.&nbsp;<br>
When&nbsp;a multi-cycle&nbsp;instruction&nbsp;is executed&nbsp;the flow&nbsp;is less&nbsp;regular, as illustrated&nbsp;in&nbsp;<br>
Figure 4.3. This&nbsp;shows a sequence of single-cycle ADD instructions with a data store&nbsp;<br>
instruction, STR, occurring&nbsp;after the first&nbsp;ADD. The cycles&nbsp;that access&nbsp;main&nbsp;memory&nbsp;<br>
are shown with&nbsp;light&nbsp;shading so it&nbsp;can be seen&nbsp;that&nbsp;memory&nbsp;is used in every cycle. The&nbsp;<br>
datapath&nbsp;is likewise used&nbsp;in&nbsp;every cycle,&nbsp;being involved in&nbsp;all&nbsp;the execute cycles,&nbsp;the&nbsp;<br>
address&nbsp;calculation and the&nbsp;data&nbsp;transfer. The decode logic is always generating the&nbsp;<br>
control&nbsp;signals for the&nbsp;datapath&nbsp;to&nbsp;use in the next&nbsp;cycle, so&nbsp;in&nbsp;addition to the explicit&nbsp;<br>
decode cycles&nbsp;it&nbsp;is&nbsp;also generating the control for the data transfer during the address&nbsp;<br>
calculation cycle of the STR.&nbsp;<br>
&nbsp;<br>
<b>Figure 4.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM multi-cycle instruction&nbsp;3-stage pipeline&nbsp;operation.&nbsp;<br>
<hr>
<A name=90></a><IMG src="index-90_1.png"><br>
<b>78</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
Thus, in this instruction sequence, all parts of the processor are&nbsp;active&nbsp;in every&nbsp;<br>
cycle and the&nbsp;memory&nbsp;is the limiting factor, denning&nbsp;the number of cycles the&nbsp;<br>
sequence must take.&nbsp;<br>
The simplest way&nbsp;to&nbsp;view&nbsp;breaks in&nbsp;the ARM&nbsp;pipeline&nbsp;is to&nbsp;observe&nbsp;that:&nbsp;<br>
•&nbsp;&nbsp;All instructions&nbsp;occupy&nbsp;the datapath&nbsp;for one&nbsp;or&nbsp;more adjacent cycles.&nbsp;<br>
•&nbsp;&nbsp;For each cycle that an&nbsp;instruction&nbsp;occupies the datapath, it&nbsp;occupies the&nbsp;decode&nbsp;<br>
logic&nbsp;in&nbsp;the&nbsp;immediately&nbsp;preceding&nbsp;cycle.&nbsp;<br>
•&nbsp;&nbsp;During the&nbsp;first&nbsp;datapath&nbsp;cycle&nbsp;each&nbsp;instruction&nbsp;issues&nbsp;a&nbsp;fetch&nbsp;for the next&nbsp;instruc&nbsp;<br>
tion but&nbsp;one.&nbsp;<br>
•&nbsp;&nbsp;Branch&nbsp;instructions&nbsp;flush and&nbsp;refill&nbsp;the instruction pipeline.&nbsp;<br>
PC behaviour&nbsp;<br>
One consequence of&nbsp;the pipelined&nbsp;execution&nbsp;model used on&nbsp;the&nbsp;ARM is&nbsp;that the pro-<br>
gram&nbsp;counter, which is&nbsp;visible to the user&nbsp;as&nbsp;r!5,&nbsp;must&nbsp;run ahead of&nbsp;the current&nbsp;<br>
instruction.&nbsp;If, as&nbsp;noted&nbsp;above, instructions&nbsp;fetch the&nbsp;next instruction but one during&nbsp;<br>
their&nbsp;first cycle, this&nbsp;suggests that the&nbsp;PC&nbsp;must point eight bytes&nbsp;(two instructions)&nbsp;<br>
ahead of&nbsp;the&nbsp;current instruction.&nbsp;<br>
This&nbsp;is, indeed, what&nbsp;happens, and&nbsp;the&nbsp;programmer who attempts&nbsp;to&nbsp;access&nbsp;the&nbsp;PC&nbsp;<br>
directly&nbsp;through r!5 must take&nbsp;account&nbsp;of the&nbsp;exposure&nbsp;of&nbsp;the&nbsp;pipeline&nbsp;here.&nbsp;However,&nbsp;<br>
for most normal&nbsp;purposes&nbsp;the&nbsp;assembler or&nbsp;compiler handles&nbsp;all&nbsp;the&nbsp;details.&nbsp;<br>
Even&nbsp;more&nbsp;complex&nbsp;behaviour is&nbsp;exposed&nbsp;if&nbsp;r!5&nbsp;is&nbsp;used&nbsp;later than&nbsp;the&nbsp;first&nbsp;cycle&nbsp;of&nbsp;<br>
an instruction, since the&nbsp;instruction&nbsp;will itself&nbsp;have&nbsp;incremented&nbsp;the PC&nbsp;during its first&nbsp;<br>
cycle.&nbsp;Such&nbsp;use of the&nbsp;PC&nbsp;is not often beneficial&nbsp;so&nbsp;the ARM&nbsp;architecture&nbsp;definition&nbsp;<br>
specifies the result&nbsp;as&nbsp;'unpredictable'&nbsp;and&nbsp;it&nbsp;should&nbsp;be&nbsp;avoided,&nbsp;especially&nbsp;since&nbsp;later&nbsp;<br>
ARMs do not&nbsp;have&nbsp;the same&nbsp;behaviour in&nbsp;these cases.&nbsp;<br>
4.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5-stage pipeline ARM organization&nbsp;<br>
All processors&nbsp;have to develop to&nbsp;meet&nbsp;the demand&nbsp;for higher performance. The&nbsp;<br>
3-stage pipeline&nbsp;used in the&nbsp;ARM cores&nbsp;up&nbsp;to&nbsp;the ARM?&nbsp;is&nbsp;very cost-effective,&nbsp;but&nbsp;<br>
higher performance requires the processor organization&nbsp;to be rethought. The time,&nbsp;<br>
<i>T&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;,&nbsp;</i>required&nbsp;to&nbsp;execute a given program&nbsp;is given&nbsp;by:&nbsp;<br>
&nbsp;<br>
where&nbsp;<i>Ninst&nbsp;</i>is&nbsp;the number&nbsp;of&nbsp;ARM&nbsp;instructions executed&nbsp;in the course&nbsp;of the pro-<br>
gram,&nbsp;&nbsp;<i>CPI&nbsp;&nbsp;</i>is&nbsp;the average number&nbsp;of clock cycles per instruction and&nbsp;<i>fclk&nbsp;&nbsp;</i>is the&nbsp;<br>
processor's clock frequency.&nbsp;Since&nbsp;<i>Ninst&nbsp;</i>is constant&nbsp;for a given program&nbsp;(compiled&nbsp;<br>
<hr>
<A name=91></a><b>5-stage pipeline&nbsp;ARM&nbsp;organization</b>&nbsp;<br>
79&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
with&nbsp;a given&nbsp;compiler using&nbsp;a given&nbsp;set of&nbsp;optimizations,&nbsp;and so on) there&nbsp;are only&nbsp;<br>
two&nbsp;ways&nbsp;to increase performance:&nbsp;<br>
•&nbsp;&nbsp;Increase&nbsp;the clock rate,&nbsp;<i>fclk.</i>&nbsp;<br>
This&nbsp;requires the logic in each pipeline stage to be simplified and, therefore, the&nbsp;<br>
number of&nbsp;pipeline&nbsp;stages to&nbsp;be increased.&nbsp;<br>
•&nbsp;&nbsp;Reduce the&nbsp;average&nbsp;number&nbsp;of clock&nbsp;cycles&nbsp;per&nbsp;instruction,&nbsp;<i>CPI.</i>&nbsp;<br>
This&nbsp;requires either that instructions&nbsp;which&nbsp;occupy&nbsp;more than one pipeline slot in&nbsp;<br>
a 3-stage pipeline&nbsp;ARM&nbsp;are&nbsp;re-implemented&nbsp;to occupy&nbsp;fewer&nbsp;slots, or&nbsp;that pipe-<br>
line&nbsp;stalls caused&nbsp;by&nbsp;dependencies between instructions&nbsp;are&nbsp;reduced, or&nbsp;a&nbsp;combi-<br>
nation of&nbsp;both.&nbsp;<br>
Memory&nbsp;<br>
The fundamental problem&nbsp;with reducing&nbsp;the&nbsp;CPI&nbsp;relative to&nbsp;a 3-stage core is&nbsp;related&nbsp;<br>
bottleneck&nbsp;<br>
to the von Neumann bottleneck - any&nbsp;stored-program&nbsp;computer with a single&nbsp;<br>
instruction and data memory will have its performance&nbsp;limited by the available&nbsp;<br>
memory bandwidth. A 3-stage ARM&nbsp;core&nbsp;accesses memory on (almost) every clock&nbsp;<br>
cycle either to fetch an instruction or to&nbsp;transfer data. Simply&nbsp;tightening up&nbsp;on the&nbsp;<br>
few cycles&nbsp;where&nbsp;the&nbsp;memory&nbsp;is not used&nbsp;will&nbsp;yield&nbsp;only a&nbsp;small performance&nbsp;gain.&nbsp;<br>
To get a significantly better CPI the&nbsp;memory&nbsp;system&nbsp;must deliver&nbsp;more than one&nbsp;<br>
value in each&nbsp;clock cycle&nbsp;either by&nbsp;delivering&nbsp;more than&nbsp;32 bits per cycle from&nbsp;a&nbsp;<br>
single&nbsp;memory or by&nbsp;having&nbsp;separate&nbsp;memories&nbsp;for instruction and data&nbsp;accesses.&nbsp;<br>
As a result&nbsp;of&nbsp;the&nbsp;above&nbsp;issues, higher&nbsp;performance ARM&nbsp;cores employ&nbsp;a&nbsp;5-stage&nbsp;<br>
pipeline&nbsp;and&nbsp;have separate&nbsp;instruction&nbsp;and&nbsp;data&nbsp;memories. Breaking&nbsp;instruction&nbsp;execu-<br>
tion down&nbsp;into five&nbsp;components&nbsp;rather&nbsp;than&nbsp;three reduces&nbsp;the&nbsp;maximum&nbsp;work which&nbsp;<br>
must be completed&nbsp;in&nbsp;a clock&nbsp;cycle,&nbsp;and&nbsp;hence allows&nbsp;a higher&nbsp;clock frequency to&nbsp;be&nbsp;<br>
used&nbsp;(provided&nbsp;that&nbsp;other system&nbsp;components, and&nbsp;particularly&nbsp;the&nbsp;instruction&nbsp;mem-<br>
ory,&nbsp;are&nbsp;also&nbsp;redesigned&nbsp;to&nbsp;operate&nbsp;at&nbsp;this&nbsp;higher clock rate). The separate&nbsp;instruction&nbsp;<br>
and&nbsp;data&nbsp;memories (which&nbsp;may&nbsp;be&nbsp;separate&nbsp;caches connected&nbsp;to&nbsp;a unified&nbsp;instruction&nbsp;<br>
and&nbsp;data&nbsp;main&nbsp;memory) allow&nbsp;a significant reduction in&nbsp;the&nbsp;core's&nbsp;CPI.&nbsp;<br>
A typical&nbsp;5-stage ARM pipeline&nbsp;is that&nbsp;employed&nbsp;in&nbsp;the ARM9TDMI.&nbsp;The&nbsp;organi-<br>
zation&nbsp;of the ARM9TDMI&nbsp;is illustrated in&nbsp;Figure 4.4&nbsp;on&nbsp;page&nbsp;81.&nbsp;<br>
The 5-stage&nbsp;<br>
The ARM&nbsp;processors which use&nbsp;a 5-stage pipeline&nbsp;have&nbsp;the following pipeline&nbsp;<br>
pipeline&nbsp;<br>
stages:&nbsp;<br>
• Fetch;&nbsp;<br>
the instruction&nbsp;is&nbsp;fetched&nbsp;from&nbsp;memory and placed in&nbsp;the instruction&nbsp;pipeline.&nbsp;<br>
•&nbsp;Decode;&nbsp;<br>
the&nbsp;instruction&nbsp;is&nbsp;decoded&nbsp;and register&nbsp;operands&nbsp;read from&nbsp;the register&nbsp;file. There&nbsp;<br>
are three operand read ports in the register file, so&nbsp;most&nbsp;ARM instructions can&nbsp;<br>
source all&nbsp;their operands in&nbsp;one cycle.&nbsp;<br>
<hr>
<A name=92></a><b>80&nbsp;</b><br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
•&nbsp;Execute;&nbsp;<br>
an operand&nbsp;is&nbsp;shifted and&nbsp;the&nbsp;ALU result&nbsp;generated.&nbsp;If the&nbsp;instruction&nbsp;is&nbsp;a load&nbsp;or&nbsp;<br>
store the memory address&nbsp;is&nbsp;computed in the ALU.&nbsp;<br>
• Buffer/data;&nbsp;<br>
data&nbsp;memory&nbsp;is accessed if required. Otherwise the ALU&nbsp;result&nbsp;is simply buf-<br>
fered&nbsp;for&nbsp;one&nbsp;clock&nbsp;cycle to&nbsp;give the&nbsp;same&nbsp;pipeline&nbsp;flow&nbsp;for&nbsp;all&nbsp;instructions.&nbsp;<br>
• Write-back;&nbsp;<br>
the results&nbsp;generated by&nbsp;the&nbsp;instruction&nbsp;are written&nbsp;back to the&nbsp;register file,&nbsp;<br>
including&nbsp;any&nbsp;data&nbsp;loaded&nbsp;from&nbsp;memory.&nbsp;<br>
This&nbsp;5-stage pipeline has been&nbsp;used for&nbsp;many RISC&nbsp;processors and is&nbsp;considered to&nbsp;<br>
be the&nbsp;'classic'&nbsp;way&nbsp;to&nbsp;design&nbsp;such a processor. Although&nbsp;the ARM&nbsp;instruction set&nbsp;was&nbsp;<br>
not&nbsp;designed&nbsp;with&nbsp;such&nbsp;a pipeline&nbsp;in&nbsp;mind,&nbsp;it&nbsp;maps&nbsp;onto&nbsp;it&nbsp;relatively&nbsp;simply.&nbsp;The princi-<br>
pal&nbsp;concessions to&nbsp;the ARM&nbsp;instruction set&nbsp;architecture in&nbsp;the organization shown in&nbsp;<br>
Figure&nbsp;4.4 on&nbsp;page&nbsp;81&nbsp;are the three source&nbsp;operand&nbsp;read&nbsp;ports and two&nbsp;write&nbsp;ports in&nbsp;<br>
the register file&nbsp;(where a 'classic'&nbsp;RISC&nbsp;has two&nbsp;read ports and&nbsp;one&nbsp;write&nbsp;port), and the&nbsp;<br>
inclusion of address incrementing hardware&nbsp;in the execute stage&nbsp;to&nbsp;support load&nbsp;and&nbsp;<br>
store multiple instructions.&nbsp;<br>
Data&nbsp;forwarding A major source of&nbsp;complexity&nbsp;in&nbsp;the&nbsp;5-stage pipeline (compared to&nbsp;the 3-stage pipe-<br>
line) is&nbsp;that,&nbsp;because instruction execution is&nbsp;spread&nbsp;across&nbsp;three&nbsp;pipeline&nbsp;stages, the&nbsp;<br>
only way to resolve&nbsp;data dependencies without stalling the pipeline&nbsp;is to&nbsp;introduce&nbsp;<br>
<i>forwarding&nbsp;</i>paths.&nbsp;<br>
Data&nbsp;dependencies arise when an instruction needs to&nbsp;use&nbsp;the result&nbsp;of one of its&nbsp;<br>
predecessors before that result has returned&nbsp;to the register file. (This issue was&nbsp;dis-<br>
cussed previously&nbsp;under&nbsp;'Pipeline hazards' on page 22.) Forwarding paths&nbsp;allow&nbsp;<br>
results&nbsp;to&nbsp;be passed between stages as soon as&nbsp;they&nbsp;are available, and the 5-stage ARM&nbsp;<br>
pipeline requires each of the three source&nbsp;operands to be&nbsp;forwarded from&nbsp;any of three&nbsp;<br>
intermediate&nbsp;result&nbsp;registers as shown in&nbsp;Figure 4.4 on&nbsp;page 81.&nbsp;<br>
There is one case where, even&nbsp;with&nbsp;forwarding, it&nbsp;is&nbsp;not&nbsp;possible&nbsp;to&nbsp;avoid a&nbsp;pipeline&nbsp;<br>
stall.&nbsp;Consider&nbsp;the following code sequence:&nbsp;<br>
LDR&nbsp;&nbsp;&nbsp;&nbsp;rN,&nbsp;[&nbsp;.&nbsp;.&nbsp;]&nbsp;<br>
; load rN&nbsp;from somewhere&nbsp;<br>
ADD&nbsp;&nbsp;&nbsp; r2,&nbsp;r1,&nbsp;rN&nbsp;&nbsp;&nbsp; &nbsp; &nbsp;&nbsp;;&nbsp;and&nbsp;use&nbsp;it&nbsp;immediately&nbsp;<br>
The processor&nbsp;cannot&nbsp;avoid a one-cycle stall&nbsp;as the value&nbsp;loaded into&nbsp;rN only&nbsp;enters&nbsp;<br>
the processor&nbsp;at&nbsp;the end of the buffer/data&nbsp;stage and it is&nbsp;needed by the following&nbsp;<br>
instruction&nbsp;at the start of the execute stage. The&nbsp;only way to&nbsp;avoid&nbsp;this stall is to&nbsp;<br>
encourage the&nbsp;compiler (or assembly&nbsp;language programmer) not to put&nbsp;a dependent&nbsp;<br>
instruction&nbsp;immediately after&nbsp;a load&nbsp;instruction.&nbsp;<br>
Since&nbsp;the 3-stage pipeline ARM&nbsp;cores&nbsp;are&nbsp;not adversely affected&nbsp;by&nbsp;this code&nbsp;<br>
sequence, existing&nbsp;ARM programs will often&nbsp;use it. Such&nbsp;programs will run&nbsp;correctly&nbsp;<br>
<hr>
<A name=93></a><IMG src="index-93_1.png"><br>
<b>5-stage pipeline&nbsp;<i>ARM&nbsp;</i></b><b>organization</b>&nbsp;<br>
<b>81</b>&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;4.4 &nbsp;&nbsp;</b>ARM9TDMI 5-stage pipeline&nbsp;organization.&nbsp;<br>
on&nbsp;5-stage ARM cores,&nbsp;but could probably&nbsp;be rewritten&nbsp;to&nbsp;run faster&nbsp;by&nbsp;simply&nbsp;reor-<br>
dering&nbsp;the instructions to&nbsp;remove&nbsp;these&nbsp;dependencies.&nbsp;<br>
PC&nbsp;generation&nbsp;<br>
The behaviour of r15, as seen&nbsp;by&nbsp;the programmer and described in 'PC&nbsp;behaviour'&nbsp;<br>
on&nbsp;page 78,&nbsp;is based&nbsp;on&nbsp;the operational&nbsp;characteristics of&nbsp;the 3-stage&nbsp;ARM&nbsp;pipeline.&nbsp;<br>
The&nbsp;5-stage&nbsp;pipeline&nbsp;reads the&nbsp;instruction&nbsp;operands&nbsp;one&nbsp;stage&nbsp;earlier in&nbsp;the pipeline,&nbsp;<br>
and would naturally&nbsp;get a different value (PC+4 rather than&nbsp;PC+8). As this would&nbsp;<br>
<hr>
<A name=94></a><b>82</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
lead&nbsp;to&nbsp;unacceptable code&nbsp;incompatibilities,&nbsp;however,&nbsp;the 5-stage&nbsp;pipeline&nbsp;ARMs&nbsp;all&nbsp;<br>
'emulate'&nbsp;the behaviour of the older 3-stage designs. Referring to Figure 4.4, the&nbsp;<br>
incremented&nbsp;PC value from&nbsp;the fetch&nbsp;stage&nbsp;is fed directly&nbsp;to the register&nbsp;file in the&nbsp;<br>
decode stage,&nbsp;bypassing&nbsp;the&nbsp;pipeline&nbsp;register between the&nbsp;two&nbsp;stages.&nbsp;PC+4 for the&nbsp;<br>
next instruction is equal to&nbsp;PC+8 for the&nbsp;current instruction, so the correct r15 value&nbsp;<br>
is obtained&nbsp;without additional hardware.&nbsp;<br>
4.3 &nbsp; ARM&nbsp;instruction&nbsp;execution&nbsp;<br>
The execution&nbsp;of an&nbsp;ARM instruction can&nbsp;best be understood by&nbsp;reference to the&nbsp;<br>
datapath organization&nbsp;as presented in&nbsp;Figure 4.1 on&nbsp;page&nbsp;76. We&nbsp;will use an&nbsp;anno-<br>
tated version&nbsp;of this&nbsp;diagram,&nbsp;omitting the&nbsp;control logic&nbsp;section,&nbsp;and&nbsp;highlighting the&nbsp;<br>
active&nbsp;buses to show&nbsp;the movement&nbsp;of&nbsp;operands&nbsp;around&nbsp;the various units in&nbsp;the pro-<br>
cessor.&nbsp;We&nbsp;start with&nbsp;a&nbsp;simple&nbsp;data&nbsp;processing&nbsp;instruction.&nbsp;<br>
Data processing&nbsp;<br>
A data&nbsp;processing&nbsp;instruction&nbsp;requires&nbsp;two&nbsp;operands, one of&nbsp;which&nbsp;is always a&nbsp;regis-<br>
instructions&nbsp;<br>
ter and the other&nbsp;is either&nbsp;a second register&nbsp;or&nbsp;an&nbsp;immediate value. The&nbsp;second&nbsp;oper-<br>
and is passed&nbsp;through&nbsp;the barrel&nbsp;shifter where it is&nbsp;subject to&nbsp;a general&nbsp;shift&nbsp;<br>
operation, then&nbsp;it is combined with the first operand in&nbsp;the ALU using a general&nbsp;<br>
ALU operation.&nbsp;Finally, the result&nbsp;from&nbsp;the&nbsp;ALU is&nbsp;written back into the destination&nbsp;<br>
register&nbsp;(and the condition&nbsp;code register&nbsp;may&nbsp;be updated).&nbsp;<br>
All&nbsp;these&nbsp;operations&nbsp;take&nbsp;place&nbsp;in&nbsp;a&nbsp;single clock&nbsp;cycle&nbsp;as shown&nbsp;in&nbsp;Figure&nbsp;4.5 on&nbsp;<br>
page 83. Note&nbsp;also&nbsp;how the PC&nbsp;value&nbsp;in&nbsp;the&nbsp;address register is incremented and&nbsp;copied&nbsp;<br>
back into both the address&nbsp;register and&nbsp;r15&nbsp;in the&nbsp;register bank, and the next instruc-<br>
tion but one is loaded into&nbsp;the&nbsp;bottom&nbsp;of the&nbsp;instruction&nbsp;pipeline&nbsp;<i>(i. pipe).&nbsp;</i>The&nbsp;imme-<br>
diate&nbsp;value,&nbsp;when&nbsp;required,&nbsp;is&nbsp;extracted from&nbsp;the&nbsp;current&nbsp;instruction&nbsp;at&nbsp;the&nbsp;top of&nbsp;the&nbsp;<br>
instruction pipeline.&nbsp;For data&nbsp;processing instructions&nbsp;only&nbsp;the&nbsp;bottom&nbsp;eight&nbsp;bits (bits&nbsp;<br>
[7:0]) of&nbsp;the&nbsp;instruction&nbsp;are&nbsp;used&nbsp;in&nbsp;the&nbsp;immediate&nbsp;value.&nbsp;<br>
Data transfer&nbsp;<br>
A&nbsp;data&nbsp;transfer (load&nbsp;or&nbsp;store)&nbsp;instruction computes&nbsp;a&nbsp;memory&nbsp;address in&nbsp;a&nbsp;manner&nbsp;<br>
instructions&nbsp;<br>
very similar to the way a data processing instruction computes&nbsp;its result. A register&nbsp;<br>
is used&nbsp;as&nbsp;the base&nbsp;address,&nbsp;to&nbsp;which&nbsp;is&nbsp;added (or from&nbsp;which is&nbsp;subtracted) an&nbsp;offset&nbsp;<br>
which again&nbsp;may&nbsp;be another register or an&nbsp;immediate&nbsp;value. This&nbsp;time, however,&nbsp;a&nbsp;<br>
12-bit immediate value is used without a&nbsp;shift operation&nbsp;rather than a&nbsp;shifted 8-bit&nbsp;<br>
value. The address is sent to&nbsp;the address&nbsp;register, and in a second cycle the data&nbsp;<br>
transfer&nbsp;takes place.&nbsp;Rather&nbsp;than leave the datapath&nbsp;largely&nbsp;idle&nbsp;during the&nbsp;data&nbsp;trans-<br>
fer cycle,&nbsp;the&nbsp;ALU holds the&nbsp;address components&nbsp;from&nbsp;the first&nbsp;cycle&nbsp;and is&nbsp;availa-<br>
ble to compute an auto-indexing&nbsp;modification to&nbsp;the base&nbsp;register&nbsp;if&nbsp;this is&nbsp;required.&nbsp;<br>
(If auto-indexing is not required&nbsp;the&nbsp;computed&nbsp;value&nbsp;is&nbsp;not&nbsp;written&nbsp;back&nbsp;to the&nbsp;base&nbsp;<br>
register&nbsp;in the second&nbsp;cycle.)&nbsp;<br>
<hr>
<A name=95></a><IMG src="index-95_1.png"><br>
<b>ARM&nbsp;instruction&nbsp;execution</b>&nbsp;<br>
<b>83</b>&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;4.5 &nbsp;&nbsp;</b>Data&nbsp;processing instruction&nbsp;datapath activity.&nbsp;<br>
The datapath&nbsp;operation for the two cycles&nbsp;of&nbsp;a data store instruction (SIR) with&nbsp;an&nbsp;<br>
immediate offset&nbsp;are shown&nbsp;in&nbsp;Figure&nbsp;4.6&nbsp;on&nbsp;page&nbsp;84.&nbsp;Note&nbsp;how the&nbsp;incremented PC&nbsp;<br>
value is stored in the register&nbsp;bank at the end of the first&nbsp;cycle so that&nbsp;the address regis-<br>
ter is&nbsp;free to&nbsp;accept the&nbsp;data&nbsp;transfer address for the second cycle,&nbsp;then&nbsp;at&nbsp;the end&nbsp;of&nbsp;<br>
the second cycle the&nbsp;PC is&nbsp;fed&nbsp;back to&nbsp;the address&nbsp;register&nbsp;to&nbsp;allow instruction&nbsp;<br>
prefetching to&nbsp;continue.&nbsp;<br>
It&nbsp;should, perhaps, be noted at&nbsp;this&nbsp;stage&nbsp;that&nbsp;the value sent to the address register in&nbsp;<br>
a cycle is&nbsp;the&nbsp;value&nbsp;used for&nbsp;the memory access in&nbsp;<i>the following&nbsp;</i>cycle. The&nbsp;address&nbsp;<br>
register is, in effect, a&nbsp;pipeline register&nbsp;between&nbsp;the&nbsp;processor&nbsp;datapath&nbsp;and&nbsp;the exter-<br>
nal memory.&nbsp;<br>
(The&nbsp;address register can&nbsp;produce the memory address&nbsp;for the&nbsp;next&nbsp;cycle a little&nbsp;<br>
before the end of the current&nbsp;cycle, moving&nbsp;responsibility&nbsp;for the pipeline delay out&nbsp;<br>
into&nbsp;the memory when this is desired.&nbsp;This can&nbsp;enable some&nbsp;memory devices to&nbsp;oper-<br>
ate&nbsp;at&nbsp;higher performance, but&nbsp;this&nbsp;detail&nbsp;can&nbsp;be postponed for the time being. For now&nbsp;<br>
we will&nbsp;view&nbsp;the address register as a pipeline&nbsp;register to&nbsp;memory.)&nbsp;<br>
<hr>
<A name=96></a><IMG src="index-96_1.png"><br>
<b>84</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Figure 4.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SIR (store register)&nbsp;datapath&nbsp;activity.&nbsp;<br>
When the&nbsp;instruction&nbsp;specifies&nbsp;the store of&nbsp;a byte&nbsp;data&nbsp;type,&nbsp;the&nbsp;'data out'&nbsp;block&nbsp;<br>
extracts the bottom&nbsp;byte from&nbsp;the register&nbsp;and replicates it four times across the&nbsp;32-bit&nbsp;<br>
data bus. External&nbsp;memory&nbsp;control logic can then use the bottom&nbsp;two&nbsp;bits of the&nbsp;<br>
address bus&nbsp;to&nbsp;activate&nbsp;the appropriate&nbsp;byte within&nbsp;the&nbsp;memory system.&nbsp;<br>
Load&nbsp;instructions&nbsp;follow a similar pattern&nbsp;except&nbsp;that&nbsp;the&nbsp;data&nbsp;from&nbsp;memory only&nbsp;<br>
gets&nbsp;as&nbsp;far as&nbsp;the&nbsp;'data&nbsp;in'&nbsp;register&nbsp;on&nbsp;the&nbsp;second&nbsp;cycle&nbsp;and&nbsp;a&nbsp;third cycle&nbsp;is&nbsp;needed to&nbsp;<br>
transfer the data&nbsp;from&nbsp;there to the destination register.&nbsp;<br>
Branch&nbsp;<br>
Branch&nbsp;instructions&nbsp;compute the target address in the&nbsp;first cycle&nbsp;as&nbsp;shown&nbsp;in&nbsp;<br>
instructions&nbsp;<br>
Figure 4.7 on&nbsp;page&nbsp;85.&nbsp;A 24-bit&nbsp;immediate field is&nbsp;extracted&nbsp;from&nbsp;the instruction&nbsp;and&nbsp;<br>
then shifted&nbsp;left&nbsp;two bit&nbsp;positions&nbsp;to&nbsp;give&nbsp;a word-aligned offset&nbsp;which is added to&nbsp;the&nbsp;<br>
PC. The result&nbsp;is issued as an&nbsp;instruction fetch address,&nbsp;and while the instruction&nbsp;<br>
pipeline refills the return address is copied into&nbsp;the&nbsp;link register (r14) if this is&nbsp;<br>
required (that is, if the instruction is a&nbsp;'branch with link').&nbsp;<br>
<hr>
<A name=97></a><IMG src="index-97_1.png"><br>
<b>ARM&nbsp;instruction&nbsp;execution</b>&nbsp;<br>
<b>85</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 4.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The first two (of&nbsp;three)&nbsp;cycles&nbsp;of&nbsp;a branch&nbsp;instruction.&nbsp;<br>
The third&nbsp;cycle,&nbsp;which is required to&nbsp;complete the pipeline refilling, is also&nbsp;used&nbsp;to&nbsp;<br>
make&nbsp;a&nbsp;small&nbsp;correction to&nbsp;the value&nbsp;stored&nbsp;in&nbsp;the&nbsp;link&nbsp;register&nbsp;in&nbsp;order&nbsp;that&nbsp;it&nbsp;points&nbsp;<br>
directly&nbsp;at&nbsp;the instruction&nbsp;which&nbsp;follows the&nbsp;branch.&nbsp;This&nbsp;is necessary because&nbsp;r15&nbsp;<br>
contains pc + 8&nbsp;whereas&nbsp;the&nbsp;address of the next instruction&nbsp;is&nbsp;pc&nbsp;+ 4&nbsp;(see&nbsp;'PC&nbsp;behav-<br>
iour'&nbsp;on&nbsp;page&nbsp;78).&nbsp;<br>
Other&nbsp;ARM instructions operate in&nbsp;a&nbsp;similar&nbsp;manner&nbsp;to&nbsp;those described&nbsp;<br>
above.&nbsp;We&nbsp;will now&nbsp;move on to look&nbsp;in&nbsp;more&nbsp;detail at&nbsp;how&nbsp;the&nbsp;datapath carries&nbsp;<br>
out&nbsp;these&nbsp;operations.&nbsp;<br>
<hr>
<A name=98></a><IMG src="index-98_1.png"><br>
<b>86</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
4.4 &nbsp; ARM&nbsp;implementation&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The&nbsp;ARM implementation follows a similar approach to that&nbsp;outlined&nbsp;in&nbsp;Chapter&nbsp;1&nbsp;<br>
for&nbsp;MU0;&nbsp;the&nbsp;design&nbsp;is&nbsp;divided&nbsp;into&nbsp;a&nbsp;datapath&nbsp;section&nbsp;that&nbsp;is&nbsp;described&nbsp;in&nbsp;<i>register&nbsp;</i><br>
<i>transfer&nbsp;level&nbsp;</i>(RTL)&nbsp;notation&nbsp;and&nbsp;a control section that&nbsp;is&nbsp;viewed&nbsp;as&nbsp;<i>a finite state&nbsp;</i><br>
<i>machine&nbsp;</i>(FSM).&nbsp;<br>
Clocking&nbsp;<br>
Unlike&nbsp;the MU0&nbsp;example presented in&nbsp;Section&nbsp;1.3 on&nbsp;page&nbsp;7, most&nbsp;ARMs&nbsp;do&nbsp;not&nbsp;<br>
scheme&nbsp;<br>
operate with edge-sensitive registers; instead&nbsp;the&nbsp;design&nbsp;is&nbsp;based&nbsp;around&nbsp;2-phase&nbsp;<br>
non-overlapping&nbsp;clocks, as&nbsp;shown&nbsp;in&nbsp;Figure&nbsp;4.8,&nbsp;which&nbsp;are&nbsp;generated&nbsp;internally&nbsp;from&nbsp;<br>
a single input&nbsp;clock&nbsp;signal. This scheme&nbsp;allows the&nbsp;use&nbsp;of&nbsp;level-sensitive transparent&nbsp;<br>
latches. Data&nbsp;movement&nbsp;is controlled&nbsp;by&nbsp;passing&nbsp;the&nbsp;data alternately through&nbsp;latches&nbsp;<br>
which&nbsp;are&nbsp;open&nbsp;during phase 1 and latches which are&nbsp;open&nbsp;during&nbsp;phase 2. The&nbsp;<br>
non-overlapping property of&nbsp;the phase 1 and&nbsp;phase&nbsp;2 clocks&nbsp;ensures&nbsp;that&nbsp;there&nbsp;are&nbsp;<br>
no&nbsp;race conditions in the circuit.&nbsp;<br>
Datapath timing&nbsp;<br>
The normal&nbsp;timing&nbsp;of&nbsp;the datapath&nbsp;components in&nbsp;a 3-stage pipeline is&nbsp;illustrated&nbsp;in&nbsp;<br>
Figure 4.9 on page 87. The register&nbsp;read buses&nbsp;are dynamic&nbsp;and&nbsp;are precharged during&nbsp;<br>
phase 2 (here&nbsp;'dynamic'&nbsp;means that&nbsp;they are&nbsp;sometimes undriven&nbsp;and retain their&nbsp;logic&nbsp;<br>
values as electrical&nbsp;charge;&nbsp;charge-retention circuits&nbsp;are used to&nbsp;give pseudo-static&nbsp;<br>
behaviour&nbsp;so&nbsp;that data&nbsp;is&nbsp;not&nbsp;lost&nbsp;if&nbsp;the&nbsp;clock&nbsp;is stopped&nbsp;at any&nbsp;point&nbsp;in&nbsp;its&nbsp;cycle). When&nbsp;<br>
phase 1 goes high,&nbsp;the selected registers discharge&nbsp;the read&nbsp;buses which become&nbsp;valid&nbsp;<br>
early in&nbsp;phase&nbsp;1.&nbsp;One operand&nbsp;is&nbsp;passed through the&nbsp;barrel shifter, which&nbsp;also uses&nbsp;<br>
dynamic techniques, and&nbsp;the&nbsp;shifter output&nbsp;becomes valid&nbsp;a&nbsp;little&nbsp;later&nbsp;in&nbsp;phase 1.&nbsp;<br>
The ALU has&nbsp;input&nbsp;latches which&nbsp;are open during&nbsp;phase 1,&nbsp;allowing&nbsp;the operands&nbsp;<br>
to&nbsp;begin combining in&nbsp;the ALU as soon&nbsp;as they are valid,&nbsp;but they close at the end of&nbsp;<br>
phase 1 so&nbsp;that&nbsp;the phase 2 precharge does not&nbsp;get&nbsp;through to&nbsp;the ALU. The&nbsp;ALU then&nbsp;<br>
continues to&nbsp;process the operands through&nbsp;phase 2,&nbsp;producing a&nbsp;valid&nbsp;output&nbsp;towards&nbsp;<br>
the end&nbsp;of&nbsp;the&nbsp;phase which&nbsp;is latched&nbsp;in&nbsp;the&nbsp;destination register at the end of phase 2.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure 4.8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>2-phase non-overlapping&nbsp;clock&nbsp;<br>
scheme.&nbsp;<br>
&nbsp;<br>
<hr>
<A name=99></a><IMG src="index-99_1.png"><br>
<b>ARM implementation</b>&nbsp;<br>
<b>87</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 4.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM datapath&nbsp;timing&nbsp;(3-stage&nbsp;pipeline).&nbsp;<br>
Note how, though the data passes through the ALU input latches, these do not&nbsp;<br>
affect the datapath timing since they are open&nbsp;when valid data&nbsp;arrives. This&nbsp;property&nbsp;of&nbsp;<br>
transparent latches is exploited in many places in the design&nbsp;of the ARM to&nbsp;ensure&nbsp;that&nbsp;<br>
clocks do&nbsp;not&nbsp;slow critical&nbsp;signals.&nbsp;<br>
The&nbsp;minimum&nbsp;datapath cycle&nbsp;time is&nbsp;therefore the sum&nbsp;of:&nbsp;<br>
•&nbsp;&nbsp;the register read&nbsp;time;&nbsp;<br>
•&nbsp;&nbsp;the shifter delay;&nbsp;<br>
•&nbsp;&nbsp;the ALU&nbsp;delay;&nbsp;<br>
•&nbsp;&nbsp;the register write set-up&nbsp;time;&nbsp;<br>
•&nbsp;&nbsp;the phase 2 to&nbsp;phase 1 non-overlap&nbsp;time.&nbsp;<br>
Of these,&nbsp;the ALU delay&nbsp;dominates.&nbsp;The&nbsp;ALU delay is&nbsp;highly&nbsp;variable, depending&nbsp;<br>
on&nbsp;the operation&nbsp;it&nbsp;is&nbsp;performing.&nbsp;Logical operations&nbsp;are&nbsp;relatively&nbsp;fast,&nbsp;since they&nbsp;<br>
involve&nbsp;no carry propagation.&nbsp;Arithmetic&nbsp;operations&nbsp;(addition,&nbsp;subtraction&nbsp;and com-<br>
parisons) involve longer&nbsp;logic&nbsp;paths as&nbsp;the&nbsp;carry&nbsp;can propagate&nbsp;across&nbsp;the word width.&nbsp;<br>
Adder&nbsp;design&nbsp;<br>
Since&nbsp;the&nbsp;32-bit&nbsp;addition time&nbsp;has a significant&nbsp;effect&nbsp;on&nbsp;the datapath cycle time,&nbsp;and&nbsp;<br>
hence the&nbsp;maximum&nbsp;clock rate and the&nbsp;processor's performance, it has been the&nbsp;<br>
focus of&nbsp;considerable&nbsp;attention during&nbsp;the&nbsp;development of&nbsp;successive&nbsp;versions of&nbsp;the&nbsp;<br>
ARM processor.&nbsp;<br>
<hr>
<A name=100></a><IMG src="index-100_1.png"><br>
<b>88</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure 4.10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The&nbsp;original ARM1&nbsp;ripple-carry adder circuit.&nbsp;<br>
The&nbsp;first&nbsp;ARM&nbsp;processor&nbsp;prototype&nbsp;used&nbsp;a&nbsp;simple ripple-carry adder as shown&nbsp;in&nbsp;<br>
Figure&nbsp;4.10. Using a CMOS&nbsp;AND-OR-INVERT gate for the carry logic&nbsp;and alternat-<br>
ing&nbsp;AND/OR logic so that&nbsp;even&nbsp;bits&nbsp;use the circuit shown&nbsp;and odd bits use&nbsp;the&nbsp;dual&nbsp;<br>
circuit with&nbsp;inverted inputs and outputs&nbsp;and&nbsp;AND and OR&nbsp;gates&nbsp;swapped around, the&nbsp;<br>
worst-case&nbsp;carry path is&nbsp;32 gates&nbsp;long.&nbsp;<br>
In&nbsp;order&nbsp;to&nbsp;allow a&nbsp;higher&nbsp;clock&nbsp;rate,&nbsp;ARM2&nbsp;used&nbsp;a&nbsp;4-bit&nbsp;carry&nbsp;look-ahead&nbsp;scheme&nbsp;<br>
to reduce the&nbsp;worst-case carry&nbsp;path length. The circuit is shown in Figure 4.11 on&nbsp;<br>
page&nbsp;89.&nbsp;The logic produces&nbsp;carry generate (G)&nbsp;and propagate (P)&nbsp;signals which&nbsp;con-<br>
trol the&nbsp;4-bit&nbsp;carry-out. The&nbsp;carry&nbsp;propagate path&nbsp;length is reduced to&nbsp;eight gate&nbsp;<br>
delays,&nbsp;again using&nbsp;merged AND-OR-INVERT gates&nbsp;and alternating AND/OR logic.&nbsp;<br>
ALU functions&nbsp;<br>
The&nbsp;ALU does&nbsp;not only add&nbsp;its two&nbsp;inputs.&nbsp;It&nbsp;must perform&nbsp;the&nbsp;full&nbsp;set of data&nbsp;oper-<br>
ations defined&nbsp;by&nbsp;the instruction&nbsp;set,&nbsp;including&nbsp;address computations&nbsp;for&nbsp;memory&nbsp;<br>
transfers,&nbsp;branch calculations, bit-wise logical functions, and so on.&nbsp;<br>
The full ARM2&nbsp;ALU logic&nbsp;is&nbsp;illustrated&nbsp;in Figure&nbsp;4.12&nbsp;on&nbsp;page&nbsp;89. The set&nbsp;of func-<br>
tions generated&nbsp;by&nbsp;this ALU and&nbsp;the&nbsp;associated&nbsp;values&nbsp;of the ALU function selects&nbsp;are&nbsp;<br>
listed in&nbsp;Table&nbsp;4.1&nbsp;on&nbsp;page&nbsp;90.&nbsp;<br>
The ARM6&nbsp;<br>
A&nbsp;further improvement&nbsp;in&nbsp;the&nbsp;worst-case&nbsp;add&nbsp;time&nbsp;was introduced&nbsp;on&nbsp;the ARM6 by&nbsp;<br>
carry-select&nbsp;<br>
using a carry-select adder. This form&nbsp;of adder computes the sums&nbsp;of&nbsp;various fields&nbsp;<br>
adder&nbsp;<br>
of the&nbsp;word&nbsp;for a carry-in&nbsp;of&nbsp;both zero and&nbsp;one, and then the final&nbsp;result&nbsp;is selected&nbsp;<br>
by using&nbsp;the&nbsp;correct&nbsp;carry-in&nbsp;value&nbsp;to&nbsp;control a&nbsp;multiplexer. The overall&nbsp;scheme&nbsp;is&nbsp;<br>
illustrated&nbsp;in&nbsp;Figure 4.13&nbsp;on page 90.&nbsp;<br>
<hr>
<A name=101></a><IMG src="index-101_1.png"><br>
<IMG src="index-101_2.png"><br>
<b>ARM implementation</b>&nbsp;<br>
89&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;4.11 &nbsp; &nbsp;</b>The ARM2 4-bit carry&nbsp;look-ahead scheme.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;4.12 &nbsp;&nbsp;</b>The ARM2 ALU logic for one&nbsp;result bit.&nbsp;<br>
The critical&nbsp;path is&nbsp;now O(log2[word width]) gates&nbsp;long, though&nbsp;direct&nbsp;comparison&nbsp;<br>
with&nbsp;previous&nbsp;schemes is&nbsp;difficult&nbsp;since the fan-out&nbsp;on&nbsp;some&nbsp;of these gates is&nbsp;high.&nbsp;<br>
However, the worst-case addition time&nbsp;is significantly&nbsp;faster&nbsp;than&nbsp;the 4-bit carry&nbsp;<br>
look-ahead&nbsp;adder at the cost of&nbsp;significantly&nbsp;increased&nbsp;silicon&nbsp;area.&nbsp;<br>
<hr>
<A name=102></a><IMG src="index-102_1.png"><br>
<IMG src="index-102_2.png"><br>
<b>90</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
<b>Table&nbsp;4.1 &nbsp;&nbsp;&nbsp;</b>ARM2 ALU function codes.&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
ARM6 ALU&nbsp;<br>
The ARM6 carry-select adder does not easily&nbsp;lead to&nbsp;a&nbsp;merging of the arithmetic&nbsp;<br>
structure&nbsp;<br>
and&nbsp;logic functions into&nbsp;a single structure as was&nbsp;used&nbsp;on&nbsp;ARM2. Instead,&nbsp;a separate&nbsp;<br>
logic unit runs in parallel&nbsp;with&nbsp;the adder, and a&nbsp;multiplexer selects the&nbsp;output from&nbsp;<br>
the adder or&nbsp;from&nbsp;the&nbsp;logic unit as required.&nbsp;<br>
The overall ALU structure is shown in Figure 4.14&nbsp;on&nbsp;page&nbsp;91.&nbsp;The input operands&nbsp;<br>
are each&nbsp;selectively&nbsp;inverted, then&nbsp;added&nbsp;and&nbsp;combined in the logic&nbsp;unit,&nbsp;and&nbsp;finally&nbsp;<br>
the required result&nbsp;is selected&nbsp;and issued on&nbsp;the ALU result&nbsp;bus.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;4.13 &nbsp;&nbsp;</b>The ARM6 carry-select adder&nbsp;scheme.&nbsp;<br>
<hr>
<A name=103></a><IMG src="index-103_1.png"><br>
<IMG src="index-103_2.png"><br>
<b>ARM implementation</b>&nbsp;<br>
<b>91</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;4.14 &nbsp;&nbsp;</b>The ARM6 ALU organization.&nbsp;<br>
The&nbsp;<i>C&nbsp;</i>and&nbsp;<i>V&nbsp;</i>flags&nbsp;are generated in&nbsp;the&nbsp;adder (they&nbsp;have&nbsp;no&nbsp;meaning for logical&nbsp;<br>
operations), the&nbsp;<i>N&nbsp;</i>flag is&nbsp;copied&nbsp;from&nbsp;bit 31 of&nbsp;the&nbsp;result&nbsp;and&nbsp;the&nbsp;<i>Z&nbsp;</i>flag&nbsp;is evaluated&nbsp;<br>
from&nbsp;the&nbsp;whole result bus.&nbsp;Note that producing the Z flag&nbsp;requires a 32-input&nbsp;NOR&nbsp;<br>
gate&nbsp;and this can&nbsp;easily&nbsp;become&nbsp;a critical&nbsp;path signal.&nbsp;<br>
Carry arbitration&nbsp;<br>
The adder logic was further improved on the ARM9TDMI,&nbsp;where a&nbsp;'carry arbitra-<br>
adder&nbsp;<br>
tion'&nbsp;adder is used. This adder computes&nbsp;all&nbsp;intermediate carry values using&nbsp;a&nbsp;<br>
'parallel-prefix' tree,&nbsp;which&nbsp;is&nbsp;a very fast&nbsp;parallel logic structure.&nbsp;<br>
The carry arbitration scheme&nbsp;recedes the&nbsp;conventional propagate-generate&nbsp;informa-<br>
tion in&nbsp;terms of two new variables,&nbsp;<i>u&nbsp;</i>and v.&nbsp;Consider the computation of the carry&nbsp;out,&nbsp;<br>
C,&nbsp;from&nbsp;a&nbsp;particular&nbsp;bit&nbsp;position&nbsp;in&nbsp;the&nbsp;adder&nbsp;with&nbsp;inputs&nbsp;A and B.&nbsp;Before&nbsp;the&nbsp;carry&nbsp;in&nbsp;<br>
is&nbsp;known,&nbsp;the information&nbsp;available is&nbsp;as&nbsp;shown&nbsp;in Table&nbsp;4.2,&nbsp;which also shows how&nbsp;<br>
<b>Table&nbsp;4.2 &nbsp;&nbsp;&nbsp;</b>ARM9 carry&nbsp;arbitration encoding.&nbsp;<br>
&nbsp;<br>
<hr>
<A name=104></a><IMG src="index-104_1.png"><br>
92&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
this&nbsp;information is&nbsp;encoded&nbsp;by&nbsp;<i>u&nbsp;</i>and&nbsp;v.&nbsp;This information can be combined&nbsp;with&nbsp;that&nbsp;<br>
from&nbsp;a neighbouring bit position using&nbsp;the formula:&nbsp;<br>
(u,v) • (w',v')&nbsp;= (v&nbsp;+&nbsp;<i>u&nbsp;• u',v + u&nbsp;• v')</i>&nbsp;<br>
Equation 12&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
It&nbsp;can be shown that&nbsp;this&nbsp;combinational&nbsp;operator&nbsp;is&nbsp;associative and hence&nbsp;<i>u&nbsp;</i>and v can&nbsp;<br>
be&nbsp;computed&nbsp;for all the&nbsp;bits in&nbsp;the sum&nbsp;using&nbsp;a&nbsp;regular parallel prefix&nbsp;tree. The logic&nbsp;<br>
required&nbsp;to&nbsp;implement Equation&nbsp;12 can combine up&nbsp;to 4 pairs&nbsp;of&nbsp;inputs in a single&nbsp;<br>
CMOS gate, producing the new&nbsp;<i>u&nbsp;</i>and v&nbsp;outputs&nbsp;from&nbsp;a single transistor structure.&nbsp;<br>
Furthermore, it can be seen&nbsp;that&nbsp;<i>u&nbsp;</i>gives the carry-out&nbsp;if&nbsp;the&nbsp;carry-in is&nbsp;one, and&nbsp;v&nbsp;<br>
gives the carry-out if the carry-in is zero,&nbsp;<i>u&nbsp;</i>and v can therefore be used to&nbsp;generate&nbsp;the&nbsp;<br>
<i>(Sum,&nbsp;Sum+1)&nbsp;</i>values required&nbsp;for&nbsp;a&nbsp;hybrid&nbsp;carry&nbsp;arbitration/carry select adder, result-<br>
ing&nbsp;in&nbsp;a&nbsp;number&nbsp;of&nbsp;possible&nbsp;designs which allow&nbsp;a trade-off between&nbsp;performance,&nbsp;<br>
area and power consumption.&nbsp;<br>
The barrel shifter&nbsp;&nbsp;The ARM architecture supports&nbsp;instructions&nbsp;which perform&nbsp;a&nbsp;shift&nbsp;operation&nbsp;in&nbsp;<br>
series with&nbsp;an&nbsp;ALU&nbsp;operation,&nbsp;leading&nbsp;to&nbsp;the organization&nbsp;shown&nbsp;in&nbsp;Figure 4.1 on&nbsp;<br>
page&nbsp;76.&nbsp;The shifter&nbsp;performance is&nbsp;therefore critical since the shift time&nbsp;contributes&nbsp;<br>
directly&nbsp;to&nbsp;the datapath&nbsp;cycle time as shown&nbsp;in&nbsp;the&nbsp;datapath&nbsp;timing&nbsp;diagram&nbsp;in&nbsp;<br>
Figure 4.9 on&nbsp;page 87.&nbsp;<br>
(Other&nbsp;processor&nbsp;architectures&nbsp;tend&nbsp;to&nbsp;have&nbsp;the&nbsp;shifter&nbsp;in&nbsp;parallel with&nbsp;the ALU,&nbsp;<br>
so&nbsp;as&nbsp;long&nbsp;as&nbsp;the shifter is&nbsp;no&nbsp;slower&nbsp;than&nbsp;the&nbsp;ALU it&nbsp;does&nbsp;not affect&nbsp;the&nbsp;datapath&nbsp;<br>
cycle&nbsp;time.)&nbsp;<br>
In order to&nbsp;minimize&nbsp;the delay through the shifter,&nbsp;a cross-bar switch&nbsp;matrix&nbsp;is&nbsp;used&nbsp;<br>
to steer each input to the appropriate&nbsp;output. The principle of&nbsp;the cross-bar switch&nbsp;is&nbsp;<br>
illustrated&nbsp;in&nbsp;Figure&nbsp;4.15,&nbsp;where a 4&nbsp;x&nbsp;4&nbsp;matrix&nbsp;is shown. (The&nbsp;ARM processors&nbsp;use a&nbsp;<br>
&nbsp;<br>
<b>Figure 4.15&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The&nbsp;cross-bar&nbsp;switch barrel shifter&nbsp;principle.&nbsp;<br>
<hr>
<A name=105></a><b>ARM&nbsp;implementation&nbsp;</b><br>
<b>93</b>&nbsp;<br>
32 x 32&nbsp;matrix.)&nbsp;Each input is connected&nbsp;to each output through a&nbsp;switch.&nbsp;If&nbsp;<br>
pre-charged dynamic logic&nbsp;is&nbsp;used,&nbsp;as&nbsp;it&nbsp;is&nbsp;on&nbsp;the ARM&nbsp;datapaths,&nbsp;each&nbsp;switch&nbsp;can&nbsp;be&nbsp;<br>
implemented&nbsp;as&nbsp;a single NMOS transistor.&nbsp;<br>
The&nbsp;shifting&nbsp;functions are&nbsp;implemented by&nbsp;wiring switches along diagonals to a&nbsp;<br>
common control input:&nbsp;<br>
•&nbsp;&nbsp;For a left or&nbsp;right shift function, one diagonal is turned on. This connects all the&nbsp;<br>
input bits to their&nbsp;respective&nbsp;outputs&nbsp;where&nbsp;they are used.&nbsp;(Not all are used, since&nbsp;<br>
some&nbsp;bits 'fall&nbsp;off the&nbsp;end'.) In the ARM the barrel shifter&nbsp;operates&nbsp;in&nbsp;negative&nbsp;<br>
logic&nbsp;where a&nbsp;'&nbsp;1'&nbsp;is&nbsp;represented as a potential near ground&nbsp;and a&nbsp;'0'&nbsp;by&nbsp;a potential&nbsp;<br>
near&nbsp;the&nbsp;supply.&nbsp;Precharging&nbsp;sets all&nbsp;the outputs to&nbsp;a&nbsp;logic '0',&nbsp;so those&nbsp;outputs&nbsp;<br>
that&nbsp;are not connected to any&nbsp;input&nbsp;during&nbsp;a&nbsp;particular&nbsp;switching&nbsp;operation&nbsp;remain&nbsp;<br>
at&nbsp;'0'&nbsp;giving the zero&nbsp;filling&nbsp;required by&nbsp;the&nbsp;shift semantics.&nbsp;<br>
•&nbsp;&nbsp;For a rotate right function,&nbsp;the right shift diagonal is enabled together&nbsp;with the&nbsp;<br>
complementary&nbsp;left&nbsp;shift diagonal. For example, on the 4-bit&nbsp;matrix&nbsp;rotate right&nbsp;<br>
one bit is implemented using&nbsp;the&nbsp;'right 1'&nbsp;and the&nbsp;'left 3'&nbsp;(3&nbsp;= 4 - 1) diagonals.&nbsp;<br>
•&nbsp;&nbsp;Arithmetic&nbsp;shift&nbsp;right&nbsp;uses&nbsp;sign-extension rather&nbsp;than zero-fill for&nbsp;the&nbsp;unconnected&nbsp;<br>
output bits.&nbsp;Separate logic&nbsp;is used&nbsp;to&nbsp;decode&nbsp;the shift&nbsp;amount and discharge those&nbsp;<br>
outputs appropriately.&nbsp;<br>
Multiplier&nbsp;design&nbsp;<br>
All ARM processors apart&nbsp;from&nbsp;the&nbsp;first prototype have included hardware support&nbsp;<br>
for&nbsp;integer&nbsp;multiplication.&nbsp;Two&nbsp;styles&nbsp;of&nbsp;multiplier&nbsp;have&nbsp;been&nbsp;used:&nbsp;<br>
•&nbsp;&nbsp;Older ARM cores include low-cost&nbsp;multiplication hardware that supports&nbsp;only&nbsp;<br>
the&nbsp;32-bit result&nbsp;multiply&nbsp;and multiply-accumulate instructions.&nbsp;<br>
•&nbsp;&nbsp;Recent&nbsp;ARM&nbsp;cores have high-performance&nbsp;multiplication&nbsp;hardware and&nbsp;support&nbsp;<br>
the&nbsp;64-bit result&nbsp;multiply&nbsp;and multiply-accumulate instructions.&nbsp;<br>
The low-cost&nbsp;support uses the&nbsp;main datapath iteratively,&nbsp;employing the barrel&nbsp;<br>
shifter&nbsp;and&nbsp;ALU to&nbsp;generate&nbsp;a 2-bit product in each&nbsp;clock cycle.&nbsp;Early-termination&nbsp;<br>
logic stops the&nbsp;iterations&nbsp;when&nbsp;there&nbsp;are&nbsp;no more ones in&nbsp;the&nbsp;multiply register.&nbsp;<br>
The multiplier&nbsp;employs a modified&nbsp;Booth's algorithm&nbsp;to&nbsp;produce&nbsp;the 2-bit&nbsp;product,&nbsp;<br>
exploiting the fact that x3&nbsp;can be implemented as x(-l)+ x4 . This&nbsp;allows all&nbsp;<br>
four&nbsp;values&nbsp;of&nbsp;the&nbsp;2-bit&nbsp;multiplier to&nbsp;be&nbsp;implemented&nbsp;by&nbsp;a simple shift&nbsp;and&nbsp;add&nbsp;or&nbsp;sub-<br>
tract, possibly&nbsp;carrying the x&nbsp;4 over&nbsp;to the next cycle.&nbsp;<br>
The&nbsp;control&nbsp;settings&nbsp;for the Nth&nbsp;cycle&nbsp;of&nbsp;the&nbsp;multiplication&nbsp;are shown in&nbsp;Table&nbsp;4.3&nbsp;<br>
on page 94. (Note that the x 2&nbsp;case&nbsp;is&nbsp;also&nbsp;implemented&nbsp;with&nbsp;a&nbsp;subtract&nbsp;and carry; it&nbsp;<br>
could&nbsp;equally&nbsp;well&nbsp;use&nbsp;an&nbsp;add with&nbsp;no&nbsp;carry,&nbsp;but the control&nbsp;logic is&nbsp;slightly simplified&nbsp;<br>
with&nbsp;this&nbsp;choice.)&nbsp;<br>
Since&nbsp;this multiplication&nbsp;uses&nbsp;the&nbsp;existing shifter and ALU, the additional&nbsp;hardware&nbsp;<br>
it&nbsp;requires&nbsp;is&nbsp;limited to&nbsp;a&nbsp;dedicated&nbsp;two-bits-per-cycle&nbsp;shift&nbsp;register for&nbsp;the&nbsp;multiplier&nbsp;<br>
and&nbsp;a&nbsp;few gates for&nbsp;the&nbsp;Booth's algorithm&nbsp;control logic.&nbsp;In&nbsp;total this&nbsp;amounts&nbsp;to&nbsp;an&nbsp;<br>
overhead of&nbsp;a few per cent&nbsp;on&nbsp;the&nbsp;area&nbsp;of the&nbsp;ARM core.&nbsp;<br>
<hr>
<A name=106></a><IMG src="index-106_1.png"><br>
<b>94</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
<b>Table&nbsp;4.3 &nbsp; &nbsp;</b>The 2-bit&nbsp;multiplication algorithm,&nbsp;Nth cycle.&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
High-speed&nbsp;<br>
Where&nbsp;multiplication performance&nbsp;is very&nbsp;important,&nbsp;more&nbsp;hardware&nbsp;resource&nbsp;must&nbsp;<br>
multiplier&nbsp;<br>
be dedicated&nbsp;to it. In&nbsp;some&nbsp;embedded&nbsp;systems the&nbsp;ARM core is used to perform&nbsp;<br>
real-time digital signal processing&nbsp;(DSP) in&nbsp;addition to general control functions.&nbsp;<br>
DSP programs are&nbsp;typically&nbsp;multiplication&nbsp;intensive&nbsp;and&nbsp;the performance of&nbsp;the&nbsp;<br>
multiplication&nbsp;hardware can&nbsp;be critical&nbsp;to&nbsp;meeting the&nbsp;real-time&nbsp;constraints.&nbsp;<br>
The&nbsp;high-performance multiplication&nbsp;used&nbsp;in&nbsp;some&nbsp;ARM&nbsp;cores&nbsp;employs a&nbsp;<br>
widely-used redundant&nbsp;binary representation to&nbsp;avoid the&nbsp;carry-propagate delays&nbsp;<br>
associated&nbsp;with&nbsp;adding&nbsp;partial&nbsp;products&nbsp;together. Intermediate&nbsp;results are held&nbsp;as&nbsp;partial&nbsp;<br>
sums&nbsp;and&nbsp;partial&nbsp;carries&nbsp;where the true&nbsp;binary result&nbsp;is&nbsp;obtained by&nbsp;adding these two&nbsp;<br>
together&nbsp;in&nbsp;a&nbsp;carry-propagate&nbsp;adder such&nbsp;as&nbsp;the&nbsp;adder&nbsp;in the&nbsp;main ALU,&nbsp;but&nbsp;this&nbsp;is&nbsp;<br>
only&nbsp;done&nbsp;once&nbsp;at&nbsp;the&nbsp;end&nbsp;of the&nbsp;multiplication.&nbsp;During&nbsp;the multiplication&nbsp;the&nbsp;partial&nbsp;<br>
sums&nbsp;and carries&nbsp;are&nbsp;combined&nbsp;in&nbsp;<b>carry-save&nbsp;&nbsp;</b>adders where&nbsp;the carries&nbsp;only&nbsp;<br>
propagate&nbsp;across&nbsp;one&nbsp;bit&nbsp;per&nbsp;addition&nbsp;stage. This&nbsp;gives&nbsp;the carry-save adder&nbsp;a&nbsp;much&nbsp;<br>
shorter logic path&nbsp;than the carry-propagate&nbsp;adder, which may&nbsp;have&nbsp;to&nbsp;propagate&nbsp;a carry&nbsp;<br>
across&nbsp;all&nbsp;32 bits. Therefore several&nbsp;carry-save&nbsp;operations&nbsp;may be&nbsp;performed&nbsp;in a single&nbsp;<br>
clock&nbsp;cycle which can&nbsp;only&nbsp;accommodate&nbsp;one&nbsp;carry-propagate&nbsp;operation.&nbsp;<br>
There are many ways to&nbsp;construct&nbsp;carry-save adders,&nbsp;but&nbsp;the simplest&nbsp;is&nbsp;the 3-input&nbsp;<br>
2-output&nbsp;form. This&nbsp;accepts&nbsp;as&nbsp;inputs&nbsp;a&nbsp;partial sum,&nbsp;a partial&nbsp;carry and&nbsp;a&nbsp;partial&nbsp;prod-<br>
uct, all of&nbsp;the&nbsp;same&nbsp;binary&nbsp;weight, and&nbsp;produces as outputs a&nbsp;new partial sum&nbsp;and&nbsp;a&nbsp;<br>
new&nbsp;partial&nbsp;carry&nbsp;where&nbsp;the&nbsp;carry&nbsp;has&nbsp;twice&nbsp;the weight&nbsp;of&nbsp;the&nbsp;sum.&nbsp;The&nbsp;logic function&nbsp;<br>
for each bit&nbsp;is&nbsp;identical&nbsp;to&nbsp;a&nbsp;conventional&nbsp;full&nbsp;adder as&nbsp;used&nbsp;in&nbsp;a ripple-carry&nbsp;<br>
carry-propagate adder&nbsp;(see Figure 4.10&nbsp;on page 88), but the structure is&nbsp;<br>
different.&nbsp;Figure 4.16&nbsp;on&nbsp;page 95&nbsp;illustrates&nbsp;the two&nbsp;structures. The carry-propagate&nbsp;<br>
adder takes two&nbsp;conventional (irredundant)&nbsp;binary&nbsp;numbers as inputs and produces a&nbsp;<br>
binary&nbsp;sum;&nbsp;the carry-save adder takes one&nbsp;binary&nbsp;and one redundant (partial sum&nbsp;<br>
and&nbsp;partial&nbsp;carry) input&nbsp;and&nbsp;produces&nbsp;a sum&nbsp;in redundant&nbsp;binary&nbsp;representation.&nbsp;<br>
<hr>
<A name=107></a><IMG src="index-107_1.png"><br>
<b>ARM&nbsp;implementation</b>&nbsp;<br>
<b>95</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 4.16&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Carry-propagate (a)&nbsp;and&nbsp;carry-save&nbsp;(b) adder structures.&nbsp;<br>
During&nbsp;the iterative&nbsp;multiplication&nbsp;stages, the sum&nbsp;is fed&nbsp;back&nbsp;and combined&nbsp;with&nbsp;<br>
one&nbsp;new&nbsp;partial product in&nbsp;each&nbsp;iteration.&nbsp;When&nbsp;all the&nbsp;partial products have&nbsp;been&nbsp;<br>
added, the redundant&nbsp;representation is&nbsp;converted into&nbsp;a&nbsp;conventional&nbsp;binary&nbsp;number by&nbsp;<br>
adding&nbsp;the partial sum&nbsp;and&nbsp;partial carry in&nbsp;the carry-propagate adder in&nbsp;the&nbsp;ALU.&nbsp;<br>
High-speed&nbsp;multipliers have&nbsp;several layers of&nbsp;carry-save adder in series, each&nbsp;han-<br>
dling&nbsp;one&nbsp;partial&nbsp;product. If&nbsp;the partial product&nbsp;is produced&nbsp;following&nbsp;a&nbsp;modified&nbsp;<br>
Booth's algorithm&nbsp;similar to&nbsp;the one&nbsp;described in&nbsp;Table 4.3&nbsp;on page 94, each stage of&nbsp;<br>
carry-save adder handles two&nbsp;bits&nbsp;of the multiplier in each cycle.&nbsp;<br>
The overall structure of the&nbsp;high-performance&nbsp;multiplier used&nbsp;on&nbsp;some&nbsp;ARM cores&nbsp;<br>
is&nbsp;shown in&nbsp;Figure&nbsp;4.17&nbsp;on&nbsp;page 96. The&nbsp;register names refer to&nbsp;the instruction fields&nbsp;<br>
described in&nbsp;Section 5.8&nbsp;on&nbsp;page 122. The&nbsp;carry-save array&nbsp;has four&nbsp;layers of adders,&nbsp;<br>
each handling two multiplier bits, so the array&nbsp;can&nbsp;multiply eight bits per clock cycle.&nbsp;<br>
The&nbsp;partial sum&nbsp;and carry&nbsp;registers are cleared at the start of the instruction, or the&nbsp;<br>
partial sum&nbsp;register&nbsp;may be&nbsp;initialized to&nbsp;the accumulate&nbsp;value.&nbsp;As the&nbsp;multiplier is&nbsp;<br>
shifted&nbsp;right&nbsp;eight&nbsp;bits&nbsp;per cycle&nbsp;in&nbsp;the&nbsp;'Rs' register,&nbsp;the&nbsp;partial&nbsp;sum and&nbsp;carry&nbsp;are&nbsp;<br>
rotated right&nbsp;eight&nbsp;bits&nbsp;per cycle. The array&nbsp;is cycled&nbsp;up&nbsp;to&nbsp;four times, using&nbsp;early ter-<br>
mination&nbsp;to&nbsp;complete&nbsp;the&nbsp;instruction&nbsp;in&nbsp;fewer&nbsp;cycles where&nbsp;the&nbsp;multiplier has sufficient&nbsp;<br>
zeros&nbsp;in&nbsp;the top&nbsp;bits, and the&nbsp;partial sum&nbsp;and carry are combined 32&nbsp;bits at a time and&nbsp;<br>
written&nbsp;back&nbsp;into&nbsp;the register bank.&nbsp;(When&nbsp;the&nbsp;multiply&nbsp;terminates early some&nbsp;realign-<br>
ment&nbsp;of the partial&nbsp;sum&nbsp;and carry&nbsp;is&nbsp;required;&nbsp;this&nbsp;is&nbsp;not&nbsp;shown in&nbsp;Figure&nbsp;4.17.)&nbsp;<br>
The high-speed&nbsp;multiplier requires considerably&nbsp;more dedicated hardware&nbsp;than the&nbsp;<br>
low-cost&nbsp;solution&nbsp;employed on&nbsp;other&nbsp;ARM&nbsp;cores. There are 160&nbsp;bits&nbsp;of&nbsp;shift&nbsp;register&nbsp;<br>
and 128 bits&nbsp;of carry-save adder logic. The incremental&nbsp;area cost&nbsp;is&nbsp;around&nbsp;10% of the&nbsp;<br>
simpler processor cores, though a rather smaller proportion of the higher-performance&nbsp;<br>
cores such&nbsp;as&nbsp;ARMS and&nbsp;StrongARM. Its benefits are that&nbsp;it speeds up&nbsp;multiplication&nbsp;<br>
<hr>
<A name=108></a><IMG src="index-108_1.png"><br>
<b>96</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;4.17 &nbsp;&nbsp;</b>ARM high-speed multiplier&nbsp;organization.&nbsp;<br>
by&nbsp;a factor of around 3&nbsp;and&nbsp;it&nbsp;supports&nbsp;the&nbsp;added&nbsp;functionality&nbsp;of&nbsp;the 64-bit result&nbsp;<br>
forms of&nbsp;the multiply&nbsp;instruction.&nbsp;<br>
The&nbsp;<br>
The last major block&nbsp;on&nbsp;the&nbsp;ARM datapath&nbsp;is the register&nbsp;bank. This is&nbsp;where all the&nbsp;<br>
register&nbsp;<br>
user-visible&nbsp;state is&nbsp;stored in&nbsp;31&nbsp;general-purpose 32-bit&nbsp;registers, amounting to&nbsp;around&nbsp;<br>
bank&nbsp;<br>
1 Kbits&nbsp;of data&nbsp;altogether. Since the basic 1-bit&nbsp;register cell is&nbsp;repeated so&nbsp;many&nbsp;times&nbsp;<br>
in&nbsp;the design,&nbsp;it is worth&nbsp;putting&nbsp;considerable&nbsp;effort into&nbsp;minimizing&nbsp;its size.&nbsp;<br>
The transistor&nbsp;circuit&nbsp;of&nbsp;the&nbsp;register cell&nbsp;used&nbsp;in&nbsp;ARM cores&nbsp;up&nbsp;to the&nbsp;ARM6&nbsp;is&nbsp;<br>
shown in&nbsp;Figure 4.18 on page&nbsp;97. The storage cell&nbsp;is&nbsp;an asymmetric&nbsp;cross-coupled pair&nbsp;<br>
of CMOS&nbsp;inverters which is overdriven by&nbsp;a&nbsp;strong signal from&nbsp;the ALU bus when the&nbsp;<br>
register&nbsp;contents&nbsp;are&nbsp;changed.&nbsp;The&nbsp;feedback&nbsp;inverter is&nbsp;made weak&nbsp;in&nbsp;order to&nbsp;mini-<br>
mize&nbsp;the cell's&nbsp;resistance to the new value. The&nbsp;<i>A&nbsp;</i>and&nbsp;<i>B&nbsp;</i>read&nbsp;buses are&nbsp;precharged to&nbsp;<br>
<i>Vdd&nbsp;</i>during&nbsp;phase 2 of the clock cycle, so the&nbsp;register cell&nbsp;need only&nbsp;discharge the read&nbsp;<br>
buses,&nbsp;which it&nbsp;does through n-type pass transistors when the read-lines are&nbsp;enabled.&nbsp;<br>
This register cell design&nbsp;works well with&nbsp;a&nbsp;5&nbsp;volt supply, but&nbsp;writing&nbsp;a '&nbsp;1'&nbsp;through&nbsp;<br>
the&nbsp;n-type&nbsp;pass transistor&nbsp;becomes difficult at lower supply&nbsp;voltages.&nbsp;Since a low&nbsp;<br>
supply&nbsp;voltage&nbsp;gives good&nbsp;power-efficiency, ARM&nbsp;cores since the ARM6&nbsp;have either&nbsp;<br>
used&nbsp;a full CMOS transmission&nbsp;gate (with&nbsp;a&nbsp;p-type&nbsp;transistor in&nbsp;parallel with&nbsp;the&nbsp;<br>
n-type&nbsp;pass transistor&nbsp;in&nbsp;the write&nbsp;circuit, requiring&nbsp;complementary&nbsp;write enable control&nbsp;<br>
lines) or a&nbsp;more&nbsp;sophisticated&nbsp;register circuit.&nbsp;<br>
These&nbsp;register&nbsp;cells are arranged in columns to&nbsp;form&nbsp;a 32-bit register, and&nbsp;the col-<br>
umns&nbsp;are packed&nbsp;together&nbsp;to form&nbsp;the&nbsp;complete&nbsp;register bank.&nbsp;The decoders&nbsp;for&nbsp;the&nbsp;<br>
<hr>
<A name=109></a><IMG src="index-109_1.png"><br>
<IMG src="index-109_2.png"><br>
<b>ARM&nbsp;implementation</b>&nbsp;<br>
<b>97</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 4.18&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM6 register&nbsp;cell circuit.&nbsp;<br>
read and&nbsp;write&nbsp;enable&nbsp;lines are then&nbsp;packed above the&nbsp;columns as shown in&nbsp;<br>
Figure 4.19, so&nbsp;the enables&nbsp;run&nbsp;vertically and the&nbsp;data&nbsp;buses&nbsp;horizontally across the&nbsp;<br>
array of register&nbsp;cells.&nbsp;Since&nbsp;a&nbsp;decoder is&nbsp;logically&nbsp;more&nbsp;complex than&nbsp;the&nbsp;register&nbsp;cell&nbsp;<br>
itself, but the horizontal pitch&nbsp;is&nbsp;chosen&nbsp;to&nbsp;suit&nbsp;the cell, the decoder layout&nbsp;can become&nbsp;<br>
very&nbsp;tight&nbsp;and the decoders themselves have&nbsp;to&nbsp;be tall&nbsp;and thin.&nbsp;<br>
&nbsp;<br>
<b>Figure 4.19&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM register&nbsp;bank floorplan.<br>
<hr>
<A name=110></a><IMG src="index-110_1.png"><br>
<b>98</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The&nbsp;ARM&nbsp;program&nbsp;counter&nbsp;register is&nbsp;physically&nbsp;part&nbsp;of&nbsp;the&nbsp;register bank&nbsp;in&nbsp;the&nbsp;<br>
simpler cores,&nbsp;but it has two&nbsp;write&nbsp;and three read ports&nbsp;whereas the other registers&nbsp;<br>
have&nbsp;one write&nbsp;and two read&nbsp;ports.&nbsp;The symmetry&nbsp;of the register&nbsp;array&nbsp;is&nbsp;preserved&nbsp;by&nbsp;<br>
putting the&nbsp;PC&nbsp;at&nbsp;one&nbsp;end&nbsp;where it&nbsp;is&nbsp;accessible&nbsp;to&nbsp;the&nbsp;additional&nbsp;ports and&nbsp;it&nbsp;can&nbsp;be&nbsp;<br>
allowed&nbsp;to&nbsp;have&nbsp;a&nbsp;'fatter'&nbsp;profile.&nbsp;<br>
The register bank&nbsp;accounts&nbsp;for around one-third of&nbsp;the total&nbsp;transistor&nbsp;count&nbsp;of&nbsp;the&nbsp;<br>
simpler ARM&nbsp;cores,&nbsp;but takes&nbsp;a proportionately&nbsp;much smaller share&nbsp;of the&nbsp;silicon&nbsp;area&nbsp;<br>
by&nbsp;virtue of&nbsp;its very&nbsp;dense,&nbsp;memory-like structure.&nbsp;It&nbsp;does not&nbsp;match&nbsp;the transistor&nbsp;<br>
density&nbsp;of&nbsp;a block of SRAM&nbsp;since it has two read ports and fits on a datapath pitch&nbsp;<br>
that&nbsp;is optimized for more complex logic functions such&nbsp;as&nbsp;the ALU. However,&nbsp;it&nbsp;is&nbsp;<br>
much denser than those logic functions&nbsp;due to&nbsp;its&nbsp;higher regularity.&nbsp;<br>
Datapath layout&nbsp;<br>
The ARM datapath is laid out to a constant pitch per bit. The pitch will be a com-<br>
promise between the optimum&nbsp;for the complex functions&nbsp;(such&nbsp;as&nbsp;the ALU) which&nbsp;<br>
are best&nbsp;suited&nbsp;to a wide pitch and the simple functions&nbsp;(such as the barrel shifter)&nbsp;<br>
which are most&nbsp;efficient when laid&nbsp;out&nbsp;on&nbsp;a&nbsp;narrow&nbsp;pitch.&nbsp;<br>
Each&nbsp;function&nbsp;is then&nbsp;laid out to this&nbsp;pitch,&nbsp;remembering&nbsp;that there&nbsp;may also be&nbsp;<br>
buses passing over&nbsp;a function&nbsp;(for&nbsp;example the B&nbsp;bus passes&nbsp;through the ALU&nbsp;but&nbsp;is&nbsp;<br>
not&nbsp;used&nbsp;by&nbsp;it); space must be&nbsp;allowed for these.&nbsp;It&nbsp;is a&nbsp;good&nbsp;idea&nbsp;to&nbsp;produce&nbsp;a&nbsp;<br>
floor-plan for the&nbsp;datapath&nbsp;noting&nbsp;the 'passenger'&nbsp;buses&nbsp;through&nbsp;each&nbsp;block,&nbsp;as&nbsp;<br>
illustrated&nbsp;in&nbsp;Figure 4.20. The order&nbsp;of&nbsp;the function blocks is&nbsp;chosen to&nbsp;minimize the&nbsp;<br>
number&nbsp;of&nbsp;additional&nbsp;buses passing over&nbsp;the more&nbsp;complex functions.&nbsp;<br>
&nbsp;<br>
<b>Figure 4.20&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM core datapath buses.&nbsp;<br>
<hr>
<A name=111></a><IMG src="index-111_1.png"><br>
<b>ARM&nbsp;implementation</b>&nbsp;<br>
<b>99</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Modern CMOS processes allow&nbsp;wiring in&nbsp;several&nbsp;metal layers (the early ARM&nbsp;<br>
cores used&nbsp;two&nbsp;metal layers). The wiring&nbsp;layers used for&nbsp;power and&nbsp;ground,&nbsp;bus signals&nbsp;<br>
along the datapath&nbsp;and control&nbsp;signals&nbsp;across the&nbsp;datapath&nbsp;must be chosen carefully&nbsp;<br>
(for example&nbsp;on ARM2&nbsp;<i>Vdd&nbsp;</i>and&nbsp;<i>Vss&nbsp;</i>run along both&nbsp;sides of&nbsp;the&nbsp;datapath&nbsp;in metal 2,&nbsp;<br>
control&nbsp;wires pass across the datapath&nbsp;in&nbsp;metal 1&nbsp;and buses&nbsp;run&nbsp;along it&nbsp;in&nbsp;metal 2).&nbsp;<br>
Control&nbsp;<br>
The control&nbsp;logic on the&nbsp;simpler&nbsp;ARM cores has three&nbsp;structural&nbsp;components&nbsp;which&nbsp;<br>
structures&nbsp;<br>
relate&nbsp;to each other as shown&nbsp;in&nbsp;Figure&nbsp;4.21.&nbsp;<br>
1.&nbsp;&nbsp;An instruction&nbsp;decoder PLA&nbsp;(programmable&nbsp;logic array).&nbsp;This unit uses&nbsp;some&nbsp;of&nbsp;<br>
the instruction&nbsp;bits and&nbsp;an internal&nbsp;cycle&nbsp;counter&nbsp;to define the class of&nbsp;operation&nbsp;<br>
to be performed on the datapath in the next&nbsp;cycle.&nbsp;<br>
2.&nbsp;&nbsp;Distributed secondary&nbsp;control associated with each of the&nbsp;major datapath func&nbsp;<br>
tion blocks. This logic uses the class information from&nbsp;the&nbsp;main decoder PLA&nbsp;<br>
to select other&nbsp;instruction bits and/or processor state information to control the&nbsp;<br>
datapath.&nbsp;<br>
3.&nbsp;&nbsp;Decentralized&nbsp;control units for specific instructions that take a variable number&nbsp;<br>
of cycles to complete&nbsp;(load and store&nbsp;multiple,&nbsp;multiply&nbsp;and coprocessor&nbsp;opera&nbsp;<br>
tions). Here the main&nbsp;decoder PLA&nbsp;locks into&nbsp;a fixed state&nbsp;until&nbsp;the&nbsp;remote&nbsp;con&nbsp;<br>
trol unit indicates completion.&nbsp;<br>
The main&nbsp;decoder PLA&nbsp;has around&nbsp;14&nbsp;inputs,&nbsp;40&nbsp;product terms and 40 outputs, the&nbsp;<br>
precise&nbsp;number varying slightly&nbsp;between&nbsp;the&nbsp;different&nbsp;cores.&nbsp;On recent&nbsp;ARM cores&nbsp;it&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;4.21 &nbsp; &nbsp;</b>ARM control logic structure.&nbsp;<br>
<hr>
<A name=112></a><b>100&nbsp;</b><br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
is&nbsp;implemented as&nbsp;two PLAs:&nbsp;a small,&nbsp;fast&nbsp;PLA which generates&nbsp;the&nbsp;time&nbsp;critical&nbsp;out-<br>
puts&nbsp;and a&nbsp;larger, slower PLA which generates&nbsp;all&nbsp;the&nbsp;other outputs.&nbsp;Functionally,&nbsp;<br>
however, it&nbsp;can&nbsp;be&nbsp;viewed&nbsp;as a&nbsp;single PLA&nbsp;unit.&nbsp;<br>
The&nbsp;'cycle count'&nbsp;block distinguishes the&nbsp;different cycles of&nbsp;multi-cycle instruc-<br>
tions&nbsp;so&nbsp;that&nbsp;the decode&nbsp;PLA can generate&nbsp;different control&nbsp;outputs&nbsp;for each cycle.&nbsp;It&nbsp;<br>
is,&nbsp;in&nbsp;fact, not&nbsp;simply&nbsp;a counter but a&nbsp;more&nbsp;general&nbsp;finite state&nbsp;machine&nbsp;capable&nbsp;of&nbsp;<br>
skipping unneeded cycles and of locking&nbsp;into a fixed state. It determines&nbsp;when the&nbsp;<br>
current&nbsp;instruction is about&nbsp;to&nbsp;complete&nbsp;and initiates&nbsp;the transfer of the&nbsp;next instruc-<br>
tion from&nbsp;the instruction pipeline, including&nbsp;aborting instructions&nbsp;at the&nbsp;end of their&nbsp;<br>
first cycle if&nbsp;they&nbsp;fail&nbsp;their condition&nbsp;test. However, much&nbsp;of&nbsp;the time&nbsp;its&nbsp;behaviour&nbsp;is&nbsp;<br>
like that of a simple counter&nbsp;so it is not&nbsp;<i>too&nbsp;</i>misleading to&nbsp;think of it&nbsp;as&nbsp;an instruc-<br>
tion&nbsp;cycle counter.&nbsp;<br>
Physical design&nbsp;<br>
So far&nbsp;we have been concerned principally&nbsp;with the logic design of an ARM core&nbsp;<br>
and said&nbsp;little about its physical implementation on a particular&nbsp;CMOS process.&nbsp;<br>
There are two&nbsp;principal mechanisms&nbsp;used&nbsp;to&nbsp;implement an&nbsp;ARM processor core (or&nbsp;<br>
any&nbsp;other core,&nbsp;for than matter)&nbsp;on&nbsp;a particular&nbsp;process:&nbsp;<br>
•&nbsp;&nbsp;a hard&nbsp;macrocell is delivered&nbsp;as physical&nbsp;layout&nbsp;ready to be&nbsp;incorporated&nbsp;into the&nbsp;<br>
final design;&nbsp;<br>
•&nbsp;&nbsp;a soft&nbsp;macrocell is delivered&nbsp;as a synthesizable design expressed in a hardware&nbsp;<br>
description language&nbsp;such as&nbsp;VHDL.&nbsp;<br>
A hard macrocell can&nbsp;be&nbsp;fully characterized&nbsp;on&nbsp;the target process and&nbsp;can&nbsp;exploit&nbsp;<br>
the area advantages of&nbsp;full-custom&nbsp;hand-tuned&nbsp;layout, but it&nbsp;can be&nbsp;used only on&nbsp;the&nbsp;<br>
particular&nbsp;process for which&nbsp;it&nbsp;has been&nbsp;designed. The&nbsp;layout&nbsp;must be&nbsp;modified&nbsp;and&nbsp;<br>
recharacterized for every&nbsp;new&nbsp;process.&nbsp;A soft&nbsp;macrocell can readily&nbsp;be&nbsp;ported to&nbsp;a&nbsp;new&nbsp;<br>
process&nbsp;technology,&nbsp;but after&nbsp;each&nbsp;process&nbsp;change&nbsp;it&nbsp;must&nbsp;still&nbsp;be&nbsp;recharacterized.&nbsp;<br>
Early&nbsp;ARM&nbsp;cores were&nbsp;delivered&nbsp;only&nbsp;as&nbsp;hard&nbsp;macrocells.&nbsp;Their&nbsp;design&nbsp;was&nbsp;based&nbsp;<br>
upon full-custom&nbsp;datapaths,&nbsp;with&nbsp;control logic designed&nbsp;at the logic schematic level&nbsp;<br>
and converted&nbsp;to layout&nbsp;using automatic&nbsp;place and&nbsp;route&nbsp;tools&nbsp;and a&nbsp;standard&nbsp;cell&nbsp;<br>
library. To ease process&nbsp;portability&nbsp;the cores&nbsp;were designed&nbsp;using generic&nbsp;design rules&nbsp;<br>
(for both&nbsp;the&nbsp;cell&nbsp;library and&nbsp;the&nbsp;full-custom&nbsp;datapath)&nbsp;that&nbsp;allowed&nbsp;geometrical&nbsp;trans-<br>
formations of&nbsp;the same&nbsp;physical layout to&nbsp;be&nbsp;used to&nbsp;map&nbsp;the same&nbsp;physical layout&nbsp;<br>
onto&nbsp;a&nbsp;range&nbsp;of&nbsp;individual&nbsp;processes with&nbsp;similar but&nbsp;not&nbsp;identical&nbsp;design&nbsp;rules.&nbsp;<br>
Recent ARM cores have&nbsp;been available in&nbsp;both&nbsp;hard and soft forms. The&nbsp;hard&nbsp;mac-<br>
rocells increasingly use&nbsp;synthesis for their control&nbsp;logic&nbsp;while&nbsp;retaining&nbsp;hand-drawn&nbsp;<br>
full-custom&nbsp;datapaths. The soft&nbsp;macrocells&nbsp;are fully&nbsp;synthesizable&nbsp;from&nbsp;a&nbsp;register&nbsp;<br>
transfer level (RTL) description.&nbsp;<br>
Some&nbsp;ARM partners have adopted a&nbsp;middle course, using a&nbsp;gate-level netlist&nbsp;<br>
description of an&nbsp;ARM core&nbsp;as their basis&nbsp;for&nbsp;porting&nbsp;to&nbsp;new&nbsp;processes. The porting&nbsp;<br>
procedure&nbsp;no&nbsp;longer involves resynthesis,&nbsp;but simply&nbsp;mapping&nbsp;the&nbsp;same&nbsp;netlist&nbsp;<br>
(using&nbsp;automatic place and&nbsp;route tools) onto&nbsp;a&nbsp;standard cell library&nbsp;implemented&nbsp;on&nbsp;<br>
the&nbsp;new&nbsp;process.&nbsp;<br>
<hr>
<A name=113></a><b>The&nbsp;ARM coprocessor interface</b>&nbsp;<br>
101&nbsp;<br>
The choice&nbsp;between&nbsp;hard and soft macrocells (or&nbsp;gate-level netlists) is&nbsp;a&nbsp;complex&nbsp;<br>
decision.&nbsp;Hard&nbsp;macrocells&nbsp;can&nbsp;clearly&nbsp;give&nbsp;the&nbsp;best&nbsp;area,&nbsp;performance&nbsp;and&nbsp;<br>
power-efficiency on&nbsp;a process, but it takes&nbsp;significant time, effort&nbsp;and cost&nbsp;to port&nbsp;<br>
them&nbsp;to&nbsp;each process.&nbsp;Soft&nbsp;macrocells and&nbsp;portable&nbsp;netlists&nbsp;are&nbsp;more&nbsp;flexible,&nbsp;and&nbsp;<br>
automated&nbsp;tools are&nbsp;now&nbsp;of&nbsp;a&nbsp;quality&nbsp;that&nbsp;means&nbsp;that&nbsp;they&nbsp;come&nbsp;close&nbsp;to&nbsp;hand&nbsp;layout&nbsp;<br>
in&nbsp;performance. The&nbsp;portablility of the soft&nbsp;macrocell may&nbsp;mean that the choice&nbsp;is&nbsp;<br>
between&nbsp;a&nbsp;soft&nbsp;macrocell on&nbsp;the&nbsp;latest&nbsp;process or a&nbsp;hard&nbsp;macrocell on&nbsp;an&nbsp;older&nbsp;process,&nbsp;<br>
and&nbsp;the&nbsp;process technology&nbsp;advantage could&nbsp;easily&nbsp;outweigh&nbsp;the&nbsp;slight&nbsp;loss of&nbsp;<br>
optimization.&nbsp;<br>
4.5 &nbsp; The&nbsp;ARM&nbsp;coprocessor&nbsp;interface&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The&nbsp;ARM&nbsp;supports a general-purpose extension&nbsp;of&nbsp;its instruction set through&nbsp;the&nbsp;<br>
addition of hardware coprocessors, and it&nbsp;also supports the software emulation of&nbsp;<br>
these&nbsp;coprocessors through the undefined instruction trap.&nbsp;<br>
Coprocessor&nbsp;<br>
The coprocessor architecture is described in&nbsp;Section 5.16 on page 136. Its&nbsp;most&nbsp;<br>
architecture&nbsp;<br>
important&nbsp;features&nbsp;are:&nbsp;<br>
•&nbsp;&nbsp;Support&nbsp;for up&nbsp;to 16 logical coprocessors.&nbsp;<br>
•&nbsp;&nbsp;Each coprocessor can have&nbsp;up&nbsp;to 16 private&nbsp;registers of any&nbsp;reasonable&nbsp;size; they&nbsp;<br>
are not limited&nbsp;to 32 bits.&nbsp;<br>
•&nbsp;&nbsp;Coprocessors&nbsp;use a load-store architecture,&nbsp;with instructions to perform&nbsp;internal&nbsp;<br>
operations on registers, instructions to load and save registers&nbsp;from&nbsp;and to&nbsp;<br>
memory, and&nbsp;instructions&nbsp;to&nbsp;move&nbsp;data to&nbsp;or from&nbsp;an&nbsp;ARM&nbsp;register.&nbsp;<br>
The simpler&nbsp;ARM cores offer the coprocessor interface at board level, so a co-<br>
processor&nbsp;may be introduced as&nbsp;a separate component.&nbsp;High clock&nbsp;speeds&nbsp;make&nbsp;<br>
board-level interfacing&nbsp;very difficult,&nbsp;so&nbsp;the&nbsp;higher-performance ARMs restrict&nbsp;the&nbsp;<br>
coprocessor interface to on-chip use, in&nbsp;particular&nbsp;for cache and&nbsp;memory&nbsp;manage-<br>
ment control&nbsp;functions, but other on-chip&nbsp;coprocessors&nbsp;may&nbsp;also be&nbsp;supported.&nbsp;<br>
ARM7TDMI&nbsp;<br>
The ARM7TDMI coprocessor interface is&nbsp;based&nbsp;on 'bus watching'&nbsp;(other ARM&nbsp;<br>
coprocessor&nbsp;<br>
cores use&nbsp;different techniques). The coprocessor is&nbsp;attached&nbsp;to&nbsp;a&nbsp;bus where the ARM&nbsp;<br>
interface&nbsp;<br>
instruction&nbsp;stream&nbsp;flows&nbsp;into the ARM,&nbsp;and&nbsp;the&nbsp;coprocessor&nbsp;copies the&nbsp;instructions&nbsp;<br>
into an&nbsp;internal&nbsp;pipeline that mimics&nbsp;the&nbsp;behaviour&nbsp;of&nbsp;the&nbsp;ARM instruction&nbsp;pipeline.&nbsp;<br>
As&nbsp;each&nbsp;coprocessor instruction&nbsp;begins&nbsp;execution&nbsp;there is&nbsp;a&nbsp;'hand-shake'&nbsp;between the&nbsp;<br>
ARM&nbsp;and&nbsp;the coprocessor&nbsp;to&nbsp;confirm&nbsp;that&nbsp;they&nbsp;are both ready to&nbsp;execute&nbsp;it.&nbsp;The&nbsp;<br>
handshake&nbsp;uses&nbsp;three signals:&nbsp;<br>
1. &nbsp;<i>cpi&nbsp;</i>(from ARM to&nbsp;all&nbsp;coprocessors).&nbsp;<br>
This signal, which stands for&nbsp;'Coprocessor&nbsp;Instruction', indicates that the ARM&nbsp;<br>
has identified&nbsp;a coprocessor instruction and&nbsp;wishes to execute it.&nbsp;<br>
<hr>
<A name=114></a><b>102</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
2.&nbsp;&nbsp;<i>cpa&nbsp;</i>(from&nbsp;the&nbsp;coprocessors to ARM).&nbsp;<br>
This&nbsp;is&nbsp;the 'Coprocessor Absent'&nbsp;signal&nbsp;which&nbsp;tells&nbsp;the&nbsp;ARM&nbsp;that&nbsp;there&nbsp;is&nbsp;no&nbsp;<br>
coprocessor present&nbsp;that is&nbsp;able to execute the current instruction.&nbsp;<br>
3.&nbsp;&nbsp;<i>cpb&nbsp;</i>(from&nbsp;the&nbsp;coprocessors to ARM).&nbsp;<br>
This is the&nbsp;'CoProcessor Busy'&nbsp;signal&nbsp;which tells the ARM that the coprocessor&nbsp;<br>
cannot begin&nbsp;executing&nbsp;the&nbsp;instruction&nbsp;yet.&nbsp;<br>
The timing is such that both the ARM and the coprocessor&nbsp;must generate their&nbsp;<br>
respective signals&nbsp;autonomously.&nbsp;The&nbsp;coprocessor cannot&nbsp;wait&nbsp;until&nbsp;it&nbsp;sees&nbsp;<i>cpi&nbsp;</i><br>
before generating&nbsp;<i>cpa&nbsp;</i>and&nbsp;<i>cpb.</i>&nbsp;<br>
Handshake&nbsp;<br>
Once a&nbsp;coprocessor instruction has entered the&nbsp;ARM7TDMI&nbsp;and coprocessor pipe-<br>
outcomes&nbsp;<br>
lines, there are four possible&nbsp;ways&nbsp;it&nbsp;may&nbsp;be&nbsp;handled&nbsp;depending on&nbsp;the&nbsp;handshake&nbsp;<br>
signals:&nbsp;<br>
1.&nbsp;&nbsp;The ARM&nbsp;may decide not to&nbsp;execute it,&nbsp;either because it falls in a&nbsp;branch&nbsp;<br>
shadow&nbsp;or&nbsp;because it&nbsp;fails its condition&nbsp;code&nbsp;test. (All ARM&nbsp;instructions are con&nbsp;<br>
ditionally&nbsp;executed, including coprocessor instructions.) ARM will not assert&nbsp;<br>
<i>cpi,&nbsp;</i>and the instruction&nbsp;will be&nbsp;discarded by&nbsp;all parties.&nbsp;<br>
2.&nbsp;&nbsp;The&nbsp;ARM may&nbsp;decide&nbsp;to&nbsp;execute&nbsp;it (and&nbsp;signal&nbsp;this&nbsp;by&nbsp;asserting&nbsp;<i>cpi),&nbsp;</i>but no&nbsp;<br>
present coprocessor can take&nbsp;it&nbsp;so&nbsp;<i>cpa&nbsp;</i>stays active. ARM will&nbsp;take&nbsp;the&nbsp;unde&nbsp;<br>
fined instruction trap and&nbsp;use&nbsp;software&nbsp;to&nbsp;recover,&nbsp;possibly&nbsp;by emulating the&nbsp;<br>
trapped instruction.&nbsp;<br>
3.&nbsp;&nbsp;ARM decides&nbsp;to execute&nbsp;the&nbsp;instruction&nbsp;and&nbsp;a coprocessor&nbsp;accepts&nbsp;it, but&nbsp;cannot&nbsp;<br>
execute it&nbsp;yet.&nbsp;The&nbsp;coprocessor takes&nbsp;<i>cpa&nbsp;</i>low but leaves&nbsp;<i>cpb&nbsp;</i>high.&nbsp;The&nbsp;ARM&nbsp;will&nbsp;<br>
'busy-wait'&nbsp;until the coprocessor takes&nbsp;<i>cpb&nbsp;</i>low,&nbsp;stalling the instruction stream&nbsp;at&nbsp;<br>
this point. If an enabled interrupt request arrives&nbsp;while the coprocessor is busy,&nbsp;<br>
ARM&nbsp;will break off to&nbsp;handle&nbsp;the interrupt, probably&nbsp;returning to&nbsp;retry the&nbsp;<br>
coprocessor instruction&nbsp;later.&nbsp;<br>
4.&nbsp;&nbsp;ARM decides to&nbsp;execute the&nbsp;instruction and a&nbsp;coprocessor accepts it&nbsp;for immedi&nbsp;<br>
ate execution,&nbsp;<i>cpi, cpa&nbsp;</i>and&nbsp;<i>cpb&nbsp;</i>are all&nbsp;taken&nbsp;low and&nbsp;both&nbsp;sides commit to&nbsp;com&nbsp;<br>
plete the&nbsp;instruction.&nbsp;<br>
Data transfers&nbsp;<br>
If the instruction is a coprocessor data transfer instruction the ARM is responsible&nbsp;<br>
for generating an&nbsp;initial&nbsp;memory&nbsp;address&nbsp;(the coprocessor&nbsp;does not require any&nbsp;con-<br>
nection&nbsp;to&nbsp;the address bus)&nbsp;but&nbsp;the&nbsp;coprocessor determines&nbsp;the&nbsp;length&nbsp;of&nbsp;the transfer;&nbsp;<br>
ARM&nbsp;will continue incrementing the address until the coprocessor&nbsp;signals&nbsp;comple-<br>
tion. The&nbsp;<i>cpa&nbsp;</i>and&nbsp;<i>cpb&nbsp;</i>handshake signals are also used&nbsp;for this purpose.&nbsp;<br>
Since&nbsp;the&nbsp;data&nbsp;transfer&nbsp;is&nbsp;not&nbsp;interruptible&nbsp;once&nbsp;it&nbsp;has started,&nbsp;coprocessors&nbsp;<br>
should&nbsp;limit the maximum&nbsp;transfer length to&nbsp;16 words&nbsp;(the same&nbsp;as&nbsp;a&nbsp;maximum&nbsp;<br>
length&nbsp;load&nbsp;or store&nbsp;multiple instruction)&nbsp;so as&nbsp;not&nbsp;to&nbsp;compromise the ARM's&nbsp;<br>
interrupt&nbsp;response.&nbsp;<br>
<hr>
<A name=115></a><IMG src="index-115_1.png"><br>
<b>Examples and exercises</b>&nbsp;<br>
<b>103</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Pre-emptive&nbsp;<br>
A coprocessor&nbsp;may begin executing an instruction as&nbsp;soon&nbsp;as it&nbsp;enters its&nbsp;pipeline&nbsp;so&nbsp;long&nbsp;<br>
execution&nbsp;<br>
as&nbsp;it&nbsp;can&nbsp;recover&nbsp;its state&nbsp;if&nbsp;the handshake does not ultimately complete. All activity&nbsp;must&nbsp;<br>
be id&nbsp;em&nbsp;potent&nbsp;(repeatable with identical results) up&nbsp;to&nbsp;the point&nbsp;of commitment.&nbsp;<br>
4.6 &nbsp; Examples&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example 4.1</b>&nbsp;<br>
<b>Why&nbsp;does r15 give&nbsp;pc + 8 in the first cycle of an instruction and pc + 12&nbsp;</b><br>
<b>in subsequent cycles on&nbsp;an ARM7?</b>&nbsp;<br>
This&nbsp;is&nbsp;the ARM&nbsp;pipeline&nbsp;being exposed&nbsp;to&nbsp;the programmer. Referring back to&nbsp;<br>
Figure&nbsp;4.2&nbsp;on&nbsp;page&nbsp;77,&nbsp;we can see that&nbsp;the&nbsp;pc value&nbsp;was incremented once when the&nbsp;<br>
current&nbsp;instruction ('&nbsp;1'&nbsp;in&nbsp;the&nbsp;figure&nbsp;below)&nbsp;was&nbsp;fetched and&nbsp;once&nbsp;when&nbsp;its successor&nbsp;<br>
('2') was fetched,&nbsp;giving&nbsp;pc +&nbsp;8 at&nbsp;the start&nbsp;of&nbsp;the&nbsp;first&nbsp;execute cycle. During&nbsp;the&nbsp;first&nbsp;<br>
execute cycle&nbsp;a third instruction&nbsp;('3') is&nbsp;fetched,&nbsp;giving&nbsp;pc +&nbsp;12 in&nbsp;all&nbsp;subsequent&nbsp;<br>
execute cycles.&nbsp;<br>
While multi-cycle instructions&nbsp;interrupt&nbsp;the pipeline&nbsp;flow they do&nbsp;not&nbsp;affect this&nbsp;<br>
aspect&nbsp;of the&nbsp;behaviour.&nbsp;An&nbsp;instruction&nbsp;always&nbsp;fetches the next-instruction-but-one&nbsp;<br>
during&nbsp;its&nbsp;first&nbsp;execute cycle, so r15 always&nbsp;progresses from&nbsp;pc +&nbsp;8 at&nbsp;the start&nbsp;of&nbsp;the&nbsp;first&nbsp;<br>
execute cycle to&nbsp;pc&nbsp;+&nbsp;12&nbsp;at the&nbsp;start&nbsp;of&nbsp;the&nbsp;second&nbsp;(and subsequent) execute cycle(s).&nbsp;<br>
(Note that&nbsp;other ARM&nbsp;processors do&nbsp;not&nbsp;share this&nbsp;behaviour, so it&nbsp;should never be&nbsp;<br>
relied upon when writing&nbsp;ARM&nbsp;programs.)&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Exercise&nbsp;4.1.1</b>&nbsp;<br>
Draw a pipeline flow diagram&nbsp;along the&nbsp;lines of the one above to&nbsp;illustrate&nbsp;the&nbsp;<br>
timing&nbsp;of an&nbsp;ARM&nbsp;branch instruction.&nbsp;(The&nbsp;branch&nbsp;target is computed&nbsp;in the&nbsp;first&nbsp;<br>
execute&nbsp;cycle&nbsp;of the instruction and issued&nbsp;to&nbsp;memory in the&nbsp;following&nbsp;cycle.)&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Exercise 4.1.2</b>&nbsp;<br>
How many execute cycles are&nbsp;there after the&nbsp;branch&nbsp;target&nbsp;calculation and&nbsp;before&nbsp;the&nbsp;<br>
instruction&nbsp;at&nbsp;the&nbsp;branch&nbsp;target&nbsp;is&nbsp;ready&nbsp;to&nbsp;execute?&nbsp;What&nbsp;does&nbsp;the&nbsp;processor&nbsp;use&nbsp;<br>
these execute cycles for?&nbsp;<br>
<hr>
<A name=116></a><b>104</b>&nbsp;<br>
<b>ARM&nbsp;Organization and Implementation</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<b>Example 4.2</b>&nbsp;<br>
<b>Complete the ARM2&nbsp;4-bit carry&nbsp;logic&nbsp;circuit outlined in Figures&nbsp;4.1 1&nbsp;and&nbsp;</b><br>
<b>4. 12 on page&nbsp;89.</b>&nbsp;<br>
The&nbsp;4-bit&nbsp;carry&nbsp;look-ahead&nbsp;scheme&nbsp;uses&nbsp;the individual bit carry&nbsp;generate and&nbsp;propa-<br>
gate&nbsp;signals produced by&nbsp;the&nbsp;logic&nbsp;shown in&nbsp;Figure 4.12.&nbsp;Denoting&nbsp;these by&nbsp;G[3:0]&nbsp;<br>
and P[3:0],&nbsp;the carry-out&nbsp;from&nbsp;the&nbsp;top bit of&nbsp;a 4-bit group&nbsp;is given&nbsp;by:&nbsp;<br>
Cout = G[3]&nbsp;+&nbsp;P[3].(G[2]&nbsp;+ P[2].(G[1]&nbsp;+ P[1].(G[0]&nbsp;+ P[0].Cin)))&nbsp;<br>
Therefore the group generate and propagate signals,&nbsp;G4 and P4, as used in&nbsp;<br>
Figure 4. 1 1 are given by:&nbsp;<br>
G4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;G[3]&nbsp;+&nbsp;P[3].(G[2] + P[2].(G[1] +&nbsp;P[1].G[0]))&nbsp;<br>
P4 &nbsp; &nbsp;=P[3].P[2].P[1].P[0]&nbsp;<br>
These&nbsp;two signals are independent of the carry-in signal and&nbsp;therefore&nbsp;can be&nbsp;set up&nbsp;<br>
ready for its arrival,&nbsp;allowing&nbsp;the carry&nbsp;to&nbsp;propagate across&nbsp;the 4-bit group&nbsp;in&nbsp;just&nbsp;one&nbsp;<br>
AND-OR-INVERT gate delay.&nbsp;<br>
<b>Exercise 4.2.1</b>&nbsp;<br>
Write a logic&nbsp;expression&nbsp;for&nbsp;one&nbsp;bit of the ALU&nbsp;output&nbsp;generated by&nbsp;the&nbsp;circuit&nbsp;<br>
shown&nbsp;in&nbsp;Figure 4.12&nbsp;in&nbsp;terms of&nbsp;the inputs and&nbsp;the function&nbsp;select lines, and&nbsp;hence&nbsp;<br>
show&nbsp;how&nbsp;all&nbsp;the&nbsp;ALU functions&nbsp;listed&nbsp;in&nbsp;Table&nbsp;4.&nbsp;1&nbsp;on&nbsp;page&nbsp;90&nbsp;are&nbsp;generated.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Exercise&nbsp;4.2.2</b>&nbsp;<br>
Estimate&nbsp;the&nbsp;gate&nbsp;count for&nbsp;the ripple-carry adder and&nbsp;for&nbsp;the 4-bit&nbsp;carry&nbsp;look-ahead&nbsp;<br>
adder, basing&nbsp;both designs on&nbsp;the&nbsp;circuit in&nbsp;Figure 4.12&nbsp;and varying only the&nbsp;carry&nbsp;<br>
scheme.&nbsp;<br>
How&nbsp;much does the extra speed of the carry&nbsp;look-ahead scheme&nbsp;cost in&nbsp;terms of&nbsp;<br>
gate&nbsp;count?&nbsp;How does&nbsp;it&nbsp;affect&nbsp;the regularity,&nbsp;and hence the design&nbsp;cost, of the adder?&nbsp;<br>
<hr>
<A name=117></a><IMG src="index-117_1.png"><br>
The ARM Instruction Set&nbsp;<br>
&nbsp;<br>
Summary of chapter contents&nbsp;<br>
In&nbsp;Chapter 3 we&nbsp;looked&nbsp;at user-level ARM&nbsp;assembly&nbsp;language programming and&nbsp;<br>
got&nbsp;the&nbsp;general&nbsp;flavour of&nbsp;the&nbsp;ARM instruction&nbsp;set. In&nbsp;this&nbsp;chapter&nbsp;we&nbsp;will&nbsp;look in&nbsp;<br>
finer detail&nbsp;at&nbsp;the instruction&nbsp;set to&nbsp;see&nbsp;the&nbsp;full range&nbsp;of&nbsp;instructions&nbsp;that are&nbsp;availa-<br>
ble in the standard ARM instruction set.&nbsp;<br>
Some&nbsp;ARM cores&nbsp;will&nbsp;also&nbsp;execute a compressed&nbsp;form&nbsp;of the instruction set&nbsp;<br>
where a&nbsp;subset of&nbsp;the&nbsp;full&nbsp;ARM instruction&nbsp;set is&nbsp;encoded into&nbsp;16-bit&nbsp;instructions.&nbsp;<br>
These instructions&nbsp;are&nbsp;Thumb' instructions, and&nbsp;are&nbsp;discussed&nbsp;in&nbsp;Chapter 7.&nbsp;The&nbsp;<br>
only&nbsp;aspects of&nbsp;the&nbsp;Thumb&nbsp;architecture&nbsp;we&nbsp;will&nbsp;see&nbsp;in&nbsp;this&nbsp;chapter are&nbsp;the&nbsp;instruc-<br>
tions available&nbsp;in&nbsp;the&nbsp;ARM instruction&nbsp;set&nbsp;which cause&nbsp;the processor&nbsp;to switch&nbsp;to&nbsp;<br>
executing&nbsp;Thumb&nbsp;instructions. Likewise,&nbsp;some&nbsp;ARM cores&nbsp;support instruction&nbsp;set&nbsp;<br>
extensions to&nbsp;enhance&nbsp;their signal&nbsp;processing capabilities,&nbsp;discussion&nbsp;of&nbsp;which&nbsp;is&nbsp;<br>
deferred to Section 8.9 on page 239.&nbsp;<br>
As&nbsp;with any&nbsp;processor's full&nbsp;instruction&nbsp;set,&nbsp;the ARM&nbsp;instruction set has&nbsp;corners&nbsp;<br>
which conceal complex behaviour. Often&nbsp;these corners are not at all useful to pro-<br>
grammers, in&nbsp;which case ARM Limited does&nbsp;not define the behaviour of&nbsp;the proces-<br>
sor in the corner cases and the corresponding instructions should not be used.&nbsp;The&nbsp;<br>
fact&nbsp;that a&nbsp;particular implementation of&nbsp;the ARM behaves&nbsp;in&nbsp;a&nbsp;particular&nbsp;way&nbsp;in&nbsp;such&nbsp;a&nbsp;<br>
case&nbsp;should&nbsp;not be&nbsp;taken&nbsp;as&nbsp;meaning&nbsp;that future&nbsp;implementations&nbsp;will behave the&nbsp;<br>
same&nbsp;way. Programs should&nbsp;only use instructions&nbsp;with defined semantics!&nbsp;<br>
Some ARM instructions&nbsp;are&nbsp;not available&nbsp;on all ARM chips;&nbsp;these&nbsp;will&nbsp;be high-<br>
lighted&nbsp;as they&nbsp;arise.&nbsp;<br>
<b>105</b>&nbsp;<br>
<hr>
<A name=118></a><b>106</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
5.1 &nbsp; Introduction&nbsp;<br>
The ARM programmers'&nbsp;model was introduced in Figure 2.1 on page&nbsp;39. In this&nbsp;<br>
chapter&nbsp;we&nbsp;will consider&nbsp;the&nbsp;supervisor&nbsp;and exception&nbsp;modes,&nbsp;so&nbsp;now&nbsp;the&nbsp;shaded&nbsp;<br>
registers will&nbsp;also come&nbsp;into&nbsp;play.&nbsp;<br>
Data types&nbsp;<br>
ARM&nbsp;processors support six&nbsp;data types:&nbsp;<br>
•&nbsp;&nbsp;8-bit&nbsp;signed&nbsp;and unsigned&nbsp;bytes.&nbsp;<br>
•&nbsp;&nbsp;16-bit&nbsp;signed&nbsp;and&nbsp;unsigned&nbsp;half-words;&nbsp;these are aligned&nbsp;on 2-byte&nbsp;boundaries.&nbsp;<br>
•&nbsp;&nbsp;32-bit&nbsp;signed&nbsp;and unsigned&nbsp;words; these are&nbsp;aligned on 4-byte boundaries.&nbsp;<br>
(Some older ARM processors do&nbsp;not&nbsp;have&nbsp;half-word and signed&nbsp;byte support.)&nbsp;<br>
ARM instructions&nbsp;are all&nbsp;32-bit words and&nbsp;must&nbsp;be&nbsp;word-aligned.&nbsp;Thumb instruc-<br>
tions&nbsp;are half-words&nbsp;and&nbsp;must be aligned&nbsp;on&nbsp;2-byte&nbsp;boundaries.&nbsp;<br>
Internally&nbsp;all ARM operations are on 32-bit operands; the shorter data types are&nbsp;<br>
only&nbsp;supported by&nbsp;data transfer instructions. When a byte is loaded&nbsp;from&nbsp;memory&nbsp;<br>
it is zero- or sign-extended to&nbsp;32 bits and&nbsp;then treated as a 32-bit value&nbsp;for internal&nbsp;<br>
processing.&nbsp;<br>
ARM coprocessors&nbsp;may&nbsp;support other data&nbsp;types, and in&nbsp;particular there is a&nbsp;<br>
defined&nbsp;set&nbsp;of&nbsp;types&nbsp;to&nbsp;represent&nbsp;floating-point&nbsp;values.&nbsp;There is&nbsp;no&nbsp;explicit&nbsp;support for&nbsp;<br>
these&nbsp;types&nbsp;within&nbsp;the ARM&nbsp;core,&nbsp;however, and&nbsp;in&nbsp;the&nbsp;absence&nbsp;of&nbsp;a floating-point&nbsp;<br>
coprocessor these types are interpreted&nbsp;by&nbsp;software&nbsp;which uses the standard types&nbsp;<br>
listed above.&nbsp;<br>
Memory&nbsp;<br>
There are two ways&nbsp;to store words in a&nbsp;byte-addressed&nbsp;memory, depending&nbsp;on&nbsp;<br>
organization&nbsp;<br>
whether the&nbsp;least&nbsp;significant byte&nbsp;is stored&nbsp;at&nbsp;a&nbsp;lower or&nbsp;higher&nbsp;address than the next&nbsp;<br>
most&nbsp;significant byte.&nbsp;Since there is no&nbsp;good&nbsp;reason&nbsp;for choosing&nbsp;one&nbsp;approach&nbsp;over&nbsp;<br>
the other the&nbsp;argument&nbsp;as to&nbsp;which&nbsp;is better is&nbsp;more&nbsp;a&nbsp;matter&nbsp;of&nbsp;religion&nbsp;than&nbsp;reason.&nbsp;<br>
The&nbsp;two schemes are illustrated in Figure&nbsp;5.1&nbsp;on page 107, which shows&nbsp;how&nbsp;an&nbsp;<br>
assortment of&nbsp;data types&nbsp;would be&nbsp;stored&nbsp;under&nbsp;the&nbsp;two schemes. ('half-word!2'&nbsp;is&nbsp;<br>
found&nbsp;at&nbsp;address 12,&nbsp;and so&nbsp;on.)&nbsp;<br>
The&nbsp;'little-endian'&nbsp;and&nbsp;'big-endian' terminology&nbsp;which&nbsp;is used&nbsp;to&nbsp;denote&nbsp;the two&nbsp;<br>
approaches&nbsp;is&nbsp;derived from&nbsp;Swift's&nbsp;<i>Gulliver&nbsp;s&nbsp;Travels.&nbsp;</i>The inhabitants&nbsp;of&nbsp;Lilliput,&nbsp;who&nbsp;<br>
are&nbsp;well known for being&nbsp;rather&nbsp;small&nbsp;are,&nbsp;in addition,&nbsp;constrained&nbsp;by&nbsp;law to&nbsp;break&nbsp;<br>
their eggs&nbsp;only at the little end.&nbsp;When&nbsp;this&nbsp;law is&nbsp;imposed, those&nbsp;of&nbsp;their fellow citizens&nbsp;<br>
who&nbsp;prefer to break their&nbsp;eggs at&nbsp;the&nbsp;big end take exception to&nbsp;the&nbsp;new rule&nbsp;and civil&nbsp;<br>
war breaks out.&nbsp;The&nbsp;big-endians eventually&nbsp;take refuge&nbsp;on&nbsp;a&nbsp;nearby&nbsp;island,&nbsp;which is the&nbsp;<br>
kingdom&nbsp;of Blefuscu. The civil&nbsp;war results&nbsp;in&nbsp;many casualties.&nbsp;<br>
The application of the&nbsp;'big-endian'&nbsp;and&nbsp;'little-endian'&nbsp;terms&nbsp;to the&nbsp;two&nbsp;ways to&nbsp;<br>
organize&nbsp;computer memory&nbsp;comes from&nbsp;'On Holy Wars&nbsp;and&nbsp;a Plea for&nbsp;Peace'&nbsp;by&nbsp;<br>
Danny&nbsp;Cohen&nbsp;in&nbsp;the&nbsp;October 1981&nbsp;issue&nbsp;<i>of Computer.</i>&nbsp;<br>
<hr>
<A name=119></a><IMG src="index-119_1.png"><br>
<b>Introduction</b>&nbsp;<br>
<b>107</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;5.1 &nbsp; &nbsp;</b>Little- and big-endian memory&nbsp;organizations.&nbsp;<br>
To&nbsp;my&nbsp;knowledge, no&nbsp;one has yet been&nbsp;mortally&nbsp;wounded in&nbsp;an argument over byte&nbsp;<br>
ordering.&nbsp;However the&nbsp;issue&nbsp;causes significant practical&nbsp;difficulties&nbsp;when&nbsp;datasets are&nbsp;<br>
transferred between&nbsp;machines&nbsp;of opposite&nbsp;orderings.&nbsp;<br>
Most&nbsp;ARM&nbsp;chips&nbsp;remain&nbsp;strictly&nbsp;neutral&nbsp;in&nbsp;the dispute and can be&nbsp;configured&nbsp;<br>
to work with&nbsp;either memory&nbsp;arrangement,&nbsp;though&nbsp;they&nbsp;default&nbsp;to&nbsp;little-endian.&nbsp;<br>
Throughout&nbsp;this&nbsp;book&nbsp;we&nbsp;will assume&nbsp;a little-endian&nbsp;ordering,&nbsp;where bytes&nbsp;of&nbsp;<br>
increasing&nbsp;significance&nbsp;are stored&nbsp;at&nbsp;increasing&nbsp;addresses in&nbsp;memory.&nbsp;ARM may&nbsp;<br>
be&nbsp;neutral,&nbsp;but&nbsp;I am&nbsp;not!&nbsp;<br>
Privileged&nbsp;<br>
Most programs&nbsp;operate in user&nbsp;mode&nbsp;as&nbsp;described&nbsp;in&nbsp;Chapter&nbsp;3.&nbsp;However,&nbsp;ARM&nbsp;has&nbsp;<br>
modes&nbsp;<br>
other&nbsp;<b>privileged&nbsp;</b>operating&nbsp;modes which&nbsp;are used&nbsp;to&nbsp;handle&nbsp;exceptions&nbsp;and&nbsp;supervi-<br>
sor calls (which&nbsp;are&nbsp;sometimes called&nbsp;<b>software interrupts).</b>&nbsp;<br>
The current&nbsp;operating mode is&nbsp;defined by&nbsp;the bottom&nbsp;five bits&nbsp;of&nbsp;the CPSR&nbsp;(see&nbsp;<br>
Figure&nbsp;2.2 on&nbsp;page&nbsp;40).&nbsp;The interpretation&nbsp;of these&nbsp;bits is summarized in&nbsp;Table&nbsp;5.1&nbsp;on&nbsp;<br>
page&nbsp;108. Where the register set&nbsp;is not&nbsp;the&nbsp;user registers,&nbsp;the&nbsp;relevant shaded&nbsp;registers&nbsp;<br>
shown&nbsp;in&nbsp;Figure 2.1 on&nbsp;page&nbsp;39&nbsp;replace the corresponding&nbsp;user&nbsp;registers and&nbsp;the&nbsp;cur-<br>
rent SPSR&nbsp;<b>(Saved Program Status&nbsp;Register;&nbsp;</b>see&nbsp;below) also becomes accessible.&nbsp;<br>
Some&nbsp;ARM processors&nbsp;do&nbsp;not&nbsp;support&nbsp;all&nbsp;of the above&nbsp;operating modes, and some&nbsp;<br>
also&nbsp;support '26-bit'&nbsp;modes for backwards&nbsp;compatibility&nbsp;with&nbsp;older ARMs;&nbsp;these will&nbsp;<br>
be&nbsp;discussed further in&nbsp;Section&nbsp;5.23&nbsp;on&nbsp;page&nbsp;147.&nbsp;<br>
The&nbsp;privileged&nbsp;modes can&nbsp;only&nbsp;be&nbsp;entered through controlled&nbsp;mechanisms;&nbsp;with&nbsp;<br>
suitable&nbsp;memory protection&nbsp;they&nbsp;allow a&nbsp;fully protected&nbsp;operating&nbsp;system&nbsp;to&nbsp;be&nbsp;built.&nbsp;<br>
This issue&nbsp;will&nbsp;be&nbsp;discussed further in&nbsp;Chapter 11.&nbsp;<br>
Most&nbsp;ARMs&nbsp;are used&nbsp;in&nbsp;embedded systems&nbsp;where such protection is&nbsp;inappropriate,&nbsp;<br>
but&nbsp;the privileged&nbsp;modes can still be&nbsp;used&nbsp;to&nbsp;give&nbsp;a&nbsp;weaker&nbsp;level of&nbsp;protection that&nbsp;is&nbsp;<br>
useful for&nbsp;trapping&nbsp;errant software.&nbsp;<br>
<hr>
<A name=120></a><IMG src="index-120_1.png"><br>
<b>108</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
<b>Table&nbsp;5.1 &nbsp; &nbsp;</b>ARM operating modes and register usage.&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The SPSRs&nbsp;<br>
Each&nbsp;privileged&nbsp;mode&nbsp;(except system&nbsp;mode) has&nbsp;associated&nbsp;with&nbsp;it a&nbsp;Saved&nbsp;Program&nbsp;<br>
Status&nbsp;Register, or SPSR. This register is used&nbsp;to save&nbsp;the state of the CPSR (Current Pro-<br>
gram&nbsp;Status&nbsp;Register) when the privileged&nbsp;mode is entered in&nbsp;order that the user state can&nbsp;<br>
be fully&nbsp;restored&nbsp;when the user process is resumed. Often the SPSR&nbsp;may&nbsp;be untouched&nbsp;<br>
from&nbsp;the time&nbsp;the privileged&nbsp;mode is entered to&nbsp;the time&nbsp;it&nbsp;is used to restore the CPSR, but&nbsp;<br>
if the privileged&nbsp;software&nbsp;is to&nbsp;be&nbsp;re-entrant (for example, if supervisor code&nbsp;makes super-<br>
visor calls&nbsp;to&nbsp;itself) then the SPSR&nbsp;must be&nbsp;copied into&nbsp;a general register and&nbsp;saved.&nbsp;<br>
&nbsp;&nbsp;&nbsp;5.2 &nbsp;&nbsp;<br>
Exceptions&nbsp;<br>
Exceptions are&nbsp;usually&nbsp;used to&nbsp;handle unexpected events&nbsp;which arise during&nbsp;the&nbsp;execu-<br>
tion&nbsp;of&nbsp;a&nbsp;program,&nbsp;such&nbsp;as&nbsp;interrupts&nbsp;or&nbsp;memory&nbsp;faults.&nbsp;In&nbsp;the&nbsp;ARM&nbsp;architecture the&nbsp;<br>
term&nbsp;is&nbsp;also used to&nbsp;cover software interrupts&nbsp;and&nbsp;undefined instruction traps (which&nbsp;<br>
do&nbsp;not&nbsp;really&nbsp;qualify as&nbsp;'unexpected')&nbsp;and&nbsp;the system&nbsp;reset&nbsp;function&nbsp;which logically&nbsp;<br>
arises before rather than&nbsp;during the execution&nbsp;of a&nbsp;program&nbsp;(although the processor&nbsp;<br>
may&nbsp;be reset&nbsp;again while&nbsp;running). These events&nbsp;are all&nbsp;grouped under the 'exception'&nbsp;<br>
heading because they&nbsp;all use the same basic mechanism&nbsp;within&nbsp;the processor. ARM&nbsp;<br>
exceptions may&nbsp;be considered&nbsp;in three&nbsp;groups:&nbsp;<br>
1.&nbsp;&nbsp;Exceptions&nbsp;generated&nbsp;as&nbsp;the&nbsp;direct&nbsp;effect&nbsp;of executing an&nbsp;instruction.&nbsp;<br>
Software&nbsp;interrupts,&nbsp;undefined&nbsp;instructions (including&nbsp;coprocessor&nbsp;instructions&nbsp;<br>
where the requested coprocessor is absent) and prefetch aborts&nbsp;(instructions that&nbsp;are&nbsp;<br>
invalid&nbsp;due to&nbsp;a&nbsp;memory&nbsp;fault&nbsp;occurring&nbsp;during fetch) come&nbsp;under this&nbsp;heading.&nbsp;<br>
2.&nbsp;&nbsp;Exceptions&nbsp;generated as&nbsp;a&nbsp;side-effect&nbsp;of&nbsp;an&nbsp;instruction.&nbsp;<br>
Data aborts (a&nbsp;memory&nbsp;fault&nbsp;during&nbsp;a&nbsp;load&nbsp;or&nbsp;store data&nbsp;access)&nbsp;are in this&nbsp;class.&nbsp;<br>
3.&nbsp;&nbsp;Exceptions generated externally,&nbsp;unrelated to&nbsp;the instruction flow.&nbsp;<br>
Reset, IRQ and FIQ&nbsp;fall into&nbsp;this category.&nbsp;<br>
<hr>
<A name=121></a><IMG src="index-121_1.png"><br>
<b>Exceptions</b>&nbsp;<br>
<b>109</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Exception entry&nbsp;&nbsp;When an exception arises,&nbsp;ARM completes the current&nbsp;instruction as best it can&nbsp;<br>
(except that&nbsp;<i>reset&nbsp;</i>exceptions&nbsp;terminate the current instruction&nbsp;immediately)&nbsp;and then&nbsp;<br>
departs&nbsp;from&nbsp;the current instruction sequence to handle the exception. Exception&nbsp;<br>
entry caused&nbsp;by&nbsp;a&nbsp;side-effect&nbsp;or&nbsp;an&nbsp;external&nbsp;event usurps the next&nbsp;instruction in&nbsp;the&nbsp;<br>
current&nbsp;sequence;&nbsp;direct-effect&nbsp;exceptions&nbsp;are&nbsp;handled&nbsp;in&nbsp;sequence&nbsp;as they&nbsp;arise.&nbsp;The&nbsp;<br>
processor performs the&nbsp;following&nbsp;sequence of actions:&nbsp;<br>
•&nbsp;&nbsp;It changes to the operating&nbsp;mode corresponding to the particular exception.&nbsp;<br>
•&nbsp;&nbsp;It&nbsp;saves&nbsp;the&nbsp;address&nbsp;of&nbsp;the instruction&nbsp;following the&nbsp;exception&nbsp;entry instruction&nbsp;in&nbsp;<br>
r14 of the new&nbsp;mode.&nbsp;<br>
•&nbsp;&nbsp;It&nbsp;saves&nbsp;the&nbsp;old&nbsp;value of&nbsp;the&nbsp;CPSR&nbsp;in&nbsp;the&nbsp;SPSR&nbsp;of&nbsp;the&nbsp;new mode.&nbsp;<br>
•&nbsp;&nbsp;It disables&nbsp;IRQs by&nbsp;setting bit 7 of the CPSR&nbsp;and, if&nbsp;the&nbsp;exception is a&nbsp;fast&nbsp;inter&nbsp;<br>
rupt, disables&nbsp;further&nbsp;fast interrupts by&nbsp;setting bit 6 of&nbsp;the&nbsp;CPSR.&nbsp;<br>
•&nbsp;&nbsp;It&nbsp;forces the&nbsp;PC&nbsp;to begin executing at the&nbsp;relevant vector&nbsp;address given&nbsp;in Table 5.2.&nbsp;<br>
<b>Table&nbsp;</b>5.2&nbsp;&nbsp;&nbsp;Exception&nbsp;vector&nbsp;addresses.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Normally the vector&nbsp;address will contain&nbsp;a&nbsp;branch&nbsp;to&nbsp;the relevant routine, though&nbsp;<br>
the FIQ&nbsp;code&nbsp;can start&nbsp;immediately since&nbsp;it&nbsp;occupies&nbsp;the&nbsp;highest&nbsp;vector&nbsp;address.&nbsp;<br>
The two banked registers in&nbsp;each of the privileged&nbsp;modes are used to hold the&nbsp;<br>
return address&nbsp;and a&nbsp;stack&nbsp;pointer;&nbsp;the&nbsp;stack pointer may be&nbsp;used to save other user&nbsp;<br>
registers so&nbsp;that&nbsp;they&nbsp;can&nbsp;be&nbsp;used&nbsp;by&nbsp;the&nbsp;exception handler.&nbsp;FIQ&nbsp;mode&nbsp;has&nbsp;additional&nbsp;<br>
private registers to give better&nbsp;performance by&nbsp;avoiding&nbsp;the&nbsp;need&nbsp;to save&nbsp;user registers&nbsp;<br>
in most cases&nbsp;where it&nbsp;is&nbsp;used.&nbsp;<br>
Exception return&nbsp;<br>
Once&nbsp;the&nbsp;exception has&nbsp;been&nbsp;handled&nbsp;the user&nbsp;task&nbsp;is&nbsp;normally&nbsp;resumed. This&nbsp;<br>
requires the&nbsp;handler code to&nbsp;restore the user&nbsp;state exactly&nbsp;as&nbsp;it&nbsp;was&nbsp;when&nbsp;the excep-<br>
tion first&nbsp;arose:&nbsp;<br>
•&nbsp;&nbsp;Any&nbsp;modified user registers must&nbsp;be&nbsp;restored from&nbsp;the handler's&nbsp;stack.&nbsp;<br>
•&nbsp;&nbsp;The CPSR&nbsp;must be&nbsp;restored&nbsp;from&nbsp;the appropriate&nbsp;SPSR.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;PC&nbsp;must&nbsp;be&nbsp;changed back&nbsp;to&nbsp;the&nbsp;relevant instruction&nbsp;address&nbsp;in&nbsp;the user&nbsp;<br>
instruction stream.&nbsp;<br>
<hr>
<A name=122></a><b>110&nbsp;</b><br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
Note that the last two of&nbsp;these steps&nbsp;cannot be carried out independently.&nbsp;If the&nbsp;<br>
CPSR&nbsp;is&nbsp;restored&nbsp;first,&nbsp;the&nbsp;banked&nbsp;r14 holding&nbsp;the&nbsp;return&nbsp;address is&nbsp;no&nbsp;longer&nbsp;access-<br>
ible;&nbsp;if&nbsp;the PC&nbsp;is restored&nbsp;first,&nbsp;the exception&nbsp;handler loses control of&nbsp;the&nbsp;instruction&nbsp;<br>
stream&nbsp;and cannot cause the restoration of the CPSR to take place. There are also&nbsp;<br>
more&nbsp;subtle&nbsp;difficulties&nbsp;to&nbsp;do&nbsp;with&nbsp;ensuring&nbsp;that&nbsp;instructions&nbsp;are&nbsp;always fetched&nbsp;in&nbsp;the&nbsp;<br>
correct&nbsp;operating mode&nbsp;to&nbsp;ensure&nbsp;that&nbsp;memory protection schemes&nbsp;are&nbsp;not bypassed.&nbsp;<br>
Therefore&nbsp;ARM provides&nbsp;two&nbsp;mechanisms&nbsp;which cause&nbsp;both steps to&nbsp;happen&nbsp;<br>
atomically&nbsp;as&nbsp;part&nbsp;of&nbsp;a single&nbsp;instruction.&nbsp;One of&nbsp;these&nbsp;is&nbsp;used&nbsp;when the&nbsp;return&nbsp;address&nbsp;<br>
has&nbsp;been kept&nbsp;in&nbsp;the banked r14 and&nbsp;the other when&nbsp;the return address&nbsp;has been saved&nbsp;<br>
onto&nbsp;a stack.&nbsp;First&nbsp;we look&nbsp;at&nbsp;the case&nbsp;where&nbsp;the return&nbsp;address is&nbsp;in&nbsp;r14.&nbsp;<br>
•&nbsp;&nbsp;To return from&nbsp;a SWI or&nbsp;undefined instruction&nbsp;trap&nbsp;use:&nbsp;<br>
MOVS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pc,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r14&nbsp;<br>
•&nbsp;&nbsp;To return from&nbsp;an IRQ,&nbsp;FIQ&nbsp;or prefetch abort&nbsp;use:&nbsp;<br>
SUBS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pc,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r14,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#4&nbsp;<br>
•&nbsp;&nbsp;To return&nbsp;from a data&nbsp;abort&nbsp;to&nbsp;retry the data&nbsp;access use:&nbsp;<br>
SUBS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pc,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r14,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#8&nbsp;<br>
The&nbsp;'s'&nbsp;modifier after&nbsp;the&nbsp;opcode&nbsp;signifies&nbsp;the special&nbsp;form of&nbsp;the&nbsp;instruction&nbsp;when&nbsp;<br>
the&nbsp;destination register&nbsp;is&nbsp;the PC. Note&nbsp;how the&nbsp;return&nbsp;instruction&nbsp;incorporates&nbsp;an&nbsp;<br>
adjustment&nbsp;to the&nbsp;return&nbsp;address&nbsp;where necessary:&nbsp;<br>
•&nbsp;&nbsp;IRQ and&nbsp;FIQ&nbsp;must&nbsp;return&nbsp;one instruction&nbsp;early in&nbsp;order to&nbsp;execute the instruction&nbsp;<br>
that was&nbsp;'usurped'&nbsp;for the exception entry.&nbsp;<br>
•&nbsp;&nbsp;Prefetch&nbsp;abort&nbsp;must return one instruction&nbsp;early to execute the&nbsp;instruction&nbsp;that&nbsp;<br>
had&nbsp;caused&nbsp;a memory&nbsp;fault when first requested.&nbsp;<br>
•&nbsp;&nbsp;Data&nbsp;abort&nbsp;must&nbsp;return two&nbsp;instructions early to&nbsp;retry the data&nbsp;transfer instruction,&nbsp;<br>
which&nbsp;was the instruction&nbsp;<i>before&nbsp;</i>the one usurped&nbsp;for exception&nbsp;entry.&nbsp;<br>
If the&nbsp;handler&nbsp;has copied the return address out onto a stack&nbsp;(in order, for example,&nbsp;<br>
to&nbsp;allow re-entrant behaviour,&nbsp;though note that&nbsp;in this&nbsp;case&nbsp;the SPSR must be saved&nbsp;as&nbsp;<br>
well as the PC)&nbsp;the restoration of the&nbsp;user&nbsp;registers and the return may be implemented&nbsp;<br>
with&nbsp;a single&nbsp;multiple&nbsp;register&nbsp;transfer&nbsp;instruction such&nbsp;as:&nbsp;<br>
LDMFD&nbsp;&nbsp;r13!,&nbsp;{r0-r3,pc}&quot;&nbsp;; restore&nbsp;and&nbsp;return&nbsp;<br>
Here&nbsp;the&nbsp;'*' after the&nbsp;register list&nbsp;(which&nbsp;must include&nbsp;the&nbsp;PC) indicates that this&nbsp;is&nbsp;<br>
a special form&nbsp;of&nbsp;the&nbsp;instruction.&nbsp;The&nbsp;CPSR&nbsp;is restored&nbsp;at&nbsp;the same&nbsp;time that&nbsp;the PC&nbsp;is&nbsp;<br>
loaded&nbsp;from&nbsp;memory,&nbsp;which&nbsp;will&nbsp;always be&nbsp;the last item&nbsp;transferred&nbsp;from&nbsp;memory&nbsp;<br>
since&nbsp;the registers are loaded in&nbsp;increasing order.&nbsp;<br>
The stack&nbsp;pointer&nbsp;(r13) used&nbsp;here&nbsp;is&nbsp;the banked&nbsp;register belonging to&nbsp;the privileged&nbsp;<br>
operating mode;&nbsp;each&nbsp;privileged&nbsp;mode&nbsp;can&nbsp;have&nbsp;its&nbsp;own&nbsp;stack&nbsp;pointer&nbsp;which must be&nbsp;<br>
initialized&nbsp;during system&nbsp;start-up.&nbsp;<br>
Clearly the stack return mechanism&nbsp;can&nbsp;only be&nbsp;employed if&nbsp;the value&nbsp;in&nbsp;r14 was&nbsp;<br>
adjusted, where&nbsp;necessary, before being saved&nbsp;onto&nbsp;the stack.&nbsp;<br>
<hr>
<A name=123></a><b>Conditional execution</b>&nbsp;<br>
111&nbsp;<br>
&nbsp;&nbsp;&nbsp;Exception&nbsp;<br>
Since&nbsp;multiple&nbsp;exceptions&nbsp;can&nbsp;arise at&nbsp;the same time&nbsp;it&nbsp;is necessary&nbsp;to&nbsp;define&nbsp;a priority&nbsp;<br>
priorities&nbsp;<br>
order to&nbsp;determine the order in&nbsp;which&nbsp;the exceptions&nbsp;are handled. On&nbsp;ARM this is:&nbsp;<br>
1.&nbsp;&nbsp;reset (highest&nbsp;priority);&nbsp;<br>
2.&nbsp;&nbsp;data&nbsp;abort;&nbsp;<br>
3.&nbsp;&nbsp;FIQ;&nbsp;<br>
4.&nbsp;&nbsp;IRQ;&nbsp;<br>
5.&nbsp;&nbsp;prefetch abort;&nbsp;<br>
6.&nbsp;&nbsp;SWI,&nbsp;undefined instruction&nbsp;(including absent&nbsp;coprocessor).&nbsp;These are mutually&nbsp;<br>
exclusive instruction&nbsp;encodings and therefore cannot&nbsp;occur&nbsp;simultaneously.&nbsp;<br>
Reset&nbsp;starts&nbsp;the processor from&nbsp;a known state and renders all&nbsp;other pending&nbsp;excep-<br>
tions&nbsp;irrelevant.&nbsp;<br>
The most complex exception&nbsp;scenario is where an FIQ, an&nbsp;IRQ and a third excep-<br>
tion (which&nbsp;is&nbsp;not&nbsp;Reset)&nbsp;happen simultaneously. FIQ has higher priority&nbsp;than IRQ and&nbsp;<br>
also&nbsp;masks it out, so the&nbsp;IRQ&nbsp;will be ignored&nbsp;until the FIQ&nbsp;handler&nbsp;explicitly enables&nbsp;<br>
IRQ or returns to the user code.&nbsp;<br>
If the third&nbsp;exception&nbsp;is&nbsp;a data&nbsp;abort, the processor will&nbsp;enter&nbsp;the data&nbsp;abort handler&nbsp;<br>
and then&nbsp;immediately enter&nbsp;the&nbsp;FIQ&nbsp;handler, since data&nbsp;abort entry&nbsp;does&nbsp;not mask&nbsp;<br>
FIQs&nbsp;out.&nbsp;The&nbsp;data&nbsp;abort&nbsp;is&nbsp;'remembered'&nbsp;in&nbsp;the return&nbsp;path&nbsp;and&nbsp;will&nbsp;be processed&nbsp;<br>
when the FIQ handler returns.&nbsp;<br>
If the third exception&nbsp;is&nbsp;not&nbsp;a&nbsp;data abort, the&nbsp;FIQ handler&nbsp;will be&nbsp;entered&nbsp;immedi-<br>
ately.&nbsp;When FIQ and IRQ have&nbsp;both completed, the program&nbsp;returns to&nbsp;the instruction&nbsp;<br>
which generated the third exception, and in&nbsp;all the remaining cases the exception will&nbsp;<br>
recur and be handled accordingly.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Address&nbsp;<br>
The observant&nbsp;reader&nbsp;will&nbsp;have&nbsp;noticed that&nbsp;Table 5.2&nbsp;on page 109&nbsp;shows the use of&nbsp;<br>
exceptions&nbsp;<br>
all of the&nbsp;first&nbsp;eight&nbsp;word&nbsp;locations in&nbsp;memory as&nbsp;exception vector&nbsp;addresses&nbsp;apart&nbsp;<br>
from&nbsp;address&nbsp;0x00000014. This&nbsp;location&nbsp;<i>was&nbsp;</i>used&nbsp;on&nbsp;earlier ARM&nbsp;processors which&nbsp;<br>
operated within a&nbsp;26-bit address space to&nbsp;trap&nbsp;load&nbsp;or&nbsp;store&nbsp;addresses which fell out-<br>
side the address space.&nbsp;These&nbsp;traps&nbsp;were&nbsp;referred&nbsp;to as 'address&nbsp;exceptions'.&nbsp;<br>
Since 32-bit ARMs&nbsp;are unable to&nbsp;generate&nbsp;addresses which fall&nbsp;outside&nbsp;their 32-bit&nbsp;<br>
address&nbsp;space,&nbsp;address exceptions have no&nbsp;role in&nbsp;the current architecture and&nbsp;the&nbsp;<br>
vector&nbsp;address at 0x00000014&nbsp;is unused.&nbsp;<br>
5.3 &nbsp; Conditional&nbsp;execution&nbsp;<br>
An unusual feature&nbsp;of&nbsp;the&nbsp;ARM instruction&nbsp;set is that every instruction&nbsp;(with the&nbsp;<br>
exception of&nbsp;certain&nbsp;v5T instructions) is&nbsp;conditionally&nbsp;executed.&nbsp;Conditional&nbsp;<br>
branches&nbsp;are&nbsp;a standard&nbsp;feature&nbsp;of most instruction sets,&nbsp;but&nbsp;ARM&nbsp;extends the&nbsp;<br>
<hr>
<A name=124></a><IMG src="index-124_1.png"><br>
<b>112</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
conditional execution to&nbsp;all of its instructions, including supervisor&nbsp;calls and&nbsp;<br>
coprocessor&nbsp;instructions.&nbsp;The&nbsp;condition field&nbsp;occupies&nbsp;the&nbsp;top four&nbsp;bits&nbsp;of&nbsp;the&nbsp;32-bit&nbsp;<br>
instruction field:&nbsp;<br>
&nbsp;<br>
<b>Figure 5.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The&nbsp;ARM condition code field.&nbsp;<br>
Each of&nbsp;the 16&nbsp;values of&nbsp;the&nbsp;condition&nbsp;field causes the&nbsp;instruction to be executed&nbsp;or&nbsp;<br>
skipped according to the values of&nbsp;the&nbsp;N,&nbsp;Z,&nbsp;C and V flags&nbsp;in the CPSR.&nbsp;The&nbsp;condi-<br>
tions&nbsp;are given&nbsp;in&nbsp;Table&nbsp;5.3&nbsp;on&nbsp;page&nbsp;113.&nbsp;Every&nbsp;ARM&nbsp;instruction mnemonic may&nbsp;be&nbsp;<br>
extended&nbsp;by&nbsp;appending&nbsp;the&nbsp;two&nbsp;letters&nbsp;defined&nbsp;in this&nbsp;table,&nbsp;though the 'always'&nbsp;condi-<br>
tion&nbsp;(AL)&nbsp;may be&nbsp;omitted&nbsp;since it&nbsp;is&nbsp;the default&nbsp;condition that is&nbsp;assumed&nbsp;if no other&nbsp;<br>
condition is&nbsp;specified.&nbsp;<br>
The 'never'&nbsp;<br>
The&nbsp;'never'&nbsp;condition (NV) should not&nbsp;be&nbsp;used - there are plenty&nbsp;of other ways&nbsp;to&nbsp;<br>
condition&nbsp;<br>
write no-ops&nbsp;(instructions&nbsp;that have no effect on the processor&nbsp;state) in&nbsp;ARM code.&nbsp;<br>
The reason to&nbsp;avoid the&nbsp;'never' condition is that ARM&nbsp;Limited&nbsp;have indicated that&nbsp;<br>
they&nbsp;may use this area of&nbsp;the&nbsp;instruction&nbsp;space for other purposes in the&nbsp;future&nbsp;(and&nbsp;<br>
have&nbsp;done so&nbsp;in architecture v5T), so although&nbsp;current&nbsp;ARMs&nbsp;may behave as&nbsp;<br>
expected, there&nbsp;is no&nbsp;guarantee that&nbsp;future variants&nbsp;will behave&nbsp;the same&nbsp;way.&nbsp;<br>
Alternative&nbsp;<br>
Where&nbsp;alternative mnemonics&nbsp;are shown in&nbsp;the same&nbsp;row in&nbsp;the condition&nbsp;table&nbsp;this&nbsp;<br>
mnemonics&nbsp;<br>
indicates&nbsp;that&nbsp;there is&nbsp;more than&nbsp;one way to&nbsp;interpret the&nbsp;condition field. For instance,&nbsp;<br>
in row 3&nbsp;the same&nbsp;condition field&nbsp;value&nbsp;can&nbsp;be&nbsp;invoked&nbsp;by&nbsp;the&nbsp;mnemonic extension&nbsp;CS&nbsp;<br>
or&nbsp;HS. Both&nbsp;cause&nbsp;the&nbsp;instruction to&nbsp;be&nbsp;executed only&nbsp;if&nbsp;the&nbsp;C bit&nbsp;in the CPSR is&nbsp;set.&nbsp;<br>
The alternatives&nbsp;are available&nbsp;because&nbsp;the&nbsp;same&nbsp;test is used in&nbsp;different circumstances.&nbsp;<br>
If you have&nbsp;previously&nbsp;added&nbsp;two unsigned&nbsp;integers&nbsp;and want&nbsp;to&nbsp;test whether there&nbsp;was&nbsp;<br>
a carry-out from&nbsp;the addition,&nbsp;you should&nbsp;use CS. If you&nbsp;have compared two unsigned&nbsp;<br>
integers and want&nbsp;to test whether the first&nbsp;was&nbsp;higher or&nbsp;the&nbsp;same&nbsp;as the second, use&nbsp;<br>
HS. The alternative&nbsp;mnemonic removes the&nbsp;need for the&nbsp;programmer to remember that&nbsp;<br>
an&nbsp;unsigned&nbsp;comparison&nbsp;sets&nbsp;the&nbsp;carry&nbsp;on&nbsp;higher&nbsp;or&nbsp;the&nbsp;same.&nbsp;<br>
The&nbsp;observant reader will&nbsp;note that&nbsp;the&nbsp;conditions&nbsp;are in pairs&nbsp;where the&nbsp;second&nbsp;<br>
condition&nbsp;is&nbsp;the&nbsp;inverse&nbsp;of&nbsp;the&nbsp;first, so&nbsp;for&nbsp;any condition&nbsp;the&nbsp;opposite&nbsp;condition&nbsp;is&nbsp;also&nbsp;<br>
available (with the exception&nbsp;of 'always', since&nbsp;'never'&nbsp;should not be used).&nbsp;Therefore&nbsp;<br>
whenever&nbsp;<i>if...then...&nbsp;</i>can&nbsp;be&nbsp;implemented&nbsp;with&nbsp;conditional instructions,&nbsp;<i>...else...&nbsp;</i>can be&nbsp;<br>
added using instructions&nbsp;with&nbsp;the opposite&nbsp;condition.&nbsp;<br>
<hr>
<A name=125></a><IMG src="index-125_1.png"><br>
<b>Branch&nbsp;and&nbsp;Branch&nbsp;with&nbsp;Link&nbsp;(B,&nbsp;BL)</b>&nbsp;<br>
<b>113</b>&nbsp;<br>
<b>Table&nbsp;</b>5.3 &nbsp;&nbsp;&nbsp;ARM&nbsp;condition&nbsp;codes.&nbsp;<br>
&nbsp;<br>
Opcode&nbsp;<br>
Mnemonic&nbsp;<br>
Status flag state&nbsp;for&nbsp;<br>
[31:28]&nbsp;&nbsp;&nbsp;&nbsp;extension&nbsp;&nbsp;&nbsp;&nbsp;Interpretation&nbsp;&nbsp;&nbsp;<br>
execution&nbsp;&nbsp;&nbsp;<br>
0000&nbsp;&nbsp;&nbsp;<br>
EQ&nbsp;&nbsp;&nbsp;<br>
Equal / equals&nbsp;zero&nbsp;&nbsp;&nbsp;<br>
Zset&nbsp;&nbsp;&nbsp;<br>
0001&nbsp;&nbsp;&nbsp;<br>
NE&nbsp;&nbsp;&nbsp;<br>
Not equal&nbsp;&nbsp;&nbsp;<br>
Z clear&nbsp;&nbsp;&nbsp;<br>
0010&nbsp;&nbsp;&nbsp;<br>
CS/HS&nbsp;&nbsp;&nbsp;<br>
Carry set&nbsp;/&nbsp;unsigned higher&nbsp;or same&nbsp;<br>
Cset&nbsp;&nbsp;&nbsp;<br>
0011&nbsp;&nbsp;&nbsp;<br>
CC/LO&nbsp;&nbsp;&nbsp;<br>
Carry clear /&nbsp;unsigned&nbsp;lower&nbsp;&nbsp;&nbsp;<br>
C clear&nbsp;&nbsp;&nbsp;<br>
0100&nbsp;&nbsp;&nbsp;<br>
Ml&nbsp;&nbsp;&nbsp;<br>
Minus / negative&nbsp;&nbsp;&nbsp;<br>
Nset&nbsp;&nbsp;&nbsp;<br>
0101&nbsp;&nbsp;&nbsp;<br>
PL&nbsp;&nbsp;&nbsp;<br>
Plus / positive&nbsp;or zero&nbsp;&nbsp;&nbsp;<br>
N clear&nbsp;&nbsp;&nbsp;<br>
0110&nbsp;&nbsp;&nbsp;<br>
VS&nbsp;&nbsp;&nbsp;<br>
Overflow&nbsp;&nbsp;&nbsp;<br>
Vset&nbsp;&nbsp;&nbsp;<br>
0111&nbsp;&nbsp;&nbsp;<br>
vc&nbsp;&nbsp;&nbsp;<br>
No overflow&nbsp;&nbsp;&nbsp;<br>
V clear&nbsp;&nbsp;&nbsp;<br>
1000&nbsp;&nbsp;&nbsp;<br>
HI&nbsp;&nbsp;&nbsp;<br>
Unsigned&nbsp;higher&nbsp;&nbsp;&nbsp;<br>
C set and&nbsp;Z clear&nbsp;&nbsp;&nbsp;<br>
1001&nbsp;&nbsp;&nbsp;<br>
LS&nbsp;&nbsp;&nbsp;<br>
Unsigned lower&nbsp;or same&nbsp;&nbsp;&nbsp;<br>
C clear or Z set&nbsp;&nbsp;&nbsp;<br>
1010&nbsp;&nbsp;&nbsp;<br>
GE&nbsp;&nbsp;&nbsp;<br>
Signed greater&nbsp;than&nbsp;or equal&nbsp;&nbsp;&nbsp;<br>
N equals V&nbsp;&nbsp;&nbsp;<br>
1011&nbsp;&nbsp;&nbsp;<br>
LT&nbsp;&nbsp;&nbsp;<br>
Signed less than&nbsp;&nbsp;&nbsp;<br>
N is not&nbsp;equal to&nbsp;V&nbsp;&nbsp;&nbsp;<br>
1100&nbsp;&nbsp;&nbsp;<br>
GT&nbsp;&nbsp;&nbsp;<br>
Signed&nbsp;greater&nbsp;than&nbsp;&nbsp;&nbsp;<br>
Z clear and N&nbsp;equals V&nbsp;&nbsp;&nbsp;<br>
1101&nbsp;&nbsp;&nbsp;<br>
LE-&nbsp;&nbsp;&nbsp;<br>
Signed less than&nbsp;or equal&nbsp;&nbsp;&nbsp;<br>
Z set or&nbsp;N&nbsp;is not&nbsp;equal to V&nbsp;&nbsp;&nbsp;<br>
1110&nbsp;&nbsp;&nbsp;<br>
AL&nbsp;&nbsp;&nbsp;<br>
Always&nbsp;&nbsp;&nbsp;<br>
any&nbsp;&nbsp;&nbsp;<br>
1111&nbsp;&nbsp;&nbsp;<br>
NV&nbsp;&nbsp;&nbsp;<br>
Never (do&nbsp;not use!)&nbsp;&nbsp;&nbsp;<br>
none&nbsp;&nbsp;&nbsp;<br>
5.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Branch and Branch with Link (B, BL)&nbsp;<br>
Branch&nbsp;and Branch with Link&nbsp;instructions&nbsp;are&nbsp;the standard way&nbsp;to cause&nbsp;a switch in&nbsp;<br>
the sequence&nbsp;of instruction&nbsp;execution.&nbsp;The ARM normally&nbsp;executes&nbsp;instructions&nbsp;<br>
from&nbsp;sequential&nbsp;word&nbsp;addresses in&nbsp;memory,&nbsp;using&nbsp;conditional&nbsp;execution&nbsp;to&nbsp;skip&nbsp;over&nbsp;<br>
individual instructions&nbsp;where required. Whenever&nbsp;the&nbsp;program&nbsp;must&nbsp;deviate&nbsp;from&nbsp;<br>
sequential&nbsp;execution&nbsp;a&nbsp;control flow&nbsp;instruction&nbsp;is used&nbsp;to&nbsp;modify&nbsp;the program&nbsp;counter.&nbsp;<br>
Although there are several ways to&nbsp;achieve this&nbsp;in&nbsp;special circumstances,&nbsp;Branch&nbsp;and&nbsp;<br>
Branch&nbsp;with&nbsp;Link&nbsp;instructions are the&nbsp;standard&nbsp;way.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;5.3 &nbsp; &nbsp;</b>Branch and Branch&nbsp;with&nbsp;Link&nbsp;binary&nbsp;encoding.&nbsp;<br>
<hr>
<A name=126></a><IMG src="index-126_1.png"><br>
<b>114</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Description&nbsp;<br>
Branch&nbsp;and Branch&nbsp;with Link instructions&nbsp;cause&nbsp;the processor to begin executing&nbsp;<br>
instructions&nbsp;from&nbsp;an address computed by&nbsp;sign extending&nbsp;the 24-bit offset specified&nbsp;<br>
in the instruction, shifting it left two places&nbsp;to form&nbsp;a&nbsp;word offset, then&nbsp;adding it to&nbsp;<br>
the program&nbsp;counter&nbsp;which contains the address of the branch&nbsp;instruction plus&nbsp;eight&nbsp;<br>
bytes. (See 'PC&nbsp;behaviour'&nbsp;on&nbsp;page&nbsp;78. for&nbsp;an explanation of the PC&nbsp;offset.)&nbsp;The&nbsp;<br>
assembler will&nbsp;compute&nbsp;the correct offset under normal circumstances.&nbsp;<br>
The&nbsp;range of the branch&nbsp;instruction is +/-&nbsp;32 Mbytes.&nbsp;<br>
The Branch&nbsp;with Link variant, which has&nbsp;the L bit (bit&nbsp;24) set, also moves the&nbsp;<br>
address of&nbsp;the&nbsp;instruction&nbsp;following&nbsp;the&nbsp;branch&nbsp;into&nbsp;the&nbsp;link&nbsp;register&nbsp;(r14)&nbsp;of&nbsp;the&nbsp;cur-<br>
rent processor&nbsp;mode. This is normally&nbsp;used&nbsp;to perform&nbsp;a&nbsp;subroutine call, with the&nbsp;<br>
return&nbsp;being&nbsp;caused by&nbsp;copying the link&nbsp;register&nbsp;back&nbsp;into&nbsp;the&nbsp;PC.&nbsp;<br>
Both&nbsp;forms of the instruction&nbsp;may&nbsp;be executed&nbsp;conditionally&nbsp;or unconditionally.&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
Assembler&nbsp;<br>
&nbsp;<br>
B{L}{&lt;cond&gt;}<br>
format&nbsp;<br>
&lt;target address&gt;&nbsp;<br>
'L'&nbsp;specifies&nbsp;the&nbsp;branch&nbsp;and&nbsp;link&nbsp;variant;&nbsp;if&nbsp;'L'&nbsp;is not included&nbsp;a branch without&nbsp;link&nbsp;is&nbsp;<br>
generated.'&lt;cond&gt;'&nbsp;should&nbsp;be&nbsp;one&nbsp;of&nbsp;the&nbsp;mnemonic&nbsp;extensions&nbsp;given&nbsp;in&nbsp;Table&nbsp;5.3&nbsp;on&nbsp;<br>
page&nbsp;113 or,&nbsp;if&nbsp;omitted, 'AL'&nbsp;is assumed.'&lt;target address&gt;'&nbsp;is normally&nbsp;a label&nbsp;in&nbsp;<br>
the assembler code; the assembler will generate&nbsp;the offset (which will be&nbsp;the&nbsp;difference&nbsp;<br>
between the address of the target and&nbsp;the address of the branch&nbsp;instruction plus&nbsp;8).&nbsp;<br>
&nbsp;&nbsp;&nbsp;Examples&nbsp;<br>
An&nbsp;unconditional&nbsp;jump:&nbsp;<br>
B LABEL&nbsp;<br>
<hr>
<A name=127></a><IMG src="index-127_1.png"><br>
<IMG src="index-127_2.png"><br>
<b>Branch,&nbsp;Branch&nbsp;with Link and exchange (BX, BLX)</b>&nbsp;<br>
115&nbsp;<br>
Conditional subroutine call:&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
(Note that&nbsp;this&nbsp;example will&nbsp;only work correctly if SUB1&nbsp;does&nbsp;not change&nbsp;the con-<br>
dition codes, since if the&nbsp;BLLT&nbsp;is taken&nbsp;it&nbsp;will return to the&nbsp;BLGE.&nbsp;If the condition&nbsp;<br>
codes are changed by SUB1,&nbsp;SUB2&nbsp;may be executed as well.)&nbsp;<br>
Notes&nbsp;<br>
1.&nbsp;&nbsp;If you are familiar with&nbsp;other&nbsp;RISC&nbsp;processors you might expect ARM&nbsp;to&nbsp;execute&nbsp;<br>
the&nbsp;instruction&nbsp;after the branch before&nbsp;moving&nbsp;to&nbsp;LABEL&nbsp;in the first&nbsp;example&nbsp;<br>
above,&nbsp;following the&nbsp;<i>delayed branch&nbsp;</i>model&nbsp;employed&nbsp;by&nbsp;many&nbsp;other RISCs. This&nbsp;<br>
expectation will&nbsp;not&nbsp;be&nbsp;fulfilled, however, since ARM does not employ&nbsp;a&nbsp;delayed&nbsp;<br>
branch&nbsp;mechanism.&nbsp;<br>
2.&nbsp;&nbsp;Branches&nbsp;which attempt to go&nbsp;past&nbsp;the beginning or&nbsp;the end&nbsp;of the 32-bit address&nbsp;<br>
space&nbsp;should&nbsp;be&nbsp;avoided&nbsp;since they&nbsp;may have&nbsp;unpredictable results.&nbsp;<br>
5.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Branch, Branch with&nbsp;Link&nbsp;and exchange (BX, BLX)&nbsp;<br>
These instructions&nbsp;are available&nbsp;on&nbsp;ARM chips which support&nbsp;the Thumb&nbsp;(16-bit)&nbsp;<br>
instruction&nbsp;set,&nbsp;and are a&nbsp;mechanism&nbsp;for switching the processor to execute Thumb&nbsp;<br>
instructions&nbsp;or&nbsp;for returning&nbsp;symmetrically&nbsp;to ARM&nbsp;and Thumb calling routines.&nbsp;A&nbsp;<br>
similar Thumb instruction&nbsp;causes the processor&nbsp;to switch back to&nbsp;32-bit&nbsp;ARM&nbsp;<br>
instructions.&nbsp;The Thumb instruction&nbsp;set&nbsp;is described in&nbsp;Chapter 7.&nbsp;<br>
BLX is available only&nbsp;on ARM processors&nbsp;that support&nbsp;architecture v5T.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
<b>Figure 5.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Branch&nbsp;(with&nbsp;optional link) and&nbsp;exchange instruction binary&nbsp;encodings.&nbsp;<br>
<hr>
<A name=128></a><IMG src="index-128_1.png"><br>
116&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Description&nbsp;<br>
In the first format the branch target&nbsp;is specified in&nbsp;a register, Rm. Bit[0] of Rm&nbsp;is&nbsp;<br>
copied&nbsp;into&nbsp;the&nbsp;T&nbsp;bit&nbsp;in&nbsp;the&nbsp;CPSR&nbsp;and&nbsp;bits[31:1]&nbsp;are&nbsp;moved into the&nbsp;PC:&nbsp;<br>
•&nbsp;&nbsp;If Rm[0] is 1, the processor&nbsp;switches to execute Thumb instructions and begins&nbsp;<br>
executing&nbsp;at the address in Rm&nbsp;aligned to a&nbsp;half-word boundary&nbsp;by&nbsp;clearing the&nbsp;<br>
bottom&nbsp;bit.&nbsp;<br>
•&nbsp;&nbsp;If Rm[0] is 0,&nbsp;the&nbsp;processor&nbsp;continues&nbsp;executing ARM&nbsp;instructions&nbsp;and begins&nbsp;<br>
executing at the address in&nbsp;Rm&nbsp;aligned&nbsp;to a&nbsp;word boundary&nbsp;by&nbsp;clearing&nbsp;Rm[l].&nbsp;<br>
In the second format the branch target is an&nbsp;address computed by&nbsp;sign extending&nbsp;<br>
the&nbsp;24-bit&nbsp;offset specified&nbsp;in&nbsp;the&nbsp;instruction, shifting&nbsp;it left two&nbsp;places&nbsp;to form&nbsp;a&nbsp;<br>
word offset, then&nbsp;adding it&nbsp;to the program&nbsp;counter&nbsp;which contains&nbsp;the address of&nbsp;the&nbsp;<br>
BX instruction&nbsp;plus eight bytes.&nbsp;(See&nbsp;'PC behaviour'&nbsp;on page 78. for&nbsp;an&nbsp;explanation&nbsp;<br>
of the PC offset.)&nbsp;The&nbsp;H bit&nbsp;(bit 24) is also&nbsp;added&nbsp;into&nbsp;bit 1 of&nbsp;the&nbsp;resulting address,&nbsp;<br>
allowing an odd half-word&nbsp;address to be selected for the target instruction which&nbsp;<br>
will&nbsp;always be&nbsp;a Thumb&nbsp;instruction&nbsp;(BL is&nbsp;used to&nbsp;target&nbsp;an ARM instruction). The&nbsp;<br>
assembler&nbsp;will&nbsp;compute the correct offset&nbsp;under&nbsp;normal circumstances. The&nbsp;range of&nbsp;<br>
the branch instruction is +/- 32&nbsp;Mbytes.&nbsp;<br>
The&nbsp;Branch&nbsp;with&nbsp;Link&nbsp;variants&nbsp;(BLX,&nbsp;available only&nbsp;on&nbsp;v5T processors)&nbsp;of&nbsp;both&nbsp;<br>
formats,&nbsp;which&nbsp;have the L bit&nbsp;(bit&nbsp;5)&nbsp;set&nbsp;in the first&nbsp;format, also&nbsp;move&nbsp;the&nbsp;address of&nbsp;<br>
the&nbsp;instruction&nbsp;following&nbsp;the branch&nbsp;into&nbsp;the&nbsp;link&nbsp;register&nbsp;(r14)&nbsp;of&nbsp;the current processor&nbsp;<br>
mode. This is&nbsp;normally&nbsp;used to save&nbsp;the return address when&nbsp;calling a Thumb subrou-<br>
tine.&nbsp;If BX&nbsp;is&nbsp;used&nbsp;as&nbsp;the&nbsp;subroutine&nbsp;return&nbsp;mechanism&nbsp;the&nbsp;instruction&nbsp;set&nbsp;of&nbsp;the&nbsp;call-<br>
ing routine&nbsp;can&nbsp;be&nbsp;saved&nbsp;along with&nbsp;the return address,&nbsp;so&nbsp;the same&nbsp;return&nbsp;mechanism&nbsp;<br>
can be used to&nbsp;return symmetrically to either an ARM or a Thumb caller from&nbsp;an&nbsp;<br>
ARM or Thumb subroutine.&nbsp;<br>
Format&nbsp;(1) instructions&nbsp;may&nbsp;be executed conditionally&nbsp;or unconditionally, but&nbsp;<br>
format (2) instructions are executed&nbsp;unconditionally.&nbsp;<br>
Assembler&nbsp;<br>
1: &nbsp; &nbsp; &nbsp;B{L}X{&lt;cond&gt;}&nbsp;Rm&nbsp;<br>
format&nbsp;<br>
2: &nbsp; &nbsp; &nbsp;BLX&nbsp;&lt;target&nbsp;address&gt;&nbsp;<br>
'&lt;target&nbsp;address&gt;'&nbsp;is&nbsp;normally&nbsp;a&nbsp;label&nbsp;in the&nbsp;assembler&nbsp;code;&nbsp;the assembler&nbsp;<br>
will&nbsp;generate&nbsp;the&nbsp;offset (which&nbsp;will&nbsp;be the&nbsp;difference between the&nbsp;word address&nbsp;of the&nbsp;<br>
target&nbsp;and&nbsp;the address&nbsp;of the&nbsp;branch&nbsp;instruction plus&nbsp;8) and set the H bit&nbsp;if appropriate.&nbsp;<br>
Examples&nbsp;<br>
&nbsp;<br>
<hr>
<A name=129></a><IMG src="index-129_1.png"><br>
<IMG src="index-129_2.png"><br>
<b>Software Interrupt (SWI)</b>&nbsp;<br>
<b>117</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Notes<br>
&nbsp;<br>
&nbsp;<br>
1.&nbsp;&nbsp;Some&nbsp;ARM processors&nbsp;which do not support&nbsp;the Thumb instruction&nbsp;set&nbsp;will trap&nbsp;<br>
these&nbsp;instructions,&nbsp;allowing&nbsp;software&nbsp;emulation&nbsp;of&nbsp;Thumb.&nbsp;<br>
2.&nbsp;&nbsp;Only&nbsp;processors that implement ARM architecture v5T support either format of&nbsp;<br>
the BLX instruction&nbsp;(see&nbsp;Section 5.23 on page 147).&nbsp;<br>
5.6 &nbsp; Software&nbsp;Interrupt (SWI)&nbsp;<br>
The software interrupt instruction is used&nbsp;for calls to&nbsp;the operating system&nbsp;and is&nbsp;<br>
often&nbsp;called&nbsp;a&nbsp;'supervisor&nbsp;call'.&nbsp;It&nbsp;puts&nbsp;the processor&nbsp;into&nbsp;supervisor&nbsp;mode&nbsp;and&nbsp;<br>
begins executing instructions&nbsp;from&nbsp;address&nbsp;0x08.&nbsp;<br>
If this&nbsp;area of&nbsp;memory is&nbsp;suitably protected&nbsp;it is possible&nbsp;to build an operating&nbsp;<br>
system&nbsp;on the&nbsp;ARM that is fully&nbsp;protected from&nbsp;a&nbsp;malicious&nbsp;user, though since ARM is&nbsp;<br>
rarely used&nbsp;in&nbsp;multi-user&nbsp;applications this&nbsp;level of protection is not often&nbsp;sought.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure 5.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Software interrupt binary&nbsp;encoding.&nbsp;<br>
Description&nbsp;<br>
The 24-bit&nbsp;immediate field&nbsp;does not&nbsp;influence the&nbsp;operation&nbsp;of the instruction&nbsp;but&nbsp;<br>
may&nbsp;be interpreted by&nbsp;the system&nbsp;code.&nbsp;<br>
If the&nbsp;condition&nbsp;is passed&nbsp;the&nbsp;instruction&nbsp;enters supervisor&nbsp;mode using&nbsp;the&nbsp;standard&nbsp;<br>
ARM&nbsp;exception&nbsp;entry sequence.&nbsp;In detail,&nbsp;the&nbsp;processor&nbsp;actions&nbsp;are:&nbsp;<br>
1.&nbsp;&nbsp;Save&nbsp;the address of&nbsp;the instruction after the&nbsp;SWI in&nbsp;r14_svc.&nbsp;<br>
2.&nbsp;&nbsp;Save the CPSR&nbsp;in SPSR_svc.&nbsp;<br>
3.&nbsp;&nbsp;Enter supervisor&nbsp;mode and&nbsp;disable IRQs (but&nbsp;not FIQs)&nbsp;by&nbsp;setting CPSR[4:0]&nbsp;to&nbsp;<br>
100112andCPSR[7]tol.&nbsp;<br>
4.&nbsp;&nbsp;Set the&nbsp;PC&nbsp;to&nbsp;08&nbsp;]6&nbsp;and&nbsp;begin executing the instructions&nbsp;there.&nbsp;<br>
To return to&nbsp;the instruction&nbsp;after&nbsp;the SWI the&nbsp;system&nbsp;routine&nbsp;must not only copy&nbsp;<br>
r14_svc back into the&nbsp;PC, but&nbsp;it must also restore the&nbsp;CPSR&nbsp;from&nbsp;SPSR_svc. This&nbsp;<br>
requires&nbsp;the&nbsp;use of&nbsp;one&nbsp;of&nbsp;the special&nbsp;forms of the&nbsp;data&nbsp;processing&nbsp;instruction&nbsp;<br>
described in&nbsp;the next&nbsp;section.&nbsp;<br>
<hr>
<A name=130></a><IMG src="index-130_1.png"><br>
118&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
Assembler&nbsp;<br>
format&nbsp;<br>
Examples&nbsp;<br>
Notes&nbsp;<br>
&nbsp;<br>
1.&nbsp;&nbsp;An&nbsp;SWI&nbsp;may&nbsp;be executed&nbsp;when the processor is already&nbsp;in supervisor&nbsp;mode pro&nbsp;<br>
vided&nbsp;the original return&nbsp;address (in&nbsp;r14_svc) and SPSR_svc&nbsp;have been&nbsp;saved;&nbsp;<br>
otherwise&nbsp;these&nbsp;registers&nbsp;will be&nbsp;overwritten when the&nbsp;SWI is&nbsp;executed.&nbsp;<br>
2.&nbsp;&nbsp;The interpretation of the 24-bit&nbsp;immediate&nbsp;is&nbsp;system&nbsp;dependent,&nbsp;but most&nbsp;systems&nbsp;<br>
support&nbsp;a standard subset for character&nbsp;I/O and similar basic functions.&nbsp;<br>
The immediates can be specified as constant expressions, but it is usually&nbsp;better&nbsp;<br>
to declare names for the required calls (and set their values) at the start of&nbsp;the&nbsp;<br>
program&nbsp;(or import a file which declares&nbsp;their values&nbsp;for the local operating sys-<br>
tem)&nbsp;and&nbsp;then&nbsp;use these names in&nbsp;the code.&nbsp;<br>
To see&nbsp;how&nbsp;to declare&nbsp;names and&nbsp;give&nbsp;them&nbsp;values look at&nbsp;the 'Examples and&nbsp;<br>
exercises'&nbsp;on page&nbsp;72.&nbsp;<br>
3.&nbsp;&nbsp;The&nbsp;first&nbsp;instruction executed&nbsp;in supervisor&nbsp;mode,&nbsp;which is at 08jg, is normally&nbsp;a&nbsp;<br>
branch to&nbsp;the SWI&nbsp;handler which&nbsp;resides&nbsp;somewhere nearby&nbsp;in&nbsp;memory. Writing&nbsp;<br>
the&nbsp;SWI&nbsp;handler to&nbsp;start&nbsp;at&nbsp;OSjg&nbsp;is&nbsp;not&nbsp;possible&nbsp;because the next memory word,&nbsp;at&nbsp;<br>
OC16, is&nbsp;the entry point&nbsp;for&nbsp;the prefetch&nbsp;abort&nbsp;handler.&nbsp;<br>
<hr>
<A name=131></a><IMG src="index-131_1.png"><br>
<b>Data&nbsp;processing instructions</b>&nbsp;<br>
<b>119</b>&nbsp;<br>
5.7 &nbsp; Data&nbsp;processing&nbsp;instructions&nbsp;<br>
The&nbsp;ARM data processing instructions&nbsp;are used&nbsp;to&nbsp;modify&nbsp;data values in registers.&nbsp;<br>
The operations&nbsp;that are supported&nbsp;include&nbsp;arithmetic and&nbsp;bit-wise logical&nbsp;combina-<br>
tions of 32-bit&nbsp;data types. One operand&nbsp;may&nbsp;be shifted or rotated&nbsp;<i>en route&nbsp;</i>to the&nbsp;<br>
ALU, allowing,&nbsp;for example,&nbsp;shift and add in&nbsp;a&nbsp;single instruction.&nbsp;<br>
Multiply&nbsp;instructions use different&nbsp;formats,&nbsp;so these are&nbsp;considered&nbsp;separately&nbsp;in&nbsp;<br>
the next&nbsp;section.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
register shift length -<b>Figure&nbsp;5.6&nbsp; &nbsp;</b><br>
Data processing instruction binary&nbsp;encoding.&nbsp;<br>
Description&nbsp;<br>
The&nbsp;ARM&nbsp;data&nbsp;processing&nbsp;instructions&nbsp;employ&nbsp;a&nbsp;3-address&nbsp;format, which&nbsp;means&nbsp;that&nbsp;<br>
the&nbsp;two source&nbsp;operands and&nbsp;the&nbsp;destination&nbsp;register&nbsp;are specified independently.&nbsp;One&nbsp;<br>
source&nbsp;operand is always a&nbsp;register; the&nbsp;second may be a&nbsp;register, a shifted register or&nbsp;<br>
an immediate&nbsp;value.&nbsp;The&nbsp;shift&nbsp;applied to&nbsp;the&nbsp;second&nbsp;operand,&nbsp;if&nbsp;it&nbsp;is&nbsp;a&nbsp;register,&nbsp;may be&nbsp;<br>
a logical&nbsp;or arithmetic shift&nbsp;or&nbsp;a rotate (see&nbsp;Figure&nbsp;3.1 on&nbsp;page&nbsp;54),&nbsp;and it&nbsp;may&nbsp;be by&nbsp;an&nbsp;<br>
amount specified either as&nbsp;an&nbsp;immediate&nbsp;quantity&nbsp;or&nbsp;by&nbsp;a fourth register.&nbsp;<br>
The&nbsp;operations&nbsp;that&nbsp;may&nbsp;be specified are&nbsp;listed&nbsp;in Table&nbsp;5.4&nbsp;on&nbsp;page&nbsp;120.&nbsp;<br>
When the&nbsp;instruction&nbsp;does not require all the available&nbsp;operands (for instance&nbsp;<br>
MOV&nbsp;ignores Rn&nbsp;and&nbsp;CMP&nbsp;ignores&nbsp;Rd) the unused&nbsp;register field&nbsp;should&nbsp;be&nbsp;set&nbsp;to&nbsp;zero.&nbsp;<br>
The assembler&nbsp;will do&nbsp;this&nbsp;automatically.&nbsp;<br>
<hr>
<A name=132></a><b>120</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
<b>Table&nbsp;5.4 &nbsp; &nbsp;</b>ARM data processing instructions.&nbsp;<br>
&nbsp;<br>
Opcode&nbsp;<br>
124:21)&nbsp;&nbsp;&nbsp;&nbsp;Mnemonic&nbsp;&nbsp;&nbsp;&nbsp;Meaning&nbsp;&nbsp;&nbsp;<br>
Effect&nbsp;&nbsp;&nbsp;<br>
0000&nbsp;&nbsp;&nbsp;<br>
AND&nbsp;&nbsp;&nbsp;<br>
Logical bit-wise&nbsp;AND&nbsp;&nbsp;&nbsp;<br>
Rd:=RnANDOp2&nbsp;&nbsp;&nbsp;<br>
0001&nbsp;&nbsp;&nbsp;<br>
EOR&nbsp;&nbsp;&nbsp;<br>
Logical bit-wise&nbsp;exclusive OR&nbsp;<br>
Rd := Rn EOR&nbsp;Op2&nbsp;&nbsp;&nbsp;<br>
0010&nbsp;&nbsp;&nbsp;<br>
SUB&nbsp;&nbsp;&nbsp;<br>
Subtract&nbsp;&nbsp;&nbsp;<br>
Rd :=&nbsp;Rn -&nbsp;Op2&nbsp;&nbsp;&nbsp;<br>
0011&nbsp;&nbsp;&nbsp;<br>
RSB&nbsp;&nbsp;&nbsp;<br>
Reverse subtract&nbsp;&nbsp;&nbsp;<br>
Rd := Op2&nbsp;- Rn&nbsp;&nbsp;&nbsp;<br>
0100&nbsp;&nbsp;&nbsp;<br>
ADD&nbsp;&nbsp;&nbsp;<br>
Add&nbsp;&nbsp;&nbsp;<br>
Rd := Rn + Op2&nbsp;&nbsp;&nbsp;<br>
0101&nbsp;&nbsp;&nbsp;<br>
ADC&nbsp;&nbsp;&nbsp;<br>
Add with&nbsp;carry&nbsp;&nbsp;&nbsp;<br>
Rd := Rn + Op2&nbsp;+ C&nbsp;&nbsp;&nbsp;<br>
0110&nbsp;&nbsp;&nbsp;<br>
SBC&nbsp;&nbsp;&nbsp;<br>
Subtract with carry&nbsp;&nbsp;&nbsp;<br>
Rd&nbsp;:= Rn&nbsp;- Op2 + C&nbsp;- 1&nbsp;&nbsp;&nbsp;<br>
0111&nbsp;&nbsp;&nbsp;<br>
RSC&nbsp;&nbsp;&nbsp;<br>
Reverse subtract&nbsp;with&nbsp;carry&nbsp;&nbsp;&nbsp;<br>
Rd&nbsp;:= Op2 - Rn + C&nbsp;- 1&nbsp;&nbsp;&nbsp;<br>
1000&nbsp;&nbsp;&nbsp;<br>
TST&nbsp;&nbsp;&nbsp;<br>
Test&nbsp;&nbsp;&nbsp;<br>
ScconRnANDOp2&nbsp;&nbsp;&nbsp;<br>
1001&nbsp;&nbsp;&nbsp;<br>
TEQ&nbsp;&nbsp;&nbsp;<br>
Test equivalence&nbsp;&nbsp;&nbsp;<br>
Sec on Rn EOR&nbsp;Op2&nbsp;&nbsp;&nbsp;<br>
1010&nbsp;&nbsp;&nbsp;<br>
CMP&nbsp;&nbsp;&nbsp;<br>
Compare&nbsp;&nbsp;&nbsp;<br>
Sec on&nbsp;Rn&nbsp;- Op2&nbsp;&nbsp;&nbsp;<br>
1011&nbsp;&nbsp;&nbsp;<br>
CMN&nbsp;&nbsp;&nbsp;<br>
Compare negated&nbsp;&nbsp;&nbsp;<br>
Sec on Rn +&nbsp;Op2&nbsp;&nbsp;&nbsp;<br>
1100&nbsp;&nbsp;&nbsp;<br>
ORR&nbsp;&nbsp;&nbsp;<br>
Logical bit-wise&nbsp;OR&nbsp;&nbsp;&nbsp;<br>
Rd := Rn OR Op2&nbsp;&nbsp;&nbsp;<br>
1101&nbsp;&nbsp;&nbsp;<br>
MOV&nbsp;&nbsp;&nbsp;<br>
Move&nbsp;&nbsp;&nbsp;<br>
Rd := Op2&nbsp;&nbsp;&nbsp;<br>
1110&nbsp;&nbsp;&nbsp;<br>
BIC&nbsp;&nbsp;&nbsp;<br>
Bit clear&nbsp;&nbsp;&nbsp;<br>
Rd:=RnANDNOTOp2&nbsp;&nbsp;&nbsp;<br>
1111&nbsp;&nbsp;&nbsp;<br>
MVN&nbsp;&nbsp;&nbsp;<br>
Move negated&nbsp;&nbsp;&nbsp;<br>
Rd:=NOTOp2&nbsp;&nbsp;&nbsp;<br>
These&nbsp;instructions&nbsp;allow&nbsp;direct&nbsp;control&nbsp;of&nbsp;whether&nbsp;or&nbsp;not&nbsp;the&nbsp;processor's condition&nbsp;<br>
codes are affected&nbsp;by their execution through&nbsp;the S bit (bit&nbsp;20). When clear, the condi-<br>
tion&nbsp;codes&nbsp;will&nbsp;be&nbsp;unchanged;&nbsp;when&nbsp;set (and&nbsp;Rd is not r15; see&nbsp;below):&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;N&nbsp;flag is&nbsp;set if the&nbsp;result is&nbsp;negative, otherwise it&nbsp;is&nbsp;cleared&nbsp;(that is,&nbsp;N equals&nbsp;<br>
bit 31 of&nbsp;the&nbsp;result).&nbsp;<br>
•&nbsp;&nbsp;The Z&nbsp;flag is set if the&nbsp;result is&nbsp;zero, otherwise it&nbsp;is&nbsp;cleared.&nbsp;<br>
•&nbsp;&nbsp;The C&nbsp;flag&nbsp;is set to the&nbsp;carry-out from&nbsp;the&nbsp;ALU when the operation&nbsp;is arithmetic&nbsp;<br>
(ADD,&nbsp;ADC,&nbsp;SUB,&nbsp;SBC,&nbsp;RSB,&nbsp;RSC,&nbsp;CMP,&nbsp;CMN)&nbsp;or&nbsp;to&nbsp;the&nbsp;carry-out&nbsp;from&nbsp;the&nbsp;<br>
shifter&nbsp;<br>
otherwise.&nbsp;If&nbsp;no shift&nbsp;is&nbsp;required, C is preserved.&nbsp;<br>
•&nbsp;&nbsp;The V&nbsp;flag&nbsp;is&nbsp;preserved in&nbsp;non-arithmetic&nbsp;operations.&nbsp;It is&nbsp;set in&nbsp;an&nbsp;arithmetic&nbsp;<br>
operation if there is an overflow from&nbsp;bit&nbsp;30&nbsp;to bit 31 and cleared if no overflow&nbsp;<br>
occurs.&nbsp;It&nbsp;has&nbsp;significance&nbsp;only&nbsp;when&nbsp;an&nbsp;arithmetic&nbsp;operation has&nbsp;operands&nbsp;that&nbsp;are&nbsp;<br>
viewed&nbsp;as 2's&nbsp;complement&nbsp;signed&nbsp;values, and&nbsp;indicates a&nbsp;result&nbsp;that&nbsp;is&nbsp;out of&nbsp;range.&nbsp;<br>
Multiply by&nbsp;a&nbsp;<br>
constant&nbsp;<br>
These&nbsp;instructions&nbsp;may&nbsp;be used to&nbsp;multiply&nbsp;a register by&nbsp;a small constant&nbsp;much&nbsp;<br>
more efficiently than can be achieved using the&nbsp;multiply&nbsp;instructions described in&nbsp;<br>
the&nbsp;next&nbsp;section.&nbsp;Examples&nbsp;are given&nbsp;below.&nbsp;<br>
<hr>
<A name=133></a><IMG src="index-133_1.png"><br>
<IMG src="index-133_2.png"><br>
<IMG src="index-133_3.png"><br>
<b>122</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Notes&nbsp;<br>
1.&nbsp;Since&nbsp;the&nbsp;immediate&nbsp;field&nbsp;must&nbsp;be&nbsp;encoded&nbsp;within&nbsp;a&nbsp;subset&nbsp;of&nbsp;a&nbsp;32-bit&nbsp;instruction,&nbsp;<br>
not all 32-bit immediate values can be represented. The binary&nbsp;encoding&nbsp;shown&nbsp;<br>
in&nbsp;Figure 5.6&nbsp;on page 119&nbsp;shows how the&nbsp;immediate values are&nbsp;encoded. The&nbsp;<br>
immediate&nbsp;value is generated by&nbsp;rotating&nbsp;an 8-bit&nbsp;immediate&nbsp;field through&nbsp;an&nbsp;<br>
even number of bit&nbsp;positions.&nbsp;<br>
5.8 &nbsp; Multiply&nbsp;instructions&nbsp;<br>
ARM&nbsp;multiply instructions produce the product of two 32-bit binary&nbsp;numbers held&nbsp;<br>
in&nbsp;registers. The result of&nbsp;multiplying&nbsp;two&nbsp;32-bit binary&nbsp;numbers is&nbsp;a 64-bit product.&nbsp;<br>
Some&nbsp;forms of&nbsp;the&nbsp;instruction,&nbsp;available&nbsp;only on&nbsp;certain&nbsp;versions of&nbsp;the&nbsp;processor,&nbsp;<br>
store&nbsp;the full&nbsp;result&nbsp;into&nbsp;two&nbsp;independently&nbsp;specified&nbsp;registers;&nbsp;other&nbsp;forms&nbsp;store&nbsp;only&nbsp;<br>
the least&nbsp;significant 32 bits into a single&nbsp;register.&nbsp;<br>
In&nbsp;all&nbsp;cases there&nbsp;is&nbsp;a&nbsp;multiply-accumulate&nbsp;variant&nbsp;that&nbsp;adds&nbsp;the&nbsp;product&nbsp;to&nbsp;a&nbsp;run-<br>
ning total&nbsp;and&nbsp;both signed&nbsp;and&nbsp;unsigned&nbsp;operands may be&nbsp;used. The&nbsp;least significant&nbsp;<br>
32&nbsp;bits&nbsp;of the&nbsp;result&nbsp;are&nbsp;the&nbsp;same&nbsp;for signed&nbsp;and&nbsp;unsigned&nbsp;operands, so&nbsp;there&nbsp;is&nbsp;no&nbsp;need&nbsp;<br>
for separate signed&nbsp;and&nbsp;unsigned versions&nbsp;of&nbsp;the 32-bit&nbsp;result&nbsp;instructions.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure 5.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Multiply&nbsp;instruction binary&nbsp;encoding.&nbsp;<br>
<hr>
<A name=134></a><b>Multiply&nbsp;instructions</b>&nbsp;<br>
<b>123</b>&nbsp;<br>
<b>Table&nbsp;</b>5.5&nbsp;&nbsp;&nbsp;Multiply&nbsp;instructions.&nbsp;<br>
&nbsp;<br>
Opcode&nbsp;<br>
[23:21]&nbsp;&nbsp;&nbsp;&nbsp;Mnemonic&nbsp;&nbsp;&nbsp;&nbsp;Meaning&nbsp;&nbsp;&nbsp;<br>
Effect&nbsp;&nbsp;&nbsp;<br>
000&nbsp;&nbsp;&nbsp;<br>
MUL&nbsp;&nbsp;&nbsp;<br>
Multiply&nbsp;(32-bit&nbsp;result)&nbsp;&nbsp;&nbsp;<br>
Rd:=(Rm*Rs)[31:0]&nbsp;&nbsp;&nbsp;<br>
001&nbsp;&nbsp;&nbsp;<br>
MLA&nbsp;&nbsp;&nbsp;<br>
Multiply-accumulate&nbsp;(32-bit&nbsp;result)&nbsp;&nbsp;&nbsp;&nbsp;Rd:=(Rm*Rs + Rn)[31:0]&nbsp;&nbsp;&nbsp;<br>
100&nbsp;&nbsp;&nbsp;<br>
UMULL&nbsp;&nbsp;&nbsp;<br>
Unsigned multiply&nbsp;long&nbsp;&nbsp;&nbsp;<br>
RdHirRdLo := Rm&nbsp;* Rs&nbsp;&nbsp;&nbsp;<br>
101&nbsp;&nbsp;&nbsp;<br>
UMLAL&nbsp;&nbsp;&nbsp;<br>
Unsigned multiply-accumulate&nbsp;long&nbsp;<br>
RdHi: RdLo += Rm&nbsp;*&nbsp;Rs&nbsp;&nbsp;&nbsp;<br>
110&nbsp;&nbsp;&nbsp;<br>
SMULL&nbsp;&nbsp;&nbsp;<br>
Signed multiply&nbsp;long&nbsp;&nbsp;&nbsp;<br>
RdHi:RdLo := Rm&nbsp;* Rs&nbsp;&nbsp;&nbsp;<br>
111&nbsp;&nbsp;&nbsp;&nbsp;SMLAL&nbsp;&nbsp;&nbsp;<br>
Signed multiply-accumulate long&nbsp;&nbsp;&nbsp;<br>
RdHi:RdLo+=Rm*Rs&nbsp;&nbsp;&nbsp;<br>
Description&nbsp;<br>
The&nbsp;functions&nbsp;of the various&nbsp;forms of&nbsp;multiply&nbsp;are listed in Table 5.5.&nbsp;The notation&nbsp;<br>
used&nbsp;in&nbsp;the table&nbsp;is&nbsp;as&nbsp;follows:&nbsp;<br>
•&nbsp;&nbsp;'RdHi:RdLo'&nbsp;is&nbsp;the 64-bit number&nbsp;formed by&nbsp;concatenating RdHi (the&nbsp;most sig&nbsp;<br>
nificant 32 bits) and RdLo (the&nbsp;least significant 32 bits).'[31:0]'&nbsp;selects only&nbsp;the&nbsp;<br>
least significant&nbsp;32 bits of&nbsp;the&nbsp;result.&nbsp;<br>
•&nbsp;&nbsp;Simple assignment is&nbsp;denoted by&nbsp;':='.&nbsp;<br>
•&nbsp;&nbsp;Accumulation (adding the right-hand side to the left) is&nbsp;denoted by'+='.&nbsp;<br>
The&nbsp;S bit controls&nbsp;the&nbsp;setting of&nbsp;the condition codes&nbsp;as&nbsp;with&nbsp;the other data&nbsp;process-<br>
ing instructions.&nbsp;When&nbsp;it is&nbsp;set in&nbsp;the&nbsp;instruction:&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;N&nbsp;flag is&nbsp;set to&nbsp;the value&nbsp;of&nbsp;bit&nbsp;31&nbsp;of&nbsp;Rd&nbsp;for&nbsp;the&nbsp;variants&nbsp;which&nbsp;produce&nbsp;a&nbsp;32-&nbsp;<br>
bit result, and&nbsp;bit 31 of&nbsp;RdHi&nbsp;for the long&nbsp;forms.&nbsp;<br>
•&nbsp;&nbsp;The Z&nbsp;flag is set if Rd or&nbsp;RdHi and&nbsp;RdLo&nbsp;are zero.&nbsp;<br>
•&nbsp;&nbsp;The C flag is set&nbsp;to&nbsp;a&nbsp;meaningless&nbsp;value.&nbsp;<br>
•&nbsp;&nbsp;The V flag&nbsp;is&nbsp;unchanged.&nbsp;<br>
Assembler&nbsp;<br>
Instructions that produce the&nbsp;least significant&nbsp;32 bits of&nbsp;the&nbsp;product:&nbsp;<br>
formats&nbsp;<br>
MUL{&lt;cond&gt;}{S} &nbsp;Rd,&nbsp;Rm,&nbsp;Rs&nbsp;<br>
MLA{&lt;cond&gt;}{S}&nbsp;&nbsp;Rd,&nbsp;Rm, Rs, Rn&nbsp;<br>
The following instructions&nbsp;produce&nbsp;the full&nbsp;64-bit result:&nbsp;<br>
&lt;mul&gt;{&lt;cond&gt;}{S}RdHi, &nbsp;&nbsp;RdLo,&nbsp;&nbsp;&nbsp;Rm, &nbsp;&nbsp;Rs&nbsp;where&nbsp;&lt;mul&gt;&nbsp;is&nbsp;<br>
one of&nbsp;the 64-bit&nbsp;multiply types (UMULL,&nbsp;UMLAL,&nbsp;SMULL,&nbsp;SMLAL).&nbsp;<br>
<hr>
<A name=135></a><IMG src="index-135_1.png"><br>
<b>124&nbsp;</b><br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
<b>Examples&nbsp;</b><br>
<b>To&nbsp;form&nbsp;a scalar&nbsp;product&nbsp;of&nbsp;two vectors:</b>&nbsp;<br>
&nbsp;<br>
MOV&nbsp;&nbsp;&nbsp;<br>
rll,&nbsp;#20&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp; initialize&nbsp;loop&nbsp;counter&nbsp;&nbsp;&nbsp;<br>
MOV&nbsp;&nbsp;&nbsp;<br>
rlO, #0&nbsp;&nbsp;&nbsp;<br>
initialize total&nbsp;&nbsp;&nbsp;<br>
LOOP &nbsp; &nbsp;LDR&nbsp;&nbsp;&nbsp;<br>
r0,&nbsp;[r8], #4&nbsp;&nbsp;&nbsp;<br>
get first&nbsp;component..&nbsp;&nbsp;&nbsp;<br>
LDR&nbsp;&nbsp;&nbsp;<br>
r1,&nbsp;[r9], #4&nbsp;&nbsp;&nbsp;<br>
. .and second&nbsp;&nbsp;&nbsp;<br>
MLA&nbsp;&nbsp;&nbsp;<br>
rlO,&nbsp;r0, r1,&nbsp;rlO&nbsp;&nbsp;&nbsp;<br>
accumulate&nbsp;product&nbsp;&nbsp;&nbsp;<br>
SUBS&nbsp;&nbsp;&nbsp;<br>
rll, rll,&nbsp;#1&nbsp;&nbsp;&nbsp;<br>
decrement&nbsp;loop counter&nbsp;&nbsp;&nbsp;<br>
BNE&nbsp;&nbsp;&nbsp;<br>
LOOP&nbsp;&nbsp;&nbsp;<br>
Notes<br>
&nbsp;<br>
&nbsp;<br>
1.&nbsp;&nbsp;Specifying r15 for any&nbsp;of the operand&nbsp;or result registers should&nbsp;be avoided as it&nbsp;<br>
produces unpredictable results.&nbsp;<br>
2.&nbsp;&nbsp;Rd, RdHi and&nbsp;RdLo should be&nbsp;distinct&nbsp;from&nbsp;Rm, and RdHi and RdLo&nbsp;should not&nbsp;<br>
be&nbsp;the&nbsp;same&nbsp;register.&nbsp;<br>
3.&nbsp;&nbsp;Early&nbsp;ARM processors only&nbsp;supported the 32-bit&nbsp;multiply&nbsp;instructions (MUL&nbsp;and&nbsp;<br>
MLA).&nbsp;The 64-bit&nbsp;multiplies are available only on ARM?&nbsp;versions&nbsp;with an&nbsp;'M'&nbsp;in&nbsp;<br>
their&nbsp;name&nbsp;(ARM7DM, ARM7TM,&nbsp;and so&nbsp;on)&nbsp;and subsequent&nbsp;processors.&nbsp;<br>
5.9 &nbsp; Count&nbsp;leading&nbsp;zeros&nbsp;(CLZ&nbsp;- architecture v5T&nbsp;only)&nbsp;<br>
This instruction is only available on&nbsp;ARM&nbsp;processors that support architecture v5T.&nbsp;<br>
It is useful for renormalizing numbers, and performs its functions far more effi-<br>
ciently&nbsp;than&nbsp;can&nbsp;be&nbsp;achieved using other&nbsp;ARM&nbsp;instructions.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
<b>Figure 5.8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Count leading&nbsp;zeros instruction binary&nbsp;encoding.&nbsp;<br>
<hr>
<A name=136></a><IMG src="index-136_1.png"><br>
<b>Single&nbsp;word&nbsp;and&nbsp;unsigned byte&nbsp;data&nbsp;transfer&nbsp;instructions</b>&nbsp;<br>
<b>125</b>&nbsp;<br>
Description&nbsp;<br>
The instruction sets&nbsp;Rd&nbsp;to the number&nbsp;of&nbsp;the bit position of&nbsp;the&nbsp;most&nbsp;significant 1 in&nbsp;<br>
Rm.&nbsp;If Rm&nbsp;is&nbsp;zero Rd&nbsp;will be&nbsp;set to&nbsp;32.&nbsp;<br>
Assembler&nbsp;<br>
format&nbsp;<br>
Example&nbsp;<br>
Notes&nbsp;<br>
&nbsp;<br>
1. Only processors that implement&nbsp;ARM&nbsp;architecture v5T support the CLZ instruc-<br>
tion (see Section 5.23 on page&nbsp;147).&nbsp;<br>
5.10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Single word and unsigned byte data transfer instructions&nbsp;<br>
These&nbsp;instructions&nbsp;are&nbsp;the most&nbsp;flexible&nbsp;way to&nbsp;transfer&nbsp;single bytes&nbsp;or&nbsp;words&nbsp;of&nbsp;data&nbsp;<br>
between&nbsp;ARM's registers and&nbsp;memory. Transferring large blocks of&nbsp;data is usually&nbsp;<br>
better done&nbsp;using&nbsp;the&nbsp;multiple&nbsp;register&nbsp;transfer&nbsp;instructions,&nbsp;and&nbsp;recent&nbsp;ARM proces-<br>
sors also&nbsp;support instructions&nbsp;for transferring&nbsp;half-words and signed bytes.&nbsp;<br>
Provided that&nbsp;a register&nbsp;has&nbsp;been initialized to point somewhere near&nbsp;(usually&nbsp;<br>
within&nbsp;4 Kbytes&nbsp;of)&nbsp;the required memory address,&nbsp;these&nbsp;instructions&nbsp;provide&nbsp;an&nbsp;effi-<br>
cient load and&nbsp;store mechanism&nbsp;with&nbsp;a relatively rich set of&nbsp;addressing modes which&nbsp;<br>
includes&nbsp;immediate&nbsp;and register offsets,&nbsp;auto-indexing&nbsp;and PC-relative.&nbsp;<br>
Description&nbsp;<br>
These&nbsp;instructions&nbsp;construct&nbsp;an&nbsp;address&nbsp;starting from&nbsp;a base register (Rn), then&nbsp;<br>
adding (U&nbsp;= 1)&nbsp;or&nbsp;subtracting (U = 0) an&nbsp;unsigned immediate or&nbsp;(possibly scaled)&nbsp;<br>
register offset. The base&nbsp;or&nbsp;computed&nbsp;address is used&nbsp;to&nbsp;load&nbsp;(L&nbsp;=&nbsp;1) or&nbsp;store&nbsp;(L&nbsp;= 0)&nbsp;<br>
an&nbsp;unsigned&nbsp;byte&nbsp;(B&nbsp;=&nbsp;1)&nbsp;or word&nbsp;(B&nbsp;=&nbsp;0)&nbsp;quantity&nbsp;to&nbsp;or from&nbsp;a register&nbsp;(Rd),&nbsp;from&nbsp;or&nbsp;<br>
to&nbsp;memory.&nbsp;When a&nbsp;byte&nbsp;is&nbsp;loaded&nbsp;into&nbsp;a&nbsp;register&nbsp;it&nbsp;is&nbsp;zero&nbsp;extended to&nbsp;32 bits.&nbsp;When&nbsp;<br>
a&nbsp;byte&nbsp;is&nbsp;stored&nbsp;into&nbsp;memory, the bottom&nbsp;eight bits&nbsp;of&nbsp;the register&nbsp;are&nbsp;stored&nbsp;into the&nbsp;<br>
addressed location.&nbsp;<br>
A pre-indexed&nbsp;(P =&nbsp;1)&nbsp;addressing&nbsp;mode&nbsp;uses&nbsp;the&nbsp;computed&nbsp;address&nbsp;for&nbsp;the&nbsp;load&nbsp;or&nbsp;<br>
store operation,&nbsp;and&nbsp;then, when&nbsp;write-back&nbsp;is&nbsp;requested (W&nbsp;=1), updates&nbsp;the base reg-<br>
ister to&nbsp;the&nbsp;computed&nbsp;value.&nbsp;<br>
<hr>
<A name=137></a><IMG src="index-137_1.png"><br>
<b>126</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Binary encoding&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;5.9 &nbsp;&nbsp;</b>Single&nbsp;word and unsigned&nbsp;byte&nbsp;data&nbsp;transfer instruction binary&nbsp;encoding.&nbsp;<br>
A post-indexed&nbsp;(P = 0)&nbsp;addressing mode uses the unmodified base register for the&nbsp;<br>
transfer and then updates the&nbsp;base register&nbsp;to the computed&nbsp;address irrespective of&nbsp;the&nbsp;<br>
W&nbsp;bit (since the offset has&nbsp;no&nbsp;significance other than as a&nbsp;base register modifier, and&nbsp;<br>
can always be&nbsp;set to&nbsp;immediate zero&nbsp;if&nbsp;no&nbsp;change is&nbsp;desired). Since&nbsp;the W&nbsp;bit&nbsp;is&nbsp;unused&nbsp;<br>
in&nbsp;this case,&nbsp;it&nbsp;has an&nbsp;alternative function&nbsp;which&nbsp;is only relevant&nbsp;in&nbsp;code&nbsp;which&nbsp;is not&nbsp;<br>
running&nbsp;in&nbsp;user&nbsp;mode:&nbsp;setting W&nbsp;= 1&nbsp;causes&nbsp;the processor&nbsp;to&nbsp;request&nbsp;a user&nbsp;mode&nbsp;<br>
access to&nbsp;memory, allowing the&nbsp;operating system&nbsp;to adopt a&nbsp;user view of the&nbsp;memory&nbsp;<br>
translation and&nbsp;protection scheme.&nbsp;<br>
<hr>
<A name=138></a><IMG src="index-138_1.png"><br>
<b>Single&nbsp;word&nbsp;and&nbsp;unsigned byte&nbsp;data&nbsp;transfer&nbsp;instructions</b>&nbsp;<br>
127&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Assembler&nbsp;<br>
<b>The&nbsp;pre-indexed&nbsp;form&nbsp;of the instruction:</b>&nbsp;<br>
format&nbsp;<br>
LDRlSTR{&lt;cond&gt;}{B} Rd,&nbsp;[Rn, &lt;offset&gt;]{!}&nbsp;<b>The&nbsp;</b><br>
<b>post-indexed form:</b>&nbsp;<br>
LDRlSTR{&lt;cond&gt;}{B}{T} Rd, [Rn],&nbsp;&lt;offset&gt;&nbsp;<b>A&nbsp;</b><br>
<b>useful PC-relative&nbsp;form that&nbsp;leaves&nbsp;the assembler&nbsp;to&nbsp;do&nbsp;all the work:</b>&nbsp;<br>
LDRlSTR{&lt;COnd&gt;}{B} &nbsp;&nbsp;Rd,&nbsp;&nbsp; &nbsp;LABEL&nbsp;<br>
LDR&nbsp;is 'load register',&nbsp;STR&nbsp;is 'store register';&nbsp;the optional 'B'&nbsp;selects an unsigned&nbsp;<br>
byte&nbsp;transfer,&nbsp;the default&nbsp;is&nbsp;word; &lt;of&nbsp;f&nbsp;set&gt;&nbsp;may&nbsp;be&nbsp;#&nbsp;+&nbsp;/-&lt;l2-bit&nbsp;immediate&gt;&nbsp;or&nbsp;<br>
+ /-Rm&nbsp;{, shift} where&nbsp;the&nbsp;shift specifier is the same&nbsp;as for data&nbsp;processing&nbsp;<br>
instructions&nbsp;except&nbsp;that&nbsp;register specified shift&nbsp;amounts&nbsp;are&nbsp;not&nbsp;available;&nbsp;!&nbsp;selects&nbsp;<br>
write-back&nbsp;(auto-indexing)&nbsp;in&nbsp;the&nbsp;pre-indexed&nbsp;form.&nbsp;<br>
The&nbsp;T&nbsp;flag&nbsp;selects the&nbsp;user&nbsp;view&nbsp;of&nbsp;the&nbsp;memory translation&nbsp;and&nbsp;protection&nbsp;system&nbsp;<br>
and&nbsp;should only be&nbsp;used in non-user&nbsp;modes.&nbsp;The&nbsp;user should fully&nbsp;understand the&nbsp;<br>
memory&nbsp;management environment&nbsp;in&nbsp;which the processor&nbsp;is being&nbsp;used,&nbsp;so&nbsp;this is&nbsp;<br>
really&nbsp;only a&nbsp;facility for&nbsp;operating system&nbsp;experts.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Examples&nbsp;<br>
To store a&nbsp;byte&nbsp;in r0 to a&nbsp;peripheral:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The assembler will use&nbsp;a pre-indexed, PC-relative addressing&nbsp;mode&nbsp;to load&nbsp;the&nbsp;<br>
address&nbsp;into&nbsp;rl. The literal&nbsp;must&nbsp;be&nbsp;within&nbsp;range (that&nbsp;is, within&nbsp;4 Kbytes&nbsp;of&nbsp;the load&nbsp;<br>
instruction)&nbsp;for this&nbsp;to&nbsp;be&nbsp;possible.&nbsp;<br>
Notes&nbsp;<br>
1.&nbsp;&nbsp;Using&nbsp;the&nbsp;PC&nbsp;as the&nbsp;base&nbsp;address delivers the&nbsp;address of&nbsp;the instruction&nbsp;plus&nbsp;eight&nbsp;<br>
bytes;&nbsp;it&nbsp;should&nbsp;not be used&nbsp;as the offset register,&nbsp;nor with any auto-indexing&nbsp;<br>
addressing&nbsp;mode&nbsp;(including any&nbsp;post-indexed&nbsp;mode).&nbsp;<br>
2.&nbsp;&nbsp;Loading a word&nbsp;into the PC causes a branch&nbsp;to the loaded address and is a&nbsp;recognized&nbsp;<br>
way&nbsp;of implementing jump&nbsp;tables. Loading a byte into the PC&nbsp;should be avoided.&nbsp;<br>
3.&nbsp;&nbsp;Storing the&nbsp;PC to&nbsp;memory&nbsp;gives different&nbsp;results on different implementations of&nbsp;<br>
the processor and should therefore be avoided if possible.&nbsp;<br>
4.&nbsp;&nbsp;In general Rd,&nbsp;Rn and&nbsp;Rm&nbsp;should be&nbsp;distinct registers, though loading&nbsp;into the&nbsp;<br>
base register (Rd = Rn) is acceptable provided auto-indexing is&nbsp;not&nbsp;used&nbsp;in the&nbsp;<br>
same&nbsp;instruction.&nbsp;<br>
5.&nbsp;&nbsp;When a word&nbsp;is loaded&nbsp;from&nbsp;a non-word-aligned&nbsp;address&nbsp;the loaded&nbsp;data&nbsp;is the&nbsp;<br>
word-aligned word containing the addressed byte, rotated so that the addressed&nbsp;<br>
byte&nbsp;is&nbsp;in&nbsp;the&nbsp;least&nbsp;significant&nbsp;byte&nbsp;of&nbsp;the destination&nbsp;register.&nbsp;Some&nbsp;ARM systems&nbsp;<br>
<hr>
<A name=139></a><IMG src="index-139_1.png"><br>
<b>128</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
may&nbsp;raise an&nbsp;exception&nbsp;under&nbsp;these circumstances&nbsp;(controlled&nbsp;by&nbsp;the A flag in bit&nbsp;1&nbsp;<br>
of CP15&nbsp;register 1, described&nbsp;in Section 11.2 on page 293).&nbsp;<br>
6.&nbsp;When&nbsp;a&nbsp;word is&nbsp;stored to&nbsp;a non-word-aligned address the&nbsp;bottom&nbsp;two&nbsp;bits&nbsp;of&nbsp;the&nbsp;<br>
address are ignored&nbsp;and&nbsp;the&nbsp;word is stored&nbsp;as though&nbsp;they had&nbsp;been&nbsp;zero.&nbsp;Some&nbsp;<br>
ARM systems&nbsp;may raise an&nbsp;exception under&nbsp;these&nbsp;circumstances (again&nbsp;controlled&nbsp;<br>
by&nbsp;the A flag&nbsp;in&nbsp;CP15&nbsp;register 1).&nbsp;<br>
5.11&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Half-word and signed byte data transfer instructions&nbsp;<br>
These instructions are not supported by&nbsp;some&nbsp;early&nbsp;ARM processors. As&nbsp;a result&nbsp;of&nbsp;<br>
their late addition to the architecture they are&nbsp;somewhat&nbsp;'shoe-horned'&nbsp;into the&nbsp;<br>
instruction space&nbsp;as&nbsp;indicated&nbsp;by the split immediate field.&nbsp;<br>
The addressing&nbsp;modes available with these&nbsp;instructions are&nbsp;a subset&nbsp;of&nbsp;those availa-<br>
ble with the unsigned&nbsp;byte&nbsp;and word forms.&nbsp;<br>
Binary encoding&nbsp;<br>
<b>31</b><br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 5.10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Half-word&nbsp;and&nbsp;signed&nbsp;byte&nbsp;data&nbsp;transfer&nbsp;instruction binary&nbsp;encoding.&nbsp;<br>
<hr>
<A name=140></a><IMG src="index-140_1.png"><br>
<b>Half-word and signed byte&nbsp;data&nbsp;transfer instructions</b>&nbsp;<br>
<b>129</b>&nbsp;<br>
Description&nbsp;<br>
These instructions are very&nbsp;similar to the&nbsp;word and unsigned byte forms&nbsp;described&nbsp;<br>
in the previous&nbsp;section, but here the immediate offset is&nbsp;limited to eight&nbsp;bits&nbsp;and the&nbsp;<br>
scaled&nbsp;register&nbsp;offset&nbsp;is&nbsp;no longer available.&nbsp;<br>
<b>Table&nbsp;5.6 &nbsp;&nbsp;</b>Data type encoding.&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The S&nbsp;and H&nbsp;bits&nbsp;define&nbsp;the&nbsp;type&nbsp;of the&nbsp;operand&nbsp;to&nbsp;be&nbsp;transferred as&nbsp;listed&nbsp;in&nbsp;<br>
Table 5.6. Note that&nbsp;the&nbsp;fourth combination&nbsp;of these&nbsp;bits, corresponding to&nbsp;an&nbsp;<br>
unsigned byte&nbsp;type, is&nbsp;not available&nbsp;in&nbsp;this&nbsp;format.&nbsp;The format&nbsp;described&nbsp;in&nbsp;the&nbsp;previ-<br>
ous section should&nbsp;be used instead. Since there is no&nbsp;difference between storing signed&nbsp;<br>
and&nbsp;unsigned&nbsp;data, the only&nbsp;relevant&nbsp;forms of this&nbsp;instruction&nbsp;format are:&nbsp;<br>
•&nbsp;&nbsp;Load&nbsp;signed byte, signed half-word or&nbsp;unsigned&nbsp;half-word.&nbsp;<br>
•&nbsp;&nbsp;Store&nbsp;half-word.&nbsp;<br>
An unsigned&nbsp;value is zero-extended to 32&nbsp;bits&nbsp;when loaded; a&nbsp;signed&nbsp;value is&nbsp;<br>
extended&nbsp;to&nbsp;32 bits by&nbsp;replicating&nbsp;the&nbsp;most&nbsp;significant bit of the&nbsp;data.&nbsp;<br>
Assembler&nbsp;<br>
The pre-indexed&nbsp;form:&nbsp;<br>
formats&nbsp;<br>
LDR|STR{&lt;cond&gt;}H|SHI&nbsp;SB&nbsp;Rd,&nbsp;&nbsp;[Rn, &lt;offset&gt;] {&nbsp;! }&nbsp;<br>
The post-indexed&nbsp;form:&nbsp;<br>
LDRlSTR{&lt;cond&gt;}H|SHlSB&nbsp;Rd, [Rn],&nbsp;&lt;offset&gt;&nbsp;<br>
<b>where&nbsp;</b>&lt;of&nbsp;fset&gt;&nbsp;is&nbsp;# + /-&lt;8-bit&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;immediate&gt;&nbsp;<b>or&nbsp;</b>+/-Rm&nbsp;<b>and&nbsp;</b>HI SHI SB&nbsp;<b>selects&nbsp;</b><br>
<b>the&nbsp;data type; otherwise the assembler format&nbsp;is&nbsp;as&nbsp;for words&nbsp;and unsigned byte&nbsp;</b><br>
<b>transfers.</b>&nbsp;<br>
<hr>
<A name=141></a><IMG src="index-141_1.png"><br>
<b>130</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Examples&nbsp;<br>
To&nbsp;expand&nbsp;an&nbsp;array&nbsp;of signed&nbsp;half-words&nbsp;into&nbsp;an&nbsp;array&nbsp;of&nbsp;words:&nbsp;<br>
ADR&nbsp;r1,&nbsp;<br>
ARRAYl&nbsp;<br>
;&nbsp;half-word array&nbsp;start&nbsp;<br>
ADR r2,&nbsp;<br>
ARRAY2&nbsp;<br>
;&nbsp;word array&nbsp;start&nbsp;<br>
ADR r3,&nbsp;<br>
ENDARR1&nbsp;<br>
;&nbsp;ARRAYl end&nbsp;+ 2&nbsp;<br>
LOOP &nbsp; LDRSH&nbsp;<br>
r0,&nbsp;[r1],&nbsp;#2&nbsp;<br>
;&nbsp;get signed&nbsp;half-word&nbsp;<br>
STR&nbsp;<br>
r0,&nbsp;[r2], #4&nbsp;<br>
;&nbsp;save word&nbsp;<br>
CMP&nbsp;r1,&nbsp;<br>
r3&nbsp;<br>
;&nbsp;check for&nbsp;end of array&nbsp;<br>
BLT LOOP&nbsp;<br>
;&nbsp;if not finished, loop&nbsp;<br>
Notes<br>
&nbsp;<br>
&nbsp;<br>
1.&nbsp;&nbsp;Similar limitations to&nbsp;those&nbsp;on&nbsp;the&nbsp;word&nbsp;and&nbsp;unsigned byte transfers described in&nbsp;<br>
the previous section apply&nbsp;on&nbsp;the use of r15&nbsp;and the&nbsp;register operands.&nbsp;<br>
2.&nbsp;&nbsp;All half-word transfers&nbsp;should use half-word aligned addresses.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
5.12 &nbsp; Multiple&nbsp;register&nbsp;transfer&nbsp;instructions&nbsp;<br>
The&nbsp;ARM multiple&nbsp;register&nbsp;transfer&nbsp;instructions&nbsp;allow any&nbsp;subset&nbsp;(or all) of the&nbsp;<br>
16 registers&nbsp;visible&nbsp;in&nbsp;the&nbsp;current operating&nbsp;mode to&nbsp;be&nbsp;loaded from&nbsp;or stored to&nbsp;<br>
memory. A form&nbsp;of the&nbsp;instruction&nbsp;also&nbsp;allows&nbsp;the&nbsp;operating system&nbsp;to load&nbsp;or&nbsp;<br>
store the&nbsp;user-mode registers to save&nbsp;or&nbsp;restore the&nbsp;user process&nbsp;state, and&nbsp;<br>
another form&nbsp;allows the&nbsp;CPSR to&nbsp;be restored from&nbsp;the SPSR as part of a return&nbsp;<br>
from&nbsp;an exception handler.&nbsp;<br>
These&nbsp;instructions are used&nbsp;on&nbsp;procedure entry&nbsp;and return&nbsp;to&nbsp;save&nbsp;and restore work-<br>
space&nbsp;registers&nbsp;and are useful&nbsp;for high-bandwidth&nbsp;memory&nbsp;block copy&nbsp;routines.&nbsp;<br>
<b>Figure&nbsp;5.11 &nbsp; &nbsp;</b>Multiple&nbsp;register data transfer&nbsp;instruction binary&nbsp;encoding.&nbsp;<br>
Binary encoding&nbsp;<br>
<hr>
<A name=142></a><b>Multiple register&nbsp;transfer instructions</b>&nbsp;<br>
<b>131</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Description&nbsp;<br>
The&nbsp;register list in the bottom&nbsp;16&nbsp;bits&nbsp;of&nbsp;the instruction includes&nbsp;a&nbsp;bit&nbsp;for each&nbsp;visi-<br>
ble register,&nbsp;with&nbsp;bit&nbsp;0&nbsp;controlling&nbsp;whether&nbsp;or&nbsp;not&nbsp;r0&nbsp;is&nbsp;transferred,&nbsp;bit&nbsp;1&nbsp;controls&nbsp;r1,&nbsp;<br>
and&nbsp;so&nbsp;on&nbsp;up&nbsp;to&nbsp;bit 15&nbsp;which controls&nbsp;the&nbsp;transfer&nbsp;of&nbsp;the&nbsp;PC.&nbsp;<br>
The registers are loaded from&nbsp;or stored&nbsp;to&nbsp;a&nbsp;contiguous&nbsp;block of&nbsp;memory&nbsp;words&nbsp;<br>
defined&nbsp;by&nbsp;the base&nbsp;register and&nbsp;the addressing mode.&nbsp;The base address&nbsp;will&nbsp;be incre-<br>
mented (U = 1)&nbsp;or decremented (U = 0) before&nbsp;(P = 1) or after (P = 0) each&nbsp;word trans-<br>
fer. Auto-indexing is&nbsp;supported;&nbsp;if&nbsp;W&nbsp;= 1 the base register&nbsp;will&nbsp;be&nbsp;increased (U = 1) or&nbsp;<br>
decreased (U =&nbsp;0) by&nbsp;the number of bytes&nbsp;transferred when&nbsp;the instruction&nbsp;completes.&nbsp;<br>
Special&nbsp;forms&nbsp;of&nbsp;the instruction&nbsp;allow it&nbsp;to&nbsp;be&nbsp;used&nbsp;to&nbsp;restore the&nbsp;CPSR:&nbsp;if&nbsp;the PC&nbsp;is&nbsp;<br>
in the register list of a load&nbsp;multiple and the&nbsp;S bit is set,&nbsp;the&nbsp;SPSR of the&nbsp;current mode&nbsp;<br>
will be&nbsp;copied into&nbsp;the CPSR, giving&nbsp;an atomic return&nbsp;and restore&nbsp;state instruction.&nbsp;<br>
This form&nbsp;should not be used in user&nbsp;mode&nbsp;code since&nbsp;there&nbsp;is no SPSR in user&nbsp;mode.&nbsp;<br>
If the&nbsp;PC is not in&nbsp;the register list and&nbsp;the S&nbsp;bit is set, both&nbsp;load&nbsp;and&nbsp;store&nbsp;multiple&nbsp;<br>
instructions&nbsp;executed&nbsp;in&nbsp;non-user modes will&nbsp;transfer the user mode&nbsp;registers (while&nbsp;<br>
using&nbsp;the&nbsp;current&nbsp;mode&nbsp;base&nbsp;register).&nbsp;This&nbsp;allows&nbsp;an&nbsp;operating&nbsp;system&nbsp;to&nbsp;save&nbsp;and&nbsp;<br>
restore user process state.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Assembler&nbsp;<br>
<b>The normal form of the&nbsp;instruction&nbsp;is:</b>&nbsp;<br>
format&nbsp;<br>
LDMISTM{&lt;cond&gt;}&lt;add mode&gt; Rn{!}, &lt;registers&gt;&nbsp;<br>
where odd&nbsp;mode&gt; specifies&nbsp;one of the addressing&nbsp;modes detailed in Table 3.1 on&nbsp;<br>
page 62. The instruction bits correspond closely&nbsp;to&nbsp;the&nbsp;mechanistic view described&nbsp;<br>
in this table,&nbsp;with&nbsp;'increment'&nbsp;corresponding to U = 1 and&nbsp;'before'&nbsp;corresponding to&nbsp;<br>
P = 1.&nbsp;'!'&nbsp;specifies auto-indexing&nbsp;(W = 1), and &lt;registers&gt; is a&nbsp;list of&nbsp;registers&nbsp;<br>
and register ranges enclosed&nbsp;in curly&nbsp;brackets,&nbsp;for example:&nbsp;{r0,&nbsp;r3-r7,&nbsp;pc}.&nbsp;<br>
In a&nbsp;non-user&nbsp;mode, the CPSR&nbsp;may&nbsp;be restored by:&nbsp;<br>
LDM{&lt;cond&gt;}&lt;add&nbsp;mode&gt;&nbsp;R&nbsp;n&nbsp;{&nbsp;!&nbsp;}&nbsp;,&nbsp;&nbsp;&nbsp;&nbsp;&lt;registers &nbsp; +&nbsp;pc&gt;^&nbsp;<br>
The register list&nbsp;must&nbsp;contain the PC. In a non-user&nbsp;mode, the user registers&nbsp;may&nbsp;be&nbsp;<br>
saved or restored by:&nbsp;<br>
LDM&nbsp;I&nbsp;STM{&lt;cond&gt;}&lt;add&nbsp;mode&gt;&nbsp;Rn, &nbsp;&nbsp;&lt;registers &nbsp;&nbsp;- &nbsp;<br>
pc&gt;~&nbsp;Here&nbsp;the&nbsp;register list&nbsp;must&nbsp;not&nbsp;contain the PC&nbsp;and write-back is&nbsp;not&nbsp;<br>
allowed.&nbsp;<br>
Examples&nbsp;<br>
To&nbsp;save&nbsp;three&nbsp;work&nbsp;registers&nbsp;and the&nbsp;return&nbsp;address upon entering&nbsp;a subroutine:&nbsp;<br>
STMFD&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r13!,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{r0-r2,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r14}&nbsp;<br>
This assumes that r13&nbsp;has&nbsp;been&nbsp;initialized&nbsp;for&nbsp;use as a stack pointer. To&nbsp;restore the&nbsp;<br>
work registers and return:&nbsp;<br>
&nbsp;&nbsp;&nbsp;LDMFD&nbsp;&nbsp;r13!, &nbsp; &nbsp;{r0-r2, &nbsp;&nbsp;<br>
pc}&nbsp;<br>
<hr>
<A name=143></a><IMG src="index-143_1.png"><br>
<b>132</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Notes<br>
&nbsp;<br>
&nbsp;<br>
1.&nbsp;&nbsp;If the&nbsp;PC is&nbsp;specified in the register list in a&nbsp;store&nbsp;multiple&nbsp;instruction, the value&nbsp;<br>
saved is&nbsp;implementation&nbsp;dependent.&nbsp;Normally, therefore,&nbsp;specifying&nbsp;the&nbsp;PC in an&nbsp;<br>
STM&nbsp;should&nbsp;be avoided.&nbsp;(Loading the&nbsp;PC has the expected result&nbsp;and is&nbsp;a stand&nbsp;<br>
ard way&nbsp;of&nbsp;returning from&nbsp;a procedure.)&nbsp;<br>
2.&nbsp;&nbsp;The&nbsp;base&nbsp;register may be&nbsp;specified&nbsp;in&nbsp;the&nbsp;transfer&nbsp;list&nbsp;of&nbsp;either&nbsp;a&nbsp;load&nbsp;or&nbsp;store mul&nbsp;<br>
tiple,&nbsp;but write-back&nbsp;should not be&nbsp;specified in&nbsp;the&nbsp;same&nbsp;instruction&nbsp;since&nbsp;the&nbsp;<br>
result of&nbsp;doing&nbsp;so is unpredictable.&nbsp;<br>
3.&nbsp;&nbsp;If the base register contains an address that&nbsp;is not word-aligned, the bottom&nbsp;two&nbsp;<br>
bits will&nbsp;be&nbsp;ignored. Some&nbsp;ARM systems&nbsp;may generate&nbsp;an exception.&nbsp;<br>
4.&nbsp;&nbsp;In&nbsp;architecture v5T only, the bottom&nbsp;bit&nbsp;of a loaded&nbsp;PC&nbsp;updates the&nbsp;Thumb&nbsp;bit.&nbsp;<br>
5.13 &nbsp; Swap&nbsp;memory&nbsp;and&nbsp;register&nbsp;instructions&nbsp;(SWP)&nbsp;<br>
Swap instructions combine&nbsp;a&nbsp;load&nbsp;and&nbsp;a&nbsp;store&nbsp;of&nbsp;a&nbsp;word&nbsp;or&nbsp;an&nbsp;unsigned&nbsp;byte in&nbsp;a&nbsp;single&nbsp;<br>
instruction. Normally&nbsp;the&nbsp;two&nbsp;transfers&nbsp;are combined into an atomic&nbsp;memory opera-<br>
tion that cannot&nbsp;be split by an&nbsp;external&nbsp;memory access (for instance from&nbsp;a&nbsp;DMA con-<br>
troller), and therefore the instruction can&nbsp;be used as the basis of a semaphore&nbsp;<br>
mechanism&nbsp;to&nbsp;give mutually exclusive access to data&nbsp;structures that&nbsp;are shared&nbsp;<br>
between&nbsp;multiple processes,&nbsp;processors,&nbsp;or&nbsp;a processor&nbsp;and a&nbsp;DMA controller.&nbsp;These&nbsp;<br>
instructions&nbsp;are&nbsp;little&nbsp;used&nbsp;outside&nbsp;their&nbsp;role&nbsp;in&nbsp;the&nbsp;construction&nbsp;of semaphores.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
<b>Figure 5.12&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Swap memory&nbsp;and register instruction binary&nbsp;encoding.&nbsp;<br>
Description&nbsp;<br>
The instruction loads the&nbsp;word&nbsp;(B&nbsp;= 0)&nbsp;or&nbsp;unsigned byte&nbsp;(B =&nbsp;1)&nbsp;at the&nbsp;memory&nbsp;loca-<br>
tion addressed&nbsp;by&nbsp;Rn into&nbsp;Rd, and stores&nbsp;the same&nbsp;data type&nbsp;from&nbsp;Rm&nbsp;into the&nbsp;same&nbsp;<br>
memory&nbsp;location.&nbsp;Rd&nbsp;and Rm&nbsp;may&nbsp;be&nbsp;the same&nbsp;register (but&nbsp;should&nbsp;both be&nbsp;distinct&nbsp;<br>
from&nbsp;Rn),&nbsp;in&nbsp;which case&nbsp;the&nbsp;register&nbsp;and&nbsp;memory values&nbsp;are exchanged. The&nbsp;ARM&nbsp;<br>
executes separate&nbsp;memory&nbsp;read and then&nbsp;memory&nbsp;write cycles,&nbsp;but asserts a&nbsp;'lock'&nbsp;<br>
signal to indicate&nbsp;to&nbsp;the memory system&nbsp;that&nbsp;the&nbsp;two&nbsp;cycles&nbsp;should not be separated.&nbsp;<br>
<hr>
<A name=144></a><IMG src="index-144_1.png"><br>
<b>Status&nbsp;register to&nbsp;general register transfer instructions</b>&nbsp;<br>
<b>133</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Assembler&nbsp;<br>
SWP{&lt;cond&gt;}{B}&nbsp;&nbsp;&nbsp;Rd, &nbsp; Rm,&nbsp;&nbsp;&nbsp;&nbsp;<br>
format&nbsp;<br>
[Rn]&nbsp;<br>
&nbsp;&nbsp;&nbsp;Example&nbsp;<br>
ADR&nbsp;&nbsp; &nbsp;&nbsp;r0,&nbsp;SEMAPHORE&nbsp;<br>
SWPB&nbsp; &nbsp;r1,&nbsp;r1,&nbsp;[r0]&nbsp;<br>
;&nbsp;exchange&nbsp;byte&nbsp;<br>
&nbsp;&nbsp;&nbsp;Notes<br>
&nbsp;<br>
&nbsp;<br>
1.&nbsp;&nbsp;The&nbsp;PC&nbsp;should&nbsp;not be used as any of the&nbsp;registers in this instruction.&nbsp;<br>
2.&nbsp;&nbsp;The&nbsp;base register (Rn) should&nbsp;not&nbsp;be&nbsp;the&nbsp;same&nbsp;as either the source&nbsp;(Rm)&nbsp;or the&nbsp;<br>
destination&nbsp;(Rd)&nbsp;register.&nbsp;<br>
5.14&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Status register to general register&nbsp;transfer instructions&nbsp;<br>
When it is necessary&nbsp;to save&nbsp;or&nbsp;modify the contents of&nbsp;the CPSR or&nbsp;the SPSR of&nbsp;the&nbsp;<br>
current&nbsp;mode, those contents&nbsp;must&nbsp;first be&nbsp;transferred into a&nbsp;general register,&nbsp;the&nbsp;<br>
selected bits&nbsp;modified and then the value&nbsp;returned to the status register. These&nbsp;<br>
instructions&nbsp;perform&nbsp;the&nbsp;first&nbsp;step in&nbsp;this sequence.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
<b>Figure 5.13&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Status&nbsp;register&nbsp;to general&nbsp;register transfer instruction binary&nbsp;encoding.&nbsp;<br>
Description&nbsp;<br>
The CPSR (R&nbsp;= 0)&nbsp;or&nbsp;the current&nbsp;mode SPSR (R&nbsp;= 1)&nbsp;is copied into the destination&nbsp;<br>
register&nbsp;(Rd).&nbsp;All 32&nbsp;bits are&nbsp;copied.&nbsp;<br>
Assembler&nbsp;<br>
MRS{&lt;cond&gt;}&nbsp; &nbsp;Rd, &nbsp;&nbsp;<br>
format&nbsp;<br>
CPSRISPSR&nbsp;<br>
&nbsp;&nbsp;&nbsp;Examples&nbsp;<br>
MRS&nbsp;<br>
r0, &nbsp;&nbsp;<br>
; move the CPSR to&nbsp;r0 ;&nbsp;<br>
CPSR&nbsp;<br>
move&nbsp;the SPSR to&nbsp;r3&nbsp;<br>
MRS&nbsp;<br>
r3, &nbsp; &nbsp;<br>
SPSR&nbsp;<br>
<hr>
<A name=145></a><IMG src="index-145_1.png"><br>
<b>134</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
Notes&nbsp;<br>
1.&nbsp;&nbsp;The SPSR&nbsp;form&nbsp;should&nbsp;not be used in user or system&nbsp;mode since there&nbsp;is&nbsp;no&nbsp;<br>
accessible&nbsp;SPSR&nbsp;in&nbsp;those&nbsp;modes.&nbsp;<br>
2.&nbsp;&nbsp;When&nbsp;modifying the CPSR or&nbsp;SPSR care&nbsp;should be taken to&nbsp;preserve the&nbsp;values&nbsp;<br>
of all&nbsp;the&nbsp;unused&nbsp;bits; this will maximize the&nbsp;probability&nbsp;of compatibility&nbsp;with&nbsp;<br>
future uses of those bits. This is best&nbsp;achieved by&nbsp;moving&nbsp;the status register to a&nbsp;<br>
general register (using&nbsp;these&nbsp;instructions),&nbsp;modifying only the necessary&nbsp;bits and&nbsp;<br>
then&nbsp;moving&nbsp;the result&nbsp;back&nbsp;to the&nbsp;status&nbsp;register.&nbsp;<br>
5.15&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;General register to status register transfer instructions&nbsp;<br>
When it&nbsp;is necessary to&nbsp;save or&nbsp;modify the contents of the&nbsp;CPSR&nbsp;or the SPSR of the&nbsp;<br>
current mode,&nbsp;those&nbsp;contents must first&nbsp;be&nbsp;transferred into a general register, the&nbsp;<br>
selected bits modified and then the value returned to the status register. These&nbsp;<br>
instructions&nbsp;perform&nbsp;the last&nbsp;step in this&nbsp;sequence.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
<b>Figure 5.14&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Transfer to&nbsp;status register&nbsp;instruction&nbsp;binary&nbsp;encoding.&nbsp;<br>
<hr>
<A name=146></a><b>General register&nbsp;to&nbsp;status&nbsp;register transfer&nbsp;instructions</b>&nbsp;<br>
<b>135</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Description&nbsp;<br>
The operand, which&nbsp;may&nbsp;be a register (Rm)&nbsp;or&nbsp;a rotated 8-bit immediate (specified in the&nbsp;<br>
same&nbsp;way&nbsp;as the immediate form&nbsp;of operand2&nbsp;in&nbsp;the&nbsp;data&nbsp;processing&nbsp;instructions),&nbsp;is&nbsp;<br>
moved under a&nbsp;field&nbsp;mask to the CPSR (R = 0) or current&nbsp;mode SPSR (R = I).&nbsp;<br>
The field mask&nbsp;controls&nbsp;the&nbsp;update of&nbsp;the four&nbsp;byte&nbsp;fields&nbsp;within&nbsp;the PSR register.&nbsp;<br>
Instruction bit 16&nbsp;determines whether&nbsp;PSR[7:0] is updated,&nbsp;bit&nbsp;17&nbsp;controls PSR[15:8],&nbsp;<br>
bit 18&nbsp;controls&nbsp;PSR[23:16]&nbsp;and bit 19&nbsp;controls&nbsp;PSR[31:24].&nbsp;<br>
When an&nbsp;immediate operand is&nbsp;used only&nbsp;the flags (PSR[31:24]) may be&nbsp;selected&nbsp;<br>
for&nbsp;update. (These&nbsp;are&nbsp;the&nbsp;only&nbsp;bits&nbsp;that&nbsp;may&nbsp;be&nbsp;updated&nbsp;by&nbsp;user-mode&nbsp;code.)&nbsp;<br>
Assembler&nbsp;<br>
MSR{&lt;cond&gt;} CPSR_fISPSR_f, #&lt;32-bit immediate&gt;&nbsp;<br>
format&nbsp;<br>
MSR{&lt;cond&gt;}&nbsp;CPSR_&lt;field&gt;ISPSR_&lt;field&gt;, Rm&nbsp;<br>
where &lt;f&nbsp;ield&gt; is&nbsp;one of:&nbsp;<br>
•&nbsp;&nbsp;c - the control&nbsp;field - PSR[7:0].&nbsp;<br>
•&nbsp;&nbsp;x - the extension field - PSR[15:8] (unused on current ARMs).&nbsp;<br>
•&nbsp;&nbsp;s - the status&nbsp;field - PSR[23:16] (unused on&nbsp;current&nbsp;ARMs).&nbsp;<br>
•&nbsp;&nbsp;f- the&nbsp;flags field -PSR[31:24].&nbsp;<br>
Examples&nbsp;<br>
To&nbsp;set the&nbsp;N, Z, C and&nbsp;V flags:&nbsp;<br>
MSR&nbsp;<br>
CPSR_f, &nbsp;&nbsp;#&amp;f0000000;&nbsp; &nbsp;set&nbsp;&nbsp;all&nbsp; the&nbsp;&nbsp;flags&nbsp;<br>
&nbsp;&nbsp;&nbsp;To&nbsp;set just the C&nbsp;flag,&nbsp;preserving&nbsp;N, Z and&nbsp;V:&nbsp;<br>
MRS&nbsp;<br>
r0, &nbsp; CPSR&nbsp;<br>
move&nbsp;the&nbsp;CPSR&nbsp;to&nbsp;r0&nbsp;set&nbsp;<br>
ORR&nbsp;<br>
r0,&nbsp;&nbsp; r0,&nbsp;&nbsp;&nbsp;&nbsp;<br>
bit&nbsp;29&nbsp;of&nbsp;r0&nbsp;move&nbsp;back&nbsp;<br>
#&amp;20000000&nbsp;<br>
to CPSR&nbsp;<br>
MSR &nbsp; &nbsp; CPSR_f,&nbsp;r0&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
To&nbsp;switch&nbsp;from supervisor&nbsp;mode&nbsp;into&nbsp;IRQ mode&nbsp;(for&nbsp;instance,&nbsp;to&nbsp;initialize&nbsp;the&nbsp;IRQ&nbsp;<br>
stack pointer&nbsp;at start&nbsp;up):&nbsp;<br>
MRS&nbsp;<br>
r0,&nbsp;CPSR&nbsp;<br>
;&nbsp;move the CPSR to r0&nbsp;<br>
BIC&nbsp;<br>
r0, r0,&nbsp;#&amp;lf&nbsp;<br>
;&nbsp;clear the&nbsp;bottom 5 bits&nbsp;<br>
ORR&nbsp;<br>
r0,&nbsp;r0,&nbsp;#&amp;12&nbsp;<br>
;&nbsp;set&nbsp;the&nbsp;bits&nbsp;to&nbsp;IRQ mode&nbsp;<br>
MSR CPSR&nbsp;<br>
c,&nbsp;<br>
r0&nbsp;<br>
;&nbsp;<br>
move back&nbsp;to&nbsp;CPSR&nbsp;<br>
In&nbsp;this&nbsp;case it&nbsp;is necessary&nbsp;to copy&nbsp;the original&nbsp;CPSR value in&nbsp;order not&nbsp;to&nbsp;change&nbsp;<br>
the interrupt&nbsp;enable&nbsp;settings.&nbsp;The&nbsp;particular&nbsp;case illustrated&nbsp;could be&nbsp;simplified&nbsp;since&nbsp;<br>
IRQ&nbsp;mode just&nbsp;requires one&nbsp;bit&nbsp;cleared from&nbsp;supervisor&nbsp;mode (see Table&nbsp;5.1&nbsp;on&nbsp;<br>
page&nbsp;108),&nbsp;but&nbsp;the code&nbsp;above&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;move between&nbsp;any&nbsp;two&nbsp;non-user&nbsp;modes&nbsp;<br>
or from&nbsp;a non-user&nbsp;mode into&nbsp;user&nbsp;mode.&nbsp;<br>
The mode change&nbsp;takes effect&nbsp;only after the&nbsp;MSR&nbsp;has&nbsp;been&nbsp;executed; the&nbsp;intermedi-<br>
ate&nbsp;working&nbsp;has&nbsp;no&nbsp;effect&nbsp;on&nbsp;the&nbsp;mode&nbsp;until&nbsp;the&nbsp;result&nbsp;is&nbsp;copied&nbsp;back&nbsp;into&nbsp;the&nbsp;CPSR.&nbsp;<br>
<hr>
<A name=147></a><b>136</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Notes<br>
&nbsp;<br>
&nbsp;<br>
1.&nbsp;&nbsp;Attempts&nbsp;to&nbsp;modify&nbsp;any&nbsp;of CPSR[23:0]&nbsp;whilst&nbsp;in&nbsp;user&nbsp;mode&nbsp;have&nbsp;no&nbsp;effect.&nbsp;<br>
2.&nbsp;&nbsp;Attempts to access the SPSR&nbsp;whilst in user&nbsp;or system&nbsp;mode&nbsp;should be avoided,&nbsp;<br>
since&nbsp;they&nbsp;have&nbsp;unpredictable results&nbsp;as there is no&nbsp;SPSR&nbsp;in these&nbsp;modes.&nbsp;<br>
5.16 &nbsp; Coprocessor&nbsp;instructions&nbsp;<br>
The ARM architecture supports a general&nbsp;mechanism&nbsp;for extending the instruction&nbsp;<br>
set&nbsp;through the addition&nbsp;of&nbsp;coprocessors. The&nbsp;most&nbsp;common&nbsp;use of&nbsp;a coprocessor is&nbsp;<br>
the system&nbsp;coprocessor used&nbsp;to control on-chip functions such as the&nbsp;cache and&nbsp;<br>
memory&nbsp;management unit on&nbsp;the&nbsp;ARM720. A floating-point&nbsp;ARM&nbsp;coprocessor has&nbsp;<br>
also been&nbsp;developed,&nbsp;and application-specific&nbsp;coprocessors are a&nbsp;possibility.&nbsp;<br>
Coprocessor&nbsp;<br>
ARM coprocessors have their own private&nbsp;register sets&nbsp;and their state is&nbsp;controlled&nbsp;<br>
registers&nbsp;<br>
by instructions&nbsp;that&nbsp;mirror the&nbsp;instructions&nbsp;that control&nbsp;ARM registers.&nbsp;<br>
The&nbsp;ARM has sole&nbsp;responsibility&nbsp;for control&nbsp;flow, so&nbsp;the&nbsp;coprocessor instructions&nbsp;<br>
are concerned with&nbsp;data&nbsp;processing and&nbsp;data&nbsp;transfer. Following RISC&nbsp;load-store&nbsp;<br>
architectural&nbsp;principles,&nbsp;these&nbsp;categories are&nbsp;cleanly&nbsp;separated.&nbsp;The&nbsp;instruction formats&nbsp;<br>
reflect this:&nbsp;<br>
Coprocessor&nbsp;<br>
•&nbsp;&nbsp;Coprocessor data operations&nbsp;are&nbsp;completely&nbsp;internal to the&nbsp;coprocessor and cause&nbsp;<br>
data operations&nbsp;<br>
a state change in the coprocessor&nbsp;registers.&nbsp;An example would be floating-point&nbsp;<br>
addition, where&nbsp;two&nbsp;registers&nbsp;in&nbsp;the&nbsp;floating-point&nbsp;coprocessor&nbsp;are&nbsp;added&nbsp;together&nbsp;<br>
and&nbsp;the result placed&nbsp;into a&nbsp;third register.&nbsp;<br>
Coprocessor&nbsp;<br>
•&nbsp;&nbsp;Coprocessor data&nbsp;transfer&nbsp;instructions&nbsp;load&nbsp;or&nbsp;store&nbsp;the&nbsp;values&nbsp;in&nbsp;coprocessor reg&nbsp;<br>
data transfers&nbsp;<br>
isters from&nbsp;or&nbsp;to memory. Since&nbsp;coprocessors&nbsp;may&nbsp;support&nbsp;their own data&nbsp;types,&nbsp;<br>
the number of&nbsp;words transferred for each&nbsp;register is coprocessor dependent. The&nbsp;<br>
ARM generates the&nbsp;memory&nbsp;address, but the coprocessor&nbsp;controls the number of&nbsp;<br>
words transferred. A coprocessor&nbsp;may&nbsp;perform&nbsp;some&nbsp;type conversion as&nbsp;part of&nbsp;<br>
the&nbsp;transfer&nbsp;(for instance the&nbsp;floating-point&nbsp;coprocessor converts&nbsp;all loaded values&nbsp;<br>
into its 80-bit internal&nbsp;representation).&nbsp;<br>
Coprocessor&nbsp;<br>
•&nbsp;&nbsp;In addition&nbsp;to&nbsp;the&nbsp;above,&nbsp;it&nbsp;is&nbsp;sometimes useful&nbsp;to&nbsp;move&nbsp;values&nbsp;between ARM&nbsp;and&nbsp;<br>
register&nbsp;transfers&nbsp;<br>
coprocessor&nbsp;&nbsp;registers. &nbsp;&nbsp;Again&nbsp;&nbsp;&nbsp;taking &nbsp;&nbsp;the &nbsp;&nbsp;floating-point &nbsp;&nbsp;coprocessor&nbsp;&nbsp;<br>
as&nbsp;&nbsp; an&nbsp;<br>
illustration,&nbsp;a 'FIX'&nbsp;instruction takes&nbsp;a floating-point&nbsp;value from&nbsp;a coprocessor&nbsp;<br>
register, converts it to&nbsp;an integer,&nbsp;and&nbsp;moves the&nbsp;integer into an&nbsp;ARM&nbsp;register.&nbsp;A&nbsp;<br>
floating-point comparison produces a&nbsp;result&nbsp;which&nbsp;is often needed to&nbsp;affect&nbsp;<br>
control&nbsp;flow,&nbsp;so&nbsp;the&nbsp;result&nbsp;of&nbsp;the compare&nbsp;must&nbsp;be&nbsp;moved&nbsp;to&nbsp;the&nbsp;ARM&nbsp;CPSR.&nbsp;<br>
<hr>
<A name=148></a><IMG src="index-148_1.png"><br>
<b>Coprocessor data&nbsp;operations</b>&nbsp;<br>
<b>137</b>&nbsp;<br>
Taken together&nbsp;these&nbsp;instructions support&nbsp;a generalized&nbsp;extension&nbsp;of the ARM&nbsp;<br>
instruction set&nbsp;to&nbsp;support application-specific&nbsp;data&nbsp;types&nbsp;and&nbsp;functions.&nbsp;<br>
5.17 &nbsp; Coprocessor&nbsp;data&nbsp;operations&nbsp;<br>
These&nbsp;instructions are&nbsp;used&nbsp;to&nbsp;control&nbsp;internal&nbsp;operations&nbsp;on&nbsp;data&nbsp;in&nbsp;coprocessor regis-<br>
ters. The standard format follows the&nbsp;3-address form&nbsp;of ARM's integer&nbsp;data&nbsp;processing&nbsp;<br>
instructions, but other interpretations of all the&nbsp;coprocessor fields are possible.&nbsp;<br>
Binary encoding&nbsp;<br>
31&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;5.15 &nbsp;&nbsp;</b>Coprocessor data&nbsp;processing&nbsp;instruction binary&nbsp;encoding.&nbsp;<br>
Description&nbsp;<br>
The ARM offers this instruction to any coprocessors that&nbsp;may&nbsp;be present. If it is&nbsp;<br>
accepted&nbsp;by&nbsp;one of&nbsp;them&nbsp;the ARM proceeds to&nbsp;the&nbsp;next instruction;&nbsp;if&nbsp;it is&nbsp;not&nbsp;<br>
accepted the ARM takes the undefined instruction trap&nbsp;(which&nbsp;may&nbsp;be used to&nbsp;<br>
implement&nbsp;a software emulation of&nbsp;the&nbsp;missing coprocessor).&nbsp;<br>
Normally the&nbsp;coprocessor identified with&nbsp;the&nbsp;coprocessor&nbsp;number CP# will&nbsp;accept&nbsp;<br>
the&nbsp;instruction and perform&nbsp;the&nbsp;operation&nbsp;denned&nbsp;by&nbsp;the Copl&nbsp;and Cop2&nbsp;fields, using&nbsp;<br>
CRn&nbsp;and CRm&nbsp;as the source&nbsp;operands and&nbsp;placing the&nbsp;result&nbsp;in&nbsp;CRd.&nbsp;<br>
Assembler&nbsp;<br>
CDP{&lt;cond&gt;} &lt;CP#&gt;, &lt;Copl&gt;, CRd, CRn, CRm{, &lt;Cop2&gt;}&nbsp;<br>
format&nbsp;<br>
Examples&nbsp;<br>
CDP &nbsp;&nbsp;&nbsp;p2,&nbsp;3,&nbsp;CO,&nbsp;Cl,&nbsp;C2&nbsp;CDPEQ&nbsp;&nbsp;&nbsp;<br>
p3, 6, Cl,&nbsp;C5, C7,&nbsp;4&nbsp;<br>
Notes&nbsp;<br>
1. The interpretation of&nbsp;the Copl,&nbsp;CRn, CRd, Cop2 and CRm&nbsp;fields&nbsp;is&nbsp;<br>
coprocessor-dependent.&nbsp;The&nbsp;above&nbsp;interpretation&nbsp;is recommended and will&nbsp;<br>
maximize compatibility&nbsp;with&nbsp;ARM development tools.&nbsp;<br>
<hr>
<A name=149></a><IMG src="index-149_1.png"><br>
<b>138</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
5.18 &nbsp; Coprocessor&nbsp;data&nbsp;transfers&nbsp;<br>
The coprocessor data&nbsp;transfer&nbsp;instructions&nbsp;are&nbsp;similar to the immediate offset&nbsp;forms&nbsp;<br>
of the&nbsp;word and unsigned byte&nbsp;data transfer&nbsp;instructions described earlier, but&nbsp;with&nbsp;<br>
the offset limited to eight&nbsp;bits rather than 12.&nbsp;<br>
Auto-indexed forms are available,&nbsp;with&nbsp;pre-&nbsp;and&nbsp;post-indexed addressing.&nbsp;<br>
Binary encoding&nbsp;<br>
31<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;5.16 &nbsp;&nbsp;</b>Coprocessor&nbsp;data&nbsp;transfer&nbsp;instruction binary encoding.&nbsp;<br>
Description&nbsp;<br>
The&nbsp;instruction is&nbsp;offered&nbsp;to&nbsp;any&nbsp;coprocessors which&nbsp;may be&nbsp;present;&nbsp;if&nbsp;none accepts&nbsp;<br>
it ARM takes&nbsp;the undefined&nbsp;instruction&nbsp;trap&nbsp;and&nbsp;may&nbsp;use software&nbsp;to&nbsp;emulate the&nbsp;<br>
coprocessor.&nbsp;Normally&nbsp;the coprocessor with&nbsp;coprocessor number CP#,&nbsp;if present,&nbsp;<br>
will&nbsp;accept&nbsp;the&nbsp;instruction.&nbsp;<br>
The&nbsp;address&nbsp;calculation takes&nbsp;place within&nbsp;the ARM,&nbsp;using&nbsp;an ARM&nbsp;base&nbsp;register&nbsp;<br>
(Rn)&nbsp;and an 8-bit immediate&nbsp;offset&nbsp;which is&nbsp;scaled to a&nbsp;word&nbsp;offset&nbsp;by&nbsp;shifting it left&nbsp;two&nbsp;<br>
bit positions. The addressing&nbsp;mode and auto-indexing&nbsp;are controlled in&nbsp;the same&nbsp;way as&nbsp;<br>
the ARM word and unsigned&nbsp;byte transfer&nbsp;instructions. This defines&nbsp;the&nbsp;first transfer&nbsp;<br>
address; subsequent words are&nbsp;transferred to or from&nbsp;incrementing word addresses.&nbsp;<br>
The data&nbsp;is&nbsp;supplied by&nbsp;or received into&nbsp;a&nbsp;coprocessor register&nbsp;(CRd),&nbsp;with&nbsp;the&nbsp;<br>
number of words transferred&nbsp;being&nbsp;controlled by&nbsp;the coprocessor and&nbsp;the&nbsp;N bit select-<br>
ing&nbsp;one&nbsp;of two&nbsp;possible&nbsp;lengths.&nbsp;<br>
Assembler&nbsp;<br>
<b>The pre-indexed form:</b>&nbsp;<br>
format&nbsp;<br>
LDCISTC{&lt;cond&gt;}{L}&nbsp;&nbsp;&nbsp;&lt;CP#&gt;,&nbsp; &nbsp;CRd,&nbsp;&nbsp; &nbsp;[Rn,&nbsp; &nbsp;&lt;offset&gt;]&nbsp;<br>
{ !&nbsp;}&nbsp;<b>The post-indexed form:</b>&nbsp;<br>
LDCISTC{&lt;cond&gt;}{L}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;CP#&gt;,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CRd,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Rn],&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;offset&gt;&nbsp;<br>
<hr>
<A name=150></a><b>Coprocessor register&nbsp;transfers</b>&nbsp;<br>
<b>139</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
In&nbsp;both cases&nbsp;LDC&nbsp;selects a load&nbsp;from&nbsp;memory&nbsp;into the coprocessor&nbsp;register,&nbsp;STC&nbsp;<br>
selects a store&nbsp;from&nbsp;the coprocessor&nbsp;register&nbsp;into&nbsp;memory. The L flag,&nbsp;if present,&nbsp;<br>
selects the long data type (N= 1). &lt;of&nbsp;fset&gt; is # +&nbsp;/-&lt;8-bit immediate;-.&nbsp;<br>
Examples&nbsp;<br>
LDC&nbsp;<br>
p6, &nbsp;&nbsp;CO, &nbsp;&nbsp; [r1]&nbsp;<br>
STCEQL&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p5,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cl,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;r&nbsp;0&nbsp;]&nbsp;,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#4&nbsp;<br>
Notes&nbsp;<br>
1.&nbsp;&nbsp;The interpretation of&nbsp;the N&nbsp;and&nbsp;CRd&nbsp;fields&nbsp;is coprocessor-dependent. The&nbsp;use&nbsp;<br>
shown&nbsp;above&nbsp;is&nbsp;recommended&nbsp;and&nbsp;will maximize compatibility with&nbsp;ARM&nbsp;devel&nbsp;<br>
opment tools.&nbsp;<br>
2.&nbsp;&nbsp;If the address is not word-aligned the two least significant bits will be&nbsp;ignored,&nbsp;<br>
though&nbsp;some&nbsp;ARM systems may raise&nbsp;an&nbsp;exception.&nbsp;<br>
3.&nbsp;&nbsp;The number of words transferred is&nbsp;controlled by&nbsp;the coprocessor and the ARM&nbsp;<br>
will continue&nbsp;to&nbsp;generate sequential addresses until&nbsp;the&nbsp;coprocessor indicates that&nbsp;<br>
the transfer should complete&nbsp;(see&nbsp;'Data&nbsp;transfers'&nbsp;on page 102). During the data&nbsp;<br>
transfer&nbsp;the ARM will not respond&nbsp;to&nbsp;interrupt requests,&nbsp;so&nbsp;coprocessor designers&nbsp;<br>
should be&nbsp;careful&nbsp;not to&nbsp;compromise&nbsp;the&nbsp;system&nbsp;interrupt response&nbsp;time&nbsp;by&nbsp;allow&nbsp;<br>
ing very long&nbsp;data transfers.&nbsp;<br>
Limiting&nbsp;the&nbsp;maximum&nbsp;transfer&nbsp;length&nbsp;to&nbsp;16 words&nbsp;will&nbsp;ensure that coprocessor&nbsp;<br>
data&nbsp;transfers take&nbsp;no longer than&nbsp;worst-case&nbsp;load&nbsp;and store&nbsp;multiple&nbsp;register&nbsp;<br>
instructions.&nbsp;<br>
5.19 &nbsp; Coprocessor&nbsp;register&nbsp;transfers&nbsp;<br>
These instructions allow&nbsp;an&nbsp;integer&nbsp;generated&nbsp;in a&nbsp;coprocessor&nbsp;to be&nbsp;transferred&nbsp;<br>
directly&nbsp;into&nbsp;a&nbsp;ARM&nbsp;register&nbsp;or&nbsp;the&nbsp;ARM&nbsp;condition code&nbsp;flags.&nbsp;Typical&nbsp;uses&nbsp;are:&nbsp;<br>
•&nbsp;&nbsp;A floating-point FIX&nbsp;operation&nbsp;which returns the&nbsp;integer to&nbsp;an ARM&nbsp;register;&nbsp;<br>
•&nbsp;&nbsp;A floating-point comparison&nbsp;which returns&nbsp;the result of the comparison&nbsp;directly&nbsp;<br>
to&nbsp;the&nbsp;ARM&nbsp;condition code&nbsp;flags&nbsp;where it&nbsp;can&nbsp;determine&nbsp;the&nbsp;control&nbsp;flow;&nbsp;<br>
•&nbsp;&nbsp;A FLOAT operation which takes an integer&nbsp;value from&nbsp;an ARM register&nbsp;and sends&nbsp;<br>
it to&nbsp;the&nbsp;coprocessor where&nbsp;it&nbsp;is converted&nbsp;to floating-point representation&nbsp;and&nbsp;<br>
placed in a&nbsp;coprocessor&nbsp;register.&nbsp;<br>
The&nbsp;system&nbsp;control coprocessors used&nbsp;to control the cache and&nbsp;memory manage-<br>
ment functions&nbsp;on the more complex ARM CPUs&nbsp;(Central Processing Units) generally&nbsp;<br>
use&nbsp;these&nbsp;instructions&nbsp;to&nbsp;access&nbsp;and&nbsp;modify&nbsp;the&nbsp;on-chip&nbsp;control&nbsp;registers.&nbsp;<br>
<hr>
<A name=151></a><IMG src="index-151_1.png"><br>
140&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
Binary encoding&nbsp;<br>
31<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;5.17 &nbsp;&nbsp;</b>Coprocessor register&nbsp;transfer instruction&nbsp;binary&nbsp;encoding.&nbsp;<br>
Description&nbsp;<br>
The instruction is offered to any&nbsp;coprocessors present; normally&nbsp;the&nbsp;coprocessor&nbsp;<br>
with coprocessor number&nbsp;CP# will&nbsp;accept the instruction.&nbsp;If no coprocessor accepts&nbsp;<br>
the&nbsp;instruction ARM raises&nbsp;an&nbsp;undefined instruction&nbsp;trap.&nbsp;<br>
If a&nbsp;coprocessor accepts&nbsp;a&nbsp;load&nbsp;from&nbsp;coprocessor instruction,&nbsp;it&nbsp;will&nbsp;normally&nbsp;per-<br>
form&nbsp;an&nbsp;operation&nbsp;defined&nbsp;by&nbsp;Copl&nbsp;and&nbsp;Cop2 on&nbsp;source operands&nbsp;CRn&nbsp;and CRm&nbsp;and&nbsp;<br>
return a&nbsp;32-bit&nbsp;integer result&nbsp;to&nbsp;the&nbsp;ARM&nbsp;which&nbsp;will&nbsp;place&nbsp;it&nbsp;in&nbsp;Rd.&nbsp;<br>
If a&nbsp;coprocessor&nbsp;accepts&nbsp;a&nbsp;store&nbsp;to&nbsp;coprocessor instruction,&nbsp;it&nbsp;will&nbsp;accept&nbsp;a 32-bit&nbsp;<br>
integer from&nbsp;the ARM register Rd&nbsp;and do something with&nbsp;it.&nbsp;<br>
If the PC&nbsp;is specified&nbsp;as&nbsp;the&nbsp;destination&nbsp;register&nbsp;Rd&nbsp;in&nbsp;a&nbsp;load&nbsp;from&nbsp;coprocessor&nbsp;<br>
instruction, the top&nbsp;four&nbsp;bits&nbsp;of&nbsp;the&nbsp;32-bit&nbsp;integer&nbsp;generated by&nbsp;the&nbsp;coprocessor are&nbsp;<br>
placed into&nbsp;the&nbsp;N, Z, C&nbsp;and V flags&nbsp;in&nbsp;the CPSR.&nbsp;<br>
Assembler&nbsp;<br>
Move&nbsp;to&nbsp;ARM&nbsp;register from&nbsp;coprocessor:&nbsp;<br>
format&nbsp;<br>
MRC{&lt;cond&gt;}&nbsp; &nbsp;&lt;CP#&gt;,&nbsp; &nbsp;&lt;Copl&gt;,&nbsp; &nbsp;Rd, &nbsp; CRn,&nbsp; &nbsp;CRm{,&nbsp; &nbsp;<br>
&lt;Cop2&gt;}&nbsp;<b>Move&nbsp;to&nbsp;coprocessor from&nbsp;ARM&nbsp;register:</b>&nbsp;<br>
MCR{&lt;cond&gt;}&nbsp;&nbsp;&nbsp;&lt;CP#&gt;,&nbsp;&nbsp;&nbsp;&lt;Copl&gt;,&nbsp;&nbsp;&nbsp;Rd,&nbsp;&nbsp;&nbsp;CRn,&nbsp;&nbsp;&nbsp;CRm{,&nbsp; &nbsp;<br>
&lt;Cop2&gt;}&nbsp;<br>
Examples&nbsp;<br>
MCR&nbsp;<br>
p14,&nbsp;&nbsp;&nbsp;3,&nbsp;&nbsp;&nbsp;r0,&nbsp;&nbsp;&nbsp;Cl, &nbsp;&nbsp;C2&nbsp;<br>
MRCCS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p2,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r3,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C3,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C4,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<i>6</i>&nbsp;<br>
Notes&nbsp;<br>
1.&nbsp;&nbsp;The Copl,&nbsp;CRn, Cop2 and CRm&nbsp;fields are&nbsp;interpreted&nbsp;by the&nbsp;coprocessor. The&nbsp;<br>
above&nbsp;interpretations&nbsp;are recommended to&nbsp;maximize compatibility&nbsp;with ARM&nbsp;<br>
development tools.&nbsp;<br>
2.&nbsp;&nbsp;Where&nbsp;the coprocessor&nbsp;must perform&nbsp;some&nbsp;internal&nbsp;work&nbsp;to&nbsp;prepare a&nbsp;32-bit&nbsp;value&nbsp;<br>
for transfer&nbsp;to the ARM&nbsp;(for&nbsp;example, a&nbsp;floating-point&nbsp;FIX&nbsp;operation&nbsp;has to con&nbsp;<br>
vert&nbsp;the&nbsp;floating-point value into its equivalent fixed-point value), this&nbsp;must take&nbsp;<br>
place before the coprocessor commits to&nbsp;the transfer. Therefore it will often be&nbsp;<br>
necessary for&nbsp;the&nbsp;coprocessor handshake to 'busy-wait' while&nbsp;the data&nbsp;is&nbsp;prepared.&nbsp;<br>
The&nbsp;ARM&nbsp;can&nbsp;take interrupts during&nbsp;the busy-wait period, and if it does get inter-<br>
rupted&nbsp;it&nbsp;will break&nbsp;off&nbsp;from&nbsp;the handshake&nbsp;to&nbsp;service the interrupt.&nbsp;It&nbsp;will&nbsp;proba-<br>
bly&nbsp;retry&nbsp;the coprocessor instruction&nbsp;when&nbsp;it returns from&nbsp;the interrupt&nbsp;service&nbsp;<br>
routine, but it&nbsp;may not; the interrupt&nbsp;may&nbsp;cause a&nbsp;task&nbsp;switch, for&nbsp;example.&nbsp;<br>
<hr>
<A name=152></a><IMG src="index-152_1.png"><br>
<b>Breakpoint instruction&nbsp;(BKPT&nbsp;-&nbsp;architecture&nbsp;v5T&nbsp;only)</b>&nbsp;<br>
<b>141</b>&nbsp;<br>
In&nbsp;either&nbsp;case,&nbsp;the&nbsp;coprocessor&nbsp;must&nbsp;give&nbsp;consistent&nbsp;results.&nbsp;Therefore the prepa-<br>
ration work&nbsp;carried out&nbsp;before the handshake commit&nbsp;phase&nbsp;must not change&nbsp;the&nbsp;<br>
coprocessor's visible state.&nbsp;<br>
3. Transfers from&nbsp;the ARM to the coprocessor are generally&nbsp;simpler since any data con-<br>
version work can take&nbsp;place&nbsp;in the coprocessor after the transfer has completed.&nbsp;<br>
5.20 &nbsp; Breakpoint&nbsp;instruction&nbsp;(BKPT - architecture v5T only)&nbsp;<br>
Breakpoint instructions&nbsp;are used for software debugging&nbsp;purposes; they cause the&nbsp;<br>
processor&nbsp;to break&nbsp;from&nbsp;normal&nbsp;instruction execution&nbsp;and enter appropriate&nbsp;debug-<br>
ging procedures.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
<b>Figure 5.18&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Breakpoint instruction binary&nbsp;encoding.&nbsp;<br>
Description&nbsp;<br>
This&nbsp;instruction causes the processor to take a prefetch abort&nbsp;when&nbsp;the debug hard-<br>
ware unit&nbsp;is&nbsp;configured&nbsp;appropriately.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Assembler&nbsp;<br>
BKPT&nbsp;<br>
format&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Example&nbsp;<br>
BKPT&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;!&nbsp;<br>
Notes&nbsp;<br>
1.&nbsp;&nbsp;Only processors that implement&nbsp;ARM architecture&nbsp;v5T support&nbsp;the BRK instruc&nbsp;<br>
tion (see Section 5.23 on page&nbsp;147).&nbsp;<br>
2.&nbsp;&nbsp;BRK instructions are unconditional -&nbsp;the condition field&nbsp;must contain the&nbsp;<br>
'ALWAYS'&nbsp;code.&nbsp;<br>
<hr>
<A name=153></a><IMG src="index-153_1.png"><br>
<IMG src="index-153_2.png"><br>
<IMG src="index-153_3.png"><br>
<b>142</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
5.21 &nbsp; Unused&nbsp;instruction&nbsp;space&nbsp;<br>
Not&nbsp;all of&nbsp;the 232&nbsp;instruction bit&nbsp;encodings&nbsp;have&nbsp;been&nbsp;assigned&nbsp;meanings; the&nbsp;encod-<br>
ings that&nbsp;have not been&nbsp;used so&nbsp;far are available&nbsp;for future&nbsp;instruction set&nbsp;extensions.&nbsp;<br>
The&nbsp;unused&nbsp;instruction&nbsp;encodings&nbsp;each&nbsp;fall&nbsp;into&nbsp;particular gaps&nbsp;left&nbsp;in&nbsp;the&nbsp;used&nbsp;<br>
encodings,&nbsp;and their likely future&nbsp;use&nbsp;can&nbsp;be&nbsp;inferred from&nbsp;where they lie.&nbsp;<br>
Unused&nbsp;<br>
These instructions look very&nbsp;like the&nbsp;multiply&nbsp;instructions described in&nbsp;Section 5.8&nbsp;<br>
arithmetic&nbsp;<br>
on page 122.&nbsp;This would be a likely&nbsp;encoding, for example,&nbsp;for an integer divide&nbsp;<br>
instructions&nbsp;<br>
instruction.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
31<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;5.19 &nbsp;&nbsp;</b>Arithmetic instruction extension&nbsp;space.&nbsp;<br>
Unused&nbsp;control&nbsp;<br>
These instructions&nbsp;include the branch&nbsp;and&nbsp;exchange&nbsp;instructions described in&nbsp;<br>
instructions&nbsp;<br>
Section&nbsp;5.5&nbsp;on&nbsp;page 115 and the status&nbsp;register transfer instructions&nbsp;described in&nbsp;<br>
Sections&nbsp;5.14&nbsp;and&nbsp;5.15&nbsp;on pages 133 and&nbsp;134.&nbsp;The gaps&nbsp;here&nbsp;could&nbsp;<i>be&nbsp;</i>used to&nbsp;<br>
encode other instructions&nbsp;that affect the processor operating&nbsp;mode.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
31<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;5.20 &nbsp;&nbsp;</b>Control instruction&nbsp;extension space.&nbsp;<br>
Unused&nbsp;load/&nbsp;<br>
There are unused encodings in the areas occupied&nbsp;by&nbsp;the swap instructions&nbsp;described in&nbsp;<br>
store&nbsp;<br>
Section 5.13&nbsp;on&nbsp;page&nbsp;132 and the load&nbsp;and store half-word and signed byte instructions&nbsp;<br>
instructions&nbsp;<br>
described in Section 5.11 on&nbsp;page 128. These&nbsp;are likely&nbsp;to be used to support additional&nbsp;<br>
data transfer instructions, should&nbsp;these be required in the future.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;5.21 &nbsp;&nbsp;&nbsp;</b>Data transfer instruction&nbsp;extension space.&nbsp;<br>
<hr>
<A name=154></a><IMG src="index-154_1.png"><br>
<IMG src="index-154_2.png"><br>
<b>Memory faults</b>&nbsp;<br>
<b>143</b>&nbsp;<br>
Unused&nbsp;<br>
The&nbsp;following&nbsp;instruction&nbsp;format&nbsp;is&nbsp;similar to&nbsp;the coprocessor data&nbsp;transfer instruc-&nbsp;<br>
Coprocessor&nbsp;<br>
tion described in Section 5.18 on page 138,&nbsp;and is likely&nbsp;to&nbsp;be used to support any&nbsp;<br>
instructions&nbsp;<br>
additional coprocessor instructions that&nbsp;may&nbsp;be required:&nbsp;<br>
&nbsp;<br>
<b>Figure 5.22&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Coprocessor instruction extension&nbsp;space.&nbsp;<br>
Undefined&nbsp;<br>
The largest area of undefined instructions&nbsp;looks like the&nbsp;word and unsigned&nbsp;byte&nbsp;<br>
instruction&nbsp;<br>
data transfer&nbsp;instruction&nbsp;described in&nbsp;Section 5.10 on page 125.&nbsp;However the&nbsp;future&nbsp;<br>
space&nbsp;<br>
options on&nbsp;this space are being kept completely open.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure 5.23&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Undefined instruction&nbsp;space.&nbsp;<br>
Behaviour&nbsp;Of&nbsp;<br>
All&nbsp;current&nbsp;ARM processors&nbsp;will&nbsp;take the undefined&nbsp;instruction trap if&nbsp;an&nbsp;attempt is&nbsp;<br>
unused&nbsp;<br>
made to execute an instruction that&nbsp;matches the encoding&nbsp;shown in Figure 5.23, in&nbsp;<br>
instructions&nbsp;<br>
the undefined instruction&nbsp;space.&nbsp;<br>
The&nbsp;latest&nbsp;ARM&nbsp;processors should take&nbsp;the&nbsp;undefined&nbsp;instruction&nbsp;trap&nbsp;if&nbsp;any&nbsp;unused&nbsp;<br>
opcode&nbsp;is executed, but&nbsp;previous versions&nbsp;(including ARM6&nbsp;and ARM?)&nbsp;will behave&nbsp;<br>
unpredictably.&nbsp;Therefore these&nbsp;instructions&nbsp;should be&nbsp;avoided!&nbsp;<br>
5.22 &nbsp; Memory&nbsp;faults&nbsp;<br>
ARM processors allow the&nbsp;memory&nbsp;system&nbsp;(or,&nbsp;more&nbsp;usually,&nbsp;the&nbsp;memory&nbsp;manage-<br>
ment&nbsp;unit) to&nbsp;fault&nbsp;on&nbsp;any memory access.&nbsp;What&nbsp;this&nbsp;means is&nbsp;that&nbsp;instead&nbsp;of&nbsp;return-<br>
ing the requested value from&nbsp;memory, the&nbsp;memory system&nbsp;returns a signal that&nbsp;<br>
indicates that&nbsp;the memory access has failed&nbsp;to complete&nbsp;correctly. The&nbsp;processor&nbsp;<br>
will&nbsp;then&nbsp;enter an&nbsp;exception&nbsp;handler&nbsp;and the system&nbsp;software&nbsp;will&nbsp;attempt&nbsp;to&nbsp;recover&nbsp;<br>
from&nbsp;the problem.&nbsp;The most common&nbsp;sources of&nbsp;a&nbsp;memory&nbsp;fault&nbsp;in a&nbsp;<br>
general-purpose machine&nbsp;are:&nbsp;<br>
<hr>
<A name=155></a><b>144</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Page absent&nbsp;<br>
• The addressed&nbsp;memory location has been paged out to disk.&nbsp;<br>
In a virtual&nbsp;memory&nbsp;system&nbsp;infrequently&nbsp;used pages are held on disk.&nbsp;An attempt&nbsp;<br>
to access instructions or&nbsp;data&nbsp;on such&nbsp;a page&nbsp;will&nbsp;fail,&nbsp;causing the&nbsp;MMU to abort&nbsp;<br>
the access.&nbsp;The system&nbsp;software&nbsp;must&nbsp;identify the&nbsp;cause of&nbsp;the abort,&nbsp;fetch&nbsp;the&nbsp;<br>
required page&nbsp;into&nbsp;memory&nbsp;from&nbsp;disk, change the translation tables in the MMU&nbsp;<br>
accordingly and retry&nbsp;the aborted&nbsp;access.&nbsp;<br>
Since&nbsp;fetching&nbsp;a page&nbsp;from&nbsp;disk is&nbsp;a slow&nbsp;process,&nbsp;the&nbsp;operating system&nbsp;will&nbsp;often&nbsp;<br>
switch out&nbsp;the&nbsp;faulted process&nbsp;and schedule another&nbsp;task&nbsp;while the transfer&nbsp;takes place.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Page protected&nbsp;<br>
The addressed&nbsp;memory location is temporarily&nbsp;inaccessible.&nbsp;<br>
When a&nbsp;page is&nbsp;loaded&nbsp;into&nbsp;memory, the operating&nbsp;system&nbsp;may initially&nbsp;make&nbsp;it&nbsp;<br>
read&nbsp;only. An&nbsp;attempt&nbsp;to&nbsp;write&nbsp;the&nbsp;page&nbsp;will&nbsp;fault, alerting&nbsp;the&nbsp;operating system&nbsp;to&nbsp;<br>
the fact that the page has been&nbsp;modified and&nbsp;must be saved when it is swapped&nbsp;<br>
out to disk&nbsp;again. (An unmodified page&nbsp;need not be written to disk again if the&nbsp;<br>
old copy&nbsp;is&nbsp;still there.)&nbsp;<br>
Some&nbsp;operating systems&nbsp;will&nbsp;periodically&nbsp;make&nbsp;pages&nbsp;inaccessible&nbsp;in&nbsp;order&nbsp;to&nbsp;<br>
generate&nbsp;statistics about their&nbsp;use&nbsp;for the paging algorithm.&nbsp;<br>
Soft memory&nbsp;<br>
A&nbsp;soft error has been detected&nbsp;in the&nbsp;memory.&nbsp;<br>
errors&nbsp;<br>
A&nbsp;large&nbsp;memory&nbsp;system&nbsp;has a not-insignificant&nbsp;error rate&nbsp;due&nbsp;to&nbsp;alpha&nbsp;particle&nbsp;<br>
radiation&nbsp;changing&nbsp;the state of&nbsp;a&nbsp;dynamic RAM storage&nbsp;cell. Where&nbsp;the memory&nbsp;<br>
system&nbsp;has&nbsp;simple error&nbsp;detection (such as&nbsp;a&nbsp;parity&nbsp;check) the&nbsp;fault&nbsp;is&nbsp;not&nbsp;recover-<br>
able so the faulting process&nbsp;must be terminated. Where the&nbsp;memory system&nbsp;has&nbsp;<br>
full error check and correct&nbsp;(ECC) hardware the processor&nbsp;will usually be una-<br>
ware of&nbsp;the error, though&nbsp;a&nbsp;fault could&nbsp;still&nbsp;be generated in&nbsp;order that the operat-<br>
ing system&nbsp;can accumulate statistics on the memory error rate. In the&nbsp;<br>
intermediate case,&nbsp;where the&nbsp;memory has a&nbsp;hardware error detector but&nbsp;relies on&nbsp;<br>
software error&nbsp;correction,&nbsp;the&nbsp;fault,&nbsp;correct and retry&nbsp;sequence is followed.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Embedded&nbsp;<br>
In a typical small&nbsp;embedded ARM application, a hard disk is usually&nbsp;unavailable,&nbsp;<br>
systems&nbsp;<br>
and&nbsp;in any&nbsp;case paging&nbsp;to disk is&nbsp;usually&nbsp;incompatible with the real-time&nbsp;constraints&nbsp;<br>
that&nbsp;the system&nbsp;must&nbsp;meet.&nbsp;Furthermore the&nbsp;memory system&nbsp;is usually&nbsp;small (a few&nbsp;<br>
megabytes&nbsp;at&nbsp;most,&nbsp;comprising&nbsp;a handful of&nbsp;memory&nbsp;chips)&nbsp;so the&nbsp;soft error&nbsp;rate is&nbsp;<br>
negligible&nbsp;and&nbsp;error&nbsp;detection is rarely&nbsp;incorporated. Therefore&nbsp;many&nbsp;embedded&nbsp;sys-<br>
tems&nbsp;will not use&nbsp;memory faults at&nbsp;all.&nbsp;<br>
A typical use&nbsp;in&nbsp;an&nbsp;embedded&nbsp;system&nbsp;might&nbsp;be to&nbsp;store a&nbsp;library&nbsp;of routines&nbsp;in&nbsp;com-<br>
pressed form&nbsp;in ROM and&nbsp;to&nbsp;use the virtual&nbsp;memory&nbsp;technique&nbsp;to&nbsp;trap calls to individ-<br>
ual routines, expanding them&nbsp;as required into RAM for execution. The benefit of&nbsp;<br>
storing them&nbsp;in compressed form&nbsp;is the reduction in&nbsp;the size&nbsp;and&nbsp;cost&nbsp;of the ROM; the&nbsp;<br>
penalty&nbsp;is&nbsp;the&nbsp;time taken for&nbsp;decompression.&nbsp;<br>
<hr>
<A name=156></a><b>Memory&nbsp;faults</b>&nbsp;<br>
<b>145</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
An additional use in an embedded system&nbsp;might be to offer some&nbsp;protection for&nbsp;<br>
processes running under&nbsp;a real-time operating system.&nbsp;<br>
Memory faults&nbsp;<br>
The ARM&nbsp;handles memory faults&nbsp;detected&nbsp;during&nbsp;instruction&nbsp;fetches&nbsp;<i>(prefetch&nbsp;</i><br>
<i>aborts)&nbsp;</i>and&nbsp;those&nbsp;detected&nbsp;during&nbsp;data&nbsp;transfers&nbsp;(<i>data&nbsp;aborts)&nbsp;</i>separately.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Prefetch&nbsp;aborts&nbsp;&nbsp;If an instruction&nbsp;fetch faults,&nbsp;the memory system&nbsp;raises&nbsp;the abort&nbsp;signal (a dedicated&nbsp;<br>
input&nbsp;to&nbsp;the&nbsp;processor)&nbsp;and returns a meaningless&nbsp;instruction&nbsp;word. Internally&nbsp;ARM&nbsp;<br>
puts the&nbsp;meaningless instruction into the instruction pipeline along with the abort&nbsp;<br>
flag, and&nbsp;then continues with&nbsp;business as&nbsp;usual until&nbsp;the instruction enters the&nbsp;<br>
decode stage, whereupon the abort flag overrides the instruction and causes the&nbsp;<br>
decoder to generate&nbsp;an exception entry sequence using the&nbsp;prefetch&nbsp;abort&nbsp;vector.&nbsp;<br>
If the aborted instruction does&nbsp;not&nbsp;get&nbsp;executed, for instance&nbsp;because it&nbsp;was fetched&nbsp;<br>
immediately after a&nbsp;branch&nbsp;instruction that&nbsp;was&nbsp;ultimately&nbsp;taken, then&nbsp;no&nbsp;exception is&nbsp;<br>
raised and the fault is ignored.&nbsp;<br>
Data aborts&nbsp;<br>
Memory faults&nbsp;which arise&nbsp;during an&nbsp;access to&nbsp;memory for a&nbsp;data&nbsp;value&nbsp;are far&nbsp;<br>
more complex&nbsp;to handle. The&nbsp;memory system&nbsp;need not differentiate&nbsp;the&nbsp;instruction&nbsp;<br>
and data cases; it simply&nbsp;raises the&nbsp;abort input when&nbsp;it&nbsp;sees an address that it can't&nbsp;<br>
handle. The processor&nbsp;has to&nbsp;work&nbsp;much&nbsp;harder in&nbsp;response&nbsp;to&nbsp;a&nbsp;data abort,&nbsp;however,&nbsp;<br>
since this is a&nbsp;problem&nbsp;with the instruction that is currently executing whereas a&nbsp;<br>
prefetch&nbsp;abort&nbsp;is a problem&nbsp;with an instruction that has not&nbsp;yet entered&nbsp;decode.&nbsp;<br>
Since the&nbsp;objective,&nbsp;in&nbsp;some&nbsp;cases,&nbsp;is&nbsp;to retry the&nbsp;instruction when&nbsp;the&nbsp;cause&nbsp;of&nbsp;the&nbsp;<br>
fault&nbsp;has been&nbsp;resolved, the&nbsp;instruction&nbsp;should do&nbsp;its best to&nbsp;ensure that its&nbsp;state&nbsp;(that&nbsp;<br>
is,&nbsp;its&nbsp;register&nbsp;values) after&nbsp;an&nbsp;abort is&nbsp;unchanged&nbsp;from&nbsp;its state&nbsp;before it&nbsp;started&nbsp;exe-<br>
cuting. Failing&nbsp;that, it should&nbsp;at&nbsp;least ensure&nbsp;that enough state can&nbsp;be recovered so&nbsp;that&nbsp;<br>
after the&nbsp;instruction&nbsp;has been&nbsp;executed&nbsp;a&nbsp;second&nbsp;time&nbsp;its&nbsp;state&nbsp;is&nbsp;the&nbsp;same&nbsp;as&nbsp;it&nbsp;would&nbsp;<br>
have&nbsp;been&nbsp;had the instruction completed&nbsp;the first time.&nbsp;<br>
LDM data&nbsp;abort&nbsp;<br>
To see just&nbsp;how hard this can get,&nbsp;consider&nbsp;a&nbsp;load&nbsp;multiple instruction with&nbsp;16 registers&nbsp;<br>
in&nbsp;the register&nbsp;list using r0&nbsp;as&nbsp;the&nbsp;base register.&nbsp;Initially the&nbsp;addresses are&nbsp;fine,&nbsp;so the&nbsp;<br>
loading begins.&nbsp;The&nbsp;first&nbsp;data&nbsp;value&nbsp;to&nbsp;arrive&nbsp;overwrites r0,&nbsp;then&nbsp;successive registers&nbsp;<br>
get written&nbsp;until&nbsp;the final address (destined&nbsp;for the PC)&nbsp;crosses a&nbsp;page&nbsp;boundary and&nbsp;<br>
faults. Most&nbsp;of the processor state&nbsp;has&nbsp;been&nbsp;lost.&nbsp;How can the processor&nbsp;recover?&nbsp;<br>
The&nbsp;abort signal is&nbsp;just&nbsp;in time&nbsp;to&nbsp;prevent&nbsp;the&nbsp;PC from&nbsp;being overwritten,&nbsp;so at&nbsp;least&nbsp;<br>
we have an address for the&nbsp;instruction that caused&nbsp;the fault.&nbsp;But we appear&nbsp;to have&nbsp;lost&nbsp;<br>
the&nbsp;base register a&nbsp;long time&nbsp;back, so&nbsp;how&nbsp;can the&nbsp;instruction be&nbsp;retried?&nbsp;Fortunately&nbsp;<br>
the&nbsp;processor has kept&nbsp;a&nbsp;copy&nbsp;of the&nbsp;base&nbsp;register value&nbsp;(possibly&nbsp;after auto-indexing)&nbsp;<br>
in a&nbsp;dark corner&nbsp;while&nbsp;the instruction was proceeding, so the last&nbsp;act&nbsp;of the&nbsp;instruction,&nbsp;<br>
when it should have&nbsp;been changing&nbsp;the PC&nbsp;to&nbsp;the new value had&nbsp;the&nbsp;PC&nbsp;access not&nbsp;<br>
faulted, is instead&nbsp;to&nbsp;copy this preserved&nbsp;value&nbsp;back&nbsp;into&nbsp;the&nbsp;base&nbsp;register.&nbsp;<br>
<hr>
<A name=157></a><b>146</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
So we&nbsp;have&nbsp;preserved&nbsp;the PC&nbsp;and&nbsp;the (modified) base&nbsp;register,&nbsp;but&nbsp;we&nbsp;have&nbsp;over-<br>
written several&nbsp;other registers&nbsp;in the meantime. The&nbsp;base&nbsp;register modification can&nbsp;be&nbsp;<br>
reversed&nbsp;by&nbsp;software, since&nbsp;we&nbsp;can&nbsp;inspect&nbsp;the&nbsp;instruction&nbsp;and&nbsp;determine&nbsp;the&nbsp;number&nbsp;<br>
of registers&nbsp;in the&nbsp;list&nbsp;and&nbsp;the&nbsp;addressing&nbsp;mode. The&nbsp;overwritten&nbsp;registers&nbsp;are&nbsp;exactly&nbsp;<br>
those&nbsp;that&nbsp;we&nbsp;will&nbsp;load again&nbsp;with&nbsp;the&nbsp;correct&nbsp;values when&nbsp;we&nbsp;retry the&nbsp;instruction,&nbsp;so&nbsp;<br>
all&nbsp;is well&nbsp;(just!).&nbsp;<br>
An historical&nbsp;<br>
The requirement to recover from&nbsp;data aborts&nbsp;was added fairly&nbsp;late in the develop-<br>
note&nbsp;<br>
ment of the first ARM processor chip. Up to that point, the various load&nbsp;and store&nbsp;<br>
multiple addressing&nbsp;modes had been implemented starting from&nbsp;the base address&nbsp;<br>
and incrementing up or decrementing down&nbsp;memory according to&nbsp;the&nbsp;mode. The&nbsp;<br>
chip was&nbsp;therefore designed&nbsp;with&nbsp;an address incrementer/decrementer unit.&nbsp;<br>
When&nbsp;it&nbsp;became&nbsp;clear&nbsp;that&nbsp;support&nbsp;for&nbsp;virtual&nbsp;memory&nbsp;was&nbsp;needed&nbsp;it&nbsp;was&nbsp;rapidly&nbsp;<br>
seen that the decrementing mode&nbsp;made abort recovery&nbsp;much harder,&nbsp;since the PC&nbsp;<br>
could be overwritten&nbsp;before&nbsp;the abort&nbsp;was&nbsp;signalled.&nbsp;Therefore the&nbsp;implementation&nbsp;<br>
was changed always to&nbsp;increment&nbsp;the&nbsp;address.&nbsp;The&nbsp;memory&nbsp;addresses used&nbsp;were&nbsp;the&nbsp;<br>
same, and the&nbsp;mapping of register to memory&nbsp;was unchanged (see Figure 3.2 on&nbsp;<br>
page&nbsp;62);&nbsp;just&nbsp;the&nbsp;order&nbsp;of&nbsp;the&nbsp;transfer was&nbsp;changed&nbsp;to&nbsp;lowest&nbsp;address&nbsp;first,&nbsp;PC last.&nbsp;<br>
This change was implemented too late&nbsp;to&nbsp;affect the&nbsp;layout of the address&nbsp;generating&nbsp;<br>
logic,&nbsp;so the&nbsp;first&nbsp;ARM silicon has an address incrementer/decrementer hard-wired&nbsp;<br>
always to increment. Needless&nbsp;to say, this&nbsp;redundancy was not carried forward to sub-<br>
sequent&nbsp;implementations.&nbsp;<br>
Abort timing&nbsp;<br>
The earlier a&nbsp;processor gets an indication of a&nbsp;fault&nbsp;from&nbsp;the&nbsp;memory&nbsp;system,&nbsp;the&nbsp;<br>
better placed it&nbsp;is to preserve&nbsp;state.&nbsp;The earlier a processor&nbsp;requires the&nbsp;fault signal,&nbsp;<br>
the harder&nbsp;the memory&nbsp;system&nbsp;is&nbsp;to design.&nbsp;There&nbsp;is&nbsp;therefore&nbsp;a tension between the&nbsp;<br>
architectural&nbsp;simplicity of&nbsp;the processor's&nbsp;fault handling&nbsp;and the engineering&nbsp;effi-<br>
ciency&nbsp;of&nbsp;the memory&nbsp;system.&nbsp;<br>
This&nbsp;tension doesn't affect&nbsp;just the&nbsp;memory&nbsp;management unit.&nbsp;Where&nbsp;the&nbsp;processor&nbsp;<br>
has&nbsp;a&nbsp;cache&nbsp;memory, the&nbsp;cache&nbsp;design&nbsp;can&nbsp;also&nbsp;be&nbsp;affected&nbsp;by the&nbsp;abort&nbsp;timing.&nbsp;<br>
Early&nbsp;ARM&nbsp;processors&nbsp;required&nbsp;the&nbsp;abort signal&nbsp;by&nbsp;the&nbsp;end&nbsp;of&nbsp;phase&nbsp;1&nbsp;of&nbsp;the&nbsp;clock&nbsp;<br>
cycle (see Figure 4.8&nbsp;on&nbsp;page&nbsp;86), before&nbsp;half-way&nbsp;through the memory&nbsp;access. A fully&nbsp;<br>
associative&nbsp;cache with a CAM-RAM (CAM is Content&nbsp;Addressable Memory) organi-<br>
zation can be&nbsp;designed&nbsp;to&nbsp;generate its hit/miss&nbsp;signal&nbsp;from&nbsp;the&nbsp;CAM&nbsp;access only,&nbsp;in&nbsp;<br>
time either&nbsp;to confirm&nbsp;a satisfactory access&nbsp;or&nbsp;to halt&nbsp;the&nbsp;processor&nbsp;in&nbsp;phase&nbsp;1.&nbsp;Once the&nbsp;<br>
processor is&nbsp;halted,&nbsp;the&nbsp;MMU has&nbsp;time to&nbsp;control&nbsp;the&nbsp;generation&nbsp;of&nbsp;the&nbsp;abort signal.&nbsp;A&nbsp;<br>
set-associative cache, on the other hand,&nbsp;will&nbsp;usually produce&nbsp;its hit/miss signal at&nbsp;the&nbsp;<br>
end&nbsp;of the&nbsp;cycle, too late&nbsp;to&nbsp;defer a miss to&nbsp;the&nbsp;MMU (which may generate an&nbsp;abort)&nbsp;<br>
without a&nbsp;significant&nbsp;performance loss.&nbsp;(The&nbsp;ARM?&nbsp;10, which has a&nbsp;set-associative&nbsp;<br>
RAM-RAM&nbsp;cache,&nbsp;does&nbsp;not&nbsp;follow&nbsp;this&nbsp;rule, and&nbsp;the&nbsp;cache&nbsp;still&nbsp;generates its hit/miss&nbsp;<br>
signal&nbsp;and the&nbsp;MMU its&nbsp;protection&nbsp;information&nbsp;before&nbsp;the end&nbsp;of phase&nbsp;1.)&nbsp;<br>
In&nbsp;order to&nbsp;ease&nbsp;the constraints on&nbsp;the&nbsp;cache&nbsp;and&nbsp;MMU&nbsp;designs, later ARMs&nbsp;were&nbsp;<br>
redesigned&nbsp;to allow&nbsp;aborts to be&nbsp;flagged at&nbsp;the&nbsp;end of the cycle,&nbsp;with a similar&nbsp;timing to&nbsp;<br>
<hr>
<A name=158></a><b>ARM&nbsp;architecture&nbsp;variants&nbsp;</b><br>
<b>147</b>&nbsp;<br>
the read data.&nbsp;The compromise&nbsp;that&nbsp;had to&nbsp;be&nbsp;accepted was that now the&nbsp;processor state&nbsp;<br>
has&nbsp;changed further so&nbsp;there&nbsp;is&nbsp;more work&nbsp;for&nbsp;the&nbsp;abort recovery&nbsp;software&nbsp;to&nbsp;do.&nbsp;<br>
Some&nbsp;ARM processors&nbsp;may&nbsp;be configured&nbsp;(by&nbsp;external&nbsp;hard-wiring&nbsp;or using the&nbsp;L&nbsp;<br>
bit,&nbsp;bit&nbsp;6&nbsp;of CP15 register 1,&nbsp;see Section&nbsp;11.2&nbsp;on&nbsp;page&nbsp;293) to&nbsp;work with&nbsp;either early&nbsp;or&nbsp;<br>
late abort timing.&nbsp;<br>
ARM data&nbsp;aborts&nbsp;&nbsp;The state&nbsp;of the ARM&nbsp;after&nbsp;a&nbsp;data&nbsp;abort&nbsp;depends on&nbsp;the particular&nbsp;processor and,&nbsp;<br>
with&nbsp;some&nbsp;processors, on&nbsp;the&nbsp;early/late&nbsp;abort configuration:&nbsp;<br>
•&nbsp;&nbsp;In all cases the PC is&nbsp;preserved (so on&nbsp;data abort&nbsp;exception entry r14_abt&nbsp;con&nbsp;<br>
tains the address of&nbsp;the&nbsp;faulting instruction&nbsp;plus eight&nbsp;bytes).&nbsp;<br>
•&nbsp;&nbsp;The base register will either&nbsp;be unmodified, or will contain a value&nbsp;modified by&nbsp;<br>
auto-indexing (it&nbsp;will not be&nbsp;overwritten by&nbsp;a&nbsp;loaded value).&nbsp;<br>
•&nbsp;&nbsp;Other load&nbsp;destination&nbsp;registers may have&nbsp;been&nbsp;overwritten, but the&nbsp;correct value&nbsp;<br>
will be&nbsp;loaded&nbsp;when the instruction is retried.&nbsp;<br>
Because&nbsp;the base register may be&nbsp;modified&nbsp;by&nbsp;auto-indexing, certain (not&nbsp;very&nbsp;use-<br>
ful) auto-indexing modes should&nbsp;be avoided.&nbsp;For example:&nbsp;<br>
LDR&nbsp;<br>
r0,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[r1],&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rl&nbsp;<br>
This&nbsp;instruction&nbsp;uses&nbsp;r1 as&nbsp;the address for the load, then uses post-indexing&nbsp;to add&nbsp;<br>
r1 to&nbsp;itself, losing the top&nbsp;bit&nbsp;in&nbsp;the process.&nbsp;If,&nbsp;following a&nbsp;data abort, only&nbsp;the&nbsp;mod-<br>
ified&nbsp;value of&nbsp;r1 is available,&nbsp;it is&nbsp;not&nbsp;possible to&nbsp;recover&nbsp;the original&nbsp;transfer&nbsp;<br>
address.&nbsp;In&nbsp;general, using&nbsp;the same&nbsp;register&nbsp;for the base and the&nbsp;index&nbsp;in&nbsp;an&nbsp;address-<br>
ing mode&nbsp;should&nbsp;be&nbsp;avoided.&nbsp;<br>
5.23 &nbsp; ARM&nbsp;architecture&nbsp;variants&nbsp;<br>
The&nbsp;ARM&nbsp;architecture has&nbsp;undergone a number&nbsp;of&nbsp;revisions in&nbsp;the course of&nbsp;its&nbsp;<br>
development.&nbsp;The various architecture&nbsp;versions&nbsp;are described&nbsp;below.&nbsp;<br>
Version 1&nbsp;<br>
ARM&nbsp;architecture version 1 describes the&nbsp;first ARM processor,&nbsp;developed&nbsp;at Acorn&nbsp;<br>
Computers Limited&nbsp;between&nbsp;1983&nbsp;and&nbsp;1985.&nbsp;These first&nbsp;ARM chips supported&nbsp;only&nbsp;<br>
26-bit addressing and had&nbsp;no&nbsp;multiply&nbsp;or&nbsp;coprocessor&nbsp;support. Their only&nbsp;use in a&nbsp;<br>
product was&nbsp;in&nbsp;the&nbsp;ARM&nbsp;second&nbsp;processor&nbsp;attachments&nbsp;to&nbsp;the&nbsp;BBC&nbsp;microcomputer;&nbsp;<br>
these&nbsp;were&nbsp;made in very&nbsp;small numbers, but established&nbsp;the ARM&nbsp;as the first com-<br>
mercially&nbsp;exploited single-chip RISC&nbsp;microprocessor.&nbsp;They&nbsp;were also used intern-<br>
ally&nbsp;within&nbsp;Acorn&nbsp;in&nbsp;prototypes&nbsp;of&nbsp;the&nbsp;Archimedes&nbsp;personal&nbsp;workstation.&nbsp;<br>
<hr>
<A name=159></a><b>148</b>&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Version 2&nbsp;<br>
The ARM2 chip&nbsp;was sold in&nbsp;volume&nbsp;in&nbsp;the&nbsp;Acorn Archimedes and&nbsp;A3000&nbsp;products.&nbsp;<br>
It&nbsp;was&nbsp;still&nbsp;a 26-bit address machine, but included the 32-bit&nbsp;result&nbsp;multiply&nbsp;instruc-<br>
tions and coprocessor&nbsp;support. ARM2&nbsp;employs the architecture that&nbsp;ARM Limited&nbsp;<br>
now calls&nbsp;ARM&nbsp;architecture version 2.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Version 2a&nbsp;<br>
The ARM3 chip was the first ARM with an on-chip&nbsp;cache. The architecture was&nbsp;<br>
very&nbsp;similar to&nbsp;version&nbsp;2,&nbsp;but&nbsp;added the&nbsp;atomic load&nbsp;and store (SWP) instruction&nbsp;<br>
and&nbsp;introduced&nbsp;the use&nbsp;of coprocessor 15&nbsp;as the system&nbsp;control coprocessor to&nbsp;<br>
manage the cache.&nbsp;<br>
Version 3&nbsp;<br>
The first&nbsp;ARM processor designed by ARM Limited&nbsp;following their establishment&nbsp;<br>
as a&nbsp;separate&nbsp;company in&nbsp;1990 was&nbsp;the&nbsp;ARM6,&nbsp;sold as&nbsp;a&nbsp;macrocell,&nbsp;a&nbsp;stand-alone&nbsp;<br>
processor&nbsp;(the&nbsp;ARM60)&nbsp;and&nbsp;as&nbsp;an&nbsp;integrated&nbsp;CPU&nbsp;with&nbsp;an&nbsp;on-chip&nbsp;cache,&nbsp;MMU and&nbsp;<br>
write&nbsp;buffer (the&nbsp;ARM600,&nbsp;and&nbsp;the ARM610&nbsp;used&nbsp;in&nbsp;the Apple Newton).&nbsp;The&nbsp;<br>
ARM6 introduced ARM architecture version&nbsp;3, which had 32-bit addressing, sepa-<br>
rate&nbsp;CPSR&nbsp;and&nbsp;SPSRs, and added the undefined and abort&nbsp;modes to allow coproces-<br>
sor emulation&nbsp;and virtual&nbsp;memory&nbsp;support&nbsp;in supervisor&nbsp;mode.&nbsp;<br>
ARM architecture version 3 is&nbsp;backwards compatible with version 2a, allowing either&nbsp;<br>
hard-wired 26-bit operation&nbsp;or process-by-process&nbsp;mixed 26- and 32-bit operation.&nbsp;<br>
Version 3G&nbsp;<br>
ARM&nbsp;architecture version 3G&nbsp;is version 3&nbsp;without backwards compatibility&nbsp;to&nbsp;ver-<br>
sion&nbsp;2a.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Version 3M&nbsp;<br>
ARM architecture version 3M&nbsp;introduces&nbsp;the signed and unsigned&nbsp;multiply&nbsp;and&nbsp;<br>
multiply-accumulate&nbsp;instructions that&nbsp;generate the&nbsp;full&nbsp;64-bit result.&nbsp;<br>
Version 4&nbsp;<br>
Version 4 of the architecture adds the&nbsp;signed and unsigned half-word and signed&nbsp;<br>
byte&nbsp;load and store&nbsp;instructions&nbsp;and reserves&nbsp;some&nbsp;of&nbsp;the S&nbsp;WI space for&nbsp;architectur-<br>
ally&nbsp;defined&nbsp;operations.&nbsp;The&nbsp;system&nbsp;mode&nbsp;(a&nbsp;privileged&nbsp;mode&nbsp;that&nbsp;uses&nbsp;the&nbsp;user&nbsp;reg-<br>
isters) is&nbsp;introduced, and several unused corners of the instruction&nbsp;space are trapped&nbsp;<br>
as undefined&nbsp;instructions.&nbsp;<br>
At&nbsp;this&nbsp;stage&nbsp;those&nbsp;uses&nbsp;of&nbsp;r15 which yielded&nbsp;'pc +&nbsp;12'&nbsp;in&nbsp;earlier ARMs are&nbsp;<br>
declared&nbsp;to&nbsp;give unpredictable&nbsp;results (so architecture version 4 compliant implemen-<br>
tations need&nbsp;not&nbsp;reproduce the 'pc +&nbsp;12'&nbsp;behaviour).&nbsp;This&nbsp;is&nbsp;the&nbsp;first&nbsp;architecture&nbsp;ver-<br>
sion&nbsp;to&nbsp;have&nbsp;a full formal definition.&nbsp;<br>
<hr>
<A name=160></a><IMG src="index-160_1.png"><br>
<b>Example and&nbsp;exercises</b>&nbsp;<br>
<b>149</b>&nbsp;<br>
Version&nbsp;4T&nbsp;<br>
The 16-bit&nbsp;Thumb compressed form&nbsp;of the&nbsp;instruction set&nbsp;is introduced&nbsp;in version&nbsp;<br>
4T of the architecture.&nbsp;<br>
Version&nbsp;5T&nbsp;<br>
Version 5T&nbsp;of&nbsp;the&nbsp;ARM&nbsp;architecture has been&nbsp;introduced&nbsp;recently,&nbsp;and&nbsp;at&nbsp;the time&nbsp;of&nbsp;<br>
writing is supported only by&nbsp;ARM10 processors (and these&nbsp;will soon support v5TE). It&nbsp;<br>
is a superset of&nbsp;architecture version 4T,&nbsp;adding&nbsp;the BLX,&nbsp;CLZ and BRK instructions.&nbsp;<br>
Version&nbsp;5TE&nbsp;<br>
Version 5TE adds the&nbsp;signal processing instruction set&nbsp;extensions described&nbsp;in&nbsp;<br>
Section 8.9 on&nbsp;page&nbsp;239&nbsp;to&nbsp;architecture version&nbsp;5T.&nbsp;<br>
Summary&nbsp;<br>
Table&nbsp;5.7 summarizes&nbsp;the&nbsp;use&nbsp;of&nbsp;the&nbsp;ARM&nbsp;architecture versions&nbsp;by&nbsp;each&nbsp;core.&nbsp;<br>
<b>Table&nbsp;</b>5.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Summary&nbsp;of&nbsp;ARM architectures.&nbsp;<br>
&nbsp;<br>
5.24 &nbsp; Example&nbsp;and&nbsp;exercises&nbsp;<br>
(See also&nbsp;Sections&nbsp;3.4&nbsp;and&nbsp;3.5&nbsp;on pages&nbsp;69 and&nbsp;72.)&nbsp;<br>
<b>Example&nbsp;5.1&nbsp;</b><br>
<b>Write&nbsp;a&nbsp;scalar product&nbsp;program&nbsp;which&nbsp;is&nbsp;significantly&nbsp;faster than that</b>&nbsp;<br>
<b>given in&nbsp;Section&nbsp;5.8&nbsp;on&nbsp;page&nbsp;122.</b>&nbsp;<br>
The original program&nbsp;takes ten cycles&nbsp;plus the (data&nbsp;dependent)&nbsp;multiply time&nbsp;for&nbsp;<br>
each pair&nbsp;of&nbsp;data values.&nbsp;Each data value&nbsp;costs three cycles to&nbsp;load and&nbsp;the branch&nbsp;<br>
costs three cycles per&nbsp;loop.&nbsp;<br>
<hr>
<A name=161></a><IMG src="index-161_1.png"><br>
150&nbsp;<br>
<b>The&nbsp;ARM Instruction Set</b>&nbsp;<br>
The load costs&nbsp;may be&nbsp;reduced&nbsp;by&nbsp;using multiple&nbsp;register&nbsp;loads and the&nbsp;branch&nbsp;cost&nbsp;<br>
by&nbsp;'loop unrolling'.&nbsp;Combining&nbsp;these two techniques&nbsp;gives a program&nbsp;such&nbsp;as:&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Now the loop&nbsp;overhead is 16 cycles plus the&nbsp;multiply&nbsp;time for&nbsp;four pairs of data&nbsp;<br>
values,&nbsp;or four&nbsp;cycles for each&nbsp;pair.&nbsp;<br>
<b>Exercise 5.1.1</b>&nbsp;<br>
Write a subprogram&nbsp;which&nbsp;copies a&nbsp;string&nbsp;of bytes&nbsp;from&nbsp;one&nbsp;memory&nbsp;location to&nbsp;<br>
another. The start of&nbsp;the&nbsp;source&nbsp;string&nbsp;will be&nbsp;passed in&nbsp;r1, the length&nbsp;(in&nbsp;bytes) in&nbsp;r2&nbsp;<br>
and the&nbsp;start of&nbsp;the destination string in&nbsp;r3.&nbsp;<br>
<b>Exercise&nbsp;5.1.2</b>&nbsp;<br>
Repeat&nbsp;the&nbsp;previous&nbsp;exercise&nbsp;using&nbsp;the&nbsp;technique&nbsp;demonstrated&nbsp;in&nbsp;the&nbsp;above&nbsp;example&nbsp;<br>
to improve the performance. Assume&nbsp;that&nbsp;both source and destination&nbsp;strings are&nbsp;<br>
word-aligned&nbsp;and the string&nbsp;is a&nbsp;multiple of&nbsp;16 bytes&nbsp;long.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Exercise&nbsp;5.1.3</b>&nbsp;<br>
Now assume&nbsp;that the source&nbsp;string is&nbsp;word-aligned but the destination string&nbsp;may&nbsp;<br>
have any byte alignment.&nbsp;The&nbsp;string is&nbsp;still a&nbsp;multiple&nbsp;of&nbsp;16 bytes long.&nbsp;Write a&nbsp;pro-<br>
gram&nbsp;which handles 16 byte&nbsp;blocks at a time, using&nbsp;multiple register transfers&nbsp;for&nbsp;<br>
the bulk of&nbsp;the&nbsp;storing but byte&nbsp;stores&nbsp;for the&nbsp;end conditions.&nbsp;<br>
<hr>
<A name=162></a><IMG src="index-162_1.png"><br>
Architectural Support for&nbsp;<br>
High-level Languages&nbsp;<br>
&nbsp;<br>
Summary of chapter contents&nbsp;<br>
High-level languages allow&nbsp;a program to be expressed&nbsp;in terms of abstractions&nbsp;<br>
such&nbsp;as&nbsp;data&nbsp;types,&nbsp;structures,&nbsp;procedures, functions,&nbsp;and so&nbsp;on.&nbsp;Since the RISC&nbsp;<br>
approach&nbsp;represents&nbsp;a movement&nbsp;away&nbsp;from instruction&nbsp;sets&nbsp;that&nbsp;attempt&nbsp;to&nbsp;sup-<br>
port&nbsp;these&nbsp;high-level&nbsp;concepts&nbsp;directly,&nbsp;we&nbsp;need&nbsp;to&nbsp;be&nbsp;satisfied that&nbsp;the more&nbsp;primi-<br>
tive&nbsp;RISC&nbsp;instruction&nbsp;set&nbsp;still&nbsp;offers building&nbsp;blocks that&nbsp;can be&nbsp;assembled to&nbsp;give&nbsp;<br>
the necessary&nbsp;support.&nbsp;<br>
In this chapter&nbsp;we&nbsp;will look&nbsp;at the requirements that a&nbsp;high-level language&nbsp;<br>
imposes&nbsp;on&nbsp;an&nbsp;architecture&nbsp;and&nbsp;see&nbsp;how&nbsp;those requirements may be&nbsp;met.&nbsp;We&nbsp;will&nbsp;<br>
use C&nbsp;as&nbsp;the example high-level&nbsp;language (though&nbsp;some&nbsp;might&nbsp;debate&nbsp;its&nbsp;qualifica-<br>
tion&nbsp;for this&nbsp;role!)&nbsp;and&nbsp;the&nbsp;ARM instruction set&nbsp;as&nbsp;the&nbsp;architecture&nbsp;that&nbsp;the language&nbsp;<br>
is&nbsp;compiled&nbsp;onto.&nbsp;<br>
In the&nbsp;course&nbsp;of this analysis,&nbsp;it&nbsp;will&nbsp;become apparent&nbsp;that&nbsp;a RISC architecture&nbsp;<br>
such as&nbsp;that&nbsp;of&nbsp;the ARM has&nbsp;a vanilla&nbsp;flavour and leaves&nbsp;a number of&nbsp;important&nbsp;<br>
decisions open for the compiler&nbsp;writer to take according&nbsp;to taste. Some&nbsp;of these&nbsp;<br>
decisions&nbsp;wil&nbsp;&nbsp;affect&nbsp;the&nbsp;ease&nbsp;with&nbsp;which a program can&nbsp;be&nbsp;built up&nbsp;from routines&nbsp;<br>
generated&nbsp;from&nbsp;different source&nbsp;languages.&nbsp;Since&nbsp;this&nbsp;is&nbsp;an&nbsp;important issue,&nbsp;there is&nbsp;<br>
a defined&nbsp;<i>ARM Procedure&nbsp;Call Standard&nbsp;</i>that&nbsp;compiler&nbsp;writers should use&nbsp;to&nbsp;ensure&nbsp;<br>
the&nbsp;consistency&nbsp;of&nbsp;entry&nbsp;and&nbsp;exit&nbsp;conditions.&nbsp;<br>
Another area that&nbsp;benefits&nbsp;from agreement&nbsp;across&nbsp;compilers&nbsp;is the support for&nbsp;<br>
floating-point&nbsp;operations,&nbsp;which use data&nbsp;types that&nbsp;are&nbsp;not&nbsp;defined&nbsp;in the ARM&nbsp;<br>
hardware instruction&nbsp;set.&nbsp;<br>
<b>151</b>&nbsp;<br>
<hr>
<A name=163></a><b>152</b>&nbsp;<br>
<b>Architectural&nbsp;Support for&nbsp;High-Level&nbsp;Languages</b>&nbsp;<br>
6.1 &nbsp; Abstraction&nbsp;in&nbsp;software&nbsp;design&nbsp;<br>
We have already&nbsp;met&nbsp;a level of&nbsp;abstraction&nbsp;that&nbsp;is important to&nbsp;software&nbsp;design.&nbsp;The&nbsp;<br>
essence of&nbsp;an&nbsp;ARM processor is&nbsp;captured&nbsp;in the&nbsp;ARM&nbsp;instruction&nbsp;set&nbsp;which&nbsp;was&nbsp;<br>
described in&nbsp;Chapter 5.&nbsp;We&nbsp;shall&nbsp;see&nbsp;in&nbsp;Chapter 9&nbsp;that&nbsp;there&nbsp;are&nbsp;many&nbsp;ways&nbsp;to&nbsp;imple-<br>
ment&nbsp;the&nbsp;ARM architecture,&nbsp;but&nbsp;the&nbsp;whole point&nbsp;of&nbsp;an&nbsp;architecture&nbsp;is to&nbsp;ensure&nbsp;that&nbsp;<br>
the programmer need not be&nbsp;concerned&nbsp;with&nbsp;particular implementation details.&nbsp;If a&nbsp;<br>
program&nbsp;works correctly&nbsp;on&nbsp;one implementation it should work&nbsp;correctly&nbsp;on them&nbsp;<br>
all&nbsp;(with&nbsp;certain&nbsp;provisos).&nbsp;<br>
Assembly-level&nbsp;<br>
A&nbsp;programmer who writes&nbsp;at the assembly&nbsp;programming level works (almost)&nbsp;<br>
abstraction&nbsp;<br>
directly&nbsp;with&nbsp;the raw&nbsp;machine instruction&nbsp;set,&nbsp;expressing&nbsp;the program&nbsp;in&nbsp;terms of&nbsp;<br>
instructions, addresses,&nbsp;registers, bytes and&nbsp;words.&nbsp;<br>
A good programmer, faced with a non-trivial task, will&nbsp;begin&nbsp;by&nbsp;determining&nbsp;<br>
higher&nbsp;levels&nbsp;of abstraction&nbsp;that simplify the&nbsp;program&nbsp;design; for&nbsp;instance&nbsp;a&nbsp;graphics&nbsp;<br>
program&nbsp;may&nbsp;do&nbsp;a lot&nbsp;of line&nbsp;drawing, so&nbsp;a&nbsp;subroutine&nbsp;that&nbsp;will draw a&nbsp;line given the&nbsp;<br>
end&nbsp;coordinates will&nbsp;be&nbsp;useful. The&nbsp;rest&nbsp;of&nbsp;the&nbsp;program&nbsp;can&nbsp;then&nbsp;work&nbsp;just&nbsp;in&nbsp;terms of&nbsp;<br>
these&nbsp;end&nbsp;coordinates.&nbsp;<br>
Abstraction is important, then, at the assembly&nbsp;programming&nbsp;level, but all the&nbsp;<br>
responsibility for&nbsp;supporting&nbsp;the abstraction and&nbsp;expressing it in&nbsp;terms of&nbsp;the&nbsp;<br>
machine primitives rests with&nbsp;the programmer, who&nbsp;must therefore have a good&nbsp;<br>
understanding&nbsp;of those primitives and be&nbsp;prepared to return frequently&nbsp;to think at&nbsp;<br>
the level of the&nbsp;machine.&nbsp;<br>
High-level&nbsp;<br>
A high-level&nbsp;language allows the programmer to&nbsp;think&nbsp;in terms of&nbsp;abstractions that&nbsp;<br>
languages&nbsp;<br>
are above&nbsp;the machine level;&nbsp;indeed,&nbsp;the programmer&nbsp;may&nbsp;not&nbsp;even&nbsp;know on&nbsp;which&nbsp;<br>
machine&nbsp;the&nbsp;program&nbsp;will&nbsp;ultimately&nbsp;run.&nbsp;Parameters&nbsp;such&nbsp;as the&nbsp;number of&nbsp;registers&nbsp;<br>
vary&nbsp;from&nbsp;architecture to architecture,&nbsp;so&nbsp;clearly these&nbsp;must not be&nbsp;reflected in the&nbsp;<br>
design of&nbsp;the language.&nbsp;<br>
The job&nbsp;of supporting the abstractions used in&nbsp;the&nbsp;high-level language&nbsp;on the&nbsp;<br>
target architecture falls upon the&nbsp;<i>compiler.&nbsp;&nbsp;</i>Compilers&nbsp;are themselves&nbsp;extremely&nbsp;<br>
complex pieces&nbsp;of software,&nbsp;and the&nbsp;efficiency of&nbsp;the&nbsp;code they&nbsp;produce depends&nbsp;<br>
to a&nbsp;considerable&nbsp;extent on the support that&nbsp;the target&nbsp;architecture&nbsp;offers them&nbsp;to&nbsp;<br>
do their job.&nbsp;<br>
At one time, the conventional wisdom&nbsp;was that the best way&nbsp;to support a com-<br>
piler&nbsp;was to&nbsp;raise&nbsp;the&nbsp;complexity of&nbsp;the instruction&nbsp;set&nbsp;to implement&nbsp;the&nbsp;high-level&nbsp;<br>
operations&nbsp;of the&nbsp;language&nbsp;directly. The&nbsp;introduction&nbsp;of&nbsp;the RISC&nbsp;philosophy&nbsp;<br>
reversed that approach,&nbsp;focusing instruction&nbsp;set design on&nbsp;flexible primitive oper-<br>
ations&nbsp;from&nbsp;which the compiler&nbsp;can build&nbsp;its high-level&nbsp;operations.&nbsp;<br>
This chapter describes the&nbsp;requirements&nbsp;of&nbsp;high-level languages and&nbsp;shows how&nbsp;<br>
they&nbsp;are&nbsp;met&nbsp;by&nbsp;the&nbsp;ARM&nbsp;architecture,&nbsp;which&nbsp;is based on&nbsp;this RISC philosophy.&nbsp;<br>
<hr>
<A name=164></a><b>Data&nbsp;types</b>&nbsp;<br>
<b>153</b>&nbsp;<br>
6.2 &nbsp; Data&nbsp;types&nbsp;<br>
It is&nbsp;possible,&nbsp;though&nbsp;not&nbsp;very&nbsp;convenient,&nbsp;to&nbsp;express&nbsp;any&nbsp;computer program&nbsp;in&nbsp;<br>
terms of&nbsp;the basic Boolean logic variables 'true'&nbsp;(1)&nbsp;and 'false'&nbsp;(0). We&nbsp;can&nbsp;see&nbsp;that&nbsp;<br>
this is&nbsp;possible,&nbsp;since at&nbsp;the gate level&nbsp;that&nbsp;is all that&nbsp;the hardware can handle.&nbsp;<br>
The&nbsp;definition&nbsp;of the&nbsp;ARM&nbsp;instruction set&nbsp;already introduces an&nbsp;abstraction away&nbsp;<br>
from&nbsp;logic variables&nbsp;when&nbsp;it&nbsp;expresses the&nbsp;functions of&nbsp;the processor in&nbsp;terms&nbsp;of&nbsp;<br>
instructions, bytes,&nbsp;words,&nbsp;addresses,&nbsp;and&nbsp;so on. Each of&nbsp;these&nbsp;terms&nbsp;describes a col-<br>
lection of&nbsp;logic variables viewed&nbsp;in a particular&nbsp;way.&nbsp;Note,&nbsp;for example, that&nbsp;an&nbsp;<br>
instruction,&nbsp;a&nbsp;data&nbsp;word&nbsp;and an&nbsp;address&nbsp;are&nbsp;all 32 bits long and a 32-bit&nbsp;memory&nbsp;loca-<br>
tion&nbsp;which contains&nbsp;one&nbsp;of&nbsp;these is&nbsp;indistinguishable from&nbsp;one&nbsp;that contains another of&nbsp;<br>
a&nbsp;different type. The difference is&nbsp;not in&nbsp;the&nbsp;way the information&nbsp;is&nbsp;stored but in&nbsp;the&nbsp;<br>
way&nbsp;it is&nbsp;used.&nbsp;A computer data&nbsp;type&nbsp;can therefore be&nbsp;characterized&nbsp;by:&nbsp;<br>
•&nbsp;&nbsp;the number&nbsp;of&nbsp;bits it&nbsp;requires;&nbsp;<br>
•&nbsp;&nbsp;the ordering&nbsp;of those bits;&nbsp;<br>
•&nbsp;&nbsp;the uses to&nbsp;which the group of&nbsp;bits is put.&nbsp;<br>
Some&nbsp;data types, such&nbsp;as addresses and instructions, exist principally to&nbsp;serve the&nbsp;<br>
purposes of&nbsp;the&nbsp;computer,&nbsp;whereas&nbsp;others exist to&nbsp;represent&nbsp;information in&nbsp;a&nbsp;way that&nbsp;<br>
is&nbsp;accessible&nbsp;to&nbsp;human&nbsp;users. The&nbsp;most&nbsp;basic&nbsp;of&nbsp;the&nbsp;latter category, in&nbsp;the&nbsp;context&nbsp;of&nbsp;<br>
computation,&nbsp;is&nbsp;the&nbsp;number.&nbsp;<br>
Numbers&nbsp;<br>
What&nbsp;started&nbsp;as&nbsp;a&nbsp;simple concept, presumably&nbsp;as&nbsp;a&nbsp;means of checking that no sheep&nbsp;<br>
had been stolen&nbsp;overnight, has evolved over the ages into&nbsp;a very&nbsp;complex&nbsp;mecha-<br>
nism&nbsp;capable&nbsp;of&nbsp;computing the behaviour&nbsp;of&nbsp;transistors a thousandth of&nbsp;a&nbsp;millimetre&nbsp;<br>
wide&nbsp;switching&nbsp;a hundred&nbsp;million times a&nbsp;second.&nbsp;<br>
Roman&nbsp;numerals&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Here&nbsp;is&nbsp;a number written by&nbsp;a&nbsp;human:&nbsp;<br>
MCMXCV&nbsp;<br>
Decimal&nbsp;<br>
The&nbsp;interpretation&nbsp;of&nbsp;this&nbsp;<b>Roman&nbsp;&nbsp;</b>numeral is&nbsp;complex;&nbsp;the value&nbsp;of&nbsp;a symbol&nbsp;<br>
numbers&nbsp;<br>
depends on&nbsp;the&nbsp;symbol&nbsp;and its positional&nbsp;relationship to&nbsp;its neighbours. This&nbsp;way of&nbsp;<br>
writing a number has largely&nbsp;(but not entirely;&nbsp;see the page numbers in the front&nbsp;<br>
matter of&nbsp;this&nbsp;book) been&nbsp;replaced by&nbsp;the&nbsp;<b>decimal&nbsp;</b>scheme&nbsp;where&nbsp;the&nbsp;same&nbsp;number&nbsp;<br>
appears as:&nbsp;<br>
1995&nbsp;<br>
Here&nbsp;we understand that the&nbsp;right-hand digit represents the number of&nbsp;units, the&nbsp;<br>
digit to its left&nbsp;the&nbsp;number&nbsp;of&nbsp;tens, then hundreds, thousands, and so&nbsp;on. Each time&nbsp;we&nbsp;<br>
move&nbsp;left&nbsp;one place the value&nbsp;of the digit&nbsp;is&nbsp;increased by&nbsp;a factor&nbsp;of&nbsp;10.&nbsp;<br>
<hr>
<A name=165></a><b>154</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Binary coded&nbsp;<br>
To represent such a&nbsp;number as a&nbsp;group of&nbsp;Boolean&nbsp;variables, the simplest thing&nbsp;<br>
decimal&nbsp;<br>
appears to&nbsp;be to&nbsp;find a&nbsp;representation&nbsp;for&nbsp;each digit and then use&nbsp;four of&nbsp;these&nbsp;to&nbsp;rep-<br>
resent the&nbsp;whole number.&nbsp;We need four&nbsp;Boolean variables to be able to represent&nbsp;<br>
each digit from&nbsp;0 to 9 differently, so the first form&nbsp;of&nbsp;this number&nbsp;that could easily&nbsp;<br>
be&nbsp;handled by&nbsp;logic gates is:&nbsp;<br>
0001&nbsp;1001&nbsp;1001&nbsp;0101&nbsp;<br>
This&nbsp;is&nbsp;the binary&nbsp;coded decimal&nbsp;scheme&nbsp;which is&nbsp;supported&nbsp;by&nbsp;some&nbsp;computers&nbsp;<br>
and&nbsp;is commonly&nbsp;used&nbsp;in&nbsp;pocket calculators.&nbsp;<br>
Binary notation&nbsp;<br>
Most computers,&nbsp;most of&nbsp;the time, abandon the human-oriented decimal&nbsp;scheme&nbsp;<br>
altogether in&nbsp;favour of&nbsp;a pure&nbsp;binary&nbsp;notation where the&nbsp;same&nbsp;number becomes:&nbsp;<br>
11111001011&nbsp;<br>
Here the&nbsp;right-hand digit&nbsp;represents units, the&nbsp;next one&nbsp;2, then 4,&nbsp;and&nbsp;so on. Each&nbsp;<br>
time&nbsp;we&nbsp;move left&nbsp;one place the value of&nbsp;the&nbsp;digit doubles. Since a&nbsp;value&nbsp;of&nbsp;2 in&nbsp;one&nbsp;<br>
column&nbsp;can be&nbsp;represented by&nbsp;a value of 1 in&nbsp;the next&nbsp;column&nbsp;left,&nbsp;we never need&nbsp;a&nbsp;<br>
digit&nbsp;to&nbsp;have&nbsp;any&nbsp;value&nbsp;other&nbsp;than&nbsp;0&nbsp;or&nbsp;1,&nbsp;and&nbsp;hence&nbsp;each binary digit&nbsp;(bit)&nbsp;can be&nbsp;rep-<br>
resented&nbsp;by&nbsp;a single Boolean variable.&nbsp;<br>
Hexadecimal&nbsp;<br>
Although&nbsp;machines use binary&nbsp;numbers&nbsp;extensively&nbsp;internally, a&nbsp;typical&nbsp;32-bit&nbsp;<br>
notation&nbsp;<br>
binary&nbsp;number&nbsp;is&nbsp;fairly&nbsp;unmemorable,&nbsp;but&nbsp;rather than convert&nbsp;it&nbsp;to the&nbsp;familiar&nbsp;deci-<br>
mal form&nbsp;(which&nbsp;is&nbsp;quite&nbsp;hard work and&nbsp;error-prone),&nbsp;computer&nbsp;users&nbsp;often&nbsp;describe&nbsp;<br>
the number in&nbsp;<b>hexadecimal&nbsp;&nbsp;</b>(base 16) notation. This is easy because the binary&nbsp;<br>
number&nbsp;can be&nbsp;split into groups of four&nbsp;binary&nbsp;digits&nbsp;and each group&nbsp;replaced by&nbsp;a&nbsp;<br>
hexadecimal number. Because, in base 16,&nbsp;we need symbols&nbsp;for numbers from&nbsp;0 to&nbsp;<br>
15, the&nbsp;early letters of&nbsp;the&nbsp;alphabet&nbsp;have&nbsp;been&nbsp;pressed&nbsp;into&nbsp;service&nbsp;where the decimal&nbsp;<br>
symbols&nbsp;run out: we use 0 to&nbsp;9 as themselves and&nbsp;A to&nbsp;F to represent 10&nbsp;to 15. Our&nbsp;<br>
number becomes:&nbsp;<br>
7CB&nbsp;<br>
(At&nbsp;one&nbsp;time&nbsp;it&nbsp;was&nbsp;common to&nbsp;use&nbsp;octal,&nbsp;base&nbsp;8,&nbsp;notation in&nbsp;a&nbsp;similar role. This&nbsp;<br>
avoids the need&nbsp;to&nbsp;use&nbsp;alphabetic characters,&nbsp;but groups of three bits are less&nbsp;conven-<br>
ient&nbsp;to&nbsp;work&nbsp;with than&nbsp;groups&nbsp;of four, so&nbsp;the&nbsp;use of&nbsp;octal&nbsp;has&nbsp;largely&nbsp;been&nbsp;abandoned.)&nbsp;<br>
Number ranges&nbsp;<br>
When writing on&nbsp;paper, we use&nbsp;the&nbsp;number&nbsp;of decimal digits that are&nbsp;required to&nbsp;<br>
represent&nbsp;the number&nbsp;we&nbsp;want&nbsp;to&nbsp;write.&nbsp;A computer usually&nbsp;reserves&nbsp;a&nbsp;fixed&nbsp;number&nbsp;<br>
of bits for a number, so if the number gets too big it&nbsp;cannot&nbsp;be represented. The&nbsp;<br>
ARM deals&nbsp;efficiently&nbsp;with 32-bit quantities, so the&nbsp;first data type that&nbsp;the&nbsp;architec-<br>
ture&nbsp;supports is the 32-bit&nbsp;(unsigned)&nbsp;integer,&nbsp;which has a value in&nbsp;the&nbsp;range:&nbsp;<br>
0&nbsp;to&nbsp;4&nbsp;294&nbsp;967 29510&nbsp;= 0 to&nbsp;FFFFFFFF16&nbsp;<br>
<hr>
<A name=166></a><b>Data&nbsp;types</b>&nbsp;<br>
<b>155</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
(The&nbsp;subscript&nbsp;indicates&nbsp;the&nbsp;number base,&nbsp;so&nbsp;the range&nbsp;above&nbsp;is&nbsp;expressed&nbsp;in&nbsp;deci-<br>
mal first and&nbsp;in&nbsp;hexadecimal second.&nbsp;Note&nbsp;how the&nbsp;hexadecimal value&nbsp;'F'&nbsp;represents a&nbsp;<br>
binary&nbsp;number of all'&nbsp;1&nbsp;'s.)&nbsp;<br>
This looks like&nbsp;a large range,&nbsp;and&nbsp;indeed&nbsp;is adequate&nbsp;for&nbsp;most purposes,&nbsp;though the&nbsp;<br>
programmer&nbsp;must&nbsp;be&nbsp;aware&nbsp;of&nbsp;its&nbsp;limitations.&nbsp;Adding&nbsp;two&nbsp;unsigned&nbsp;numbers near the&nbsp;<br>
maximum&nbsp;value within&nbsp;the range will give&nbsp;the wrong answer, since the&nbsp;correct answer&nbsp;<br>
cannot be&nbsp;represented&nbsp;within 32&nbsp;bits. The C&nbsp;flag in&nbsp;the program&nbsp;status&nbsp;register&nbsp;gives&nbsp;<br>
the&nbsp;only&nbsp;indication&nbsp;that something&nbsp;has&nbsp;gone&nbsp;wrong&nbsp;and the&nbsp;answer is not to&nbsp;be&nbsp;trusted.&nbsp;<br>
If a large number is subtracted from&nbsp;a small number, the result will&nbsp;be&nbsp;negative and&nbsp;<br>
cannot&nbsp;be&nbsp;represented by&nbsp;an&nbsp;unsigned&nbsp;integer&nbsp;of any&nbsp;size.&nbsp;<br>
Signed integers&nbsp;<br>
In&nbsp;many&nbsp;cases it is useful&nbsp;to be able to represent negative&nbsp;numbers as&nbsp;well as posi-<br>
tive&nbsp;ones. Here&nbsp;the ARM supports a&nbsp;2's complement binary notation where the&nbsp;value&nbsp;<br>
of&nbsp;the&nbsp;top bit&nbsp;is&nbsp;made&nbsp;negative; in&nbsp;a 32-bit&nbsp;signed integer all&nbsp;the bits&nbsp;have&nbsp;the&nbsp;same&nbsp;<br>
value&nbsp;as&nbsp;they&nbsp;have&nbsp;in&nbsp;the unsigned&nbsp;case&nbsp;apart&nbsp;from&nbsp;bit&nbsp;31,&nbsp;which&nbsp;has&nbsp;the&nbsp;value&nbsp;-231&nbsp;<br>
instead&nbsp;of+231. Now the&nbsp;range&nbsp;of&nbsp;numbers is:&nbsp;<br>
-2&nbsp;147 483 64810&nbsp;to +2&nbsp;147 483&nbsp;64710&nbsp;=&nbsp;8000000016&nbsp;to 7FFFFFFF,6&nbsp;<br>
Note&nbsp;that&nbsp;the&nbsp;sign&nbsp;of&nbsp;the number is&nbsp;determined by&nbsp;bit 31&nbsp;alone, and the positive&nbsp;<br>
integer&nbsp;values&nbsp;have&nbsp;exactly&nbsp;the same&nbsp;representation as&nbsp;their&nbsp;unsigned&nbsp;equivalents.&nbsp;<br>
The ARM, in&nbsp;common with most processors, uses the 2's complement notation for&nbsp;<br>
signed&nbsp;integers&nbsp;because&nbsp;adding&nbsp;or&nbsp;subtracting them&nbsp;requires exactly&nbsp;the same&nbsp;Boolean&nbsp;<br>
logic functions&nbsp;as&nbsp;are&nbsp;needed&nbsp;for unsigned&nbsp;integers, so&nbsp;there&nbsp;is&nbsp;no&nbsp;need&nbsp;to&nbsp;have&nbsp;sepa-<br>
rate instructions (the exception being&nbsp;multiplication with a full 64-bit result; here&nbsp;<br>
ARM&nbsp;<i>does&nbsp;</i>have separate signed and unsigned&nbsp;instructions).&nbsp;<br>
The&nbsp;'architectural support'&nbsp;for signed&nbsp;integers is the&nbsp;V&nbsp;flag&nbsp;in the program status&nbsp;<br>
registers&nbsp;which has no use when the operands are unsigned but indicates an&nbsp;<b>over-</b><br>
<b>flow&nbsp;</b>(out&nbsp;of&nbsp;range)&nbsp;error when&nbsp;signed&nbsp;operands&nbsp;are combined.&nbsp;The&nbsp;source&nbsp;operands&nbsp;<br>
cannot be out&nbsp;of&nbsp;range&nbsp;since they&nbsp;are&nbsp;represented&nbsp;as 32-bit values, but when&nbsp;two&nbsp;<br>
numbers near&nbsp;the extremes&nbsp;of&nbsp;the&nbsp;range are added or&nbsp;subtracted, the&nbsp;result&nbsp;could&nbsp;fall&nbsp;<br>
outside the&nbsp;range; its 32-bit&nbsp;representation&nbsp;will be&nbsp;an&nbsp;in-range&nbsp;number of the wrong&nbsp;<br>
value and&nbsp;sign.&nbsp;<br>
Other number&nbsp;<br>
The&nbsp;natural&nbsp;representation&nbsp;of&nbsp;a number in&nbsp;the&nbsp;ARM&nbsp;is&nbsp;as a signed or&nbsp;unsigned&nbsp;32-bit&nbsp;<br>
sizes&nbsp;<br>
integer;&nbsp;indeed, internally to&nbsp;the&nbsp;processor that&nbsp;is&nbsp;all that there is. However,&nbsp;all ARM&nbsp;<br>
processors will perform&nbsp;unsigned&nbsp;8-bit&nbsp;(byte) loads and&nbsp;stores, allowing&nbsp;small&nbsp;posi-<br>
tive numbers to&nbsp;occupy a smaller space in&nbsp;memory than&nbsp;a 32-bit word,&nbsp;and all but&nbsp;<br>
the earliest&nbsp;versions of&nbsp;the&nbsp;processor&nbsp;also&nbsp;support signed byte&nbsp;and signed&nbsp;and&nbsp;<br>
unsigned 16-bit transfers, also principally&nbsp;to reduce the&nbsp;memory&nbsp;required to store&nbsp;<br>
small values.&nbsp;<br>
Where&nbsp;a 32-bit&nbsp;integer is&nbsp;too small,&nbsp;larger numbers&nbsp;can&nbsp;be handled&nbsp;using multiple&nbsp;<br>
words and&nbsp;multiple registers. A 64-bit addition can be&nbsp;performed with two 32-bit&nbsp;<br>
<hr>
<A name=167></a><b>156</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
additions, using&nbsp;the C flag&nbsp;in&nbsp;the status&nbsp;register to propagate the carry&nbsp;from&nbsp;the lower&nbsp;<br>
word to the higher word:&nbsp;<br>
; 64-bit&nbsp;addition of&nbsp;[r1,r0] to&nbsp;[r3,r2]&nbsp;<br>
ADDS&nbsp; &nbsp;r2,&nbsp;r2,&nbsp;r0&nbsp;&nbsp;&nbsp; &nbsp; &nbsp;&nbsp;;&nbsp;add&nbsp;low,&nbsp;save&nbsp;carry&nbsp;<br>
ADC&nbsp;&nbsp;&nbsp; r3,&nbsp;r3,&nbsp;r1&nbsp;&nbsp;&nbsp; &nbsp; &nbsp;&nbsp;;&nbsp;add&nbsp;high&nbsp;with&nbsp;carry&nbsp;<br>
Real numbers&nbsp;<br>
So&nbsp;far&nbsp;we have&nbsp;just&nbsp;considered&nbsp;integers,&nbsp;or&nbsp;whole&nbsp;numbers. 'Real'&nbsp;numbers&nbsp;are&nbsp;used&nbsp;<br>
to&nbsp;represent&nbsp;fractions&nbsp;and&nbsp;transcendental&nbsp;values&nbsp;that&nbsp;are&nbsp;useful&nbsp;when&nbsp;dealing with&nbsp;<br>
physical quantities.&nbsp;<br>
The&nbsp;representation&nbsp;of&nbsp;real&nbsp;numbers in&nbsp;computers is&nbsp;a&nbsp;big issue that&nbsp;is&nbsp;deferred&nbsp;to&nbsp;<br>
the next&nbsp;section.&nbsp;An&nbsp;ARM&nbsp;core has&nbsp;no&nbsp;support&nbsp;for&nbsp;real&nbsp;data&nbsp;types, though&nbsp;ARM&nbsp;Lim-<br>
ited has defined a set of types and instructions that&nbsp;operate&nbsp;on them. These&nbsp;instructions&nbsp;<br>
are either executed on a floating-point coprocessor or emulated in&nbsp;software.&nbsp;<br>
Printable&nbsp;<br>
After&nbsp;the&nbsp;number, the&nbsp;next&nbsp;most&nbsp;basic&nbsp;data&nbsp;type is&nbsp;the&nbsp;printable character.&nbsp;To control&nbsp;<br>
characters&nbsp;<br>
a&nbsp;standard&nbsp;printer&nbsp;we&nbsp;need&nbsp;a&nbsp;way to&nbsp;represent all the normal characters&nbsp;such&nbsp;as&nbsp;the&nbsp;<br>
upper and lower&nbsp;case&nbsp;alphabet,&nbsp;decimal digits&nbsp;from&nbsp;0 to&nbsp;9,&nbsp;punctuation&nbsp;marks&nbsp;and&nbsp;a&nbsp;<br>
number&nbsp;of special characters&nbsp;such&nbsp;as&nbsp;£,&nbsp;$, %,&nbsp;and&nbsp;so on.&nbsp;<br>
ASCII&nbsp;<br>
Counting all&nbsp;these different&nbsp;characters, the total&nbsp;rapidly&nbsp;approaches a hundred&nbsp;or so.&nbsp;<br>
Some&nbsp;time ago&nbsp;the binary&nbsp;representation of&nbsp;these characters&nbsp;was standardized in the&nbsp;<br>
7-bit&nbsp;ASCII&nbsp;(American Standard for&nbsp;Computer Information Interchange)&nbsp;code,&nbsp;which&nbsp;<br>
includes&nbsp;these&nbsp;printable&nbsp;characters&nbsp;and a number of control&nbsp;codes whose&nbsp;names reflect&nbsp;<br>
the teletype&nbsp;origins&nbsp;of the code,&nbsp;such as&nbsp;'carriage return',&nbsp;'line feed', and 'bell'.&nbsp;<br>
The normal way to store an ASCII character&nbsp;in&nbsp;a computer&nbsp;is to&nbsp;put&nbsp;the 7-bit&nbsp;binary&nbsp;<br>
code&nbsp;into&nbsp;an&nbsp;8-bit&nbsp;byte. Many&nbsp;systems extend&nbsp;the&nbsp;code&nbsp;using,&nbsp;for example, the&nbsp;8-bit&nbsp;<br>
ISO character set where the other 128 binary&nbsp;codes within&nbsp;the byte represent special&nbsp;<br>
characters (for&nbsp;instance, characters with accents). The&nbsp;most&nbsp;flexible way&nbsp;to&nbsp;represent&nbsp;<br>
characters is the 16-bit 'Unicode'&nbsp;which incorporates&nbsp;many such 8-bit character sets&nbsp;<br>
within&nbsp;a single&nbsp;encoding.&nbsp;<br>
'1995'&nbsp;encoded&nbsp;as 8-bit&nbsp;printable characters is:&nbsp;<br>
00110001&nbsp;00111001 00111001&nbsp;00110101&nbsp;=31&nbsp;39&nbsp;39&nbsp;3516&nbsp;<br>
ARM support for&nbsp;<br>
The support&nbsp;in&nbsp;the&nbsp;ARM&nbsp;architecture for&nbsp;handling characters is&nbsp;the&nbsp;unsigned&nbsp;byte&nbsp;<br>
characters&nbsp;<br>
load and store&nbsp;instructions;&nbsp;these have already&nbsp;been&nbsp;mentioned as&nbsp;being&nbsp;available to&nbsp;<br>
support&nbsp;small unsigned&nbsp;integers,&nbsp;but that&nbsp;role is&nbsp;rare&nbsp;compared&nbsp;with&nbsp;their frequency&nbsp;<br>
of use&nbsp;for transferring&nbsp;ASCII&nbsp;characters.&nbsp;<br>
There is nothing&nbsp;in&nbsp;the&nbsp;ARM&nbsp;architecture that reflects the&nbsp;particular codes defined&nbsp;<br>
by&nbsp;ASCII;&nbsp;any&nbsp;other encoding is&nbsp;equally&nbsp;well supported provided it&nbsp;uses no&nbsp;more than&nbsp;<br>
eight&nbsp;bits. However,&nbsp;it&nbsp;would&nbsp;be perverse&nbsp;these days&nbsp;to&nbsp;choose&nbsp;a&nbsp;different&nbsp;code&nbsp;for&nbsp;<br>
characters without&nbsp;having a very&nbsp;good reason.&nbsp;<br>
<hr>
<A name=168></a><b>Data types</b>&nbsp;<br>
157&nbsp;<br>
&nbsp;&nbsp;&nbsp;Byte ordering&nbsp;<br>
The above&nbsp;ASCII example&nbsp;highlights&nbsp;an&nbsp;area&nbsp;of&nbsp;some&nbsp;potential&nbsp;difficulty.&nbsp;It&nbsp;is written&nbsp;<br>
to be&nbsp;read&nbsp;from&nbsp;left to&nbsp;right,&nbsp;but&nbsp;if&nbsp;it&nbsp;is read&nbsp;as&nbsp;a&nbsp;32-bit&nbsp;word,&nbsp;the&nbsp;least&nbsp;significant&nbsp;byte&nbsp;<br>
is at&nbsp;the right.&nbsp;A character&nbsp;output&nbsp;routine might&nbsp;print&nbsp;characters&nbsp;at&nbsp;successive increas-<br>
ing&nbsp;byte&nbsp;addresses, in which&nbsp;case, with&nbsp;'little-endian'&nbsp;addressing,&nbsp;it&nbsp;will&nbsp;print '5991'.&nbsp;<br>
We&nbsp;clearly need&nbsp;to&nbsp;be&nbsp;careful&nbsp;about&nbsp;the&nbsp;order&nbsp;of bytes within&nbsp;words in&nbsp;memory.&nbsp;<br>
(ARMs can operate&nbsp;with&nbsp;either little-&nbsp;or&nbsp;big-endian&nbsp;addressing.&nbsp;See&nbsp;'Memory&nbsp;<br>
organization'on&nbsp;page 106.)&nbsp;<br>
High-level&nbsp;<br>
A high-level&nbsp;language&nbsp;defines the data&nbsp;types that&nbsp;it needs in its specification,&nbsp;usually&nbsp;<br>
languages&nbsp;<br>
without&nbsp;reference to any&nbsp;particular architecture that it&nbsp;may&nbsp;run on. Sometimes the&nbsp;<br>
number of&nbsp;bits used to&nbsp;represent a particular data type is&nbsp;architecture-dependent in&nbsp;<br>
order to&nbsp;allow a&nbsp;machine&nbsp;to&nbsp;use&nbsp;its&nbsp;most&nbsp;efficient&nbsp;size.&nbsp;<br>
ANSI C&nbsp;basic&nbsp;<br>
The dialect of the&nbsp;'C'&nbsp;language defined by&nbsp;the American National Standards Insti-<br>
data&nbsp;types&nbsp;<br>
tute&nbsp;(ANSI), and therefore&nbsp;known&nbsp;as 'ANSI standard&nbsp;C'&nbsp;or&nbsp;simply&nbsp;'ANSI&nbsp;C',&nbsp;defines&nbsp;<br>
the&nbsp;following basic data&nbsp;types:&nbsp;<br>
•&nbsp;&nbsp;Signed and&nbsp;unsigned&nbsp;<b>characters&nbsp;</b>of&nbsp;at least&nbsp;eight bits.&nbsp;<br>
•&nbsp;&nbsp;Signed and&nbsp;unsigned&nbsp;<b>short integers&nbsp;</b>of&nbsp;at&nbsp;least 16&nbsp;bits.&nbsp;<br>
•&nbsp;&nbsp;Signed and&nbsp;unsigned&nbsp;<b>integers&nbsp;</b>of&nbsp;at&nbsp;least 16&nbsp;bits.&nbsp;<br>
•&nbsp;&nbsp;Signed and&nbsp;unsigned&nbsp;<b>long integers&nbsp;</b>of&nbsp;at least 32 bits.&nbsp;<br>
•&nbsp;&nbsp;<b>Floating-point, double&nbsp;</b>and&nbsp;<b>long double&nbsp;</b>floating-point numbers.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Enumerated&nbsp;</b>types.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Bitfields.&nbsp;</b><br>
The ARM C&nbsp;compiler adopts&nbsp;the&nbsp;minimum&nbsp;sizes for&nbsp;each&nbsp;of these&nbsp;types&nbsp;except&nbsp;the&nbsp;<br>
standard&nbsp;integer, where&nbsp;it&nbsp;uses&nbsp;32-bit&nbsp;values&nbsp;since&nbsp;this&nbsp;is&nbsp;the&nbsp;most frequently&nbsp;used&nbsp;data&nbsp;<br>
type and&nbsp;the ARM supports&nbsp;32-bit&nbsp;operations&nbsp;more efficiently than 16-bit&nbsp;operations.&nbsp;<br>
Enumerated types&nbsp;(where variables&nbsp;have&nbsp;one value&nbsp;out&nbsp;of&nbsp;a&nbsp;specified&nbsp;set of possible&nbsp;<br>
values)&nbsp;are&nbsp;implemented as&nbsp;the&nbsp;smallest&nbsp;integer type&nbsp;with&nbsp;the necessary&nbsp;range&nbsp;of val-<br>
ues. Bitfield&nbsp;types (sets&nbsp;of Boolean&nbsp;variables)&nbsp;are implemented within&nbsp;integers; several&nbsp;<br>
may&nbsp;share one&nbsp;integer,&nbsp;with&nbsp;the first&nbsp;declared&nbsp;holding the&nbsp;lowest bit&nbsp;position,&nbsp;but&nbsp;may&nbsp;<br>
not straddle word&nbsp;boundaries.&nbsp;<br>
ANSI C derived&nbsp;<br>
In&nbsp;addition,&nbsp;the&nbsp;ANSI C&nbsp;standard&nbsp;defines&nbsp;derived&nbsp;data&nbsp;types:&nbsp;<br>
data types&nbsp;<br>
•&nbsp;&nbsp;<b>Arrays&nbsp;</b>of&nbsp;several&nbsp;objects&nbsp;of&nbsp;the same&nbsp;type.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Functions&nbsp;</b>which return&nbsp;an object of&nbsp;a given&nbsp;type.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Structures&nbsp;</b>containing a sequence&nbsp;of&nbsp;objects&nbsp;of&nbsp;various types.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Pointers&nbsp;</b>(which&nbsp;are usually&nbsp;machine addresses) to&nbsp;objects&nbsp;of&nbsp;a given&nbsp;type.<b>&nbsp;</b><br>
<hr>
<A name=169></a><b>158</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
• Unions which allow objects of different types to occupy the same space at&nbsp;<br>
different times.&nbsp;<br>
ARM pointers&nbsp;are&nbsp;32&nbsp;bits&nbsp;long&nbsp;(the&nbsp;size&nbsp;of&nbsp;ARM&nbsp;native&nbsp;addresses) and&nbsp;resemble&nbsp;<br>
unsigned integers,&nbsp;though note&nbsp;that&nbsp;they&nbsp;obey different arithmetic&nbsp;rules.&nbsp;<br>
The&nbsp;ARM&nbsp;C compiler aligns&nbsp;characters on&nbsp;byte&nbsp;boundaries (that is, at the&nbsp;next&nbsp;<br>
available&nbsp;address), short&nbsp;integers at&nbsp;even&nbsp;addresses and&nbsp;all&nbsp;other&nbsp;types&nbsp;on&nbsp;word&nbsp;bound-<br>
aries.&nbsp;A structure always&nbsp;starts&nbsp;on&nbsp;a word&nbsp;boundary&nbsp;with&nbsp;the first-named component,&nbsp;<br>
then subsequent&nbsp;components&nbsp;are&nbsp;packed&nbsp;as&nbsp;closely&nbsp;as&nbsp;possible&nbsp;consistent with&nbsp;these&nbsp;<br>
alignment rules. (Packed structures&nbsp;violate&nbsp;the&nbsp;alignment rules;&nbsp;use&nbsp;of memory is dis-<br>
cussed&nbsp;more extensively&nbsp;in Section&nbsp;6.9 on&nbsp;page&nbsp;180.)&nbsp;<br>
ARM&nbsp;<br>
We have seen&nbsp;above that the&nbsp;ARM integer&nbsp;core provides&nbsp;native support for&nbsp;signed&nbsp;<br>
architectural&nbsp;<br>
and unsigned 32-bit integers and for unsigned bytes, covering the C integer (given&nbsp;<br>
support for&nbsp;C&nbsp;<br>
the decision to&nbsp;implement these as 32-bit values),&nbsp;long&nbsp;integer&nbsp;and unsigned&nbsp;charac-<br>
data&nbsp;types&nbsp;<br>
ter&nbsp;types.&nbsp;Pointers&nbsp;are&nbsp;implemented&nbsp;as&nbsp;native&nbsp;ARM&nbsp;addresses&nbsp;and are&nbsp;therefore&nbsp;sup-<br>
ported directly.&nbsp;<br>
The&nbsp;ARM&nbsp;addressing&nbsp;modes&nbsp;provide reasonable&nbsp;support for arrays&nbsp;and&nbsp;structures:&nbsp;<br>
base&nbsp;plus scaled&nbsp;index&nbsp;addressing&nbsp;allows&nbsp;an&nbsp;array&nbsp;of objects&nbsp;of a&nbsp;size&nbsp;which&nbsp;is&nbsp;2&quot;&nbsp;bytes&nbsp;<br>
to be&nbsp;scanned using&nbsp;a pointer&nbsp;to the&nbsp;start of the array&nbsp;and a loop&nbsp;variable as&nbsp;the&nbsp;index;&nbsp;<br>
base plus immediate&nbsp;offset&nbsp;addressing gives&nbsp;access to&nbsp;an&nbsp;object&nbsp;within&nbsp;a&nbsp;structure.&nbsp;<br>
However, additional&nbsp;address&nbsp;calculation&nbsp;instructions will&nbsp;be&nbsp;necessary&nbsp;for&nbsp;more com-<br>
plex accesses.&nbsp;<br>
Current versions of the ARM include signed byte and signed and unsigned&nbsp;<br>
16-bit loads&nbsp;and stores, providing some&nbsp;native&nbsp;support for short integer and&nbsp;<br>
signed&nbsp;character&nbsp;types.&nbsp;<br>
Floating-point types&nbsp;are discussed&nbsp;in&nbsp;the next&nbsp;section,&nbsp;however&nbsp;here we can note&nbsp;<br>
that the basic&nbsp;ARM core offers little direct&nbsp;support&nbsp;for them. These types (and the&nbsp;<br>
instructions&nbsp;that&nbsp;manipulate&nbsp;them) are,&nbsp;in the&nbsp;absence&nbsp;of&nbsp;specific floating-point&nbsp;sup-<br>
port&nbsp;hardware,&nbsp;handled&nbsp;by&nbsp;complex software&nbsp;emulation&nbsp;routines.&nbsp;<br>
6.3 &nbsp; Floating-point&nbsp;data&nbsp;types&nbsp;<br>
Floating-point numbers attempt&nbsp;to&nbsp;represent&nbsp;real&nbsp;numbers with uniform&nbsp;accuracy.&nbsp;A&nbsp;<br>
generic way&nbsp;to&nbsp;represent a real&nbsp;number&nbsp;is in&nbsp;the form:&nbsp;<br>
<i>R =&nbsp;a x bn</i>&nbsp;<br>
Equation 13&nbsp;<br>
where&nbsp;<i>n</i>&nbsp;is chosen so&nbsp;that&nbsp;<i>a&nbsp;</i>falls&nbsp;within a defined&nbsp;range of&nbsp;values;&nbsp;<i>b&nbsp;</i>is&nbsp;usually&nbsp;<br>
implicit&nbsp;in the&nbsp;data type&nbsp;and is&nbsp;often equal to&nbsp;2.&nbsp;<br>
<hr>
<A name=170></a><IMG src="index-170_1.png"><br>
<b>Floating-point&nbsp;data&nbsp;types</b>&nbsp;<br>
<b>159</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;IEEE&nbsp;754&nbsp;<br>
There&nbsp;are&nbsp;many&nbsp;complex&nbsp;issues to&nbsp;resolve with&nbsp;the&nbsp;handling of&nbsp;floating-point&nbsp;num-<br>
bers&nbsp;in computers to ensure that the results&nbsp;are&nbsp;consistent&nbsp;when&nbsp;the same&nbsp;program&nbsp;is&nbsp;<br>
run&nbsp;on&nbsp;different&nbsp;machines.&nbsp;The consistency&nbsp;problem&nbsp;was greatly aided&nbsp;by&nbsp;the intro-<br>
duction&nbsp;in&nbsp;1985&nbsp;of&nbsp;the&nbsp;IEEE Standard&nbsp;for Binary Floating-Point Arithmetic&nbsp;(ANSI/&nbsp;<br>
IEEE Standard&nbsp;754-1985, sometimes referred&nbsp;to simply&nbsp;as IEEE&nbsp;754) which&nbsp;defines&nbsp;<br>
in&nbsp;considerable detail how&nbsp;floating-point&nbsp;numbers should be represented,&nbsp;the&nbsp;accu-<br>
racy with&nbsp;which calculations should be performed, how&nbsp;errors&nbsp;should be detected&nbsp;<br>
and returned, and&nbsp;so&nbsp;on.&nbsp;<br>
The&nbsp;most compact&nbsp;representation&nbsp;of&nbsp;a&nbsp;floating-point&nbsp;number defined&nbsp;by&nbsp;IEEE&nbsp;754&nbsp;<br>
is&nbsp;the&nbsp;32-bit&nbsp;'single precision'&nbsp;format:&nbsp;<br>
Single precision&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;6.1 &nbsp;&nbsp;&nbsp;</b>IEEE 754 single precision floating-point number format.&nbsp;<br>
The number is&nbsp;made up&nbsp;from&nbsp;a&nbsp;<b>sign&nbsp;bit&nbsp;</b>('S'),&nbsp;an&nbsp;<b>exponent&nbsp;</b>which is&nbsp;an&nbsp;unsigned&nbsp;<br>
integer&nbsp;value&nbsp;with&nbsp;a 'bias'&nbsp;of+127&nbsp;(for&nbsp;normalized&nbsp;numbers) and&nbsp;a&nbsp;<b>fractional&nbsp;</b>compo-<br>
nent. A&nbsp;number of terms in the previous&nbsp;sentence&nbsp;may be unfamiliar. To&nbsp;explain them,&nbsp;<br>
let us&nbsp;look&nbsp;at how&nbsp;a&nbsp;number we&nbsp;recognize,'&nbsp;1995',&nbsp;is&nbsp;converted&nbsp;into this format.&nbsp;<br>
We start from&nbsp;the binary&nbsp;representation of 1995, which&nbsp;has already&nbsp;been presented:&nbsp;<br>
11111001011&nbsp;This&nbsp;is&nbsp;a&nbsp;positive&nbsp;number,&nbsp;<br>
so the S&nbsp;bit&nbsp;will&nbsp;be&nbsp;zero.&nbsp;<br>
Normalized&nbsp;<br>
The first step&nbsp;is to&nbsp;<b>normalize&nbsp;</b>the number, which&nbsp;means convert it into the form&nbsp;<br>
numbers&nbsp;<br>
shown&nbsp;in&nbsp;Equation&nbsp;13 on page 158&nbsp;where 1&nbsp;<i>&lt;a&lt;2&nbsp;</i>and&nbsp;<i>b&nbsp;</i>= 2. Looking&nbsp;at the&nbsp;<br>
binary&nbsp;form&nbsp;of&nbsp;the number,&nbsp;<i>a&nbsp;</i>can be constrained within&nbsp;this range by&nbsp;inserting a&nbsp;<br>
'binary point'&nbsp;(similar&nbsp;in&nbsp;interpretation to&nbsp;the&nbsp;more&nbsp;familiar decimal&nbsp;point) after the&nbsp;<br>
first'&nbsp;1'.&nbsp;The implicit position of&nbsp;the binary&nbsp;point in&nbsp;the binary&nbsp;integer&nbsp;representation&nbsp;<br>
is to the right&nbsp;of the right-most digit, so&nbsp;here we have to&nbsp;move it left&nbsp;ten places.&nbsp;<br>
Hence the normalized&nbsp;representation of&nbsp;1995 is:&nbsp;<br>
1995&nbsp;= 1.111100101&nbsp;Ix210&nbsp;<br>
Equation&nbsp;14&nbsp;<br>
where&nbsp;<i>a&nbsp;</i>and&nbsp;<i>n&nbsp;</i>are both in&nbsp;binary notation.&nbsp;<br>
When any number is normalized, the bit in&nbsp;front of the binary point in&nbsp;<i>a&nbsp;&nbsp;</i>will be&nbsp;<br>
a&nbsp;' 1'&nbsp;(otherwise the number is&nbsp;not normalized). Therefore&nbsp;there&nbsp;is no&nbsp;need to store&nbsp;<br>
this bit.&nbsp;<br>
<hr>
<A name=171></a><IMG src="index-171_1.png"><br>
<b>160</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Exponent bias&nbsp;<br>
Finally,&nbsp;since the&nbsp;format is required&nbsp;to&nbsp;represent&nbsp;very&nbsp;small numbers as&nbsp;well&nbsp;as&nbsp;very&nbsp;<br>
large&nbsp;ones,&nbsp;some&nbsp;numbers may require negative exponents in&nbsp;their&nbsp;normalized&nbsp;form.&nbsp;<br>
Rather than&nbsp;use a signed exponent,&nbsp;the standard specifies&nbsp;a 'bias'. This bias (+127&nbsp;<br>
for single&nbsp;precision&nbsp;normalized numbers)&nbsp;is added to&nbsp;the exponent&nbsp;value. Hence&nbsp;<br>
1995&nbsp;is represented as:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure 6.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>IEEE 754 single precision representation&nbsp;of '1995'.&nbsp;<br>
The exponent is 127+10&nbsp;= 137; the&nbsp;fraction is&nbsp;zero-extended&nbsp;to the right&nbsp;to fill&nbsp;the&nbsp;<br>
23-bit field.&nbsp;<br>
Normalized&nbsp;<br>
In general,&nbsp;the value of a 32-bit normalized&nbsp;number&nbsp;is given&nbsp;by:&nbsp;<br>
value&nbsp;<br>
value (norm)&nbsp;= (-l)Sx l.fractionx 2(exponent&quot;127)&nbsp;<br>
Equation 15&nbsp;<br>
Although this format represents a wide range&nbsp;of values&nbsp;efficiently, it&nbsp;has&nbsp;one rather&nbsp;<br>
glaring&nbsp;problem:&nbsp;there is no&nbsp;way to&nbsp;represent zero. Therefore the IEEE&nbsp;754 standard&nbsp;<br>
reserves numbers where the exponent is&nbsp;either&nbsp;zero&nbsp;or 255 to&nbsp;represent special values:&nbsp;<br>
•&nbsp;&nbsp;Zero is represented by&nbsp;a&nbsp;zero&nbsp;exponent&nbsp;and&nbsp;fraction&nbsp;(but either&nbsp;sign&nbsp;value, so&nbsp;pos&nbsp;<br>
itive&nbsp;and&nbsp;negative zeros can be&nbsp;represented).&nbsp;<br>
•&nbsp;&nbsp;Plus or minus&nbsp;infinity&nbsp;are&nbsp;represented by&nbsp;the maximum&nbsp;exponent&nbsp;value with&nbsp;a&nbsp;<br>
zero&nbsp;fraction and the appropriate sign bit.&nbsp;<br>
•&nbsp;&nbsp;NaN (Not&nbsp;a Number)&nbsp;is indicated&nbsp;by&nbsp;the maximum&nbsp;exponent and&nbsp;a non-zero&nbsp;<br>
fraction;&nbsp;'quiet'&nbsp;NaNs&nbsp;have&nbsp;a&nbsp;T in&nbsp;the most significant&nbsp;fraction&nbsp;bit position&nbsp;and&nbsp;<br>
'signalling'&nbsp;NaNs have a '0'&nbsp;in&nbsp;that&nbsp;bit (but&nbsp;a T somewhere else, otherwise they&nbsp;<br>
look like infinity).&nbsp;<br>
•&nbsp;&nbsp;Denormalized numbers, which are numbers that are just&nbsp;too small to normalize&nbsp;<br>
within&nbsp;this format, have&nbsp;a&nbsp;zero&nbsp;exponent,&nbsp;a&nbsp;non-zero fraction&nbsp;and&nbsp;a&nbsp;value&nbsp;given&nbsp;by:&nbsp;<br>
value (denorm)&nbsp;= (-l)s&nbsp;x O.fractionx2(-126)&nbsp;<br>
Equation 16&nbsp;<br>
The&nbsp;'NaN'&nbsp;format&nbsp;is used to&nbsp;represent&nbsp;the&nbsp;results of&nbsp;invalid&nbsp;floating-point oper-<br>
ations,&nbsp;such&nbsp;as&nbsp;taking&nbsp;the&nbsp;logarithm&nbsp;of a&nbsp;negative&nbsp;number,&nbsp;and prevents&nbsp;a series&nbsp;of&nbsp;<br>
operations from&nbsp;producing&nbsp;an&nbsp;apparently&nbsp;valid&nbsp;result&nbsp;when&nbsp;an&nbsp;intermediate&nbsp;error con-<br>
dition&nbsp;was not&nbsp;checked.&nbsp;<br>
<hr>
<A name=172></a><IMG src="index-172_1.png"><br>
<IMG src="index-172_2.png"><br>
<b>Floating-point&nbsp;data&nbsp;types</b>&nbsp;<br>
<b>161</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Double precision&nbsp;&nbsp;For&nbsp;many&nbsp;purposes the accuracy offered&nbsp;by the&nbsp;single&nbsp;precision format is inade-<br>
quate.&nbsp;Greater&nbsp;accuracy&nbsp;may&nbsp;be achieved&nbsp;by&nbsp;using the&nbsp;double&nbsp;precision format&nbsp;<br>
which uses 64&nbsp;bits to&nbsp;store&nbsp;each floating-point value.&nbsp;<br>
The&nbsp;interpretation is&nbsp;similar to&nbsp;that&nbsp;for single&nbsp;precision&nbsp;values, but now the&nbsp;expo-<br>
nent&nbsp;bias&nbsp;for&nbsp;normalized&nbsp;numbers&nbsp;is&nbsp;+1023:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;6.3&nbsp; &nbsp;</b>IEEE 754&nbsp;double precision&nbsp;floating-point number&nbsp;format.&nbsp;<br>
Double extended&nbsp;<br>
Even greater&nbsp;accuracy is&nbsp;available&nbsp;from&nbsp;the double extended&nbsp;precision&nbsp;format,&nbsp;<br>
precision&nbsp;<br>
which&nbsp;uses 80&nbsp;bits of&nbsp;information&nbsp;spread&nbsp;across three&nbsp;words.&nbsp;The&nbsp;exponent bias is&nbsp;<br>
16383, and the J bit is the bit to the left of the binary&nbsp;point (and is a T for all nor-<br>
malized&nbsp;numbers):&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;6.4&nbsp; &nbsp;</b>IEEE 754&nbsp;double extended precision&nbsp;floating-point number&nbsp;format.&nbsp;<br>
Packed decimal&nbsp;<br>
In&nbsp;addition to&nbsp;the binary floating-point&nbsp;representations detailed&nbsp;above, the&nbsp;IEEE 754&nbsp;<br>
standard&nbsp;also&nbsp;specifies&nbsp;packed decimal&nbsp;formats.&nbsp;Referring back&nbsp;to&nbsp;Equation 13&nbsp;on&nbsp;<br>
page 158, in&nbsp;these packed&nbsp;formats&nbsp;<i>b&nbsp;</i>is&nbsp;10 and&nbsp;<i>a&nbsp;</i>and&nbsp;<i>n&nbsp;</i>are stored&nbsp;in&nbsp;a&nbsp;binary coded&nbsp;<br>
decimal&nbsp;format as described&nbsp;in&nbsp;'Binary coded decimal'&nbsp;on&nbsp;page 154.&nbsp;The number is&nbsp;<br>
normalized&nbsp;so&nbsp;that&nbsp;1&nbsp;&lt; a&nbsp;&lt;&nbsp;10 .&nbsp;The&nbsp;packed&nbsp;decimal&nbsp;format is&nbsp;shown&nbsp;on&nbsp;page&nbsp;162:&nbsp;<br>
<hr>
<A name=173></a><IMG src="index-173_1.png"><br>
<IMG src="index-173_2.png"><br>
<b>162</b>&nbsp;<br>
<b>Architectural&nbsp;Support for&nbsp;High-Level&nbsp;Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;6.5&nbsp; &nbsp;</b>IEEE 754&nbsp;packed decimal&nbsp;floating-point number&nbsp;format.&nbsp;<br>
The sign of&nbsp;the&nbsp;exponent is held&nbsp;in&nbsp;bit 31&nbsp;of&nbsp;the&nbsp;first&nbsp;word&nbsp;('E')&nbsp;and&nbsp;the&nbsp;sign&nbsp;of&nbsp;the&nbsp;<br>
decimal in bit 30&nbsp;('D').&nbsp;The value of&nbsp;the&nbsp;number&nbsp;is:&nbsp;<br>
value (packed)&nbsp;= (-1)° x&nbsp;decimal x 1&nbsp;o&quot;'1&gt;*x&nbsp;exponent)&nbsp;<br>
Equation&nbsp;17&nbsp;<br>
Extended&nbsp;<br>
The extended&nbsp;packed decimal format occupies&nbsp;four&nbsp;words&nbsp;to give higher&nbsp;precision.&nbsp;<br>
packed decimal&nbsp;<br>
The&nbsp;value&nbsp;is&nbsp;still as&nbsp;given by&nbsp;Equation&nbsp;17 above&nbsp;and the format is:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;6.6 &nbsp;&nbsp;&nbsp;</b>IEEE 754 extended packed&nbsp;decimal&nbsp;floating-point number format.&nbsp;<br>
ARM floating-<br>
Although&nbsp;there&nbsp;is no direct support&nbsp;for any of&nbsp;these&nbsp;floating-point data types in&nbsp;<br>
point&nbsp;<br>
a standard ARM integer core, ARM Limited has defined a set of floating point&nbsp;<br>
instructions&nbsp;<br>
instructions&nbsp;within&nbsp;the coprocessor&nbsp;instruction space.&nbsp;These instructions&nbsp;are&nbsp;<br>
normally&nbsp;implemented entirely&nbsp;in&nbsp;software through&nbsp;the undefined instruction&nbsp;<br>
trap&nbsp;(which&nbsp;collects&nbsp;any coprocessor instructions&nbsp;that&nbsp;are&nbsp;not&nbsp;accepted&nbsp;by&nbsp;a&nbsp;<br>
hardware coprocessor), but a subset&nbsp;may&nbsp;be handled in&nbsp;hardware by&nbsp;the FPA10&nbsp;<br>
floating-point coprocessor.&nbsp;<br>
<hr>
<A name=174></a><b>The&nbsp;ARM floating-point&nbsp;architecture</b>&nbsp;<br>
<b>163</b>&nbsp;<br>
ARM&nbsp;floating-&nbsp;<br>
As an&nbsp;alternative to the&nbsp;ARM&nbsp;floating-point&nbsp;instruction&nbsp;set (and&nbsp;the only option&nbsp;for&nbsp;<br>
point&nbsp;library&nbsp;<br>
Thumb code),&nbsp;ARM&nbsp;Limited also supplies a&nbsp;C&nbsp;floating-point&nbsp;library&nbsp;which&nbsp;supports&nbsp;<br>
IEEE single and&nbsp;double&nbsp;precision&nbsp;formats. The C&nbsp;compiler has&nbsp;a flag&nbsp;to select&nbsp;this route&nbsp;<br>
which produces&nbsp;code that&nbsp;is both faster (by&nbsp;avoiding the need to&nbsp;intercept,&nbsp;decode and&nbsp;<br>
emulate the floating-point instructions) and&nbsp;more compact&nbsp;(since only the functions&nbsp;<br>
which are used&nbsp;need be&nbsp;included in&nbsp;the image) than&nbsp;software&nbsp;emulation.&nbsp;<br>
6.4 &nbsp; The&nbsp;ARM&nbsp;floating-point&nbsp;architecture&nbsp;<br>
Where full floating-point&nbsp;support&nbsp;is required,&nbsp;the&nbsp;ARM&nbsp;floating-point architecture&nbsp;<br>
provides extensive support for the&nbsp;data types described in&nbsp;the previous section either&nbsp;<br>
entirely&nbsp;in&nbsp;software or using&nbsp;a combined&nbsp;software/hardware solution&nbsp;based around&nbsp;<br>
the FPA10 floating-point accelerator.&nbsp;<br>
The ARM floating-point architecture presents:&nbsp;<br>
•&nbsp;&nbsp;An interpretation&nbsp;of the coprocessor instruction set&nbsp;when&nbsp;the coprocessor&nbsp;number&nbsp;<br>
is&nbsp;1&nbsp;or&nbsp;2.&nbsp;(The&nbsp;floating-point&nbsp;system&nbsp;uses two&nbsp;logical&nbsp;coprocessor&nbsp;numbers.)&nbsp;<br>
•&nbsp;&nbsp;Eight&nbsp;80-bit&nbsp;floating-point&nbsp;registers&nbsp;in&nbsp;coprocessors&nbsp;1 and 2 (the&nbsp;same&nbsp;physical&nbsp;<br>
registers&nbsp;appear&nbsp;in&nbsp;both&nbsp;logical coprocessors).&nbsp;<br>
•&nbsp;&nbsp;A user-visible&nbsp;floating-point&nbsp;status&nbsp;register&nbsp;(FPSR) which controls&nbsp;various&nbsp;oper&nbsp;<br>
ating&nbsp;options&nbsp;and indicates&nbsp;error&nbsp;conditions.&nbsp;<br>
•&nbsp;&nbsp;Optionally, a&nbsp;floating-point&nbsp;control&nbsp;register&nbsp;(FPCR)&nbsp;which is&nbsp;user-invisible and&nbsp;<br>
should&nbsp;be&nbsp;used&nbsp;only&nbsp;by&nbsp;the&nbsp;support&nbsp;software&nbsp;specific to the&nbsp;hardware accelerator.&nbsp;<br>
Note that the&nbsp;ARM coprocessor architecture allows&nbsp;the floating-point&nbsp;emulator&nbsp;<br>
(FPE) software to&nbsp;be used interchangeably&nbsp;with&nbsp;the combination of the FPA10 and the&nbsp;<br>
floating-point&nbsp;accelerator support code&nbsp;(FPASC), or any other&nbsp;hardware-software&nbsp;<br>
combination that supports the&nbsp;same&nbsp;set of instructions. Application binaries&nbsp;will work&nbsp;<br>
with&nbsp;either support environment, though&nbsp;the&nbsp;compiler optimization strategy&nbsp;is&nbsp;differ-<br>
ent&nbsp;(the FPE software works best&nbsp;with&nbsp;grouped floating-point instructions whereas the&nbsp;<br>
FPA10/FPASC&nbsp;works best&nbsp;with distributed instructions).&nbsp;<br>
FPAIOdata&nbsp;<br>
The ARM&nbsp;FPA10&nbsp;hardware&nbsp;floating-point&nbsp;accelerator&nbsp;supports single, double&nbsp;and&nbsp;<br>
types&nbsp;<br>
extended&nbsp;double precision&nbsp;formats. Packed&nbsp;decimal formats are supported&nbsp;only&nbsp;by&nbsp;<br>
software.&nbsp;<br>
The coprocessor registers are all&nbsp;extended&nbsp;double&nbsp;precision, and&nbsp;all&nbsp;internal calcula-<br>
tions are carried out&nbsp;in&nbsp;this,&nbsp;the highest&nbsp;precision format,&nbsp;except&nbsp;that&nbsp;there&nbsp;are faster ver-<br>
sions of&nbsp;some&nbsp;instructions&nbsp;which do not&nbsp;produce&nbsp;the full&nbsp;80-bit&nbsp;accuracy. However&nbsp;loads&nbsp;<br>
and stores between&nbsp;memory and these registers can&nbsp;convert&nbsp;the precision&nbsp;as required.&nbsp;<br>
<hr>
<A name=175></a><IMG src="index-175_1.png"><br>
<IMG src="index-175_2.png"><br>
<b>164</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
This&nbsp;is&nbsp;similar to&nbsp;the&nbsp;treatment&nbsp;of&nbsp;integers in&nbsp;the&nbsp;ARM&nbsp;integer architecture,&nbsp;where&nbsp;<br>
all internal operations&nbsp;are on&nbsp;32-bit quantities, but&nbsp;memory transfers&nbsp;can specify&nbsp;bytes&nbsp;<br>
and half-words.&nbsp;<br>
Load and store&nbsp;<br>
Since there are only&nbsp;eight&nbsp;floating-point&nbsp;registers,&nbsp;the&nbsp;register&nbsp;specifier field&nbsp;in&nbsp;the&nbsp;<br>
floating&nbsp;<br>
coprocessor data&nbsp;transfer&nbsp;instruction&nbsp;(shown&nbsp;in&nbsp;Figure 5.16&nbsp;on&nbsp;page 138)&nbsp;has a spare&nbsp;<br>
instructions&nbsp;<br>
bit which is used here as an&nbsp;additional data&nbsp;size&nbsp;specifier:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;6.7&nbsp; &nbsp;</b>Load and store floating binary&nbsp;encoding.&nbsp;<br>
The other fields&nbsp;in this&nbsp;format&nbsp;are described&nbsp;in Section 5.18&nbsp;on page 138. The X&nbsp;<br>
and&nbsp;Y bits&nbsp;allow one&nbsp;of&nbsp;four&nbsp;precisions&nbsp;to&nbsp;be&nbsp;specified,&nbsp;choosing&nbsp;between single,&nbsp;dou-<br>
ble,&nbsp;double&nbsp;extended&nbsp;and&nbsp;packed&nbsp;decimal. (The&nbsp;choice&nbsp;between&nbsp;packed&nbsp;decimal and&nbsp;<br>
extended&nbsp;packed decimal is&nbsp;controlled by&nbsp;a bit in&nbsp;the&nbsp;FPSR.)&nbsp;<br>
Load and&nbsp;store&nbsp;<br>
The load&nbsp;and store multiple&nbsp;floating-point&nbsp;registers&nbsp;instructions&nbsp;are used&nbsp;to save and&nbsp;<br>
multiple floating&nbsp;<br>
restore the&nbsp;floating-point&nbsp;register state.&nbsp;Each register is saved using three&nbsp;memory&nbsp;<br>
words, and the precise&nbsp;format is not defined; it is intended that the only use&nbsp;for&nbsp;the&nbsp;<br>
saved values&nbsp;will be to reload them&nbsp;using the equivalent load&nbsp;multiple floating&nbsp;<br>
instruction to&nbsp;restore the context.&nbsp;'FRd'&nbsp;specifies the&nbsp;first&nbsp;register&nbsp;to be transferred,&nbsp;<br>
and 'X'&nbsp;and&nbsp;'Y'&nbsp;encode the number of&nbsp;registers transferred which can be&nbsp;from&nbsp;one&nbsp;<br>
to&nbsp;four.&nbsp;Note&nbsp;that these&nbsp;instructions use coprocessor number 2,&nbsp;whereas the&nbsp;other&nbsp;<br>
floating-point&nbsp;instructions use&nbsp;coprocessor number 1.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
31<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 6.8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Load and store multiple floating binary&nbsp;encoding.&nbsp;<br>
<hr>
<A name=176></a><IMG src="index-176_1.png"><br>
<IMG src="index-176_2.png"><br>
<b>The&nbsp;ARM&nbsp;floating-point&nbsp;architecture</b>&nbsp;<br>
<b>165</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Floating-point&nbsp;<br>
The floating-point&nbsp;data&nbsp;operations perform&nbsp;arithmetic functions on values&nbsp;in&nbsp;the floating-<br>
data operations&nbsp;<br>
point&nbsp;registers;&nbsp;their only interaction with&nbsp;the&nbsp;outside&nbsp;world&nbsp;is to&nbsp;confirm&nbsp;that they&nbsp;<br>
should complete through the&nbsp;ARM&nbsp;coprocessor handshake. (Indeed, a floating-point&nbsp;<br>
coprocessor&nbsp;may&nbsp;begin executing one of these&nbsp;instructions before the handshake begins&nbsp;<br>
so long as&nbsp;it&nbsp;waits for&nbsp;confirmation from&nbsp;the ARM&nbsp;before&nbsp;committing&nbsp;a state&nbsp;change.)&nbsp;<br>
&nbsp;<br>
<b>Figure 6.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Floating-point data processing&nbsp;binary encoding.&nbsp;<br>
The instruction format&nbsp;has a number of&nbsp;opcode bits, augmented&nbsp;by&nbsp;extra bits from&nbsp;<br>
each&nbsp;of the three register specifier&nbsp;fields&nbsp;since only three&nbsp;bits are&nbsp;required to specify&nbsp;<br>
one of the eight floating-point&nbsp;registers:&nbsp;<br>
•&nbsp;&nbsp;'i'&nbsp;selects between a register ('FRm') or one of&nbsp;eight&nbsp;constants for the&nbsp;second&nbsp;<br>
operand.&nbsp;<br>
•&nbsp;&nbsp;'e' and 'Cop2' control&nbsp;the&nbsp;destination&nbsp;size and the&nbsp;rounding mode.&nbsp;<br>
•&nbsp;&nbsp;'j' selects between&nbsp;monadic (single operand) and dyadic&nbsp;(two&nbsp;operand) operations.&nbsp;<br>
The&nbsp;instructions&nbsp;include simple&nbsp;arithmetic&nbsp;operations&nbsp;(add, subtract, multiply,&nbsp;<br>
divide,&nbsp;remainder,&nbsp;power), transcendental&nbsp;functions&nbsp;(log,&nbsp;exponential,&nbsp;sin, cos, tan,&nbsp;<br>
arcsin, arccos,&nbsp;arctan) and assorted others&nbsp;(square root,&nbsp;move, absolute&nbsp;value, round).&nbsp;<br>
Floating-point&nbsp;<br>
The register&nbsp;transfer instructions&nbsp;accept&nbsp;a&nbsp;value&nbsp;from or&nbsp;return a&nbsp;value to an&nbsp;ARM&nbsp;<br>
register&nbsp;transfers&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;register. This&nbsp;is&nbsp;generally&nbsp;combined with&nbsp;a floating-point&nbsp;processing function.&nbsp;<br>
&nbsp;<br>
<b>Figure 6.10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Floating-point&nbsp;register transfer binary&nbsp;encoding.&nbsp;<br>
Transfers&nbsp;from&nbsp;ARM&nbsp;to&nbsp;the&nbsp;floating-point&nbsp;unit&nbsp;include 'float' (convert&nbsp;an&nbsp;integer&nbsp;in&nbsp;an&nbsp;<br>
ARM&nbsp;register&nbsp;to a real&nbsp;in&nbsp;a floating-point&nbsp;register) and writes to&nbsp;the floating-point&nbsp;status&nbsp;<br>
and control&nbsp;registers;&nbsp;going the other way&nbsp;there is&nbsp;'fix' (convert&nbsp;a real&nbsp;in&nbsp;a floating-point&nbsp;<br>
register&nbsp;to&nbsp;an&nbsp;integer&nbsp;in&nbsp;an ARM register)&nbsp;and&nbsp;reads of&nbsp;the&nbsp;status&nbsp;and&nbsp;control registers.&nbsp;<br>
The floating-point compare instructions are&nbsp;special cases&nbsp;of&nbsp;this instruction&nbsp;type,&nbsp;<br>
where Rd&nbsp;is&nbsp;r15. Two floating-registers&nbsp;are&nbsp;compared and the result of the comparison&nbsp;<br>
<hr>
<A name=177></a><IMG src="index-177_1.png"><br>
<b>166</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
is returned&nbsp;to&nbsp;the N,&nbsp;Z, C&nbsp;and V flags&nbsp;in&nbsp;the&nbsp;ARM CPSR where they can&nbsp;directly&nbsp;con-<br>
trol the execution&nbsp;of&nbsp;conditional instructions:&nbsp;<br>
•&nbsp;&nbsp;N indicates 'less than'.&nbsp;<br>
•&nbsp;&nbsp;Z indicates&nbsp;equality.&nbsp;<br>
•&nbsp;&nbsp;C and V&nbsp;indicate more complex conditions, including&nbsp;'unordered'&nbsp;comparison&nbsp;<br>
results&nbsp;which can arise&nbsp;when&nbsp;an&nbsp;operand is a&nbsp;'NaN'&nbsp;(not a number).&nbsp;<br>
Floating-point&nbsp;<br>
The&nbsp;design&nbsp;of&nbsp;the&nbsp;FPAIO&nbsp;is&nbsp;guided&nbsp;by&nbsp;the&nbsp;typical&nbsp;frequencies&nbsp;of&nbsp;the&nbsp;various&nbsp;floating-<br>
instruction&nbsp;<br>
point instructions. These&nbsp;were&nbsp;measured&nbsp;running compiled programs using&nbsp;the&nbsp;<br>
frequencies&nbsp;<br>
floating-point&nbsp;emulator&nbsp;software&nbsp;and are summarized&nbsp;in Table&nbsp;6.1.&nbsp;<br>
The&nbsp;statistics&nbsp;are dominated by&nbsp;the number&nbsp;of load&nbsp;and&nbsp;store operations that&nbsp;take&nbsp;<br>
place.&nbsp;As a&nbsp;result,&nbsp;the&nbsp;FPAIO has&nbsp;been&nbsp;designed&nbsp;to&nbsp;allow these to&nbsp;operate concurrently&nbsp;<br>
with&nbsp;internal&nbsp;arithmetic operations.&nbsp;<br>
<b>Table&nbsp;6.1&nbsp; &nbsp;&nbsp;</b>Floating-point&nbsp;instruction&nbsp;frequencies.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
FPA10&nbsp;<br>
The&nbsp;internal&nbsp;organization&nbsp;of&nbsp;the&nbsp;FPAIO is&nbsp;illustrated&nbsp;in&nbsp;Figure&nbsp;6.11&nbsp;on&nbsp;page&nbsp;167.&nbsp;Its&nbsp;<br>
organization&nbsp;<br>
external&nbsp;interface is&nbsp;to&nbsp;the&nbsp;ARM data&nbsp;bus and the&nbsp;coprocessor handshake&nbsp;signals,&nbsp;so&nbsp;<br>
it&nbsp;has&nbsp;a modest pin-count requirement.&nbsp;The major components are:&nbsp;<br>
•&nbsp;&nbsp;The coprocessor pipeline&nbsp;follower&nbsp;(see&nbsp;Section 4.5 on page&nbsp;101).&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;load/store&nbsp;unit&nbsp;that&nbsp;carries out&nbsp;format&nbsp;conversion&nbsp;on&nbsp;floating-point&nbsp;data&nbsp;types&nbsp;<br>
as&nbsp;they&nbsp;are&nbsp;loaded from&nbsp;and stored to memory.&nbsp;<br>
•&nbsp;&nbsp;The register&nbsp;bank&nbsp;which stores eight&nbsp;80-bit&nbsp;extended&nbsp;precision floating-point&nbsp;<br>
operands.&nbsp;<br>
•&nbsp;&nbsp;The arithmetic unit&nbsp;which incorporates&nbsp;an adder, a&nbsp;multiplier&nbsp;and a&nbsp;divider,&nbsp;<br>
together&nbsp;with&nbsp;rounding&nbsp;and&nbsp;normalizing hardware.&nbsp;<br>
<hr>
<A name=178></a><IMG src="index-178_1.png"><br>
<b>The&nbsp;ARM floating-point&nbsp;architecture</b>&nbsp;<br>
167&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;6.11 &nbsp;&nbsp;&nbsp;</b>FPA10 internal organization.&nbsp;<br>
The load/store&nbsp;unit operates&nbsp;concurrently&nbsp;with&nbsp;the&nbsp;arithmetic&nbsp;unit,&nbsp;enabling&nbsp;new&nbsp;<br>
operands&nbsp;to&nbsp;be&nbsp;loaded from&nbsp;memory&nbsp;while previously&nbsp;loaded&nbsp;operands are&nbsp;being&nbsp;proc-<br>
essed.&nbsp;Hardware&nbsp;interlocks&nbsp;protect&nbsp;against&nbsp;data&nbsp;hazards.&nbsp;<br>
FPA10&nbsp;pipeline&nbsp;<br>
The&nbsp;FPA10 arithmetic&nbsp;unit operates in four&nbsp;pipeline stages:&nbsp;<br>
1.&nbsp;&nbsp;Prepare: align operands.&nbsp;<br>
2.&nbsp;&nbsp;Calculate:&nbsp;add,&nbsp;multiply&nbsp;or&nbsp;divide.&nbsp;<br>
3.&nbsp;&nbsp;Align:&nbsp;normalize the&nbsp;result.&nbsp;<br>
4.&nbsp;&nbsp;Round: apply&nbsp;appropriate rounding to the&nbsp;result.&nbsp;<br>
A floating-point&nbsp;operation&nbsp;can&nbsp;begin as soon&nbsp;as&nbsp;it is detected&nbsp;in&nbsp;the instruction pipe-<br>
line (that&nbsp;is,&nbsp;before the ARM&nbsp;handshake&nbsp;has&nbsp;occurred),&nbsp;but&nbsp;the result&nbsp;write-back must&nbsp;<br>
await the handshake.&nbsp;<br>
Floating-point&nbsp;<br>
The FPA&nbsp;registers represent additional process state which must be&nbsp;saved and&nbsp;<br>
context switches&nbsp;&nbsp;restored&nbsp;across&nbsp;context&nbsp;switches.&nbsp;However,&nbsp;typically only&nbsp;a&nbsp;small&nbsp;number&nbsp;of&nbsp;active&nbsp;<br>
processes&nbsp;use floating-point instructions.&nbsp;Therefore saving&nbsp;and restoring&nbsp;the FPA&nbsp;<br>
registers on every&nbsp;switch&nbsp;is&nbsp;an unnecessary&nbsp;overhead.&nbsp;Instead,&nbsp;the software mini-<br>
mizes&nbsp;the&nbsp;number&nbsp;of&nbsp;saves&nbsp;and restores&nbsp;by&nbsp;the following&nbsp;algorithm:&nbsp;<br>
• When a&nbsp;process using the&nbsp;FPA is switched out,&nbsp;the FPA registers are not saved&nbsp;<br>
but the&nbsp;FPA is&nbsp;turned&nbsp;off.&nbsp;<br>
<hr>
<A name=179></a><b>168</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
•&nbsp;If a&nbsp;subsequent&nbsp;process executes a&nbsp;floating-point&nbsp;instruction&nbsp;this&nbsp;will&nbsp;trap;&nbsp;the&nbsp;trap&nbsp;<br>
code&nbsp;will&nbsp;save&nbsp;the&nbsp;FPA state and enable&nbsp;the FPA.&nbsp;<br>
Thus&nbsp;the FPA&nbsp;state&nbsp;saving&nbsp;and&nbsp;restoring overhead&nbsp;is&nbsp;only&nbsp;incurred&nbsp;for&nbsp;processes&nbsp;<br>
which use&nbsp;the&nbsp;FPA; in a&nbsp;typical system&nbsp;with&nbsp;only&nbsp;one&nbsp;process using&nbsp;the&nbsp;FPA, the&nbsp;over-<br>
head is avoided&nbsp;altogether.&nbsp;<br>
FPA10&nbsp;<br>
The FPA10 is used as a&nbsp;macrocell on&nbsp;the ARM7500FE&nbsp;chip (see Section 13.5 on&nbsp;<br>
applications&nbsp;<br>
page&nbsp;360).&nbsp;<br>
TheVFPIO&nbsp;<br>
A&nbsp;much&nbsp;higher performance floating-point&nbsp;unit, the&nbsp;VFP10, has been&nbsp;designed&nbsp;to&nbsp;<br>
operate with the ARM10TDMI processor&nbsp;core&nbsp;(see&nbsp;Section 12.6 on page 341). The&nbsp;<br>
VFP10 supports a different floating-point&nbsp;instruction set from&nbsp;the FPA 10 that&nbsp;<br>
includes support&nbsp;for vector floating-point&nbsp;operations.&nbsp;<br>
6.5 &nbsp; Expressions&nbsp;<br>
Unsigned&nbsp;arithmetic on&nbsp;an&nbsp;n-bit&nbsp;integer&nbsp;is&nbsp;defined&nbsp;in&nbsp;ANSI C to be modulo&nbsp;2&quot;, so&nbsp;<br>
overflow&nbsp;cannot occur.&nbsp;Therefore&nbsp;the basic ARM&nbsp;integer data processing&nbsp;instructions&nbsp;<br>
implement&nbsp;most of the C integer arithmetic, bit-wise&nbsp;and shift primitives&nbsp;directly.&nbsp;<br>
Exceptions&nbsp;are&nbsp;division&nbsp;and remainder which&nbsp;require&nbsp;several&nbsp;ARM instructions.&nbsp;<br>
Register&nbsp;use&nbsp;<br>
Since&nbsp;all data&nbsp;processing instructions&nbsp;operate&nbsp;only&nbsp;on&nbsp;values&nbsp;in&nbsp;register,&nbsp;the key&nbsp;to&nbsp;the&nbsp;<br>
efficient evaluation&nbsp;of a complex expression is&nbsp;to get the required values into&nbsp;the&nbsp;regis-<br>
ters in the right order and to ensure that frequently&nbsp;used values are normally&nbsp;resident in&nbsp;<br>
registers.&nbsp;There&nbsp;is&nbsp;clearly a&nbsp;trade-off&nbsp;between&nbsp;the&nbsp;number of&nbsp;values&nbsp;that&nbsp;can&nbsp;be&nbsp;held&nbsp;in&nbsp;<br>
registers and&nbsp;the number of registers remaining for intermediate results during expres-<br>
sion evaluation&nbsp;(remembering&nbsp;that&nbsp;registers are&nbsp;also needed&nbsp;to hold the addresses of&nbsp;<br>
operands&nbsp;that&nbsp;must be fetched from&nbsp;memory). Optimizing&nbsp;this&nbsp;trade-off is&nbsp;a major task&nbsp;<br>
for the&nbsp;compiler, as is sorting out the&nbsp;right order to&nbsp;load&nbsp;and combine&nbsp;operands to&nbsp;<br>
achieve&nbsp;the result prescribed&nbsp;by&nbsp;the operator precedence&nbsp;defined in the language.&nbsp;<br>
ARM support&nbsp;<br>
The&nbsp;3-address&nbsp;instruction format used&nbsp;by&nbsp;the ARM&nbsp;gives&nbsp;the&nbsp;compiler&nbsp;the maximum&nbsp;<br>
flexibility&nbsp;in&nbsp;how it&nbsp;preserves&nbsp;or&nbsp;re-uses&nbsp;registers during&nbsp;expression&nbsp;evaluation.&nbsp;<br>
Thumb instructions&nbsp;are&nbsp;generally&nbsp;2-address, which&nbsp;restricts the compiler's&nbsp;freedom&nbsp;<br>
to&nbsp;some&nbsp;extent, and&nbsp;the smaller number&nbsp;of&nbsp;general&nbsp;registers&nbsp;also makes its&nbsp;job&nbsp;harder&nbsp;<br>
(and will result&nbsp;in less efficient&nbsp;code).&nbsp;<br>
Accessing&nbsp;<br>
A procedure&nbsp;will normally&nbsp;work&nbsp;with&nbsp;operands that&nbsp;are presented&nbsp;in one&nbsp;of&nbsp;the&nbsp;fol-<br>
operands&nbsp;<br>
lowing&nbsp;ways, and&nbsp;can be&nbsp;accessed&nbsp;as indicated:&nbsp;<br>
<hr>
<A name=180></a><b>Expressions</b>&nbsp;<br>
<b>169</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
1.&nbsp;&nbsp;As&nbsp;an argument passed&nbsp;through&nbsp;a&nbsp;register.&nbsp;<br>
Pointer&nbsp;<br>
arithmetic<br>
The&nbsp;value is&nbsp;already in a register,&nbsp;so&nbsp;no&nbsp;further&nbsp;work&nbsp;is necessary.&nbsp;<br>
&nbsp;<br>
2.&nbsp;&nbsp;As an argument passed on&nbsp;the stack.&nbsp;<br>
Stack pointer&nbsp;(r13) relative addressing&nbsp;with an&nbsp;immediate&nbsp;offset known at&nbsp;<br>
compile-time&nbsp;allows the operand&nbsp;to&nbsp;be&nbsp;collected&nbsp;with&nbsp;a&nbsp;single&nbsp;LDR.&nbsp;<br>
3.&nbsp;&nbsp;As a constant in the procedure's literal pool.&nbsp;<br>
PC-relative addressing,&nbsp;again with&nbsp;an immediate&nbsp;offset known&nbsp;at compile-time,&nbsp;<br>
gives access with a single LDR.&nbsp;<br>
4.&nbsp;&nbsp;As&nbsp;a local&nbsp;variable.&nbsp;<br>
Local variables are allocated space&nbsp;on the stack&nbsp;and are accessed by&nbsp;a stack&nbsp;<br>
pointer relative LDR.&nbsp;<br>
5.&nbsp;&nbsp;As&nbsp;a global variable.&nbsp;<br>
Global&nbsp;(and static)&nbsp;variables are allocated&nbsp;space&nbsp;in&nbsp;the static&nbsp;area&nbsp;and&nbsp;are&nbsp;<br>
accessed by static base relative addressing. The static base is usually in r9 (see&nbsp;<br>
the 'ARM Procedure Call&nbsp;Standard'&nbsp;on page 176).&nbsp;<br>
If&nbsp;the&nbsp;value&nbsp;that&nbsp;is&nbsp;passed&nbsp;is&nbsp;a&nbsp;pointer, an&nbsp;additional&nbsp;LDR&nbsp;(with&nbsp;an&nbsp;immediate&nbsp;off-<br>
set)&nbsp;may&nbsp;be&nbsp;required&nbsp;to access an operand&nbsp;within the&nbsp;structure that it&nbsp;points to.&nbsp;<br>
Arithmetic on pointers depends&nbsp;on the size of the data&nbsp;type that&nbsp;the pointers are pointing&nbsp;<br>
to. If a pointer is&nbsp;incremented it changes in&nbsp;units of the size of&nbsp;the data&nbsp;item&nbsp;in&nbsp;bytes.&nbsp;<br>
Thus:&nbsp;<br>
int &nbsp; *p;&nbsp;<br>
P &nbsp;= &nbsp;P+l;&nbsp;<br>
will&nbsp;increase&nbsp;the value&nbsp;of&nbsp;p&nbsp;by 4 bytes.&nbsp;Since the size of&nbsp;a data type is known&nbsp;at&nbsp;<br>
compile-time,&nbsp;the&nbsp;compiler&nbsp;can&nbsp;scale&nbsp;constants by&nbsp;an&nbsp;appropriate&nbsp;amount.&nbsp;If a&nbsp;varia-<br>
ble is used&nbsp;as an&nbsp;offset it&nbsp;must&nbsp;be scaled at&nbsp;run-time:&nbsp;<br>
int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4&nbsp;&nbsp;;&nbsp;<br>
p &nbsp; = &nbsp;p &nbsp;+ &nbsp;&nbsp;<br>
i;&nbsp;<br>
If p is&nbsp;held in r0 and i in r1, the change to p&nbsp;may be compiled as:&nbsp;<br>
ADD&nbsp;&nbsp;&nbsp; r0,&nbsp;r0,&nbsp;r1,&nbsp;LSL&nbsp;#2&nbsp;;&nbsp;scale&nbsp;r1&nbsp;<i>to&nbsp;</i>int&nbsp;<br>
Where the&nbsp;data type is&nbsp;a&nbsp;structure&nbsp;with&nbsp;a size which is&nbsp;not a power of&nbsp;2&nbsp;bytes,&nbsp;a&nbsp;<br>
multiplication&nbsp;by a small constant is&nbsp;required. The shift&nbsp;and add instructions can&nbsp;<br>
usually&nbsp;produce&nbsp;the&nbsp;desired product in a small number&nbsp;of&nbsp;operations, using&nbsp;a tempo-<br>
rary register&nbsp;where&nbsp;necessary.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Arrays&nbsp;<br>
Arrays in C are little&nbsp;more than a shorthand notation for pointer operations, so the&nbsp;<br>
above comments apply&nbsp;here&nbsp;too.&nbsp;The declaration:&nbsp;<br>
int &nbsp; a[10];&nbsp;<br>
<hr>
<A name=181></a>170&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
establishes a name, a,&nbsp;for the&nbsp;array&nbsp;which is&nbsp;just a pointer&nbsp;to the first element, and a&nbsp;<br>
reference to a&nbsp;[ i ] is equivalent to the pointer-plus-offset form&nbsp;*&nbsp;(a+ i); the two&nbsp;may&nbsp;<br>
be&nbsp;used interchangeably.&nbsp;<br>
6.6 &nbsp; Conditional&nbsp;statements&nbsp;<br>
Conditional statements are&nbsp;executed if the Boolean result of a test is&nbsp;true&nbsp;(or&nbsp;false);&nbsp;<br>
in C these include if...else&nbsp;statements and switches&nbsp;(C&nbsp;'case'&nbsp;statements).&nbsp;<br>
if...else&nbsp;<br>
The&nbsp;ARM&nbsp;architecture&nbsp;offers unusually&nbsp;efficient&nbsp;support&nbsp;for&nbsp;conditional&nbsp;expressions&nbsp;<br>
when&nbsp;the&nbsp;conditionally executed&nbsp;statement&nbsp;is&nbsp;small.&nbsp;<br>
For example, here is a&nbsp;C statement to find the&nbsp;maximum&nbsp;of two integers:&nbsp;<br>
if&nbsp;&nbsp;&nbsp;(a&gt;b) &nbsp; c=a; &nbsp;&nbsp;else&nbsp;&nbsp;c=b;&nbsp;<br>
If the&nbsp;variables a,&nbsp;b and c&nbsp;are&nbsp;in&nbsp;registers r0,&nbsp;r1&nbsp;and&nbsp;r2,&nbsp;the&nbsp;compiled&nbsp;code&nbsp;could&nbsp;be&nbsp;<br>
as simple as:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
CMP&nbsp;<br>
r0, r1&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
MOVGT&nbsp;<br>
r2, r0&nbsp;<br>
(a&gt;b)...&nbsp;;&nbsp; &nbsp;&nbsp;<br>
MOVLE&nbsp;<br>
r2, rl&nbsp;<br>
&nbsp;&nbsp;..c=a..&nbsp;<br>
..else&nbsp;&nbsp;<br>
c=b&nbsp;<br>
(In this&nbsp;particular case&nbsp;the C&nbsp;compiler can&nbsp;produce&nbsp;a rather&nbsp;more obvious sequence:&nbsp;<br>
MOV CMP&nbsp;&nbsp;r2, r0 r0,&nbsp;<br>
; &nbsp; c=a&nbsp;<br>
MOVLE&nbsp;<br>
r1 r&nbsp;2&nbsp;,&nbsp;&nbsp;<br>
; &nbsp;&nbsp;if&nbsp;&nbsp;&nbsp;<br>
r&nbsp;l&nbsp;&nbsp;<br>
(a&gt;b)...&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.&nbsp;.&nbsp;.&nbsp;c&nbsp;=&nbsp;b&nbsp;&nbsp;<br>
However, this doesn't&nbsp;scale well&nbsp;to&nbsp;more&nbsp;complex 'if&nbsp;statements&nbsp;so&nbsp;we will&nbsp;ignore&nbsp;<br>
it in&nbsp;this general discussion.)&nbsp;<br>
The 'if and 'else'&nbsp;sequences may&nbsp;be&nbsp;a few&nbsp;instructions&nbsp;long with the&nbsp;same&nbsp;condi-<br>
tion on&nbsp;each instruction&nbsp;(provided none of&nbsp;the conditionally&nbsp;executed instructions&nbsp;<br>
changes the condition codes), but beyond&nbsp;two or three instructions it is&nbsp;generally&nbsp;<br>
better&nbsp;to fall&nbsp;back&nbsp;on&nbsp;the&nbsp;more&nbsp;conventional&nbsp;solution:&nbsp;<br>
CMP&nbsp;<br>
r0, &nbsp;&nbsp;rl&nbsp;<br>
;&nbsp;&nbsp;if&nbsp;&nbsp;&nbsp;(a&gt;b)...&nbsp;<br>
BLE&nbsp;ELSE&nbsp;<br>
;&nbsp;<br>
skip clause if false&nbsp;<br>
MOV&nbsp;<br>
r2,&nbsp;r0&nbsp;<br>
; &nbsp;..c=a..&nbsp;<br>
B&nbsp;<br>
ENDIF&nbsp;<br>
;&nbsp;skip else clause&nbsp;<br>
ELSE&nbsp;&nbsp;&nbsp;MOV&nbsp;<br>
r2, rl&nbsp;<br>
;&nbsp;...else&nbsp;c=b&nbsp;<br>
ENDIF&nbsp;<br>
Here the&nbsp;'if and&nbsp;'else'&nbsp;sequences&nbsp;may be any&nbsp;length and&nbsp;may use the condition&nbsp;<br>
codes freely&nbsp;(including, for example,&nbsp;for&nbsp;nested if statements)&nbsp;since they are not&nbsp;<br>
required&nbsp;beyond&nbsp;the branch&nbsp;immediately&nbsp;following&nbsp;the&nbsp;compare&nbsp;instruction.&nbsp;<br>
<hr>
<A name=182></a><IMG src="index-182_1.png"><br>
<IMG src="index-182_2.png"><br>
<b>Conditional statements</b>&nbsp;<br>
171&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Note, however, that whichever branch&nbsp;is&nbsp;taken, this&nbsp;second&nbsp;code&nbsp;sequence&nbsp;will take&nbsp;</b><br>
<b>approximately&nbsp;twice as&nbsp;long&nbsp;to&nbsp;execute&nbsp;as&nbsp;the first for this&nbsp;simple example. Branches&nbsp;</b><br>
<b>are expensive&nbsp;on the ARM, so the absence of them from the first sequence makes it&nbsp;</b><br>
<b>very efficient.</b>&nbsp;<br>
switches&nbsp;<br>
<b>A switch, or case, statement extends the two-way decision of an if...else statement to&nbsp;</b><br>
<b>many ways. The standard&nbsp;C form of a switch&nbsp;statement is:</b>&nbsp;<br>
switch (expression) {&nbsp;<br>
case&nbsp;constant-expression]:&nbsp;statements;&nbsp;case&nbsp;<br>
constant-expressio^: statementS2&nbsp;<br>
&nbsp;<br>
case constant-expression^: statements^&nbsp;<br>
default:&nbsp;statements^&nbsp;<br>
}&nbsp;<br>
Normally each group&nbsp;of&nbsp;statements ends&nbsp;with a 'break'&nbsp;(or&nbsp;a 'return') to cause the&nbsp;<br>
switch statement&nbsp;to terminate,&nbsp;otherwise&nbsp;the C&nbsp;semantics cause execution&nbsp;to&nbsp;fall&nbsp;<br>
through&nbsp;to the&nbsp;next&nbsp;group&nbsp;of&nbsp;statements. A&nbsp;switch statement with 'breaks'&nbsp;can always&nbsp;<br>
be translated into an equivalent&nbsp;series of if..else statements:&nbsp;<br>
temp = expression;&nbsp;<br>
if (temp==constant-expressionj)&nbsp;{statements]}&nbsp;<br>
else ...&nbsp;<br>
else if (temp==constant-expressionN) {statements^}&nbsp;<br>
else {statementsj)}&nbsp;<br>
However this&nbsp;can&nbsp;result in slow&nbsp;code&nbsp;if the switch&nbsp;statement&nbsp;has many&nbsp;cases.&nbsp;An&nbsp;<br>
alternative is to&nbsp;use&nbsp;<i>a jump table.&nbsp;</i>In&nbsp;its simplest form&nbsp;a jump&nbsp;table contains&nbsp;a target&nbsp;<br>
address for each possible value&nbsp;of the switch&nbsp;expression:&nbsp;<br>
&nbsp;<br>
Clearly&nbsp;it&nbsp;is&nbsp;not&nbsp;possible for the jump&nbsp;table&nbsp;to contain an address for every&nbsp;possible&nbsp;<br>
value of a 32-bit integer, and equally&nbsp;clearly&nbsp;it&nbsp;is vital&nbsp;that&nbsp;the jump&nbsp;table&nbsp;look-up&nbsp;does&nbsp;<br>
not fall past the end&nbsp;of the table, so some&nbsp;checking is necessary.&nbsp;<br>
<hr>
<A name=183></a><b>172</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
Another way&nbsp;of compiling&nbsp;a switch&nbsp;statement is illustrated&nbsp;by&nbsp;a&nbsp;procedure in the&nbsp;<br>
'Dhrystone'&nbsp;benchmark program&nbsp;which ends&nbsp;(effectively)&nbsp;as follows:&nbsp;<br>
switch (a)&nbsp;{&nbsp;<br>
case 0: *b&nbsp;= 0; break;&nbsp;<br>
case 1: if (c&gt;100) *b = 0; else *b = 3; break;&nbsp;<br>
case 2: *b = 1; break&nbsp;<br>
case&nbsp;3:&nbsp;break;&nbsp;<br>
case 4:&nbsp;*b&nbsp;= 2;&nbsp;break;&nbsp;} /*&nbsp;<br>
end of&nbsp;switch */ }&nbsp;/*&nbsp;end of&nbsp;<br>
procedure&nbsp;*/&nbsp;<br>
The code&nbsp;which is&nbsp;generated&nbsp;highlights&nbsp;a&nbsp;number of aspects of&nbsp;the&nbsp;ARM&nbsp;instruc-<br>
tion&nbsp;set.&nbsp;The&nbsp;switch&nbsp;statement&nbsp;is&nbsp;implemented&nbsp;by&nbsp;adding&nbsp;the&nbsp;value&nbsp;of&nbsp;the&nbsp;expression&nbsp;<br>
(in&nbsp;v2;&nbsp;the&nbsp;register&nbsp;naming convention&nbsp;follows the&nbsp;ARM&nbsp;Procedure Call&nbsp;Standard&nbsp;<br>
which will&nbsp;be described&nbsp;in&nbsp;Section 6.8 on&nbsp;page&nbsp;176) to&nbsp;the&nbsp;PC&nbsp;after scaling it&nbsp;to&nbsp;a&nbsp;<br>
word offset. The overrun case falls through the add instruction into&nbsp;the slot&nbsp;left&nbsp;free by&nbsp;<br>
the PC offset.&nbsp;Any cases&nbsp;which require a single instruction (such as case&nbsp;3), and the&nbsp;<br>
last case whatever its length,&nbsp;can&nbsp;be completed&nbsp;in&nbsp;line;&nbsp;others require a branch. This&nbsp;<br>
example also illustrates an&nbsp;if...then...else implemented using conditional&nbsp;instructions.&nbsp;<br>
;&nbsp;on&nbsp;entry al = 0,&nbsp;a2&nbsp;=&nbsp;3,&nbsp;v2&nbsp;=&nbsp;switch&nbsp;expression&nbsp;<br>
CMP&nbsp;<br>
v2,#4&nbsp;<br>
check value for&nbsp;overrun..&nbsp;<br>
ADDLS&nbsp;&nbsp;pc,pc,v2,LSL&nbsp;#2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;..if&nbsp;OK,&nbsp;add to&nbsp;pc&nbsp;(+8)&nbsp;<br>
LDMDB&nbsp;&nbsp;fp,{vl,v2,fp,sp,pc} ;&nbsp;&nbsp;..if&nbsp;not&nbsp;OK,&nbsp;return&nbsp;<br>
B&nbsp;<br>
LO&nbsp;<br>
case 0&nbsp;<br>
B&nbsp;<br>
LI&nbsp;<br>
case 1&nbsp;<br>
B&nbsp;<br>
L2&nbsp;<br>
case&nbsp;2&nbsp;<br>
LDMDB&nbsp;&nbsp;fp,{vl,v2,fp,sp,pc} ; case 3&nbsp;(return)&nbsp;<br>
MOV&nbsp;<br>
al,#2&nbsp;<br>
case 4&nbsp;<br>
STR&nbsp;<br>
al,[vl]&nbsp;<br>
LDMDB&nbsp;&nbsp;fp,{vl,v2,fp,sp,pc} ;&nbsp;return&nbsp;<br>
LO&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;STR&nbsp;<br>
al,[vl]&nbsp;<br>
LDMDB&nbsp;&nbsp;fp,{vl,v2,fp,sp,pc} ;&nbsp;return&nbsp;<br>
LI&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LDR&nbsp;<br>
a3,c_ADDR &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;;&nbsp;get&nbsp;address&nbsp;of&nbsp;c&nbsp;<br>
LDR&nbsp;<br>
a3,&nbsp;[a3]&nbsp;<br>
;&nbsp;get c&nbsp;<br>
CMP&nbsp;<br>
a3,#&amp;64&nbsp;<br>
;&nbsp;c&gt;100?..&nbsp;<br>
STRLE&nbsp;&nbsp;a2,&nbsp;[vl]&nbsp;<br>
;&nbsp;&nbsp;..&nbsp;No:&nbsp;&nbsp;*b&nbsp;=&nbsp;3&nbsp;<br>
STRGT&nbsp;&nbsp;al,&nbsp;[vl]&nbsp;<br>
;&nbsp;&nbsp;.. Yes: *b&nbsp;= 0&nbsp;<br>
LDMDB&nbsp;&nbsp;fp,{vl,v2,fp,sp,pc) ;&nbsp;return&nbsp;<br>
c_ADDR &nbsp;DCD&nbsp;<br>
&lt;address of c&gt;&nbsp;<br>
L2&nbsp;&nbsp;&nbsp;&nbsp; MOV&nbsp;<br>
al,ttl&nbsp;<br>
STR&nbsp;<br>
al,[vl]&nbsp;<br>
;&nbsp;*b&nbsp;=&nbsp;1&nbsp;<br>
LDMDB&nbsp;&nbsp;fp,{vl,v2,fp,sp,pc} ;&nbsp;return&nbsp;<br>
<hr>
<A name=184></a><IMG src="index-184_1.png"><br>
<b>Loops&nbsp;</b><br>
<b>173</b>&nbsp;<br>
6.7 &nbsp; Loops&nbsp;<br>
The C language&nbsp;supports three forms of&nbsp;loop&nbsp;control structure:&nbsp;<br>
•&nbsp;&nbsp;for(el;e2;e3){..}&nbsp;<br>
•&nbsp;&nbsp;while (el) {..}&nbsp;<br>
•&nbsp;&nbsp;do {..} while (el)&nbsp;<br>
Here el,&nbsp;e2&nbsp;and&nbsp;e3&nbsp;are expressions which evaluate to&nbsp;'true'&nbsp;or&nbsp;'false' and&nbsp;{..}&nbsp;is&nbsp;the&nbsp;<br>
body&nbsp;of the loop&nbsp;which is executed&nbsp;a number&nbsp;of times determined by&nbsp;the&nbsp;control struc-<br>
ture.&nbsp;Often&nbsp;the body&nbsp;of&nbsp;a loop&nbsp;is very&nbsp;simple,&nbsp;which&nbsp;puts the&nbsp;onus on&nbsp;the compiler&nbsp;to&nbsp;<br>
minimize the&nbsp;overhead of the control structure. Each loop&nbsp;must have at&nbsp;least one&nbsp;<br>
branch&nbsp;instruction,&nbsp;but&nbsp;any&nbsp;more would&nbsp;be&nbsp;wasteful.&nbsp;<br>
for&nbsp;loops&nbsp;<br>
A&nbsp;typical&nbsp;'for'&nbsp;loop uses the&nbsp;control&nbsp;expressions to&nbsp;manage&nbsp;an index:&nbsp;<br>
for&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(i=0;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i&lt;10;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i++) &nbsp; &nbsp;{a[i] &nbsp; &nbsp;= &nbsp; 0}&nbsp;<br>
The first&nbsp;control&nbsp;expression&nbsp;is&nbsp;executed&nbsp;once before the&nbsp;loop&nbsp;begins, the&nbsp;second&nbsp;is&nbsp;<br>
tested each time&nbsp;the loop&nbsp;is entered and&nbsp;controls whether&nbsp;the loop is executed, and the&nbsp;<br>
third is executed at the&nbsp;end&nbsp;of&nbsp;each pass&nbsp;through the&nbsp;loop&nbsp;to prepare&nbsp;for the&nbsp;next&nbsp;pass.&nbsp;<br>
This&nbsp;loop could be compiled as:&nbsp;<br>
&nbsp;<br>
(This&nbsp;example illustrates the optimization&nbsp;technique&nbsp;of&nbsp;<i>strength reduction,&nbsp;</i>which&nbsp;<br>
means&nbsp;moving fixed operations outside the loop. The first&nbsp;two instructions are logi-<br>
cally&nbsp;inside the loop in&nbsp;the&nbsp;C&nbsp;program, but&nbsp;have been&nbsp;moved outside since&nbsp;they&nbsp;are&nbsp;ini-<br>
tializing registers to the same&nbsp;constants each time round the loop.)&nbsp;<br>
This&nbsp;code&nbsp;may be improved&nbsp;by&nbsp;omitting the&nbsp;conditional&nbsp;branch to&nbsp;EXIT&nbsp;and apply-<br>
ing&nbsp;the opposite condition&nbsp;to&nbsp;the following&nbsp;instructions, causing&nbsp;the&nbsp;program&nbsp;to&nbsp;fall&nbsp;<br>
through rather&nbsp;than&nbsp;branch round&nbsp;them&nbsp;when&nbsp;the terminating&nbsp;condition&nbsp;is met. How-<br>
ever, it&nbsp;can be&nbsp;further improved by&nbsp;moving&nbsp;the test to&nbsp;the bottom&nbsp;of&nbsp;the&nbsp;loop (which is&nbsp;<br>
possible here since the initialization and test&nbsp;are with constants, so the compiler can be&nbsp;<br>
sure that the loop&nbsp;will be&nbsp;executed at least once).&nbsp;<br>
<hr>
<A name=185></a><b>174&nbsp;</b><br>
<b>Architectural&nbsp;Support&nbsp;for&nbsp;High-Level&nbsp;Languages</b>&nbsp;<br>
while loops&nbsp;<br>
A 'while'&nbsp;loop has a&nbsp;simpler structure&nbsp;and&nbsp;generally controls&nbsp;loops&nbsp;where the&nbsp;<br>
number of iterations is not a&nbsp;constant or&nbsp;clearly&nbsp;denned by&nbsp;a variable at run-time.&nbsp;<br>
The standard conceptual arrangement&nbsp;of&nbsp;a 'while'&nbsp;loop&nbsp;is&nbsp;as follows:&nbsp;<br>
LOOP &nbsp;&nbsp;..&nbsp;<br>
;&nbsp;evaluate expression&nbsp;<br>
BEQ &nbsp;&nbsp;&nbsp; EXIT&nbsp;<br>
.&nbsp;.&nbsp;;&nbsp;<br>
loop&nbsp;<br>
body&nbsp;<br>
B &nbsp;&nbsp;&nbsp; &nbsp;LOOP&nbsp;<br>
EXIT&nbsp;<br>
The two branches&nbsp;appear to&nbsp;be&nbsp;necessary&nbsp;since the&nbsp;code must&nbsp;allow&nbsp;for&nbsp;the case&nbsp;<br>
where the&nbsp;body is not&nbsp;executed at all.&nbsp;A little reordering&nbsp;produces more efficient code:&nbsp;<br>
B &nbsp; &nbsp; &nbsp; TEST&nbsp;<br>
LOOP&nbsp;&nbsp;&nbsp;&nbsp;.&nbsp;.&nbsp;<br>
;&nbsp;loop&nbsp;body&nbsp;<br>
TEST &nbsp;&nbsp; ..&nbsp;<br>
;&nbsp;&nbsp;evaluate expression&nbsp;<br>
BNE &nbsp; &nbsp;&nbsp;LOOP&nbsp;<br>
EXIT&nbsp;<br>
This&nbsp;second&nbsp;code sequence&nbsp;executes&nbsp;the&nbsp;loop body and&nbsp;evaluates the control&nbsp;<br>
expression&nbsp;exactly&nbsp;the&nbsp;same&nbsp;way as&nbsp;the&nbsp;original&nbsp;version&nbsp;and&nbsp;has&nbsp;the&nbsp;same&nbsp;code&nbsp;size,&nbsp;<br>
but&nbsp;it executes&nbsp;one fewer (untaken) branch&nbsp;per iteration, so&nbsp;the second&nbsp;branch has been&nbsp;<br>
removed from&nbsp;the loop&nbsp;overhead. An&nbsp;even&nbsp;more efficient&nbsp;code sequence&nbsp;can be&nbsp;pro-<br>
duced&nbsp;by&nbsp;the compiler:&nbsp;<br>
.&nbsp;.&nbsp;;&nbsp;<br>
evaluate&nbsp;expression&nbsp;<br>
BEQ&nbsp;&nbsp;E&nbsp;X&nbsp;I&nbsp;T&nbsp;&nbsp;<br>
;&nbsp;&nbsp;<br>
skip loop if necessary&nbsp;<br>
LOOP&nbsp;&nbsp;&nbsp;&nbsp;. .&nbsp;<br>
;&nbsp;loop body&nbsp;<br>
T&nbsp;E&nbsp;S&nbsp;T&nbsp;&nbsp;&nbsp;.&nbsp;.&nbsp;&nbsp;<br>
;&nbsp;evaluate&nbsp;expression&nbsp;<br>
BNE&nbsp;LOOP&nbsp;<br>
EXIT&nbsp;<br>
The saving&nbsp;here&nbsp;is that&nbsp;one fewer branch&nbsp;is executed&nbsp;each&nbsp;time&nbsp;the complete&nbsp;'while'&nbsp;<br>
structure is&nbsp;encountered&nbsp;(assuming&nbsp;that&nbsp;the&nbsp;body is executed&nbsp;at&nbsp;least once).&nbsp;This is a&nbsp;<br>
modest gain&nbsp;and costs extra&nbsp;instructions, so&nbsp;it&nbsp;is worthwhile&nbsp;only&nbsp;if&nbsp;performance&nbsp;mat-<br>
ters&nbsp;much more&nbsp;than&nbsp;code size.&nbsp;<br>
do..while&nbsp;loops&nbsp;<br>
The&nbsp;conceptual&nbsp;arrangement of a 'do..while' loop&nbsp;is similar&nbsp;to the improved&nbsp;'while'&nbsp;<br>
loop&nbsp;above, but&nbsp;without&nbsp;the&nbsp;initial&nbsp;branch&nbsp;since the&nbsp;loop&nbsp;body&nbsp;is executed&nbsp;before the&nbsp;<br>
test (and is&nbsp;therefore always&nbsp;executed at least&nbsp;once):&nbsp;<br>
LOOP&nbsp;&nbsp;&nbsp;&nbsp;.&nbsp;.&nbsp;<br>
;&nbsp;loop&nbsp;body&nbsp;<br>
; evaluate&nbsp;expression&nbsp;BNE &nbsp;&nbsp;&nbsp;&nbsp;<br>
LOOP EXIT&nbsp;<br>
<hr>
<A name=186></a><IMG src="index-186_1.png"><br>
Functions&nbsp;<b>and procedures</b>&nbsp;<br>
<b>175</b>&nbsp;<br>
6.8 &nbsp; Functions&nbsp;and&nbsp;procedures&nbsp;<br>
Program design&nbsp;<br>
Good&nbsp;programming&nbsp;practice requires that large&nbsp;programs&nbsp;are broken&nbsp;down into&nbsp;<br>
components that are&nbsp;small enough to be thoroughly&nbsp;tested;&nbsp;a large,&nbsp;monolithic pro-<br>
gram&nbsp;is&nbsp;too complex to&nbsp;test&nbsp;fully&nbsp;and is likely&nbsp;to have&nbsp;'bugs'&nbsp;in hidden corners that&nbsp;<br>
do&nbsp;not emerge&nbsp;early&nbsp;enough in&nbsp;the&nbsp;program's&nbsp;life to&nbsp;be&nbsp;fixed before the program&nbsp;is&nbsp;<br>
shipped to users.&nbsp;<br>
Each small software component&nbsp;should&nbsp;perform&nbsp;a specified operation&nbsp;using a&nbsp;<br>
well-defined&nbsp;interface. How&nbsp;it&nbsp;performs&nbsp;this&nbsp;operation&nbsp;should&nbsp;be&nbsp;of&nbsp;no&nbsp;significance to&nbsp;<br>
the&nbsp;rest of the&nbsp;program&nbsp;(this is&nbsp;the principle&nbsp;<b>of abstraction;&nbsp;</b>see&nbsp;Section&nbsp;6.1 on&nbsp;page&nbsp;<br>
152).&nbsp;<br>
Program&nbsp;<br>
hierarchy&nbsp;<br>
Furthermore, the full program&nbsp;should be designed as a&nbsp;<b>hierarchy&nbsp;</b>of components,&nbsp;<br>
not&nbsp;simply&nbsp;a flat&nbsp;list.&nbsp;<br>
A typical&nbsp;hierarchy&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;Figure&nbsp;6.12.&nbsp;The&nbsp;top&nbsp;of&nbsp;the&nbsp;hierarchy&nbsp;is&nbsp;the&nbsp;pro-<br>
gram&nbsp;called&nbsp;<i>main.&nbsp;</i>The&nbsp;remaining hierarchy is&nbsp;fairly&nbsp;informal;&nbsp;lower-level&nbsp;routines&nbsp;<br>
may&nbsp;be shared&nbsp;by&nbsp;higher-level&nbsp;routines,&nbsp;calls&nbsp;may&nbsp;skip levels, and&nbsp;the depth&nbsp;may&nbsp;vary&nbsp;<br>
across the hierarchy.&nbsp;<br>
Leaf routines&nbsp;<br>
At the lowest level of&nbsp;the&nbsp;hierarchy there are&nbsp;<b>leaf&nbsp;</b>routines;&nbsp;these&nbsp;are&nbsp;routines&nbsp;which&nbsp;<br>
do not themselves call any lower-level&nbsp;routines.&nbsp;In&nbsp;a&nbsp;typical program&nbsp;some&nbsp;of the&nbsp;<br>
bottom-level&nbsp;routines will&nbsp;be&nbsp;<b>library or&nbsp;system&nbsp;</b>functions;&nbsp;these&nbsp;are&nbsp;predefined&nbsp;<br>
&nbsp;<br>
<b>Figure 6.12&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Typical hierarchical program structure.&nbsp;<br>
<hr>
<A name=187></a><b>176</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
operations which may&nbsp;or&nbsp;may not be&nbsp;leaf routines (that is,&nbsp;they&nbsp;may&nbsp;or&nbsp;may&nbsp;not&nbsp;have&nbsp;<br>
internal&nbsp;structure).&nbsp;<br>
Terminology&nbsp;<br>
There are&nbsp;several terms that&nbsp;are used to&nbsp;describe components of&nbsp;this program&nbsp;struc-<br>
ture, often imprecisely.&nbsp;We&nbsp;shall&nbsp;attempt&nbsp;to&nbsp;apply terms&nbsp;as&nbsp;follows:&nbsp;<br>
•&nbsp;&nbsp;<b>Subroutine:&nbsp;</b>a&nbsp;generic term&nbsp;for a routine that is called by&nbsp;a higher-level&nbsp;routine,&nbsp;<br>
particularly&nbsp;when viewing a program&nbsp;at&nbsp;the assembly&nbsp;language&nbsp;level.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Function:&nbsp;</b>a subroutine which returns a&nbsp;value through&nbsp;its&nbsp;name. A typical&nbsp;invoca&nbsp;<br>
tion looks like:<b>&nbsp;</b><br>
c&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;max&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(a,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b);&nbsp;<br>
<b>•&nbsp;Procedure:&nbsp;</b>a&nbsp;subroutine&nbsp;which&nbsp;is&nbsp;called&nbsp;to carry out&nbsp;some&nbsp;operation on&nbsp;specified&nbsp;<br>
data&nbsp;item(s). A typical&nbsp;invocation looks like:&nbsp;<br>
printf &nbsp; (&quot;Hello &nbsp;WorldXn&quot;);&nbsp;<br>
C functions&nbsp;<br>
Some&nbsp;programming languages&nbsp;make&nbsp;a clear distinction between&nbsp;functions&nbsp;and&nbsp;pro-<br>
cedures, but&nbsp;C does not.&nbsp;In C all subroutines are functions, but they can&nbsp;have&nbsp;<br>
side-effects in addition&nbsp;to returning a value, and when the returned value is of type&nbsp;<br>
'void'&nbsp;it is effectively&nbsp;suppressed and&nbsp;only&nbsp;the side-effects remain, giving a&nbsp;<br>
behaviour&nbsp;which&nbsp;looks&nbsp;just&nbsp;like&nbsp;a&nbsp;procedure.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Arguments and&nbsp;&nbsp;An&nbsp;<b>argument&nbsp;</b>is an&nbsp;expression passed&nbsp;to&nbsp;a&nbsp;function&nbsp;call;&nbsp;a&nbsp;value&nbsp;received by&nbsp;the&nbsp;<br>
parameters&nbsp;<br>
function is a&nbsp;<b>parameter.&nbsp;</b>C uses&nbsp;a strict&nbsp;'call by value'&nbsp;semantics,&nbsp;so a copy is&nbsp;made&nbsp;<br>
of&nbsp;each&nbsp;argument&nbsp;when&nbsp;a&nbsp;function&nbsp;is called and, though&nbsp;the&nbsp;function&nbsp;may&nbsp;change the&nbsp;<br>
values of its parameters, since&nbsp;these are&nbsp;only&nbsp;copies of the&nbsp;arguments the&nbsp;arguments&nbsp;<br>
themselves&nbsp;are&nbsp;not&nbsp;affected.&nbsp;<br>
(A&nbsp;<b>call&nbsp;by&nbsp;reference&nbsp;</b>semantics would cause&nbsp;any change&nbsp;to&nbsp;a parameter&nbsp;within&nbsp;a&nbsp;<br>
function to be&nbsp;passed&nbsp;back&nbsp;to the calling program,&nbsp;which&nbsp;clearly&nbsp;only makes sense&nbsp;<br>
when&nbsp;the argument is a&nbsp;simple variable, but&nbsp;C does not support this.)&nbsp;<br>
The way a C function can&nbsp;change&nbsp;data&nbsp;within the&nbsp;calling&nbsp;program,&nbsp;other than by&nbsp;<br>
returning&nbsp;a&nbsp;single&nbsp;value,&nbsp;is&nbsp;when&nbsp;it&nbsp;is&nbsp;passed&nbsp;a&nbsp;pointer&nbsp;to the data&nbsp;as an&nbsp;argument.&nbsp;The&nbsp;<br>
function can then use&nbsp;the&nbsp;pointer&nbsp;to access&nbsp;and modify the&nbsp;data&nbsp;structure.&nbsp;<br>
ARM Procedure&nbsp;<br>
In&nbsp;order&nbsp;to&nbsp;support flexible mixing&nbsp;of&nbsp;routines&nbsp;generated by different&nbsp;compilers and&nbsp;<br>
Call Standard&nbsp;<br>
written&nbsp;in assembly language,&nbsp;ARM&nbsp;Limited&nbsp;has&nbsp;defined&nbsp;a&nbsp;set&nbsp;of rules for procedure&nbsp;<br>
entry&nbsp;and&nbsp;exit.&nbsp;The ARM Procedure Call Standard (APCS)&nbsp;is&nbsp;employed&nbsp;by the ARM&nbsp;<br>
C compiler, though&nbsp;this is&nbsp;of&nbsp;significance to&nbsp;the&nbsp;C&nbsp;programmer&nbsp;only when&nbsp;the&nbsp;<br>
assembly-level&nbsp;output&nbsp;must be understood&nbsp;in&nbsp;detail.&nbsp;<br>
<hr>
<A name=188></a><b>Functions&nbsp;and&nbsp;procedures</b>&nbsp;<br>
<b>177</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The APCS imposes&nbsp;a number of&nbsp;conventions&nbsp;on&nbsp;the otherwise&nbsp;'vanilla'&nbsp;flavour of&nbsp;<br>
the ARM architecture:&nbsp;<br>
•&nbsp;&nbsp;It defines particular uses&nbsp;for the&nbsp;'general-purpose'&nbsp;registers.&nbsp;<br>
•&nbsp;&nbsp;It&nbsp;defines&nbsp;which form&nbsp;of&nbsp;stack&nbsp;is&nbsp;used&nbsp;from&nbsp;the full/empty,&nbsp;ascending/descending&nbsp;<br>
choices&nbsp;supported by&nbsp;the&nbsp;ARM instruction&nbsp;set.&nbsp;<br>
•&nbsp;&nbsp;It defines the&nbsp;format of a&nbsp;stack-based data structure used&nbsp;for back-tracing&nbsp;when&nbsp;<br>
debugging programs.&nbsp;<br>
•&nbsp;&nbsp;It defines the&nbsp;function argument and result passing&nbsp;mechanism&nbsp;to be used by&nbsp;all&nbsp;<br>
externally&nbsp;visible functions and procedures.&nbsp;('Externally&nbsp;visible'&nbsp;means that the&nbsp;<br>
procedure interface is&nbsp;offered&nbsp;outside&nbsp;the current programming&nbsp;module.&nbsp;A&nbsp;func&nbsp;<br>
tion&nbsp;which&nbsp;is used&nbsp;only&nbsp;within&nbsp;the current&nbsp;module&nbsp;may be&nbsp;optimized by&nbsp;deviating&nbsp;<br>
from&nbsp;this convention.)&nbsp;<br>
•&nbsp;&nbsp;It supports the ARM shared library&nbsp;mechanism,&nbsp;which&nbsp;means it supports a&nbsp;<br>
standard way for shared (re-entrant)&nbsp;code&nbsp;to&nbsp;access static&nbsp;data.&nbsp;<br>
ARCS register&nbsp;<br>
The&nbsp;convention&nbsp;for&nbsp;the&nbsp;use&nbsp;of&nbsp;the&nbsp;16 currently visible ARM registers&nbsp;is&nbsp;summarized&nbsp;<br>
usage&nbsp;<br>
in&nbsp;Table 6.2. The&nbsp;registers&nbsp;are divided into&nbsp;three sets:&nbsp;<br>
<b>Table&nbsp;6.2 &nbsp;&nbsp;&nbsp;</b>APCS&nbsp;register&nbsp;use&nbsp;convention.&nbsp;<br>
&nbsp;<br>
Register&nbsp;&nbsp;&nbsp;&nbsp;APCS name&nbsp;&nbsp;&nbsp;&nbsp;APCS role&nbsp;&nbsp;&nbsp;<br>
0&nbsp;&nbsp;&nbsp;<br>
al&nbsp;&nbsp;&nbsp;<br>
Argument 1&nbsp;/&nbsp;integer result&nbsp;/&nbsp;scratch&nbsp;register&nbsp;&nbsp;&nbsp;<br>
1&nbsp;&nbsp;&nbsp;<br>
a2&nbsp;&nbsp;&nbsp;<br>
Argument 2&nbsp;/ scratch&nbsp;register&nbsp;&nbsp;&nbsp;<br>
2&nbsp;&nbsp;&nbsp;<br>
a3&nbsp;&nbsp;&nbsp;<br>
Argument 3&nbsp;/ scratch&nbsp;register&nbsp;&nbsp;&nbsp;<br>
3&nbsp;&nbsp;&nbsp;<br>
a4&nbsp;&nbsp;&nbsp;<br>
Argument 4&nbsp;/ scratch&nbsp;register&nbsp;&nbsp;&nbsp;<br>
4&nbsp;&nbsp;&nbsp;<br>
vl&nbsp;&nbsp;&nbsp;<br>
Register variable&nbsp;1&nbsp;&nbsp;&nbsp;<br>
5&nbsp;&nbsp;&nbsp;<br>
v2&nbsp;&nbsp;&nbsp;<br>
Register variable&nbsp;2&nbsp;&nbsp;&nbsp;<br>
6&nbsp;&nbsp;&nbsp;<br>
v3&nbsp;&nbsp;&nbsp;<br>
Register variable&nbsp;3&nbsp;&nbsp;&nbsp;<br>
7&nbsp;&nbsp;&nbsp;<br>
v4&nbsp;&nbsp;&nbsp;<br>
Register variable&nbsp;4&nbsp;&nbsp;&nbsp;<br>
8&nbsp;&nbsp;&nbsp;<br>
v5&nbsp;&nbsp;&nbsp;<br>
Register variable&nbsp;5&nbsp;&nbsp;&nbsp;<br>
9&nbsp;&nbsp;&nbsp;<br>
sb/v6&nbsp;&nbsp;&nbsp;<br>
Static&nbsp;base&nbsp;/&nbsp;register&nbsp;variable&nbsp;6&nbsp;&nbsp;&nbsp;<br>
10&nbsp;&nbsp;&nbsp;<br>
sl/v7&nbsp;&nbsp;&nbsp;<br>
Stack limit / register variable&nbsp;7&nbsp;&nbsp;&nbsp;<br>
11&nbsp;&nbsp;&nbsp;<br>
fp&nbsp;&nbsp;&nbsp;<br>
Frame pointer&nbsp;&nbsp;&nbsp;<br>
12&nbsp;&nbsp;&nbsp;<br>
ip&nbsp;&nbsp;&nbsp;<br>
Scratch&nbsp;reg.&nbsp;/&nbsp;new sb&nbsp;in&nbsp;inter-link-unit&nbsp;calls&nbsp;&nbsp;&nbsp;<br>
13&nbsp;&nbsp;&nbsp;<br>
sp&nbsp;&nbsp;&nbsp;<br>
Lower end&nbsp;of&nbsp;current&nbsp;stack frame&nbsp;&nbsp;&nbsp;<br>
14&nbsp;&nbsp;&nbsp;<br>
Ir&nbsp;&nbsp;&nbsp;<br>
Link address&nbsp;/ scratch&nbsp;register&nbsp;&nbsp;&nbsp;<br>
15&nbsp;&nbsp;&nbsp;<br>
pc&nbsp;&nbsp;&nbsp;<br>
Program&nbsp;counter&nbsp;&nbsp;&nbsp;<br>
<hr>
<A name=189></a><b>178&nbsp;</b><br>
<b>Architectural&nbsp;Support&nbsp;for&nbsp;High-Level&nbsp;Languages</b>&nbsp;<br>
1.&nbsp;&nbsp;Four&nbsp;argument&nbsp;registers which&nbsp;pass&nbsp;values into the&nbsp;function.&nbsp;<br>
The function need not preserve these so&nbsp;it can use them&nbsp;as scratch&nbsp;registers once&nbsp;<br>
it has used&nbsp;or&nbsp;saved its parameter values.&nbsp;Since they&nbsp;will not be preserved across&nbsp;<br>
any calls this&nbsp;function&nbsp;makes to other&nbsp;functions, they&nbsp;must be&nbsp;saved&nbsp;across such&nbsp;<br>
calls if&nbsp;they&nbsp;contain values&nbsp;that are needed&nbsp;again.&nbsp;Hence,&nbsp;they are&nbsp;<b>caller-saved&nbsp;</b><br>
register&nbsp;variables&nbsp;when&nbsp;so used.&nbsp;<br>
2.&nbsp;&nbsp;Five&nbsp;(to&nbsp;seven) register variables&nbsp;which&nbsp;the function must return with&nbsp;unchanged&nbsp;<br>
values.&nbsp;<br>
These&nbsp;are&nbsp;<b>callee-saved&nbsp;</b>register variables. This function&nbsp;must&nbsp;save&nbsp;them&nbsp;if&nbsp;it&nbsp;<br>
wishes to&nbsp;use&nbsp;the&nbsp;registers,&nbsp;but&nbsp;it&nbsp;can&nbsp;rely&nbsp;on&nbsp;functions it calls&nbsp;not changing&nbsp;them.&nbsp;<br>
3.&nbsp;&nbsp;Seven (to five) registers which&nbsp;have&nbsp;a&nbsp;dedicated&nbsp;role, at least some&nbsp;of&nbsp;the&nbsp;time.&nbsp;<br>
The link register (Ir), for example, carries the return address on function entry,&nbsp;<br>
but if&nbsp;it is&nbsp;saved (as it&nbsp;must&nbsp;be if&nbsp;the&nbsp;function calls subfunctions) it&nbsp;may then be&nbsp;<br>
used&nbsp;as&nbsp;a scratch register.&nbsp;<br>
APCS variants&nbsp;<br>
There are several (16)&nbsp;different&nbsp;variants&nbsp;of&nbsp;the&nbsp;APCS which&nbsp;are&nbsp;used&nbsp;to&nbsp;generate&nbsp;<br>
code&nbsp;for&nbsp;a range&nbsp;of&nbsp;different&nbsp;systems. They&nbsp;support:&nbsp;<br>
•&nbsp;&nbsp;32-or 26-bit PCs.&nbsp;<br>
Older ARM processors operated in&nbsp;a 26-bit address space and some&nbsp;later ver-<br>
sions continue&nbsp;to support this&nbsp;for backwards&nbsp;compatibility&nbsp;reasons.&nbsp;<br>
•&nbsp;&nbsp;Implicit or&nbsp;explicit&nbsp;stack-limit&nbsp;checking.&nbsp;<br>
Stack&nbsp;overflow&nbsp;must be&nbsp;detected if&nbsp;code&nbsp;is&nbsp;to&nbsp;operate&nbsp;reliably.&nbsp;The&nbsp;compiler can&nbsp;<br>
insert instructions&nbsp;to perform explicit&nbsp;checks for&nbsp;overflow.&nbsp;<br>
Where&nbsp;memory&nbsp;management&nbsp;hardware&nbsp;is&nbsp;available,&nbsp;an&nbsp;ARM&nbsp;system&nbsp;can&nbsp;allocate&nbsp;<br>
memory&nbsp;to&nbsp;the stack in units&nbsp;of a page.&nbsp;If the next logical&nbsp;page is&nbsp;mapped out, a&nbsp;<br>
stack overflow&nbsp;will&nbsp;cause a&nbsp;data abort and&nbsp;be detected.&nbsp;Therefore&nbsp;the&nbsp;memory&nbsp;<br>
management&nbsp;unit can&nbsp;perform&nbsp;stack-limit&nbsp;checking and&nbsp;there&nbsp;is no need&nbsp;for the&nbsp;<br>
compiler&nbsp;to insert&nbsp;instructions to perform&nbsp;explicit checks.&nbsp;<br>
•&nbsp;&nbsp;Two&nbsp;ways to&nbsp;pass floating-point&nbsp;arguments.&nbsp;<br>
The ARM floating-point architecture (see&nbsp;Section 6.4 on page 163) specifies a&nbsp;set&nbsp;<br>
of eight floating-point&nbsp;registers. The&nbsp;APCS&nbsp;can use these to pass&nbsp;floating-point&nbsp;<br>
arguments into&nbsp;functions, and&nbsp;this is the&nbsp;most efficient&nbsp;solution&nbsp;when the&nbsp;system&nbsp;<br>
makes extensive use of&nbsp;floating-point variables. If, however, the system&nbsp;makes&nbsp;<br>
little or no&nbsp;use of floating-point&nbsp;types (and&nbsp;many&nbsp;ARM systems do not) this&nbsp;<br>
approach&nbsp;incurs a small overhead&nbsp;which&nbsp;is avoided&nbsp;by&nbsp;passing&nbsp;floating-point&nbsp;<br>
arguments in the integer&nbsp;registers and/or&nbsp;on&nbsp;the stack.&nbsp;<br>
•&nbsp;&nbsp;Re-entrant&nbsp;or&nbsp;non-re-entrant code.&nbsp;<br>
Code specified as&nbsp;re-entrant is&nbsp;position-independent&nbsp;and&nbsp;addresses all&nbsp;data&nbsp;indir-<br>
ectly&nbsp;through the static base&nbsp;register&nbsp;(sb). This code&nbsp;can be&nbsp;placed&nbsp;in a ROM and&nbsp;<br>
<hr>
<A name=190></a><IMG src="index-190_1.png"><br>
<IMG src="index-190_2.png"><br>
<b>Functions&nbsp;and&nbsp;procedures</b>&nbsp;<br>
<b>179</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
can be&nbsp;shared by&nbsp;several&nbsp;client processes.&nbsp;Generally,&nbsp;code to&nbsp;be placed in&nbsp;a&nbsp;ROM&nbsp;<br>
or&nbsp;a shared library&nbsp;should&nbsp;be&nbsp;re-entrant&nbsp;whereas application&nbsp;code&nbsp;will not&nbsp;be.&nbsp;<br>
Argumen<br>
A&nbsp;C&nbsp;function&nbsp;may&nbsp;have&nbsp;many&nbsp;(or&nbsp;even&nbsp;a&nbsp;variable&nbsp;number of)&nbsp;arguments.&nbsp;The&nbsp;APCS&nbsp;<br>
t passing&nbsp;<br>
organizes&nbsp;the&nbsp;arguments&nbsp;as&nbsp;follows:&nbsp;<br>
1.&nbsp;&nbsp;If&nbsp;floating-point values are passed through&nbsp;floating-point registers, the&nbsp;first&nbsp;four&nbsp;<br>
floating-point&nbsp;arguments&nbsp;are&nbsp;loaded&nbsp;into the first four&nbsp;floating-point&nbsp;registers.&nbsp;<br>
2.&nbsp;&nbsp;All remaining&nbsp;arguments are&nbsp;organized&nbsp;into&nbsp;a list&nbsp;of words;&nbsp;the first four words&nbsp;are&nbsp;<br>
loaded into al&nbsp;to a4, then the remaining&nbsp;words are pushed onto the&nbsp;stack in&nbsp;<br>
reverse order.&nbsp;<br>
Note&nbsp;that&nbsp;multi-word&nbsp;arguments,&nbsp;including&nbsp;double&nbsp;precision&nbsp;floating-point values,&nbsp;<br>
may&nbsp;be&nbsp;passed in integer&nbsp;registers, on the&nbsp;stack,&nbsp;or&nbsp;even split&nbsp;across&nbsp;the&nbsp;registers&nbsp;and&nbsp;<br>
the stack.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Result return&nbsp;<br>
A simple result (such&nbsp;as an&nbsp;integer) is&nbsp;returned through&nbsp;al.&nbsp;A more complex result is&nbsp;<br>
returned&nbsp;in memory to&nbsp;a&nbsp;location specified&nbsp;by an address which is&nbsp;effectively&nbsp;passed&nbsp;<br>
as an&nbsp;additional first argument&nbsp;to the&nbsp;function through&nbsp;al.&nbsp;<br>
Function entry&nbsp;<br>
A simple leaf&nbsp;function&nbsp;which can perform all its functions using&nbsp;only&nbsp;al to a4&nbsp;can&nbsp;<br>
and exit&nbsp;<br>
be&nbsp;compiled&nbsp;into&nbsp;code&nbsp;with&nbsp;a minimal&nbsp;calling&nbsp;overhead:&nbsp;<br>
&nbsp;<br>
In&nbsp;typical programs&nbsp;somewhere around 50% of&nbsp;all function calls are&nbsp;to leaf&nbsp;func-<br>
tions,&nbsp;and&nbsp;these&nbsp;are&nbsp;often&nbsp;quite&nbsp;simple.&nbsp;<br>
Where registers&nbsp;must be saved, the function&nbsp;must create a stack frame. This can be&nbsp;<br>
compiled efficiently using ARM's load and store multiple&nbsp;instructions:&nbsp;<br>
&nbsp;<br>
Here&nbsp;the number of&nbsp;registers&nbsp;which are&nbsp;saved and&nbsp;restored&nbsp;will&nbsp;be the&nbsp;minimum&nbsp;<br>
required to implement the function. Note the value saved from&nbsp;the link register (Ir)&nbsp;is&nbsp;<br>
returned&nbsp;directly&nbsp;to the&nbsp;program&nbsp;counter (pc),&nbsp;and therefore Ir is available as&nbsp;a scratch&nbsp;<br>
register&nbsp;in the body&nbsp;of&nbsp;the&nbsp;function&nbsp;(which&nbsp;it&nbsp;was not&nbsp;in&nbsp;the simple&nbsp;case above).&nbsp;<br>
<hr>
<A name=191></a><b>180</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
More complex&nbsp;function entry&nbsp;sequences are&nbsp;used&nbsp;where needed&nbsp;to&nbsp;create stack&nbsp;<br>
backtrace&nbsp;data&nbsp;structures,&nbsp;handle floating-point&nbsp;arguments&nbsp;passed&nbsp;in&nbsp;floating-point&nbsp;<br>
registers,&nbsp;check&nbsp;for stack&nbsp;overflow, and&nbsp;so&nbsp;on.&nbsp;<br>
Tail continued&nbsp;<br>
Simple&nbsp;functions that call&nbsp;another&nbsp;function&nbsp;immediately&nbsp;before&nbsp;returning often do&nbsp;not&nbsp;<br>
functions&nbsp;<br>
incur&nbsp;any significant call&nbsp;overhead;&nbsp;the&nbsp;compiler&nbsp;will cause the code to&nbsp;return directly&nbsp;<br>
from&nbsp;the&nbsp;continuing function. This makes&nbsp;veneer functions (functions&nbsp;that simply&nbsp;<br>
reorder arguments,&nbsp;change&nbsp;their type or&nbsp;add an&nbsp;extra&nbsp;argument) particularly&nbsp;efficient.&nbsp;<br>
ARM efficiency&nbsp;<br>
Overall&nbsp;the ARM supports&nbsp;functions and&nbsp;procedures&nbsp;efficiently&nbsp;and flexibly. The&nbsp;<br>
various&nbsp;flavours of&nbsp;the procedure call standard&nbsp;match different application require-<br>
ments well, and all result in&nbsp;efficient code. The load&nbsp;and store&nbsp;multiple register&nbsp;<br>
instructions are exploited&nbsp;to&nbsp;good&nbsp;effect by&nbsp;the compiler in this context; without&nbsp;<br>
them&nbsp;calls&nbsp;to non-leaf functions&nbsp;would&nbsp;be much more&nbsp;costly.&nbsp;<br>
The compiler is also&nbsp;able&nbsp;to&nbsp;make effective&nbsp;optimizations for leaf and tail&nbsp;continued&nbsp;<br>
functions, thereby encouraging good&nbsp;programming styles.&nbsp;Programmers can use&nbsp;better&nbsp;<br>
structured design when leaf&nbsp;function calls are&nbsp;efficient&nbsp;and can&nbsp;exploit&nbsp;abstraction&nbsp;<br>
better when&nbsp;veneer functions&nbsp;are efficient.&nbsp;<br>
6.9 &nbsp; Use&nbsp;of&nbsp;memory&nbsp;<br>
An ARM system,&nbsp;like most computer&nbsp;systems, has its&nbsp;memory&nbsp;arranged as a linear&nbsp;<br>
set of&nbsp;logical&nbsp;addresses.&nbsp;A C&nbsp;program&nbsp;expects to&nbsp;have&nbsp;access to a&nbsp;fixed area of&nbsp;pro-<br>
gram&nbsp;memory (where&nbsp;the application&nbsp;image&nbsp;resides) and to&nbsp;memory&nbsp;to&nbsp;support two&nbsp;<br>
data areas that grow&nbsp;dynamically&nbsp;and&nbsp;where the compiler often&nbsp;cannot&nbsp;work out&nbsp;a&nbsp;<br>
maximum&nbsp;size. These&nbsp;dynamic&nbsp;data&nbsp;areas are:&nbsp;<br>
• The&nbsp;stack.&nbsp;<br>
Whenever&nbsp;a&nbsp;(non-trivial)&nbsp;function is called,&nbsp;a new activation frame is&nbsp;created on&nbsp;<br>
the stack containing a backtrace&nbsp;record, local (non-static) variables, and so on.&nbsp;<br>
When a function returns its&nbsp;stack space is&nbsp;automatically&nbsp;recovered and&nbsp;will be&nbsp;<br>
reused&nbsp;for the&nbsp;next function call.&nbsp;<br>
• The&nbsp;heap.&nbsp;<br>
The heap is an area of&nbsp;memory used to&nbsp;satisfy&nbsp;program&nbsp;requests (malloc ()) for&nbsp;<br>
more&nbsp;memory&nbsp;for new data&nbsp;structures.&nbsp;A program&nbsp;which continues to request&nbsp;<br>
memory over&nbsp;a long period&nbsp;of time&nbsp;should&nbsp;be careful to&nbsp;free up&nbsp;<i>all&nbsp;</i>sections that&nbsp;<br>
are&nbsp;no&nbsp;longer&nbsp;needed,&nbsp;otherwise the heap&nbsp;will&nbsp;grow&nbsp;until&nbsp;memory&nbsp;runs&nbsp;out.&nbsp;<br>
Address space&nbsp;<br>
The&nbsp;normal use of&nbsp;memory&nbsp;is&nbsp;illustrated in&nbsp;Figure 6.13&nbsp;on&nbsp;page 181.&nbsp;Where an appli-<br>
model&nbsp;<br>
cation can use the entire&nbsp;memory space&nbsp;(or where a&nbsp;memory&nbsp;management unit can&nbsp;<br>
&nbsp;<br>
<hr>
<A name=192></a><IMG src="index-192_1.png"><br>
<b>Use of&nbsp;memory</b>&nbsp;<br>
181&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;6.13 &nbsp;&nbsp;</b>The&nbsp;standard&nbsp;ARM C&nbsp;program&nbsp;address&nbsp;space model.&nbsp;<br>
allow an&nbsp;application to think it&nbsp;has&nbsp;the&nbsp;entire&nbsp;memory space), the&nbsp;application image is&nbsp;<br>
loaded&nbsp;into&nbsp;the&nbsp;lowest address, the heap&nbsp;grows upwards from the top of the&nbsp;application&nbsp;<br>
and the stack&nbsp;grows downwards from&nbsp;the top&nbsp;of&nbsp;memory. The unused&nbsp;memory&nbsp;<br>
between the top of the heap&nbsp;and the&nbsp;bottom&nbsp;of the stack is&nbsp;allocated&nbsp;on&nbsp;demand to the&nbsp;<br>
heap or&nbsp;the stack, and&nbsp;if&nbsp;it runs out the&nbsp;program&nbsp;stops&nbsp;due to&nbsp;lack of&nbsp;memory.&nbsp;<br>
In&nbsp;a typical&nbsp;memory&nbsp;managed ARM&nbsp;system&nbsp;the&nbsp;logical&nbsp;space&nbsp;allocated to&nbsp;a single&nbsp;<br>
application&nbsp;will be very&nbsp;large, in the&nbsp;range&nbsp;of 1 to 4&nbsp;Gbytes. The&nbsp;memory&nbsp;manage-<br>
ment&nbsp;unit&nbsp;will allocate additional pages, on demand, to&nbsp;the heap&nbsp;or&nbsp;the stack,&nbsp;until&nbsp;it&nbsp;<br>
runs&nbsp;out of&nbsp;pages&nbsp;to&nbsp;allocate (either&nbsp;due&nbsp;to having&nbsp;allocated&nbsp;all&nbsp;the&nbsp;physical&nbsp;memory&nbsp;<br>
pages, or, in&nbsp;a&nbsp;system&nbsp;with virtual memory,&nbsp;due&nbsp;to&nbsp;running&nbsp;out&nbsp;of&nbsp;swap space on&nbsp;the&nbsp;<br>
hard disk). This&nbsp;will usually be a long time before&nbsp;the top of the heap&nbsp;meets the&nbsp;<br>
bottom&nbsp;of&nbsp;the stack.&nbsp;<br>
In&nbsp;a&nbsp;system&nbsp;with&nbsp;no&nbsp;memory&nbsp;management&nbsp;support the&nbsp;application&nbsp;will&nbsp;be allocated&nbsp;<br>
all (if&nbsp;it&nbsp;is&nbsp;the only application to run at&nbsp;the time) or part&nbsp;(if&nbsp;more than&nbsp;one&nbsp;application&nbsp;<br>
is to&nbsp;run)&nbsp;of the physical&nbsp;memory&nbsp;address space remaining&nbsp;once&nbsp;the&nbsp;operating system&nbsp;<br>
has&nbsp;had its&nbsp;requirements&nbsp;met,&nbsp;and then the&nbsp;application runs&nbsp;out&nbsp;of memory&nbsp;precisely&nbsp;<br>
when&nbsp;the&nbsp;top&nbsp;of the&nbsp;heap&nbsp;meets the&nbsp;bottom&nbsp;of the&nbsp;stack.&nbsp;<br>
<hr>
<A name=193></a><IMG src="index-193_1.png"><br>
<b>182</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Chunked stack&nbsp;&nbsp;Other address space&nbsp;models are possible, including implementing&nbsp;a&nbsp;'chunked'&nbsp;stack&nbsp;<br>
model&nbsp;<br>
where the stack is&nbsp;a series&nbsp;of&nbsp;chained chunks&nbsp;within&nbsp;the heap.&nbsp;This&nbsp;causes&nbsp;the appli-<br>
cation to occupy&nbsp;a&nbsp;single contiguous area&nbsp;of&nbsp;memory,&nbsp;which grows in&nbsp;one direction&nbsp;<br>
as required, and&nbsp;may be&nbsp;more&nbsp;convenient where memory is&nbsp;very&nbsp;tight.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Stack behaviour&nbsp;&nbsp;It is&nbsp;important&nbsp;to&nbsp;understand the&nbsp;dynamic behaviour of&nbsp;the&nbsp;stack&nbsp;while&nbsp;a program&nbsp;is&nbsp;<br>
running, since&nbsp;it sheds some&nbsp;light&nbsp;on&nbsp;the&nbsp;scoping rules for local&nbsp;variables (which&nbsp;are&nbsp;<br>
allocated space on&nbsp;the stack).&nbsp;<br>
Consider this simple program&nbsp;structure:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Assuming&nbsp;that&nbsp;the&nbsp;compiler allocates&nbsp;stack space&nbsp;for each&nbsp;function&nbsp;call, the&nbsp;stack&nbsp;<br>
behaviour&nbsp;will be as&nbsp;shown in&nbsp;Figure 6.14. At&nbsp;each&nbsp;function&nbsp;call,&nbsp;stack space is allo-<br>
cated&nbsp;for&nbsp;arguments (if&nbsp;they&nbsp;cannot&nbsp;all&nbsp;be&nbsp;passed in&nbsp;registers), to&nbsp;save&nbsp;registers for&nbsp;use&nbsp;<br>
within&nbsp;the function,&nbsp;to save&nbsp;the return&nbsp;address and the&nbsp;old stack&nbsp;pointer, and to&nbsp;allocate&nbsp;<br>
memory&nbsp;on the&nbsp;stack for local&nbsp;variables.&nbsp;<br>
Note&nbsp;how all the stack&nbsp;space is&nbsp;recovered on&nbsp;function exit&nbsp;and&nbsp;reused&nbsp;for&nbsp;subse-<br>
quent calls, and how the two calls to func2 () are allocated&nbsp;different&nbsp;memory areas&nbsp;<br>
(at times t3 and t6&nbsp;in Figure&nbsp;6.14&nbsp;on page&nbsp;183),&nbsp;so&nbsp;even&nbsp;if&nbsp;the&nbsp;memory&nbsp;used&nbsp;for a&nbsp;local&nbsp;<br>
variable&nbsp;in&nbsp;the&nbsp;first&nbsp;call&nbsp;had&nbsp;not been&nbsp;overwritten&nbsp;in&nbsp;an&nbsp;intervening&nbsp;call&nbsp;to&nbsp;another&nbsp;<br>
function, the&nbsp;old value cannot be&nbsp;accessed&nbsp;in&nbsp;the second&nbsp;call&nbsp;since&nbsp;its&nbsp;address is&nbsp;not&nbsp;<br>
known. Once&nbsp;a&nbsp;procedure has&nbsp;exited, local variable&nbsp;values are lost&nbsp;forever.&nbsp;<br>
Data storage&nbsp;<br>
The&nbsp;various&nbsp;data types supported in C require&nbsp;differing&nbsp;amounts of&nbsp;memory to&nbsp;store&nbsp;<br>
their binary&nbsp;representations.&nbsp;The basic data&nbsp;types&nbsp;occupy&nbsp;a byte&nbsp;(chars), a half-word&nbsp;<br>
(short&nbsp;ints),&nbsp;a&nbsp;word&nbsp;(ints,&nbsp;single&nbsp;precision float)&nbsp;or multiple&nbsp;words (double&nbsp;precision&nbsp;<br>
floats).&nbsp;Derived&nbsp;data types&nbsp;(structs, arrays,&nbsp;unions,&nbsp;and&nbsp;so on) are defined&nbsp;in&nbsp;terms&nbsp;of&nbsp;<br>
multiple&nbsp;basic data&nbsp;types.&nbsp;<br>
The ARM instruction set,&nbsp;in&nbsp;common&nbsp;with&nbsp;many&nbsp;other&nbsp;RISC&nbsp;processors, is&nbsp;most&nbsp;<br>
efficient at&nbsp;loading and&nbsp;storing&nbsp;data&nbsp;items&nbsp;when&nbsp;they&nbsp;are&nbsp;appropriately&nbsp;aligned in&nbsp;<br>
<hr>
<A name=194></a><IMG src="index-194_1.png"><br>
<b>Use of memory</b>&nbsp;<br>
<b>183</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 6.14&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Example stack&nbsp;behaviour.&nbsp;<br>
memory. A byte&nbsp;access&nbsp;can&nbsp;be made to&nbsp;any byte&nbsp;address&nbsp;with&nbsp;equal&nbsp;efficiency,&nbsp;but&nbsp;<br>
storing&nbsp;a word&nbsp;to&nbsp;a&nbsp;non-word-aligned&nbsp;address is&nbsp;very&nbsp;inefficient,&nbsp;taking&nbsp;up&nbsp;to&nbsp;seven&nbsp;<br>
ARM&nbsp;instructions&nbsp;and requiring&nbsp;temporary&nbsp;work registers.&nbsp;<br>
Data&nbsp;alignment&nbsp;<br>
Therefore&nbsp;the&nbsp;ARM C compiler generally&nbsp;aligns&nbsp;data&nbsp;items&nbsp;on&nbsp;appropriate&nbsp;boundaries:&nbsp;<br>
•&nbsp;&nbsp;Bytes&nbsp;are&nbsp;stored&nbsp;at any byte&nbsp;address.&nbsp;<br>
•&nbsp;&nbsp;Half-words&nbsp;are&nbsp;stored&nbsp;at&nbsp;even&nbsp;byte&nbsp;addresses.&nbsp;<br>
•&nbsp;&nbsp;Words are stored&nbsp;on&nbsp;four-byte&nbsp;boundaries.&nbsp;<br>
Where several&nbsp;data&nbsp;items&nbsp;of different&nbsp;types&nbsp;are declared at&nbsp;the&nbsp;same&nbsp;time, the&nbsp;com-<br>
piler will&nbsp;introduce&nbsp;<b>padding&nbsp;</b>where necessary to&nbsp;achieve this alignment:&nbsp;<br>
struct SI {char c; int x; short s;} examplel;&nbsp;<br>
This structure&nbsp;will occupy three&nbsp;words of&nbsp;memory as&nbsp;shown in Figure&nbsp;6.15 on&nbsp;<br>
page&nbsp;184.&nbsp;(Note&nbsp;that structures&nbsp;are&nbsp;also&nbsp;padded&nbsp;to&nbsp;end on&nbsp;a word boundary.)&nbsp;<br>
Arrays are&nbsp;laid out&nbsp;in&nbsp;memory by repeating&nbsp;the appropriate&nbsp;basic data&nbsp;item, obey-<br>
ing the alignment&nbsp;rules&nbsp;for each&nbsp;item.&nbsp;<br>
Memory&nbsp;<br>
Given the data&nbsp;alignment&nbsp;rules outlined above, the programmer&nbsp;can help&nbsp;the com-<br>
efficiency&nbsp;<br>
piler&nbsp;to&nbsp;minimize memory wastage&nbsp;by&nbsp;organizing structures&nbsp;appropriately. A&nbsp;struc-<br>
ture&nbsp;with the&nbsp;same&nbsp;contents&nbsp;as above, but&nbsp;reordered as below, occupies only&nbsp;two&nbsp;<br>
memory words instead of&nbsp;the&nbsp;original three:&nbsp;<br>
<hr>
<A name=195></a><IMG src="index-195_1.png"><br>
<IMG src="index-195_2.png"><br>
<IMG src="index-195_3.png"><br>
<b>184</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;6.15 &nbsp;&nbsp;</b>An example&nbsp;of&nbsp;normal&nbsp;struct&nbsp;memory&nbsp;allocation.&nbsp;<br>
struct&nbsp;<i>S2&nbsp;</i>{char c; short s; int x;} example2;&nbsp;<br>
This will result&nbsp;in the memory occupancy&nbsp;illustrated in&nbsp;Figure 6.16.&nbsp;In&nbsp;general,&nbsp;<br>
ordering&nbsp;structure&nbsp;elements&nbsp;so&nbsp;that&nbsp;types smaller&nbsp;than&nbsp;a&nbsp;word&nbsp;can&nbsp;be&nbsp;grouped within&nbsp;a&nbsp;<br>
word will minimize the&nbsp;amount&nbsp;of padding&nbsp;that&nbsp;the&nbsp;compiler has to&nbsp;insert&nbsp;to maintain&nbsp;<br>
efficient alignment.&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;6.16 &nbsp;&nbsp;</b>An example&nbsp;of&nbsp;more&nbsp;efficient struct&nbsp;memory&nbsp;allocation.&nbsp;<br>
Packed structs&nbsp;<br>
Sometimes it is&nbsp;necessary to&nbsp;exchange data&nbsp;with other computers that follow differ-<br>
ent alignment&nbsp;conventions, or to pack data tightly&nbsp;to&nbsp;minimize&nbsp;memory use even&nbsp;<br>
though this&nbsp;will reduce performance. For&nbsp;such purposes the ARM C compiler can&nbsp;<br>
produce&nbsp;code&nbsp;that&nbsp;works with&nbsp;packed&nbsp;data structures&nbsp;where all the&nbsp;padding&nbsp;is&nbsp;<br>
removed:&nbsp;<br>
..packed&nbsp;struct&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;S3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{char&nbsp;c;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int&nbsp;&nbsp;&nbsp;&nbsp;x;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;short&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<i>s&nbsp;;&nbsp;}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i><br>
example3;&nbsp;<br>
A packed struct&nbsp;gives&nbsp;precise&nbsp;control&nbsp;of the&nbsp;alignment of all&nbsp;the fields but&nbsp;incurs the&nbsp;<br>
overhead&nbsp;of&nbsp;the ARM's relatively inefficient&nbsp;access to&nbsp;non-aligned&nbsp;operands,&nbsp;and&nbsp;<br>
therefore&nbsp;should only be used&nbsp;when strictly necessary. The&nbsp;memory occupancy of the&nbsp;<br>
packed structure&nbsp;declared&nbsp;above&nbsp;is&nbsp;illustrated in&nbsp;Figure 6.17.&nbsp;<br>
&nbsp;<br>
<b>Figure 6.17&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>An example of&nbsp;packed struct memory&nbsp;allocation.&nbsp;<br>
<hr>
<A name=196></a><b>Run-time&nbsp;environment&nbsp;</b><br>
<b>185</b>&nbsp;<br>
6.10 &nbsp; Run-time&nbsp;environment&nbsp;<br>
A C&nbsp;program&nbsp;requires&nbsp;an&nbsp;environment&nbsp;in&nbsp;which to operate; this is&nbsp;usually&nbsp;provided&nbsp;<br>
through a library of&nbsp;functions that the C program&nbsp;can call.&nbsp;In a PC or&nbsp;workstation&nbsp;a&nbsp;<br>
C&nbsp;programmer&nbsp;can&nbsp;expect&nbsp;to find&nbsp;the&nbsp;full&nbsp;ANSI&nbsp;C library, giving&nbsp;access to&nbsp;a broad&nbsp;<br>
range of functions such as file&nbsp;management, input and&nbsp;output (print f ()), the real-<br>
time clock, and&nbsp;so&nbsp;on.&nbsp;<br>
Minimal run-time&nbsp;<br>
In&nbsp;a small embedded&nbsp;system&nbsp;such&nbsp;as&nbsp;a mobile telephone,&nbsp;most of&nbsp;these functions are&nbsp;<br>
library&nbsp;<br>
irrelevant.&nbsp;ARM Limited&nbsp;supplies a&nbsp;minimal&nbsp;stand-alone run-time&nbsp;library&nbsp;which,&nbsp;<br>
once ported to&nbsp;the target&nbsp;environment, allows basic&nbsp;C programs&nbsp;to&nbsp;run.&nbsp;This library&nbsp;<br>
therefore reflects&nbsp;the minimal&nbsp;requirements&nbsp;of&nbsp;a C&nbsp;program.&nbsp;It comprises:&nbsp;<br>
•&nbsp;&nbsp;Division and&nbsp;remainder&nbsp;functions.&nbsp;<br>
Since the&nbsp;ARM instruction&nbsp;set does not include divide&nbsp;instructions, these are&nbsp;<br>
implemented&nbsp;as library&nbsp;functions.&nbsp;<br>
•&nbsp;Stack-limit&nbsp;checking&nbsp;functions.&nbsp;<br>
A&nbsp;minimal embedded&nbsp;system is&nbsp;unlikely to&nbsp;have&nbsp;memory&nbsp;management&nbsp;hardware&nbsp;<br>
available&nbsp;for stack overflow&nbsp;detection;&nbsp;therefore&nbsp;these&nbsp;library functions&nbsp;are&nbsp;<br>
needed&nbsp;to&nbsp;ensure&nbsp;programs&nbsp;operate&nbsp;safely.&nbsp;<br>
•&nbsp;&nbsp;Stack&nbsp;and heap&nbsp;management.&nbsp;<br>
All&nbsp;C programs use&nbsp;the&nbsp;stack&nbsp;for (many)&nbsp;function calls, and all&nbsp;but the&nbsp;most triv-<br>
ial create&nbsp;data&nbsp;structures on the heap.&nbsp;<br>
•&nbsp;Program&nbsp;start&nbsp;up.&nbsp;<br>
Once the stack&nbsp;and&nbsp;heap are&nbsp;initialized,&nbsp;the program&nbsp;starts&nbsp;with a&nbsp;call&nbsp;to main ().&nbsp;<br>
•&nbsp;Program&nbsp;termination.&nbsp;<br>
Most&nbsp;programs&nbsp;terminate&nbsp;by calling _exit&nbsp;(); even a&nbsp;program&nbsp;which runs for-<br>
ever&nbsp;should&nbsp;terminate if an error is detected.&nbsp;<br>
The&nbsp;total size&nbsp;of&nbsp;the&nbsp;code&nbsp;generated for&nbsp;this&nbsp;minimal library is&nbsp;736&nbsp;bytes,&nbsp;and it&nbsp;is&nbsp;<br>
implemented&nbsp;in&nbsp;a&nbsp;way that&nbsp;allows the linker to omit&nbsp;any unreferenced&nbsp;sections&nbsp;to&nbsp;<br>
reduce&nbsp;the library&nbsp;image&nbsp;to&nbsp;around half&nbsp;a&nbsp;kilobyte in&nbsp;many&nbsp;cases. This is a&nbsp;great&nbsp;deal&nbsp;<br>
smaller than&nbsp;the full&nbsp;ANSI C library.&nbsp;<br>
<hr>
<A name=197></a><b>186</b>&nbsp;<br>
<b>Architectural Support&nbsp;for High-Level Languages</b>&nbsp;<br>
6.11 &nbsp; Examples&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example 6.1</b>&nbsp;<br>
<b>Write,&nbsp;compile and&nbsp;run&nbsp;a&nbsp;'Hello&nbsp;World'&nbsp;program&nbsp;written&nbsp;in&nbsp;C.</b>&nbsp;<br>
The following program&nbsp;has the&nbsp;required&nbsp;function:&nbsp;<br>
/* Hello World&nbsp;in&nbsp;C */&nbsp;<br>
#include &lt;stdio.h&gt;&nbsp;<br>
int main() {&nbsp;<br>
printf( &quot;Hello World\n&quot; );&nbsp;<br>
return&nbsp;<br>
(&nbsp;&nbsp;&nbsp;0&nbsp; &nbsp;);&nbsp;}&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The&nbsp;principal&nbsp;things&nbsp;to note from&nbsp;this&nbsp;example are:&nbsp;<br>
•&nbsp;&nbsp;The '#include'&nbsp;directive which allows this&nbsp;program&nbsp;to use all the standard&nbsp;input&nbsp;<br>
and output&nbsp;functions&nbsp;available in&nbsp;C.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;declaration&nbsp;of&nbsp;the&nbsp;'main'&nbsp;procedure. Every C&nbsp;program&nbsp;must have&nbsp;exactly&nbsp;<br>
one of&nbsp;these as the program&nbsp;is run by&nbsp;calling&nbsp;it.&nbsp;<br>
•&nbsp;&nbsp;The 'printf (.&nbsp;.}'&nbsp;statement&nbsp;calls&nbsp;a function&nbsp;provided&nbsp;in&nbsp;stdio&nbsp;which&nbsp;sends&nbsp;<br>
output to the&nbsp;standard output&nbsp;device. By&nbsp;default this&nbsp;is the&nbsp;display terminal.&nbsp;<br>
As&nbsp;with the&nbsp;assembly&nbsp;programming&nbsp;exercises, the&nbsp;major challenge is&nbsp;to&nbsp;establish&nbsp;<br>
the&nbsp;flow&nbsp;through the tools&nbsp;from&nbsp;editing the text&nbsp;to&nbsp;compiling, linking&nbsp;and&nbsp;running the&nbsp;<br>
program.&nbsp;Once&nbsp;this&nbsp;program&nbsp;is working,&nbsp;generating&nbsp;more complex&nbsp;programs is fairly&nbsp;<br>
straightforward (at least&nbsp;until&nbsp;the complexity&nbsp;reaches&nbsp;the&nbsp;point where the&nbsp;design of&nbsp;the&nbsp;<br>
program&nbsp;becomes a challenge in&nbsp;itself).&nbsp;<br>
Using the ARM software development tools, the&nbsp;above&nbsp;program&nbsp;should&nbsp;be saved&nbsp;as&nbsp;<br>
'HelloW.c'. Then&nbsp;a&nbsp;new&nbsp;project&nbsp;should&nbsp;be&nbsp;created&nbsp;using&nbsp;the&nbsp;Project&nbsp;Manager&nbsp;and&nbsp;this&nbsp;<br>
file&nbsp;added (as&nbsp;the&nbsp;only file&nbsp;in&nbsp;the&nbsp;project). A&nbsp;click&nbsp;on&nbsp;the 'Build'&nbsp;button will&nbsp;cause&nbsp;the&nbsp;<br>
program&nbsp;to be&nbsp;compiled and&nbsp;linked,&nbsp;then&nbsp;the&nbsp;'Go'&nbsp;button will&nbsp;run it&nbsp;on&nbsp;the ARMulator,&nbsp;<br>
hopefully&nbsp;giving&nbsp;the expected&nbsp;output in&nbsp;the&nbsp;terminal window.&nbsp;<br>
<b>Exercise 6.1.1</b>&nbsp;<br>
Generate an assembly&nbsp;listing&nbsp;from&nbsp;the compiler (using the&nbsp;'-s'&nbsp;option) and&nbsp;look&nbsp;at&nbsp;<br>
the code which is&nbsp;produced.&nbsp;<br>
<b>Exercise&nbsp;6.1.2</b>&nbsp;<br>
Run the program&nbsp;under the debugger, using&nbsp;single-stepping&nbsp;to observe the progress&nbsp;<br>
of&nbsp;the processor&nbsp;through&nbsp;the code.&nbsp;<br>
<hr>
<A name=198></a><IMG src="index-198_1.png"><br>
<IMG src="index-198_2.png"><br>
<b>Examples&nbsp;and&nbsp;exercises</b>&nbsp;<br>
<b>187</b>&nbsp;<br>
<b>Example&nbsp;6.2&nbsp;</b><br>
<b>Write the&nbsp;number 2001&nbsp;in 32-bit&nbsp;binary, binary-coded decimal, ASCII</b>&nbsp;<br>
<b>and single-precision&nbsp;floating-point&nbsp;notation.</b>&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Exercise 6.2.1</b>&nbsp;<br>
Write a C program&nbsp;to&nbsp;convert a date presented&nbsp;in&nbsp;Roman&nbsp;numerals&nbsp;into&nbsp;decimal&nbsp;<br>
form.&nbsp;<br>
<b>Example 6.3</b>&nbsp;<br>
<b>Show&nbsp;how&nbsp;the&nbsp;following&nbsp;data&nbsp;is organized&nbsp;in&nbsp;memory:</b>&nbsp;<br>
struct&nbsp;SI&nbsp;{char&nbsp;c;&nbsp;int&nbsp;x;};&nbsp;struct&nbsp;<br>
<i>S2 {</i>&nbsp;<br>
char c2[5];&nbsp;<br>
SI&nbsp;&nbsp;&nbsp;si [2]; }&nbsp;<br>
example;&nbsp;<br>
The first&nbsp;structure statement&nbsp;only&nbsp;declares&nbsp;a type,&nbsp;so no&nbsp;memory is&nbsp;allocated. The&nbsp;<br>
second establishes a structure called&nbsp;'example'&nbsp;comprising an array&nbsp;of five characters&nbsp;<br>
followed by&nbsp;an&nbsp;array&nbsp;of two structures of type SI. The structures must&nbsp;start&nbsp;on a&nbsp;word&nbsp;<br>
boundary, so the character array&nbsp;will&nbsp;be padded out&nbsp;to&nbsp;fill&nbsp;two words and each structure&nbsp;<br>
will&nbsp;also&nbsp;occupy two&nbsp;words.&nbsp;The memory&nbsp;organization is therefore as shown&nbsp;below:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Exercise 6.3.1</b>&nbsp;<br>
Show&nbsp;how&nbsp;the&nbsp;same&nbsp;structure would be&nbsp;organized in&nbsp;memory&nbsp;if&nbsp;it&nbsp;were packed.&nbsp;<br>
<hr>
<A name=199></a><IMG src="index-199_1.png"><br>
The Thumb Instruction Set&nbsp;<br>
&nbsp;<br>
Summary of chapter contents&nbsp;<br>
The Thumb&nbsp;instruction&nbsp;set&nbsp;addresses the&nbsp;issue&nbsp;of&nbsp;code&nbsp;density.&nbsp;It may&nbsp;be&nbsp;viewed&nbsp;<br>
as&nbsp;a&nbsp;compressed&nbsp;form&nbsp;of&nbsp;a subset&nbsp;of&nbsp;the ARM instruction&nbsp;set.&nbsp;Thumb&nbsp;instructions&nbsp;<br>
map onto&nbsp;ARM instructions,&nbsp;and the Thumb programmer's model maps onto the&nbsp;<br>
ARM&nbsp;programmer's model.&nbsp;Implementations of&nbsp;Thumb&nbsp;use dynamic&nbsp;decompres-<br>
sion&nbsp;in&nbsp;an&nbsp;ARM instruction&nbsp;pipeline&nbsp;and then&nbsp;instructions execute&nbsp;as&nbsp;standard ARM&nbsp;<br>
instructions&nbsp;within the processor.&nbsp;<br>
Thumb is not a complete&nbsp;architecture; it&nbsp;is&nbsp;not anticipated that&nbsp;a processor&nbsp;<br>
would&nbsp;execute&nbsp;Thumb&nbsp;instructions&nbsp;without&nbsp;also&nbsp;supporting&nbsp;the&nbsp;ARM instruction&nbsp;set.&nbsp;<br>
Therefore the&nbsp;Thumb instruction&nbsp;set&nbsp;need only&nbsp;support common&nbsp;application&nbsp;func-<br>
tions, allowing recourse to&nbsp;the full ARM instruction set where necessary (for&nbsp;<br>
instance,&nbsp;all exceptions&nbsp;automatically&nbsp;enter&nbsp;ARM mode).&nbsp;<br>
Thumb&nbsp;is&nbsp;fully&nbsp;supported&nbsp;by&nbsp;ARM&nbsp;development&nbsp;tools,&nbsp;and an&nbsp;application can&nbsp;mix&nbsp;<br>
ARM and&nbsp;Thumb&nbsp;subroutines&nbsp;flexibly&nbsp;to&nbsp;optimize&nbsp;performance&nbsp;or&nbsp;code&nbsp;density&nbsp;on&nbsp;a&nbsp;<br>
routine-by-routine&nbsp;basis.&nbsp;<br>
This&nbsp;chapter covers&nbsp;the Thumb architecture&nbsp;and&nbsp;implementation,&nbsp;and&nbsp;suggests&nbsp;<br>
the characteristics&nbsp;of&nbsp;applications&nbsp;that&nbsp;are likely&nbsp;to&nbsp;benefit&nbsp;from&nbsp;using Thumb.&nbsp;In&nbsp;the&nbsp;<br>
right&nbsp;application,&nbsp;use&nbsp;of the Thumb&nbsp;instruction set can improve&nbsp;power-efficiency,&nbsp;<br>
save&nbsp;cost&nbsp;and&nbsp;enhance performance all&nbsp;at&nbsp;once.&nbsp;<br>
<b>188</b>&nbsp;<br>
<hr>
<A name=200></a><b>The Thumb&nbsp;bit in&nbsp;the&nbsp;CPSR</b>&nbsp;<br>
<b>189</b>&nbsp;<br>
7.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The Thumb bit in the CPSR&nbsp;<br>
ARM processors&nbsp;which&nbsp;support the Thumb&nbsp;instruction set can&nbsp;also&nbsp;execute the&nbsp;<br>
standard 32-bit&nbsp;ARM&nbsp;instruction set,&nbsp;and&nbsp;the interpretation of&nbsp;the instruction stream&nbsp;<br>
at any particular time&nbsp;is determined by&nbsp;bit&nbsp;5 of the CPSR, the T bit&nbsp;(see&nbsp;Figure&nbsp;2.2&nbsp;<br>
on page&nbsp;40). If&nbsp;T is set the&nbsp;processor interprets the instruction stream&nbsp;as 16-bit&nbsp;<br>
Thumb instructions, otherwise it interprets&nbsp;it&nbsp;as&nbsp;standard&nbsp;ARM instructions.&nbsp;<br>
Not&nbsp;all&nbsp;ARM processors&nbsp;are capable of&nbsp;executing&nbsp;Thumb&nbsp;instructions; those&nbsp;that&nbsp;<br>
are have a T in&nbsp;their name,&nbsp;such as the ARM7TDMI described in Section 9.1 on&nbsp;<br>
page 248.&nbsp;<br>
Thumb entry&nbsp;<br>
ARM&nbsp;cores&nbsp;start up, after&nbsp;reset,&nbsp;executing&nbsp;ARM instructions. The normal way they&nbsp;<br>
switch to execute Thumb instructions is&nbsp;by executing a Branch and Exchange&nbsp;<br>
instruction&nbsp;(BX, see&nbsp;Section&nbsp;5.5 on&nbsp;page&nbsp;115).&nbsp;This&nbsp;instruction&nbsp;sets the&nbsp;T bit if&nbsp;the&nbsp;<br>
bottom&nbsp;bit of&nbsp;the specified&nbsp;register&nbsp;was&nbsp;set,&nbsp;and&nbsp;switches the program&nbsp;counter&nbsp;to&nbsp;the&nbsp;<br>
address given&nbsp;in the&nbsp;remainder of&nbsp;the&nbsp;register.&nbsp;Note&nbsp;that&nbsp;since the&nbsp;instruction causes&nbsp;<br>
a&nbsp;branch&nbsp;it&nbsp;flushes&nbsp;the&nbsp;instruction&nbsp;pipeline,&nbsp;removing&nbsp;any&nbsp;ambiguity over the inter-<br>
pretation of&nbsp;any instructions&nbsp;already in the&nbsp;pipeline&nbsp;(they&nbsp;are&nbsp;simply&nbsp;not&nbsp;executed).&nbsp;<br>
Other&nbsp;instructions which&nbsp;change&nbsp;from&nbsp;ARM&nbsp;to&nbsp;Thumb code&nbsp;include&nbsp;exception&nbsp;<br>
returns,&nbsp;either&nbsp;using a&nbsp;special&nbsp;form&nbsp;of data&nbsp;processing&nbsp;instruction or&nbsp;a special form&nbsp;of&nbsp;<br>
load multiple register&nbsp;instruction (see&nbsp;'Exception return'&nbsp;on&nbsp;page&nbsp;109). Both&nbsp;of&nbsp;these&nbsp;<br>
instructions&nbsp;are&nbsp;generally&nbsp;used&nbsp;to&nbsp;return&nbsp;to&nbsp;whatever&nbsp;instruction stream&nbsp;was being exe-<br>
cuted&nbsp;before&nbsp;the exception&nbsp;was entered&nbsp;and&nbsp;are&nbsp;not&nbsp;intended&nbsp;for a&nbsp;deliberate&nbsp;switch&nbsp;to&nbsp;<br>
Thumb&nbsp;mode. Like BX,&nbsp;they&nbsp;also change&nbsp;the program&nbsp;counter and therefore flush&nbsp;the&nbsp;<br>
instruction pipeline.&nbsp;<br>
Thumb exit&nbsp;<br>
An&nbsp;explicit&nbsp;switch&nbsp;back&nbsp;to&nbsp;an ARM instruction&nbsp;stream&nbsp;can&nbsp;be&nbsp;caused&nbsp;by&nbsp;executing&nbsp;a&nbsp;<br>
Thumb&nbsp;BX instruction&nbsp;as described&nbsp;in&nbsp;Section 7.3 on page 191.&nbsp;<br>
An implicit&nbsp;return&nbsp;to an ARM&nbsp;instruction stream&nbsp;takes&nbsp;place&nbsp;whenever&nbsp;an exception&nbsp;<br>
is taken, since&nbsp;exception&nbsp;entry&nbsp;is&nbsp;always&nbsp;handled in&nbsp;ARM code.&nbsp;<br>
Thumb systems&nbsp;<br>
It should&nbsp;be clear&nbsp;from&nbsp;the&nbsp;above&nbsp;that&nbsp;all Thumb systems include some&nbsp;ARM&nbsp;code,&nbsp;<br>
if only to handle initialization&nbsp;and exception&nbsp;entry.&nbsp;<br>
It is likely, however, that&nbsp;most Thumb applications will make more than this mini-<br>
mal use of ARM code. A typical&nbsp;embedded system&nbsp;will include&nbsp;a small amount&nbsp;of fast&nbsp;<br>
32-bit memory on the&nbsp;same&nbsp;chip as&nbsp;the ARM core&nbsp;and will&nbsp;execute&nbsp;speed-critical&nbsp;rou-<br>
tines&nbsp;(such&nbsp;as&nbsp;digital&nbsp;signal&nbsp;processing&nbsp;algorithms)&nbsp;in&nbsp;ARM&nbsp;code&nbsp;from this&nbsp;memory.&nbsp;<br>
The bulk of the code will not&nbsp;be speed critical and may execute from&nbsp;a 16-bit&nbsp;off-chip&nbsp;<br>
ROM. This is&nbsp;discussed further&nbsp;at&nbsp;the&nbsp;end&nbsp;of the chapter.&nbsp;<br>
<hr>
<A name=201></a><IMG src="index-201_1.png"><br>
<b>190</b>&nbsp;<br>
<b>The&nbsp;Thumb&nbsp;Instruction Set</b>&nbsp;<br>
7.2 &nbsp; The&nbsp;Thumb&nbsp;programmer's&nbsp;model&nbsp;<br>
The&nbsp;Thumb instruction set&nbsp;is&nbsp;a subset&nbsp;of&nbsp;the&nbsp;ARM&nbsp;instruction&nbsp;set&nbsp;and&nbsp;the&nbsp;instructions&nbsp;<br>
operate on a restricted view&nbsp;of the ARM registers.&nbsp;The programmer's&nbsp;model is illus-<br>
trated&nbsp;in&nbsp;Figure&nbsp;7.1.&nbsp;The&nbsp;instruction set&nbsp;gives full&nbsp;access&nbsp;to&nbsp;the&nbsp;eight&nbsp;'Lo'&nbsp;general&nbsp;pur-<br>
pose registers r0&nbsp;to&nbsp;r7,&nbsp;and makes&nbsp;extensive&nbsp;use&nbsp;of r13&nbsp;to&nbsp;r15&nbsp;for special&nbsp;purposes:&nbsp;<br>
•&nbsp;&nbsp;r13 is used as&nbsp;a stack&nbsp;pointer.&nbsp;<br>
•&nbsp;&nbsp;r14 is used as the link register.&nbsp;<br>
•&nbsp;&nbsp;r15 is the program&nbsp;counter&nbsp;(PC).&nbsp;<br>
These&nbsp;uses follow very closely the&nbsp;way these&nbsp;registers&nbsp;are&nbsp;used&nbsp;by&nbsp;the ARM&nbsp;<br>
instruction set,&nbsp;though&nbsp;the use&nbsp;of&nbsp;r13 as a&nbsp;stack&nbsp;pointer in&nbsp;ARM&nbsp;code is purely a&nbsp;soft-<br>
ware&nbsp;convention,&nbsp;whereas&nbsp;in Thumb code&nbsp;it&nbsp;is&nbsp;somewhat&nbsp;hard-wired.&nbsp;The remaining&nbsp;<br>
registers (r8 to&nbsp;r!2 and&nbsp;the&nbsp;CPSR)&nbsp;have only restricted&nbsp;access:&nbsp;<br>
•&nbsp;&nbsp;A few instructions allow the 'Hi'&nbsp;registers&nbsp;(r8 to r15) to be specified.&nbsp;<br>
•&nbsp;&nbsp;The CPSR condition code flags are set by&nbsp;arithmetic and logical operations and&nbsp;<br>
control&nbsp;conditional&nbsp;branching.&nbsp;<br>
Thumb-ARM&nbsp;<br>
All&nbsp;Thumb&nbsp;instructions&nbsp;are 16&nbsp;bits long. They&nbsp;map onto&nbsp;ARM instructions so&nbsp;they&nbsp;<br>
similarities&nbsp;<br>
inherit&nbsp;many&nbsp;properties of&nbsp;the&nbsp;ARM&nbsp;instruction set:&nbsp;<br>
&nbsp;<br>
<b>Figure 7.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Thumb accessible registers.&nbsp;<br>
<hr>
<A name=202></a><b>Thumb&nbsp;branch&nbsp;instructions</b>&nbsp;<br>
<b>191</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
•&nbsp;&nbsp;The load-store&nbsp;architecture&nbsp;with data processing, data transfer and control flow&nbsp;<br>
instructions.&nbsp;<br>
•&nbsp;&nbsp;Support for 8-bit byte, 16-bit&nbsp;half-word and 32-bit word data types where half-words&nbsp;<br>
are aligned on&nbsp;2-byte boundaries and words are aligned on&nbsp;4-byte boundaries.&nbsp;<br>
•&nbsp;&nbsp;A 32-bit unsegmented&nbsp;memory.&nbsp;<br>
Thumb-ARM&nbsp;<br>
However, in order to&nbsp;achieve&nbsp;a 16-bit&nbsp;instruction&nbsp;length&nbsp;a&nbsp;number&nbsp;of&nbsp;characteristic&nbsp;<br>
differences&nbsp;<br>
features of&nbsp;the ARM instruction&nbsp;set have&nbsp;been abandoned:&nbsp;<br>
•&nbsp;&nbsp;Most&nbsp;Thumb&nbsp;instructions are&nbsp;executed&nbsp;unconditionally.&nbsp;<br>
<i>(All&nbsp;</i>ARM&nbsp;instructions&nbsp;are&nbsp;executed&nbsp;conditionally.)&nbsp;<br>
•&nbsp;&nbsp;Many&nbsp;Thumb data&nbsp;processing&nbsp;instructions&nbsp;use&nbsp;a&nbsp;2-address&nbsp;format (the&nbsp;destination&nbsp;<br>
register&nbsp;is&nbsp;the same&nbsp;as&nbsp;one&nbsp;of the source&nbsp;registers).&nbsp;<br>
(ARM data processing instructions, with the exception of the 64-bit&nbsp;multiplies,&nbsp;<br>
use a 3-address&nbsp;format.)&nbsp;<br>
•&nbsp;&nbsp;Thumb instruction formats are less regular than ARM instruction formats, as a&nbsp;<br>
result of&nbsp;the dense encoding.&nbsp;<br>
Thumb&nbsp;<br>
All exceptions&nbsp;return the processor&nbsp;to ARM execution and are handled within&nbsp;the&nbsp;<br>
exceptions&nbsp;<br>
ARM programmer's&nbsp;model.&nbsp;Since the T&nbsp;bit resides in&nbsp;the CPSR, it&nbsp;is&nbsp;saved&nbsp;on&nbsp;<br>
exception entry in the appropriate SPSR,&nbsp;and the same return from exception&nbsp;<br>
instruction will&nbsp;restore the state of the processor and leave it executing ARM or&nbsp;<br>
Thumb instructions according to the&nbsp;state&nbsp;when the exception arose.&nbsp;<br>
Note&nbsp;that&nbsp;the&nbsp;ARM&nbsp;exception&nbsp;return instructions, described in&nbsp;'Exception return'&nbsp;<br>
on page 109, involve return&nbsp;address adjustments to compensate&nbsp;for the&nbsp;ARM pipe-<br>
line behaviour. Since Thumb&nbsp;instructions&nbsp;are two bytes rather than&nbsp;four bytes long,&nbsp;<br>
the natural offset&nbsp;should be&nbsp;different when&nbsp;an&nbsp;exception&nbsp;is&nbsp;entered&nbsp;from&nbsp;Thumb exe-<br>
cution,&nbsp;since the&nbsp;PC value copied into&nbsp;the exception-mode link&nbsp;register will have&nbsp;<br>
incremented&nbsp;by a&nbsp;multiple&nbsp;of&nbsp;two rather&nbsp;than&nbsp;four&nbsp;bytes.&nbsp;However,&nbsp;the&nbsp;Thumb archi-<br>
tecture&nbsp;requires&nbsp;that&nbsp;the&nbsp;link&nbsp;register&nbsp;value&nbsp;be automatically adjusted&nbsp;to&nbsp;match&nbsp;the&nbsp;<br>
ARM return&nbsp;offset, allowing&nbsp;the same&nbsp;return&nbsp;instruction to&nbsp;work&nbsp;in&nbsp;both cases,&nbsp;<br>
rather&nbsp;than&nbsp;have&nbsp;the return sequence made more&nbsp;complex.&nbsp;<br>
7.3 &nbsp; Thumb&nbsp;branch&nbsp;instructions&nbsp;<br>
These&nbsp;control flow&nbsp;instructions&nbsp;include&nbsp;the&nbsp;various&nbsp;forms&nbsp;of&nbsp;PC-relative&nbsp;branch&nbsp;and&nbsp;<br>
branch-and-link instruction&nbsp;seen&nbsp;in the ARM instruction&nbsp;set,&nbsp;and the&nbsp;<br>
branch-and-exchange instruction for switching&nbsp;between&nbsp;the ARM&nbsp;and&nbsp;Thumb&nbsp;<br>
instruction sets.&nbsp;<br>
<hr>
<A name=203></a><IMG src="index-203_1.png"><br>
<b>192</b>&nbsp;<br>
<b>The&nbsp;Thumb&nbsp;Instruction Set</b>&nbsp;<br>
The ARM instructions&nbsp;have&nbsp;a&nbsp;large (24-bit)&nbsp;offset field&nbsp;which&nbsp;clearly will not&nbsp;fit in&nbsp;<br>
a 16-bit&nbsp;instruction format. Therefore the Thumb instruction set&nbsp;includes various ways&nbsp;<br>
of subsetting the functionality.&nbsp;<br>
Binary&nbsp;<br>
encodings&nbsp;<br>
Description&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;7.2&nbsp; &nbsp;</b>Thumb&nbsp;branch&nbsp;instruction binary&nbsp;encodings.&nbsp;<br>
Typical uses&nbsp;of branch&nbsp;instructions include:&nbsp;<br>
1.&nbsp;&nbsp;short conditional branches to&nbsp;control&nbsp;(for example) loop exit;&nbsp;<br>
2.&nbsp;&nbsp;medium-range&nbsp;unconditional&nbsp;branches&nbsp;to&nbsp;'goto'&nbsp;sections of&nbsp;code;&nbsp;<br>
3.&nbsp;&nbsp;long-range&nbsp;subroutine&nbsp;calls.&nbsp;<br>
ARM&nbsp;handles&nbsp;all these&nbsp;with the same&nbsp;instruction,&nbsp;typically&nbsp;wasting many&nbsp;bits&nbsp;of&nbsp;<br>
the 24-bit&nbsp;offset&nbsp;in&nbsp;the first&nbsp;two cases. Thumb has to&nbsp;be&nbsp;more efficient,&nbsp;using different&nbsp;<br>
formats for each of these cases, numbered respectively&nbsp;in Figure&nbsp;7.2.&nbsp;<br>
The first two formats show&nbsp;how the condition&nbsp;field&nbsp;is traded&nbsp;off against the offset&nbsp;<br>
length. The condition&nbsp;field in the first&nbsp;format&nbsp;is the same&nbsp;as&nbsp;that in&nbsp;all ARM instruc-<br>
tions&nbsp;(see Section5.3&nbsp;on&nbsp;page&nbsp;111); in&nbsp;both&nbsp;cases the&nbsp;offset is shifted left one bit&nbsp;(to&nbsp;<br>
give half-word&nbsp;alignment)&nbsp;and sign-extended to 32 bits.&nbsp;<br>
The third&nbsp;format is more subtle. The&nbsp;branch&nbsp;and link&nbsp;subroutine mechanism&nbsp;often&nbsp;<br>
needs to&nbsp;have a long range, which is difficult within&nbsp;a 16-bit instruction format.&nbsp;There-<br>
fore Thumb uses two instructions, both&nbsp;with&nbsp;this&nbsp;format,&nbsp;to&nbsp;give a combined&nbsp;22-bit&nbsp;<br>
half-word&nbsp;offset&nbsp;(which is&nbsp;sign-extended to&nbsp;32 bits). The range of&nbsp;the instruction is&nbsp;<br>
therefore&nbsp;+/- 4&nbsp;Mbytes. In&nbsp;order to&nbsp;make the&nbsp;two instructions&nbsp;independent,&nbsp;so that,&nbsp;for&nbsp;<br>
example, an interrupt&nbsp;can&nbsp;be taken&nbsp;between&nbsp;them, the link&nbsp;register is&nbsp;used&nbsp;as temper-&nbsp;<br>
<hr>
<A name=204></a><b>Thumb&nbsp;branch&nbsp;instructions</b>&nbsp;<br>
<b>193</b>&nbsp;<br>
ary storage.&nbsp;It&nbsp;will&nbsp;be&nbsp;overwritten at&nbsp;the end&nbsp;of&nbsp;the&nbsp;instruction pair&nbsp;anyway,&nbsp;so it&nbsp;can't&nbsp;<br>
contain anything useful.&nbsp;The operation of the instruction&nbsp;pair&nbsp;is:&nbsp;<br>
1.&nbsp;&nbsp;(H=0)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LR :=&nbsp;PC +&nbsp;(sign-extended&nbsp;offset&nbsp;shifted left 12&nbsp;places);&nbsp;<br>
2.&nbsp;&nbsp;(H=l) &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; PC&nbsp;:=&nbsp;LR&nbsp;+&nbsp;(offset&nbsp;shifted&nbsp;left&nbsp;1&nbsp;place);&nbsp;<br>
LR := oldPC&nbsp;+ 3.&nbsp;<br>
Here&nbsp;'oldPC'&nbsp;is the&nbsp;address of the second&nbsp;instruction;&nbsp;the return address has&nbsp;two&nbsp;<br>
bytes added&nbsp;to&nbsp;point&nbsp;to&nbsp;the next&nbsp;instruction&nbsp;and the bottom&nbsp;bit&nbsp;set&nbsp;to&nbsp;indicate&nbsp;that&nbsp;the&nbsp;<br>
caller is a&nbsp;Thumb routine.&nbsp;<br>
Format&nbsp;3a&nbsp;is&nbsp;an&nbsp;alternative&nbsp;second&nbsp;step&nbsp;which gives the&nbsp;BLX&nbsp;variant;&nbsp;it&nbsp;is&nbsp;only&nbsp;<br>
available&nbsp;in architecture v5T.&nbsp;It uses&nbsp;the same&nbsp;first step as BL&nbsp;above:&nbsp;<br>
1.&nbsp;&nbsp;(BL,&nbsp;H=0)&nbsp;LR&nbsp;:= PC +&nbsp;(sign-extended offset&nbsp;shifted left 12&nbsp;places);&nbsp;<br>
2.&nbsp;&nbsp;(BLX) &nbsp;&nbsp; &nbsp; &nbsp;&nbsp;PC&nbsp;:=&nbsp;LR&nbsp;+&nbsp;(offset&nbsp;shifted&nbsp;left 1 place) &amp; Oxfffffffc;&nbsp;<br>
LR := oldPC&nbsp;+ 3;&nbsp;<br>
the Thumb&nbsp;bit&nbsp;is&nbsp;cleared.&nbsp;<br>
Note&nbsp;that&nbsp;as&nbsp;the target&nbsp;is&nbsp;an&nbsp;ARM&nbsp;instruction,&nbsp;the&nbsp;offset&nbsp;only&nbsp;requires&nbsp;10&nbsp;bits&nbsp;and&nbsp;<br>
the&nbsp;computed PC value may still have bit&nbsp;[1] set, so&nbsp;it&nbsp;is&nbsp;cleared implicitly.&nbsp;<br>
The fourth format&nbsp;maps directly&nbsp;onto the ARM B{L}X instructions (see&nbsp;<br>
Section&nbsp;5.5 on&nbsp;page 115, except that with&nbsp;BLX (available&nbsp;in architecture v5T only)&nbsp;<br>
r14&nbsp;is set to&nbsp;the address of&nbsp;the&nbsp;following&nbsp;instruction&nbsp;plus&nbsp;1,&nbsp;indicating&nbsp;that&nbsp;the&nbsp;caller&nbsp;<br>
was&nbsp;Thumb code).&nbsp;Here&nbsp;'H'&nbsp;can&nbsp;be&nbsp;set&nbsp;to&nbsp;select&nbsp;a&nbsp;'Hi'&nbsp;register (r8&nbsp;to&nbsp;r15).&nbsp;<br>
Assembler&nbsp;<br>
B&lt;cond&gt; &lt;label&gt;&nbsp;;&nbsp;&nbsp;format&nbsp;1&nbsp;&nbsp;-&nbsp;Thumb target&nbsp;<br>
format&nbsp;<br>
B&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&lt;label&gt;&nbsp;;&nbsp;&nbsp;format&nbsp;&nbsp;2&nbsp;&nbsp;-&nbsp;Thumb target&nbsp;<br>
BL &nbsp;&nbsp;&nbsp;&nbsp;&lt;label&gt;&nbsp;;&nbsp;&nbsp;format 3&nbsp;&nbsp;-&nbsp;Thumb target&nbsp;<br>
BLX &nbsp; &nbsp;&nbsp;&lt;label&gt;&nbsp;;&nbsp;<br>
format&nbsp;3a&nbsp;-&nbsp;ARM target&nbsp;<br>
B{L}X &nbsp;Rm&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;;&nbsp;<br>
format&nbsp;4&nbsp;&nbsp;-&nbsp;ARM or Thumb&nbsp;target&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
A branch and link generates both format&nbsp;3 instructions. It is not intended that&nbsp;<br>
format 3 instructions&nbsp;are&nbsp;used&nbsp;individually;&nbsp;they should&nbsp;always&nbsp;appear in pairs.&nbsp;Like-<br>
wise,&nbsp;BLX&nbsp;generates&nbsp;a format 3&nbsp;instruction and&nbsp;a format&nbsp;3a&nbsp;instruction.&nbsp;<br>
The&nbsp;assembler&nbsp;will&nbsp;compute the&nbsp;relevant offset&nbsp;to insert&nbsp;into&nbsp;the&nbsp;instruction&nbsp;from&nbsp;<br>
the current instruction&nbsp;address,&nbsp;the&nbsp;address of the target&nbsp;label, and a&nbsp;small correction&nbsp;<br>
for the&nbsp;pipeline&nbsp;behaviour. If the target&nbsp;is&nbsp;out&nbsp;of range an&nbsp;error&nbsp;message will&nbsp;be&nbsp;output.&nbsp;<br>
Equivalent&nbsp;ARM&nbsp;<br>
Although&nbsp;formats 1 to&nbsp;3 are&nbsp;very&nbsp;similar&nbsp;to the&nbsp;ARM&nbsp;branch&nbsp;and branch-with-link&nbsp;<br>
instruction&nbsp;<br>
instructions, the ARM instructions&nbsp;support&nbsp;only&nbsp;word (4-byte)&nbsp;offsets whereas&nbsp;the&nbsp;<br>
Thumb instructions require half-word (2-byte) offsets. Therefore there is&nbsp;no direct&nbsp;<br>
mapping&nbsp;from these Thumb&nbsp;instructions into the ARM instruction set. The ARM&nbsp;<br>
cores&nbsp;that support Thumb&nbsp;are&nbsp;slightly modified to&nbsp;support&nbsp;half-word&nbsp;branch offsets,&nbsp;<br>
with&nbsp;ARM&nbsp;branch&nbsp;instructions&nbsp;being&nbsp;mapped&nbsp;to&nbsp;even&nbsp;half-word offsets.&nbsp;<br>
<hr>
<A name=205></a><IMG src="index-205_1.png"><br>
194&nbsp;<br>
<b>The&nbsp;Thumb&nbsp;Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Format 4 is equivalent&nbsp;to the&nbsp;ARM instruction with&nbsp;the same&nbsp;assembler syntax.&nbsp;The&nbsp;<br>
BLX variant&nbsp;is&nbsp;supported&nbsp;only&nbsp;by&nbsp;ARM processors that&nbsp;implement architecture v5T.&nbsp;<br>
Subroutine call&nbsp;<br>
The above instructions, and the equivalent&nbsp;ARM instructions, allow for&nbsp;subroutine&nbsp;<br>
and return&nbsp;<br>
calls to&nbsp;functions&nbsp;written in&nbsp;an instruction&nbsp;set the&nbsp;same&nbsp;as, or opposite to, the caller.&nbsp;<br>
Functions&nbsp;that are called only&nbsp;from&nbsp;the&nbsp;same instruction set can use the conven-<br>
tional&nbsp;BL&nbsp;call&nbsp;and&nbsp;MOV&nbsp;pc, r14 or&nbsp;LDMFD&nbsp;sp!, {. .&nbsp;,pc) (in Thumb code,&nbsp;<br>
POP&nbsp;{. . ., pc}) return&nbsp;sequences.&nbsp;<br>
Functions that&nbsp;can be called from&nbsp;the&nbsp;opposite instruction set or&nbsp;from&nbsp;either&nbsp;<br>
instruction set&nbsp;can return&nbsp;with&nbsp;BX&nbsp;lr or&nbsp;LDMFD&nbsp;sp!, {. .&nbsp;.&nbsp;,rN};&nbsp;BX&nbsp;rN&nbsp;(in&nbsp;Thumb&nbsp;<br>
code, POP { . . . , rN} ; BX rN).&nbsp;<br>
ARM processors that support architecture v5T can also return with&nbsp;LDMFD&nbsp;sp!,&nbsp;<br>
{. . .,&nbsp;pc} (in&nbsp;Thumb code,&nbsp;POP&nbsp;{. .&nbsp;.,&nbsp;pc})&nbsp;as these instructions use&nbsp;the bottom&nbsp;bit&nbsp;<br>
of&nbsp;the loaded&nbsp;PC&nbsp;value to&nbsp;update&nbsp;the&nbsp;Thumb&nbsp;bit,&nbsp;but&nbsp;this is&nbsp;not&nbsp;supported&nbsp;in&nbsp;architec-<br>
tures earlier&nbsp;than&nbsp;v5T.&nbsp;<br>
7.4 &nbsp; Thumb&nbsp;software&nbsp;interrupt&nbsp;instruction&nbsp;<br>
The Thumb&nbsp;software interrupt instruction&nbsp;behaves exactly&nbsp;like the&nbsp;ARM&nbsp;equivalent&nbsp;<br>
and&nbsp;the exception&nbsp;entry sequence causes the&nbsp;processor&nbsp;to&nbsp;switch&nbsp;to ARM&nbsp;execution.&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;7.3&nbsp; &nbsp;</b>Thumb&nbsp;software&nbsp;interrupt binary&nbsp;encoding.&nbsp;<br>
Description&nbsp;<br>
This&nbsp;instruction causes the&nbsp;following&nbsp;actions:&nbsp;<br>
•&nbsp;&nbsp;The address of&nbsp;the next&nbsp;Thumb&nbsp;instruction&nbsp;is&nbsp;saved in&nbsp;r14_svc.&nbsp;<br>
•&nbsp;&nbsp;The CPSR&nbsp;is saved in SPSR_svc.&nbsp;<br>
•&nbsp;&nbsp;The processor&nbsp;disables&nbsp;IRQ,&nbsp;clears the Thumb&nbsp;bit&nbsp;and enters supervisor&nbsp;mode by&nbsp;<br>
modifying&nbsp;the&nbsp;relevant bits&nbsp;in&nbsp;the&nbsp;CPSR.&nbsp;<br>
•&nbsp;&nbsp;The PC is forced&nbsp;to&nbsp;address&nbsp;0x08.&nbsp;<br>
The&nbsp;ARM instruction&nbsp;SWI handler is then&nbsp;entered. The normal&nbsp;return instruction&nbsp;<br>
restores the&nbsp;Thumb execution&nbsp;state.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Assembler&nbsp;<br>
SWI&nbsp;<br>
&lt;8-bit &nbsp;&nbsp;<br>
format&nbsp;<br>
immediate&gt;&nbsp;<br>
<hr>
<A name=206></a><IMG src="index-206_1.png"><br>
<b>Thumb data processing&nbsp;instructions</b>&nbsp;<br>
195&nbsp;<br>
&nbsp;&nbsp;&nbsp;Equivalent&nbsp;ARM&nbsp;&nbsp;The equivalent ARM&nbsp;instruction has&nbsp;an identical assembler syntax; the 8-bit imme-<br>
instruction&nbsp;<br>
diate is&nbsp;zero-extended to&nbsp;fill the&nbsp;24-bit&nbsp;field&nbsp;in&nbsp;the&nbsp;ARM&nbsp;instruction.&nbsp;<br>
Clearly,&nbsp;this limits the SWIs&nbsp;available&nbsp;to Thumb code to&nbsp;the first 256 of&nbsp;the 16 mil-<br>
lion potential ARM SWIs.&nbsp;<br>
7.5 &nbsp; Thumb&nbsp;data&nbsp;processing&nbsp;instructions&nbsp;<br>
Thumb data processing instructions comprise a highly&nbsp;optimized set of&nbsp;fairly&nbsp;com-<br>
plex&nbsp;formats covering&nbsp;the operations&nbsp;most&nbsp;commonly&nbsp;required by&nbsp;a&nbsp;compiler.&nbsp;<br>
The functions of these&nbsp;instructions&nbsp;are&nbsp;clear&nbsp;enough.&nbsp;The selection&nbsp;of&nbsp;those&nbsp;to&nbsp;<br>
include and&nbsp;those to&nbsp;leave out&nbsp;is&nbsp;far&nbsp;less&nbsp;obvious, but is based&nbsp;on&nbsp;a detailed&nbsp;under-<br>
standing&nbsp;of&nbsp;the&nbsp;needs&nbsp;of&nbsp;typical application&nbsp;programs.&nbsp;<br>
&nbsp;<br>
Binary&nbsp;<br>
encodings&nbsp;<br>
<b>Figure 7.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Thumb&nbsp;data processing instruction binary&nbsp;encodings.&nbsp;<br>
<hr>
<A name=207></a><IMG src="index-207_1.png"><br>
196&nbsp;<br>
<b>The&nbsp;Thumb&nbsp;Instruction Set</b>&nbsp;<br>
Description&nbsp;<br>
These instructions all&nbsp;map onto ARM data processing&nbsp;(including&nbsp;multiply) instruc-&nbsp;<br>
tions.&nbsp;Although ARM&nbsp;supports a generalized&nbsp;shift on&nbsp;one operand together&nbsp;with an&nbsp;<br>
ALU&nbsp;operation&nbsp;in&nbsp;a&nbsp;single&nbsp;instruction,&nbsp;the&nbsp;Thumb instruction set&nbsp;separates&nbsp;shift&nbsp;<br>
and ALU operations into separate instructions, so here the shift operation is pre-<br>
sented&nbsp;as&nbsp;an opcode&nbsp;rather&nbsp;than&nbsp;as&nbsp;an operand&nbsp;modifier.&nbsp;<br>
<b>Assembler&nbsp;</b><br>
<b>The various instruction&nbsp;formats&nbsp;are:</b>&nbsp;<br>
<b>format</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Equivalent&nbsp;ARM&nbsp;&nbsp;The ARM data&nbsp;processing instructions that have equivalents in the Thumb instruc-<br>
instructions&nbsp;<br>
tion set are listed&nbsp;below, with&nbsp;their Thumb&nbsp;equivalents in the&nbsp;comment&nbsp;field.&nbsp;<br>
Instructions&nbsp;that&nbsp;use the 'Lo',&nbsp;general-purpose&nbsp;registers (r0 to&nbsp;r7):&nbsp;<br>
ARM instruction&nbsp;<br>
Thumb&nbsp;instruction&nbsp;<br>
MOVS&nbsp;Rd,&nbsp;<br>
#&lt;#imm8&gt;&nbsp;<br>
;&nbsp;MOV Rd,&nbsp;<br>
#&lt;#imm8&gt;&nbsp;<br>
MVNS&nbsp;Rd,&nbsp;<br>
Rm&nbsp;<br>
;&nbsp;MVN&nbsp;Rd,&nbsp;<br>
Rm&nbsp;<br>
CMP&nbsp;Rn,&nbsp;<br>
#&lt;#imm8&gt;&nbsp;<br>
;&nbsp;CMP&nbsp;Rn,&nbsp;<br>
#&lt;#imm8&gt;&nbsp;<br>
CMP&nbsp;<br>
Rn, Rm&nbsp;<br>
;&nbsp;CMP&nbsp;Rn,&nbsp;<br>
Rm&nbsp;<br>
CMN&nbsp;<br>
Rn, Rm&nbsp;<br>
;&nbsp;CMN&nbsp;Rn,&nbsp;<br>
Rm&nbsp;<br>
TST&nbsp;Rn,&nbsp;<br>
Rm&nbsp;<br>
;&nbsp;TST Rn,&nbsp;<br>
Rm&nbsp;<br>
ADDS&nbsp;<br>
Rd,&nbsp;&nbsp;Rn, #&lt;#imm3&gt;&nbsp;<br>
;&nbsp;ADD&nbsp;&nbsp;Rd,&nbsp;&nbsp;Rn, #&lt;#imm3&gt;&nbsp;<br>
ADDS&nbsp;Rd,&nbsp;<br>
Rd, #&lt;#imm8&gt;&nbsp;<br>
;&nbsp;ADD&nbsp;Rd,&nbsp;<br>
#&lt;#imm8&gt;&nbsp;<br>
ADDS&nbsp;<br>
Rd,&nbsp;&nbsp;Rn, Rm&nbsp;<br>
;&nbsp;ADD&nbsp;&nbsp;Rd,&nbsp;&nbsp;Rn, Rm&nbsp;<br>
ADCS&nbsp;Rd,&nbsp;<br>
Rd, Rm&nbsp;<br>
;&nbsp;ADC&nbsp;Rd,&nbsp;<br>
Rm&nbsp;<br>
SUBS&nbsp;<br>
Rd,&nbsp;&nbsp;Rn, #&lt;#imm3&gt;&nbsp;<br>
;&nbsp;SUB&nbsp;Rd,&nbsp;<br>
Rn, #&lt;#imm3&gt;&nbsp;<br>
SUBS&nbsp;<br>
Rd,&nbsp;&nbsp;Rd, #&lt;#imm8&gt;&nbsp;<br>
;&nbsp;SUB&nbsp;&nbsp;Rd,&nbsp;&nbsp;#&lt;#imm8&gt;&nbsp;<br>
SUBS&nbsp;<br>
Rd,&nbsp;&nbsp;Rn, Rm&nbsp;<br>
;&nbsp;SUB&nbsp;Rd,&nbsp;<br>
Rn, Rm&nbsp;<br>
SBCS&nbsp;Rd,&nbsp;<br>
Rd, Rm&nbsp;<br>
;&nbsp;SBC&nbsp;Rd,&nbsp;<br>
Rm&nbsp;<br>
RSBS&nbsp;<br>
Rd,&nbsp;&nbsp;Rn, #0&nbsp;<br>
;&nbsp;NEC&nbsp;Rd,&nbsp;<br>
Rn&nbsp;<br>
MOVS&nbsp;<br>
Rd,&nbsp;&nbsp;Rm, LSL #&lt;#sh&gt;&nbsp;&nbsp;;&nbsp;LSL&nbsp;&nbsp;Rd,&nbsp;&nbsp;Rm, #&lt;#sh&gt;&nbsp;<br>
<hr>
<A name=208></a><b>Thumb data processing&nbsp;instructions&nbsp;</b><br>
<b>197</b>&nbsp;<br>
;&nbsp; ARM&nbsp;&nbsp;instruction&nbsp;<br>
Thumb&nbsp;&nbsp;instruction&nbsp;<br>
MOVS&nbsp;&nbsp;&nbsp;&nbsp;Rd,&nbsp;Rd,&nbsp;LSL&nbsp;Rs&nbsp;<br>
;&nbsp;LSL&nbsp;Rd,&nbsp;Rs&nbsp;<br>
MOVS &nbsp;&nbsp; Rd,&nbsp;Rm,&nbsp;LSR&nbsp;#&lt;#sh&gt;&nbsp;<br>
;&nbsp;LSR&nbsp;&nbsp;Rd, Rm, #&lt;#sh&gt;&nbsp;<br>
MOVS&nbsp;&nbsp;&nbsp;&nbsp;Rd,&nbsp;Rd,&nbsp;LSR&nbsp;Rs&nbsp;<br>
;&nbsp;LSR&nbsp;Rd,&nbsp;Rs&nbsp;<br>
MOVS &nbsp;&nbsp; Rd,&nbsp;Rm,&nbsp;ASR&nbsp;#&lt;#sh&gt;&nbsp;<br>
;&nbsp;ASR&nbsp;&nbsp;Rd, Rm, #&lt;#sh&gt;&nbsp;<br>
MOVS&nbsp;&nbsp;&nbsp;&nbsp;Rd,&nbsp;Rd,&nbsp;ASR&nbsp;Rs&nbsp;<br>
;&nbsp;ASR&nbsp;Rd,&nbsp;Rs&nbsp;<br>
MOVS&nbsp;&nbsp;&nbsp;&nbsp;Rd,&nbsp;Rd,&nbsp;ROR&nbsp;Rs&nbsp;<br>
;&nbsp;ROR&nbsp;Rd,&nbsp;Rs&nbsp;<br>
ANDS &nbsp;&nbsp; Rd,&nbsp;Rd,&nbsp;Rm&nbsp;<br>
;&nbsp;AND&nbsp;Rd,&nbsp;Rm&nbsp;<br>
EORS &nbsp;&nbsp; Rd,&nbsp;Rd,&nbsp;Rm&nbsp;<br>
;&nbsp;EOR&nbsp;Rd,&nbsp;Rm&nbsp;<br>
ORRS &nbsp;&nbsp;Rd,&nbsp;Rd,&nbsp;Rm&nbsp;<br>
;&nbsp;ORR&nbsp;Rd,&nbsp;Rm&nbsp;<br>
BICS &nbsp;&nbsp;Rd,&nbsp;Rd,&nbsp;Rm&nbsp;<br>
;&nbsp;BIG&nbsp;&nbsp;Rd, Rm&nbsp;<br>
MULS &nbsp;&nbsp;Rd,&nbsp;Rm,&nbsp;Rd&nbsp;<br>
;&nbsp;MUL&nbsp;&nbsp;Rd, Rm&nbsp;<br>
<b>Instructions that operate with&nbsp;or on the&nbsp;'Hi'&nbsp;registers (r8 to r15), in some&nbsp;cases in&nbsp;</b><br>
<b>combination with a 'Lo' register:</b>&nbsp;<br>
; &nbsp;ARM&nbsp;instruction&nbsp;<br>
Thumb&nbsp;instruction&nbsp;<br>
ADD&nbsp;&nbsp; &nbsp;Rd,&nbsp;Rd,&nbsp;Rm&nbsp;<br>
;&nbsp;ADD&nbsp;&nbsp;Rd, Rm (1/2 Hi&nbsp;regs)&nbsp;<br>
CMP &nbsp; &nbsp;Rn,&nbsp;Rm&nbsp;<br>
;&nbsp;CMP&nbsp;&nbsp;Rn,&nbsp;Rm&nbsp;(1/2&nbsp;Hi regs)&nbsp;<br>
MOV &nbsp; &nbsp;Rd,&nbsp;Rm&nbsp;<br>
;&nbsp;MOV&nbsp;&nbsp;Rd,&nbsp;Rm&nbsp;(1/2&nbsp;Hi regs)&nbsp;<br>
ADD&nbsp;&nbsp; &nbsp;&nbsp;Rd,&nbsp;PC,&nbsp;#&lt;#imm8&gt;&nbsp;<br>
;&nbsp;ADD&nbsp;Rd,&nbsp;PC,&nbsp;#&lt;#imm8&gt;&nbsp;<br>
ADD &nbsp;&nbsp; Rd,&nbsp;SP,&nbsp;#&lt;#imm8&gt;&nbsp;<br>
;&nbsp;ADD&nbsp;Rd,&nbsp;SP,&nbsp;#&lt;#imm8&gt;&nbsp;<br>
ADD &nbsp;&nbsp; SP,&nbsp;SP,&nbsp;#&lt;#imm7&gt;&nbsp;<br>
;&nbsp;ADD&nbsp;SP,&nbsp;SP,&nbsp;#&lt;#imm7&gt;&nbsp;<br>
SUB&nbsp;&nbsp; &nbsp;&nbsp;SP,&nbsp;SP,&nbsp;#&lt;#imm7&gt;&nbsp;<br>
;&nbsp;SUB&nbsp;SP,&nbsp;SP,&nbsp;#&lt;#imm7&gt;&nbsp;<br>
&nbsp;<br>
Notes&nbsp;<br>
1.&nbsp;&nbsp;<i>All&nbsp;</i>the data&nbsp;processing instructions that&nbsp;operate with and on the 'Lo'&nbsp;registers&nbsp;<br>
update&nbsp;the condition code bits (the S bit&nbsp;is&nbsp;set&nbsp;in&nbsp;the equivalent&nbsp;ARM&nbsp;instruc&nbsp;<br>
tion).&nbsp;<br>
2.&nbsp;&nbsp;The instructions that operate with&nbsp;and&nbsp;on&nbsp;the 'Hi'&nbsp;registers&nbsp;do&nbsp;<i>not&nbsp;</i>change&nbsp;the&nbsp;<br>
condition&nbsp;code bits, with&nbsp;the exception of CMP which only changes&nbsp;the condi&nbsp;<br>
tion codes.&nbsp;<br>
3.&nbsp;&nbsp;The instructions that&nbsp;are indicated above as&nbsp;requiring&nbsp;'1&nbsp;or&nbsp;2&nbsp;Hi&nbsp;regs' must&nbsp;have&nbsp;<br>
one&nbsp;or&nbsp;both&nbsp;register&nbsp;operands specified&nbsp;in&nbsp;the 'Hi' register&nbsp;area.&nbsp;<br>
4.&nbsp;&nbsp;#imm3, #imm7 and&nbsp;#imm8 denote&nbsp;3-,&nbsp;7-&nbsp;and&nbsp;8-bit&nbsp;immediate fields&nbsp;respectively.&nbsp;<br>
#sh denotes a&nbsp;5-bit&nbsp;shift&nbsp;amount&nbsp;field.&nbsp;<br>
<hr>
<A name=209></a><IMG src="index-209_1.png"><br>
<b>198</b>&nbsp;<br>
<b>The&nbsp;Thumb&nbsp;Instruction Set</b>&nbsp;<br>
7.6 &nbsp; Thumb&nbsp;single&nbsp;register&nbsp;data&nbsp;transfer&nbsp;instructions&nbsp;<br>
Again the choice&nbsp;of&nbsp;ARM&nbsp;instructions&nbsp;which are&nbsp;represented&nbsp;in&nbsp;the Thumb&nbsp;<br>
instruction&nbsp;set&nbsp;appears complex,&nbsp;but&nbsp;is&nbsp;based&nbsp;on&nbsp;the&nbsp;sort&nbsp;of&nbsp;things&nbsp;that&nbsp;compilers&nbsp;<br>
like to do&nbsp;frequently.&nbsp;<br>
Note&nbsp;the larger&nbsp;offsets for&nbsp;accesses to the&nbsp;literal pool (PC-relative) and&nbsp;to&nbsp;the stack&nbsp;<br>
(SP-relative),&nbsp;and&nbsp;the&nbsp;restricted support given to signed operands (base&nbsp;plus&nbsp;register&nbsp;<br>
addressing&nbsp;only)&nbsp;compared&nbsp;with&nbsp;unsigned&nbsp;operands&nbsp;(base&nbsp;plus&nbsp;offset&nbsp;or register).&nbsp;<br>
Binary&nbsp;<br>
encodings&nbsp;<br>
&nbsp;<br>
<b>Figure 7.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Thumb single&nbsp;register&nbsp;data&nbsp;transfer&nbsp;binary encodings.&nbsp;<br>
Description&nbsp;<br>
These instructions are a carefully derived&nbsp;subset of&nbsp;the&nbsp;ARM single&nbsp;register transfer&nbsp;<br>
instructions,&nbsp;and&nbsp;have&nbsp;exactly the&nbsp;same&nbsp;semantics&nbsp;as the&nbsp;ARM&nbsp;equivalent.&nbsp;<br>
In all cases the offset is&nbsp;scaled to the size&nbsp;of the data type, so, for instance, the&nbsp;<br>
range of the 5-bit offset is 32&nbsp;bytes in&nbsp;a load or store byte instruction, 64&nbsp;bytes in&nbsp;a&nbsp;<br>
load&nbsp;or&nbsp;store&nbsp;half-word&nbsp;instruction&nbsp;and&nbsp;128&nbsp;bytes&nbsp;in&nbsp;a&nbsp;load&nbsp;or&nbsp;store word&nbsp;instruction.&nbsp;<br>
Assembler&nbsp;<br>
The&nbsp;various&nbsp;assembler&nbsp;formats&nbsp;are:&nbsp;<br>
format&nbsp;<br>
1&nbsp;:<br>
&lt;op&gt;&nbsp;<br>
Rd,&nbsp;&nbsp;[Rn, #&lt;#off5&gt;]&nbsp;;&nbsp;&lt;Op&gt;&nbsp;= LDRILDRB|STRISTRB&nbsp;<br>
2&nbsp;:<br>
Rd, [Rn,&nbsp;<br>
&lt;op&gt;&nbsp;<br>
#&lt;#off5&gt;] ;&nbsp;&lt;op&gt; = LDRHISTRH&nbsp;<br>
3:<br>
&lt;op&gt;&nbsp;Rd,&nbsp;[Rn,&nbsp;Rm] &nbsp; &nbsp; &nbsp;;&nbsp;&lt;op&gt;&nbsp;=&nbsp;..&nbsp;<br>
; .. LDRILDRHILDRSHILDRBILDRSBISTRISTRHISTRB&nbsp;<br>
<i>A&nbsp;:&nbsp;</i><br>
LDR&nbsp;&nbsp;Rd, [PC,&nbsp;#&lt;#off8&gt;]&nbsp;<br>
5:<br>
&lt;op&gt;&nbsp;Rd, [SP,&nbsp;#&lt;#off8&gt;] ;&nbsp;&lt;op&gt; = LDRISTR&nbsp;<br>
<hr>
<A name=210></a><IMG src="index-210_1.png"><br>
<b>Thumb&nbsp;multiple&nbsp;register&nbsp;data&nbsp;transfer instructions</b>&nbsp;<br>
199&nbsp;<br>
&nbsp;&nbsp;&nbsp;Equivalent ARM&nbsp;&nbsp;The&nbsp;ARM&nbsp;equivalents&nbsp;to&nbsp;these&nbsp;Thumb instructions&nbsp;have&nbsp;identical assembler&nbsp;formats.&nbsp;<br>
instruction&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
Notes&nbsp;<br>
1.&nbsp;&nbsp;#of&nbsp;f 5 and&nbsp;toff 8 denote 5-&nbsp;and 8-bit immediate offsets&nbsp;respectively.&nbsp;The&nbsp;assem&nbsp;<br>
bler format&nbsp;specifies the offset in bytes in&nbsp;all cases. The 5-&nbsp;or 8-bit offset&nbsp;in the&nbsp;<br>
instruction binary is&nbsp;scaled by&nbsp;the size of&nbsp;the data type.&nbsp;<br>
2.&nbsp;&nbsp;As with the&nbsp;ARM&nbsp;instructions,&nbsp;the&nbsp;signed&nbsp;variants are only&nbsp;supported by&nbsp;the load&nbsp;<br>
instructions&nbsp;since store signed and&nbsp;store unsigned&nbsp;have&nbsp;exactly&nbsp;the&nbsp;same&nbsp;effect.&nbsp;<br>
7.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Thumb multiple&nbsp;register data transfer instructions&nbsp;<br>
As in&nbsp;the&nbsp;ARM&nbsp;instruction set,&nbsp;the Thumb&nbsp;multiple&nbsp;register&nbsp;transfer instructions are&nbsp;<br>
useful&nbsp;both&nbsp;for&nbsp;procedure&nbsp;entry&nbsp;and&nbsp;return&nbsp;and&nbsp;for&nbsp;memory&nbsp;block copy.&nbsp;Here,&nbsp;how-<br>
ever, the tighter&nbsp;encoding&nbsp;means that&nbsp;the two uses&nbsp;must be&nbsp;separated&nbsp;and the number&nbsp;<br>
of addressing&nbsp;modes restricted. Otherwise&nbsp;these instructions very&nbsp;much&nbsp;follow the&nbsp;<br>
spirit of&nbsp;their ARM equivalents.&nbsp;<br>
Binary&nbsp;<br>
encodings&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;7.6&nbsp; &nbsp;</b>Thumb&nbsp;multiple&nbsp;register data&nbsp;transfer binary&nbsp;encodings.&nbsp;<br>
Description&nbsp;<br>
The block copy&nbsp;forms of the instruction use the LDMIA and STMIA&nbsp;addressing&nbsp;<br>
modes&nbsp;(see&nbsp;Figure 3.2 on&nbsp;page 62).&nbsp;The base&nbsp;register may&nbsp;be any&nbsp;of&nbsp;the 'Lo'&nbsp;regis-<br>
ters (r0 to r7), and the register list&nbsp;may&nbsp;include any subset of these registers but&nbsp;<br>
should not include the base&nbsp;register itself&nbsp;since write-back&nbsp;is always&nbsp;selected (and&nbsp;<br>
the result of&nbsp;a&nbsp;load or&nbsp;store&nbsp;multiple&nbsp;register&nbsp;with the base register in the list and&nbsp;<br>
write-back&nbsp;selected is&nbsp;unpredictable).&nbsp;<br>
The&nbsp;stack forms use SP&nbsp;(r13)&nbsp;as&nbsp;the&nbsp;base&nbsp;register&nbsp;and again&nbsp;always&nbsp;use write-back.&nbsp;<br>
The stack&nbsp;model&nbsp;is fixed&nbsp;as full-descending.&nbsp;In addition&nbsp;to the&nbsp;eight registers which&nbsp;<br>
may be&nbsp;specified&nbsp;in&nbsp;the register&nbsp;list,&nbsp;the&nbsp;link&nbsp;register&nbsp;(LR,&nbsp;or r14)&nbsp;may be included&nbsp;in&nbsp;<br>
the 'PUSH'&nbsp;instruction and&nbsp;the&nbsp;PC&nbsp;(r15) may be&nbsp;included in&nbsp;the 'POP' form,&nbsp;optimiz-<br>
ing&nbsp;procedure entry&nbsp;and&nbsp;exit&nbsp;sequences as&nbsp;is&nbsp;often&nbsp;done&nbsp;in&nbsp;ARM&nbsp;code.&nbsp;<br>
<hr>
<A name=211></a><b>200</b>&nbsp;<br>
<b>The&nbsp;Thumb&nbsp;Instruction Set</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Assembler&nbsp;<br>
&lt;reg list&gt;&nbsp;is a&nbsp;list&nbsp;of registers&nbsp;and register&nbsp;ranges from&nbsp;r0&nbsp;to r7.&nbsp;<br>
format&nbsp;<br>
LDMIA&nbsp;Rn!,&nbsp;<br>
{&lt;reg&nbsp;<br>
list&gt;)&nbsp;<br>
STMIA&nbsp;Rn!,&nbsp;<br>
{&lt;reg&nbsp;<br>
list&gt;}&nbsp;<br>
POP&nbsp;<br>
{&lt;reg list&gt;{, pc}}&nbsp;<br>
PUSH&nbsp;<br>
{&lt;reg list&gt;{, lr}}&nbsp;<br>
&nbsp;&nbsp;&nbsp;Equivalent&nbsp;ARM&nbsp;&nbsp;The equivalent&nbsp;ARM instructions have the&nbsp;same&nbsp;assembler format in the first two&nbsp;<br>
instruction&nbsp;<br>
cases, and replace&nbsp;POP&nbsp;and&nbsp;PUSH&nbsp;with the appropriate addressing&nbsp;mode in the&nbsp;<br>
second&nbsp;two&nbsp;cases.&nbsp;Block&nbsp;copy:&nbsp;<br>
LDMIA&nbsp;Rn!,&nbsp;{&lt;reg list&gt;}&nbsp;<br>
STMIA&nbsp;Rn!,&nbsp;{&lt;reg list&gt;}&nbsp;<br>
<b>Pop:</b>&nbsp;<br>
LDMFD&nbsp;SP!,&nbsp;{&lt;reg&nbsp;<br>
list&gt;{,&nbsp;<br>
pc}}&nbsp;<br>
Push:&nbsp;<br>
STMFD SP!,&nbsp;{&lt;reg&nbsp;<br>
list&gt;{,&nbsp;<br>
lr}}&nbsp;<br>
Notes<br>
&nbsp;<br>
&nbsp;<br>
1.&nbsp;&nbsp;The base register should&nbsp;be&nbsp;word-aligned.&nbsp;If it is not, some&nbsp;systems&nbsp;will ignore&nbsp;<br>
the bottom&nbsp;two address bits&nbsp;but others&nbsp;may generate an&nbsp;alignment&nbsp;exception.&nbsp;<br>
2.&nbsp;&nbsp;Since all these&nbsp;instructions use base write-back, the base&nbsp;register should&nbsp;not be&nbsp;<br>
included in the register&nbsp;list.&nbsp;<br>
3.&nbsp;&nbsp;The&nbsp;register list is&nbsp;encoded&nbsp;with one bit&nbsp;for each register; bit 0 indicates whether&nbsp;<br>
r0&nbsp;will&nbsp;be transferred, bit 1 controls&nbsp;r1, etc. The R bit controls the&nbsp;PC&nbsp;and&nbsp;LR&nbsp;<br>
options&nbsp;in the&nbsp;POP&nbsp;and&nbsp;PUSH&nbsp;instructions.&nbsp;<br>
4.&nbsp;&nbsp;In architecture&nbsp;v5T only, the&nbsp;bottom&nbsp;bit of a loaded&nbsp;PC updates the Thumb bit,&nbsp;<br>
enabling a&nbsp;direct&nbsp;return to a Thumb&nbsp;or&nbsp;ARM caller.&nbsp;<br>
7.8 &nbsp; Thumb&nbsp;breakpoint&nbsp;instruction&nbsp;<br>
The Thumb breakpoint&nbsp;instruction behaves exactly&nbsp;like the ARM equivalent.&nbsp;<br>
Breakpoint&nbsp;instructions are used for software debugging&nbsp;purposes; they&nbsp;cause the&nbsp;<br>
processor to&nbsp;break from&nbsp;normal instruction&nbsp;execution and&nbsp;enter appropriate&nbsp;<br>
debugging&nbsp;procedures.&nbsp;<br>
<hr>
<A name=212></a><IMG src="index-212_1.png"><br>
<b>Thumb implementation</b>&nbsp;<br>
<b>201</b>&nbsp;<br>
Binary encoding&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;7.7&nbsp; &nbsp;</b>Thumb&nbsp;breakpoint binary&nbsp;encoding.&nbsp;<br>
Description&nbsp;<br>
This&nbsp;instruction causes the processor to take a prefetch abort&nbsp;when&nbsp;the debug hard-<br>
ware unit&nbsp;is&nbsp;configured&nbsp;appropriately.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Assembler&nbsp;<br>
BKPT&nbsp;<br>
format&nbsp;<br>
Equivalent&nbsp;ARM &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;equivalent&nbsp;ARM&nbsp;instruction has an&nbsp;identical assembler&nbsp;syntax. The&nbsp;BRK&nbsp;<br>
instruc-&nbsp;<br>
instruction&nbsp;<br>
tion is&nbsp;supported only&nbsp;by&nbsp;ARM processors&nbsp;that&nbsp;implement ARM architecture v5T.&nbsp;<br>
7.9 &nbsp; Thumb&nbsp;implementation&nbsp;<br>
The&nbsp;Thumb instruction&nbsp;set&nbsp;can&nbsp;be&nbsp;incorporated&nbsp;into&nbsp;a&nbsp;3-stage&nbsp;pipeline&nbsp;ARM&nbsp;proces-<br>
sor macrocell&nbsp;with&nbsp;relatively&nbsp;minor&nbsp;changes to most of&nbsp;the processor&nbsp;logic (the&nbsp;<br>
5-stage pipeline implementations are trickier). The biggest addition is the&nbsp;<br>
Thumb&nbsp;instruction decompressor in&nbsp;the&nbsp;instruction&nbsp;pipeline; this&nbsp;logic&nbsp;translates&nbsp;a&nbsp;<br>
Thumb instruction into its equivalent ARM instruction.&nbsp;The organization of this&nbsp;<br>
logic is&nbsp;shown&nbsp;in&nbsp;Figure 7.8&nbsp;on&nbsp;page&nbsp;202.&nbsp;<br>
The addition&nbsp;of the&nbsp;decompressor logic in&nbsp;series with the instruction&nbsp;decoder&nbsp;might&nbsp;<br>
be expected&nbsp;to&nbsp;increase&nbsp;the decode latency, but in&nbsp;fact&nbsp;the ARM?&nbsp;pipeline&nbsp;does&nbsp;rela-<br>
tively little&nbsp;work&nbsp;in&nbsp;phase 1 of&nbsp;the decode cycle.&nbsp;Therefore the&nbsp;decompression logic&nbsp;<br>
can&nbsp;be&nbsp;accommodated here&nbsp;without&nbsp;compromising the&nbsp;cycle&nbsp;time&nbsp;or&nbsp;increasing&nbsp;the&nbsp;<br>
pipeline&nbsp;latency,&nbsp;and the&nbsp;ARM7TDMI Thumb pipeline&nbsp;operates in&nbsp;exactly&nbsp;the way&nbsp;<br>
described&nbsp;in&nbsp;'The&nbsp;3-stage pipeline'&nbsp;on page&nbsp;75.&nbsp;<br>
Instruction&nbsp;<br>
The Thumb decompressor performs&nbsp;a&nbsp;static translation&nbsp;from&nbsp;the 16-bit Thumb&nbsp;<br>
mapping&nbsp;<br>
instruction&nbsp;into&nbsp;the equivalent 32-bit&nbsp;ARM&nbsp;instruction. This&nbsp;involves performing&nbsp;a&nbsp;<br>
look-up to&nbsp;translate the&nbsp;major and&nbsp;minor opcodes, zero-extending the 3-bit register&nbsp;<br>
specifiers&nbsp;to&nbsp;give&nbsp;4-bit&nbsp;specifiers&nbsp;and mapping&nbsp;other&nbsp;fields&nbsp;across&nbsp;as&nbsp;required.&nbsp;<br>
As&nbsp;an&nbsp;example,&nbsp;the mapping&nbsp;of a&nbsp;Thumb 'ADD&nbsp;Rd,&nbsp;#imm8'&nbsp;instruction (see&nbsp;<br>
Section 7.5&nbsp;on&nbsp;page&nbsp;195)&nbsp;to the corresponding&nbsp;ARM&nbsp;'ADDS&nbsp;&nbsp;Rd,Rd,&nbsp;#imm8'&nbsp;<br>
instruction&nbsp;(described&nbsp;in&nbsp;Section 5.7&nbsp;on page 119) is&nbsp;shown in&nbsp;Figure 7.9 on&nbsp;<br>
page 202. Note that:&nbsp;<br>
<hr>
<A name=213></a><IMG src="index-213_1.png"><br>
<IMG src="index-213_2.png"><br>
<b>202</b>&nbsp;<br>
<b>The&nbsp;Thumb&nbsp;Instruction Set</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 7.8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The&nbsp;Thumb instruction decompressor organization.&nbsp;<br>
&nbsp;<br>
<b>Figure 7.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Thumb&nbsp;to&nbsp;ARM instruction&nbsp;mapping.&nbsp;<br>
<hr>
<A name=214></a><b>Thumb applications</b>&nbsp;<br>
<b>203</b>&nbsp;<br>
•&nbsp;&nbsp;Since the only conditional Thumb instructions are branches, the condition&nbsp;<br>
'always'&nbsp;is&nbsp;used&nbsp;in translating&nbsp;all other&nbsp;Thumb&nbsp;instructions.&nbsp;<br>
i&nbsp;<br>
•&nbsp;&nbsp;Whether&nbsp;or&nbsp;not&nbsp;a&nbsp;Thumb&nbsp;data processing&nbsp;instruction&nbsp;should&nbsp;modify the condition&nbsp;<br>
codes in&nbsp;the CPSR&nbsp;is&nbsp;implicit in the&nbsp;Thumb&nbsp;opcode;&nbsp;this&nbsp;must&nbsp;be&nbsp;made&nbsp;explicit&nbsp;in&nbsp;<br>
the ARM instruction.&nbsp;<br>
•&nbsp;&nbsp;The Thumb 2-address format can always&nbsp;be&nbsp;mapped&nbsp;into&nbsp;the&nbsp;ARM 3-address format&nbsp;<br>
by&nbsp;replicating a&nbsp;register&nbsp;specifier. (Going the other way&nbsp;is not, in general, possible.)&nbsp;<br>
The&nbsp;simplicity&nbsp;of the&nbsp;decompression&nbsp;logic&nbsp;is&nbsp;crucial&nbsp;to the&nbsp;efficiency of&nbsp;the&nbsp;Thumb&nbsp;<br>
instruction set.&nbsp;There would&nbsp;be&nbsp;little merit in&nbsp;the&nbsp;Thumb architecture&nbsp;if&nbsp;it&nbsp;resulted&nbsp;in&nbsp;<br>
complex, slow&nbsp;and&nbsp;power-hungry&nbsp;decompression&nbsp;logic.&nbsp;<br>
7.10 &nbsp; Thumb&nbsp;applications&nbsp;<br>
To&nbsp;see&nbsp;where Thumb offers&nbsp;a benefit&nbsp;we&nbsp;need&nbsp;to&nbsp;review its properties.&nbsp;Thumb&nbsp;<br>
instructions&nbsp;are 16 bits long&nbsp;and encode&nbsp;the functionality of an&nbsp;ARM&nbsp;instruction&nbsp;in&nbsp;<br>
half the number of&nbsp;bits, but&nbsp;since a Thumb instruction typically&nbsp;has less&nbsp;semantic&nbsp;<br>
content than an&nbsp;ARM instruction,&nbsp;a&nbsp;particular program&nbsp;will&nbsp;require more&nbsp;Thumb&nbsp;<br>
instructions&nbsp;than&nbsp;it&nbsp;would&nbsp;have&nbsp;needed&nbsp;ARM&nbsp;instructions. The&nbsp;ratio&nbsp;will&nbsp;vary&nbsp;from&nbsp;<br>
program&nbsp;to program, but in&nbsp;a typical example Thumb code&nbsp;may require 70% of&nbsp;the&nbsp;<br>
space of ARM code. Therefore&nbsp;if we&nbsp;compare the&nbsp;Thumb&nbsp;solution&nbsp;with the pure&nbsp;<br>
ARM code&nbsp;solution, the&nbsp;following&nbsp;characteristics&nbsp;emerge:&nbsp;<br>
&nbsp;<br>
Thumb&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;Thumb&nbsp;code&nbsp;requires&nbsp;70% of&nbsp;the space&nbsp;of the&nbsp;ARM code.&nbsp;<br>
properties&nbsp;<br>
•&nbsp;&nbsp;The Thumb&nbsp;code&nbsp;uses&nbsp;40%&nbsp;more&nbsp;instructions&nbsp;than&nbsp;the&nbsp;ARM&nbsp;code.&nbsp;<br>
•&nbsp;&nbsp;With&nbsp;32-bit&nbsp;memory,&nbsp;the&nbsp;ARM&nbsp;code&nbsp;is&nbsp;40%&nbsp;faster&nbsp;than&nbsp;the Thumb&nbsp;code.&nbsp;<br>
•&nbsp;&nbsp;With&nbsp;16-bit memory, the Thumb&nbsp;code&nbsp;is&nbsp;45%&nbsp;faster&nbsp;than the ARM&nbsp;code.&nbsp;<br>
•&nbsp;&nbsp;Thumb&nbsp;code&nbsp;uses&nbsp;30%&nbsp;less&nbsp;external&nbsp;memory&nbsp;power than ARM&nbsp;code.&nbsp;<br>
So&nbsp;where performance is all-important,&nbsp;a system&nbsp;should&nbsp;use 32-bit&nbsp;memory&nbsp;and&nbsp;<br>
run ARM&nbsp;code. Where cost&nbsp;and&nbsp;power consumption&nbsp;are&nbsp;more&nbsp;important,&nbsp;a&nbsp;16-bit&nbsp;<br>
memory system&nbsp;and Thumb code&nbsp;may be&nbsp;a&nbsp;better&nbsp;choice. However,&nbsp;there&nbsp;are&nbsp;inter-<br>
mediate&nbsp;positions which may&nbsp;give&nbsp;the&nbsp;best&nbsp;of&nbsp;both worlds:&nbsp;<br>
&nbsp;&nbsp;&nbsp;Thumb systems&nbsp;&nbsp;• A&nbsp;high-end&nbsp;32-bit&nbsp;ARM&nbsp;system&nbsp;may&nbsp;use&nbsp;Thumb code&nbsp;for&nbsp;certain&nbsp;non-critical&nbsp;rou-<br>
tines to save&nbsp;power&nbsp;or&nbsp;memory requirements.&nbsp;<br>
<hr>
<A name=215></a><IMG src="index-215_1.png"><br>
<b>204</b>&nbsp;<br>
<b>The&nbsp;Thumb&nbsp;Instruction Set</b>&nbsp;<br>
• A low-end&nbsp;16-bit&nbsp;system&nbsp;may have a&nbsp;small&nbsp;amount of&nbsp;on-chip&nbsp;32-bit RAM&nbsp;for&nbsp;<br>
critical routines running ARM code, but use off-chip&nbsp;Thumb code for all&nbsp;<br>
non-critical&nbsp;routines.&nbsp;<br>
The&nbsp;second&nbsp;of&nbsp;these&nbsp;examples&nbsp;is&nbsp;perhaps closer to&nbsp;the&nbsp;sort&nbsp;of application for&nbsp;which&nbsp;<br>
Thumb was developed.&nbsp;Mobile&nbsp;telephone&nbsp;and&nbsp;pager&nbsp;applications&nbsp;incorporate real-time&nbsp;<br>
digital signal&nbsp;processing&nbsp;(DSP) functions&nbsp;that&nbsp;may&nbsp;require&nbsp;the full&nbsp;power&nbsp;of&nbsp;the ARM,&nbsp;<br>
but&nbsp;these&nbsp;are&nbsp;tightly&nbsp;coded&nbsp;routines&nbsp;that&nbsp;can&nbsp;fit&nbsp;in&nbsp;a&nbsp;small&nbsp;amount&nbsp;of&nbsp;on-chip&nbsp;memory.&nbsp;<br>
The more complex and much larger code that&nbsp;controls the&nbsp;user interface,&nbsp;battery&nbsp;man-<br>
agement&nbsp;system, and so&nbsp;on, is less time-critical, and the use of Thumb code will&nbsp;<br>
enable&nbsp;off-chip ROMs to&nbsp;give good&nbsp;performance on&nbsp;an&nbsp;8-&nbsp;or 16-bit bus, saving&nbsp;cost&nbsp;<br>
and&nbsp;improving&nbsp;battery&nbsp;life.&nbsp;<br>
7.11 &nbsp; Example&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example&nbsp;7.1&nbsp;</b><br>
<b>Rewrite the&nbsp;'Hello&nbsp;World'&nbsp;program&nbsp;in&nbsp;Section&nbsp;3.4&nbsp;on&nbsp;page&nbsp;69&nbsp;to&nbsp;use</b>&nbsp;<br>
<b>Thumb&nbsp;instructions. How&nbsp;do the ARM and&nbsp;Thumb code&nbsp;sizes&nbsp;compare?</b>&nbsp;<br>
Here is&nbsp;the&nbsp;original&nbsp;ARM&nbsp;program:&nbsp;<br>
&nbsp;<br>
Most&nbsp;of&nbsp;these&nbsp;instructions&nbsp;have&nbsp;direct Thumb equivalents;&nbsp;however,&nbsp;some&nbsp;do&nbsp;<br>
not. The&nbsp;load&nbsp;byte instruction does&nbsp;not support auto-indexing&nbsp;and&nbsp;the&nbsp;supervisor&nbsp;<br>
call cannot be conditionally&nbsp;executed. Hence the Thumb&nbsp;code needs to be slightly&nbsp;<br>
modified:&nbsp;<br>
AREA&nbsp;<br>
HelloW_Thumb,CODE,READONLY&nbsp;<br>
SWI_WriteC&nbsp;<br>
EQU &nbsp; &nbsp;&amp;0 &nbsp; &nbsp; &nbsp; &nbsp;;&nbsp;output&nbsp;character&nbsp;in&nbsp;r0&nbsp;<br>
SWI_Exit&nbsp;<br>
EQU &nbsp; &nbsp;&amp;11 &nbsp; &nbsp; &nbsp; ;&nbsp;finish&nbsp;program&nbsp;<br>
ENTRY&nbsp;<br>
; code entry point&nbsp;;&nbsp;<br>
CODES2&nbsp;<br>
enter&nbsp;in&nbsp;ARM state&nbsp;<br>
<hr>
<A name=216></a><b>Example and&nbsp;exercises</b>&nbsp;<br>
205&nbsp;<br>
ADR r0,&nbsp;<br>
START+1&nbsp;<br>
;&nbsp;get Thumb&nbsp;entry address&nbsp;<br>
BX r0&nbsp;<br>
;&nbsp;enter Thumb area&nbsp;<br>
CODE16&nbsp;<br>
;&nbsp;Thumb code&nbsp;follows..&nbsp;<br>
START &nbsp;ADR&nbsp;<br>
r1, TEXT&nbsp;<br>
;&nbsp;r1 -&gt; &quot;Hello World&quot;&nbsp;<br>
LOOP &nbsp; LDRB&nbsp;<br>
r0, [r1]&nbsp;<br>
;&nbsp;get the next byte&nbsp;<br>
ADD&nbsp;<br>
r1,&nbsp;r1,&nbsp;#1&nbsp;<br>
;&nbsp;increment pointer&nbsp;&nbsp;**T&nbsp;<br>
CMP&nbsp;r0,&nbsp;<br>
#0&nbsp;<br>
;&nbsp;check for text end&nbsp;<br>
BEQ&nbsp;DONE&nbsp;<br>
;&nbsp;finished?&nbsp;**T&nbsp;<br>
SWI&nbsp;SWI_WriteC&nbsp;<br>
;&nbsp;if not end&nbsp;print . .&nbsp;<br>
B&nbsp;LOOP&nbsp;<br>
;&nbsp;.. and&nbsp;loop&nbsp;back&nbsp;<br>
DONE &nbsp;&nbsp;SWI&nbsp;<br>
SWI_Exit&nbsp;<br>
;&nbsp;end of execution&nbsp;<br>
ALIGN&nbsp;<br>
;&nbsp;to ensure&nbsp;ADR works&nbsp;<br>
TEXT &nbsp; &nbsp;DATA&nbsp;<br>
&quot;Hello World&quot;,&amp;0a,&amp;0d,&amp;00&nbsp;<br>
END&nbsp;<br>
The two additional instructions&nbsp;required to compensate&nbsp;for the features absent from&nbsp;<br>
the Thumb&nbsp;instruction set are&nbsp;marked&nbsp;with&nbsp;'**T'&nbsp;in&nbsp;the above&nbsp;listing.&nbsp;The ARM&nbsp;code&nbsp;<br>
size&nbsp;is&nbsp;six&nbsp;instructions&nbsp;plus&nbsp;14&nbsp;bytes&nbsp;of&nbsp;data,&nbsp;38&nbsp;bytes&nbsp;in&nbsp;all.&nbsp;The&nbsp;Thumb code&nbsp;size&nbsp;is&nbsp;<br>
eight instructions plus&nbsp;14&nbsp;bytes of data&nbsp;(ignoring&nbsp;the preamble&nbsp;required&nbsp;to&nbsp;switch&nbsp;the&nbsp;<br>
processor to&nbsp;executing Thumb&nbsp;instructions), making&nbsp;30&nbsp;bytes in&nbsp;all.&nbsp;<br>
This&nbsp;example illustrates&nbsp;a&nbsp;number of important&nbsp;points&nbsp;to&nbsp;bear in mind when&nbsp;writing&nbsp;<br>
Thumb code:&nbsp;<br>
•&nbsp;&nbsp;The assembler needs&nbsp;to know when&nbsp;to produce ARM code&nbsp;and when&nbsp;to produce&nbsp;<br>
Thumb&nbsp;code.&nbsp;The&nbsp;'CODES&nbsp;2'&nbsp;and&nbsp;'CODE16'&nbsp;directives&nbsp;provide&nbsp;this&nbsp;information.&nbsp;<br>
(These are&nbsp;instructions&nbsp;to the assembler and do&nbsp;not&nbsp;themselves&nbsp;cause any code&nbsp;to&nbsp;<br>
be generated.)&nbsp;<br>
•&nbsp;&nbsp;Since&nbsp;the&nbsp;processor&nbsp;is executing&nbsp;ARM&nbsp;instructions&nbsp;when&nbsp;it&nbsp;calls&nbsp;the&nbsp;code, explicit&nbsp;<br>
provision&nbsp;must&nbsp;be&nbsp;made&nbsp;to&nbsp;instruct&nbsp;it&nbsp;to&nbsp;execute&nbsp;the&nbsp;Thumb&nbsp;instructions.&nbsp;The&nbsp;<br>
'BX&nbsp;rO'&nbsp;instruction achieves this, provided that r0 has been&nbsp;initialized appropri&nbsp;<br>
ately.&nbsp;Note particularly that the bottom&nbsp;bit&nbsp;of r0 is&nbsp;set to cause the processor to&nbsp;<br>
execute&nbsp;Thumb&nbsp;instructions&nbsp;at&nbsp;the&nbsp;branch&nbsp;target.&nbsp;<br>
•&nbsp;&nbsp;In&nbsp;Thumb code&nbsp;'ADR'&nbsp;can&nbsp;only&nbsp;generate word-aligned addresses. As&nbsp;Thumb&nbsp;<br>
instructions&nbsp;are&nbsp;half-words,&nbsp;there&nbsp;is&nbsp;no&nbsp;guarantee&nbsp;that&nbsp;a location&nbsp;following an&nbsp;<br>
arbitrary&nbsp;number&nbsp;of&nbsp;Thumb&nbsp;instructions&nbsp;will&nbsp;be&nbsp;word-aligned.&nbsp;Therefore&nbsp;the&nbsp;<br>
example program&nbsp;has an explicit 'ALIGN'&nbsp;before the text&nbsp;string.&nbsp;<br>
In order to assemble&nbsp;and run&nbsp;this program&nbsp;on&nbsp;the ARM software&nbsp;development&nbsp;<br>
toolkit, an&nbsp;assembler that can generate Thumb code must be invoked and&nbsp;the&nbsp;<br>
ARMula-tor&nbsp;must&nbsp;emulate&nbsp;a&nbsp;'Thumb-aware'&nbsp;processor&nbsp;core.&nbsp;The&nbsp;default setting&nbsp;of&nbsp;the&nbsp;<br>
Project Manager targets an&nbsp;ARM6&nbsp;core&nbsp;and generates only 32-bit ARM code.&nbsp;This&nbsp;<br>
may&nbsp;be&nbsp;changed by&nbsp;choosing 'Project'&nbsp;from&nbsp;the&nbsp;'Options'&nbsp;menu&nbsp;within the Project&nbsp;<br>
Manager&nbsp;<br>
<hr>
<A name=217></a><b>206&nbsp;</b><br>
<b>The&nbsp;Thumb&nbsp;Instruction Set</b>&nbsp;<br>
and selecting 'TCC/TASM'&nbsp;in&nbsp;the 'Tools'&nbsp;dialogue box&nbsp;before generating the code.&nbsp;<br>
The 'Target Processor' will&nbsp;automatically&nbsp;switch to&nbsp;the&nbsp;Thumb-aware ARM7t when&nbsp;<br>
this is&nbsp;done.&nbsp;<br>
Otherwise,&nbsp;assembling&nbsp;and running Thumb code is&nbsp;just&nbsp;like&nbsp;using&nbsp;ARM code.&nbsp;<br>
<b>Exercise&nbsp;7.1.1</b>&nbsp;<br>
Convert the other programs&nbsp;in&nbsp;Sections&nbsp;3.4 and 3.5 on&nbsp;pages&nbsp;69&nbsp;and 72&nbsp;into&nbsp;Thumb&nbsp;<br>
code and&nbsp;compare&nbsp;their&nbsp;sizes&nbsp;with the original&nbsp;ARM code.&nbsp;<br>
<b>Exercise 7.1.2</b>&nbsp;<br>
Use&nbsp;TCC to generate Thumb code from&nbsp;C source programs&nbsp;(starting,&nbsp;as&nbsp;usual,&nbsp;with&nbsp;<br>
a 'Hello&nbsp;World'&nbsp;program). Look&nbsp;at&nbsp;the&nbsp;assembly&nbsp;code generated by&nbsp;the C compiler&nbsp;<br>
(using&nbsp;the&nbsp;'-s'&nbsp;option). Compare&nbsp;the&nbsp;code&nbsp;size&nbsp;and&nbsp;the&nbsp;execution&nbsp;time&nbsp;with&nbsp;the&nbsp;<br>
same&nbsp;programs&nbsp;compiled&nbsp;into&nbsp;ARM&nbsp;code.&nbsp;<br>
<hr>
<A name=218></a><IMG src="index-218_1.png"><br>
Architectural Support for&nbsp;<br>
System Development&nbsp;<br>
&nbsp;<br>
Summary of chapter contents&nbsp;<br>
Designing&nbsp;any&nbsp;computer&nbsp;system&nbsp;is&nbsp;a&nbsp;complex&nbsp;task;&nbsp;designing&nbsp;an&nbsp;embedded&nbsp;<br>
'system-on-chip' is a daunting one. The&nbsp;development often takes place entirely&nbsp;<br>
within a CAD&nbsp;environment,&nbsp;and the first silicon must&nbsp;not&nbsp;only function&nbsp;but it must&nbsp;<br>
deliver the necessary performance and be&nbsp;manufacturable. The only scope for&nbsp;<br>
fixing&nbsp;design&nbsp;flaws&nbsp;is&nbsp;in the software;&nbsp;to modify the chip&nbsp;in order to&nbsp;correct errors&nbsp;<br>
takes too&nbsp;long&nbsp;and usually&nbsp;incurs considerable cost.&nbsp;<br>
For the&nbsp;past&nbsp;two&nbsp;decades&nbsp;the principal&nbsp;approach&nbsp;to&nbsp;microprocessor&nbsp;system&nbsp;<br>
development has been based upon the&nbsp;<i>In-Circuit&nbsp;Emulator&nbsp;</i>(ICE). The system&nbsp;itself&nbsp;<br>
was a printed&nbsp;circuit board&nbsp;incorporating&nbsp;a microprocessor chip&nbsp;and various&nbsp;<br>
memory&nbsp;and&nbsp;peripheral&nbsp;devices.&nbsp;To&nbsp;use&nbsp;the&nbsp;ICE,&nbsp;the&nbsp;microprocessor&nbsp;was&nbsp;removed&nbsp;<br>
from its socket&nbsp;and replaced&nbsp;by a header plug&nbsp;with&nbsp;an umbilical connection to the&nbsp;<br>
ICE equipment.&nbsp;The&nbsp;ICE&nbsp;emulated&nbsp;the function&nbsp;of&nbsp;the&nbsp;microprocessor&nbsp;and gave&nbsp;the&nbsp;<br>
user&nbsp;an&nbsp;inside&nbsp;view&nbsp;on&nbsp;the&nbsp;internal&nbsp;state&nbsp;of&nbsp;the&nbsp;system,&nbsp;giving&nbsp;access&nbsp;to&nbsp;read&nbsp;and&nbsp;<br>
modify&nbsp;processor registers&nbsp;and memory values, to&nbsp;set breakpoints,&nbsp;and&nbsp;so&nbsp;on.&nbsp;<br>
Now&nbsp;that&nbsp;the&nbsp;microprocessor itself&nbsp;has&nbsp;become&nbsp;just&nbsp;a&nbsp;cell&nbsp;on&nbsp;a&nbsp;larger&nbsp;chip, this&nbsp;<br>
whole&nbsp;approach&nbsp;has&nbsp;collapsed.&nbsp;It&nbsp;is&nbsp;not&nbsp;possible&nbsp;to&nbsp;unplug&nbsp;part&nbsp;of&nbsp;a&nbsp;chip!&nbsp;There&nbsp;is,&nbsp;<br>
as&nbsp;yet,&nbsp;no&nbsp;approach&nbsp;that&nbsp;has replaced&nbsp;the ICE&nbsp;in&nbsp;all its roles,&nbsp;but there are&nbsp;several&nbsp;<br>
techniques&nbsp;that contribute,&nbsp;some of&nbsp;which require&nbsp;explicit&nbsp;support&nbsp;in&nbsp;the proces-<br>
sor's architecture.&nbsp;This chapter&nbsp;covers&nbsp;the&nbsp;techniques available to support the&nbsp;<br>
development&nbsp;of system&nbsp;chips&nbsp;based&nbsp;on&nbsp;ARM cores&nbsp;and&nbsp;the architectural features&nbsp;<br>
built&nbsp;into&nbsp;the&nbsp;cores&nbsp;to&nbsp;assist&nbsp;in this&nbsp;process.&nbsp;<br>
<b>207</b>&nbsp;<br>
<hr>
<A name=219></a><b>208</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
8.1 &nbsp; The&nbsp;ARM&nbsp;memory&nbsp;interface&nbsp;<br>
In&nbsp;this&nbsp;section&nbsp;we look&nbsp;at&nbsp;the general principles involved in connecting&nbsp;an ARM&nbsp;pro-<br>
cessor&nbsp;to&nbsp;a memory system&nbsp;built from&nbsp;standard&nbsp;memory parts.&nbsp;The&nbsp;efficiency&nbsp;of&nbsp;the&nbsp;<br>
memory interface is an&nbsp;important determinant of the&nbsp;system&nbsp;performance, so these&nbsp;<br>
principles must be well&nbsp;understood by&nbsp;the designer who&nbsp;wishes&nbsp;to&nbsp;develop&nbsp;a&nbsp;<br>
high-performance&nbsp;system.&nbsp;<br>
More recent&nbsp;ARM cores have direct AMBA interfaces (see Section 8.2 on&nbsp;<br>
page&nbsp;216), but&nbsp;many&nbsp;of the basic&nbsp;issues&nbsp;discussed here still&nbsp;apply.&nbsp;<br>
ARM bus signals&nbsp;<br>
ARM processor chips vary in&nbsp;the details of&nbsp;their bus interfaces, but they&nbsp;are gener-<br>
ally similar in&nbsp;nature. The&nbsp;memory bus&nbsp;interface&nbsp;signals&nbsp;include the&nbsp;following:&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;32-bit&nbsp;address&nbsp;bus,&nbsp;<i>A[31:0],&nbsp;</i>which&nbsp;gives&nbsp;the&nbsp;byte&nbsp;address&nbsp;of&nbsp;the&nbsp;data&nbsp;to&nbsp;be&nbsp;<br>
accessed.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;32-bit&nbsp;bidirectional data&nbsp;bus,&nbsp;<i>D[3J:OJ,&nbsp;</i>along&nbsp;which&nbsp;the data&nbsp;is&nbsp;transferred.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
•&nbsp;&nbsp;Signals&nbsp;that&nbsp;specify&nbsp;whether the&nbsp;memory is&nbsp;needed&nbsp;<i>(mreq)&nbsp;</i>and&nbsp;whether the&nbsp;<br>
address is&nbsp;sequential&nbsp;<i>(seq);&nbsp;</i>these&nbsp;are&nbsp;issued in&nbsp;the&nbsp;previous cycle so that&nbsp;the&nbsp;<br>
memory&nbsp;control logic can&nbsp;prepare appropriately.&nbsp;<br>
•&nbsp;&nbsp;Signals that specify the direction (r/w) and size&nbsp;<i>(b/w&nbsp;</i>on earlier processors;&nbsp;<br>
<i>mas[1:0]&nbsp;</i>on&nbsp;later&nbsp;processors) of the transfer.&nbsp;<br>
•&nbsp;&nbsp;Bus timing and control signals&nbsp;<i>(abe, ale, ape, dbe, lock, bl[3:0]).</i>&nbsp;<br>
Simple&nbsp;memory&nbsp;<br>
The simplest form&nbsp;of&nbsp;memory interface&nbsp;is suitable&nbsp;for&nbsp;operation&nbsp;with&nbsp;ROM and&nbsp;<br>
interface&nbsp;<br>
static&nbsp;RAM (SRAM).&nbsp;These&nbsp;devices require&nbsp;the&nbsp;address to&nbsp;be&nbsp;stable&nbsp;until&nbsp;the end&nbsp;of&nbsp;<br>
the cycle,&nbsp;which&nbsp;may&nbsp;be achieved by&nbsp;disabling the address pipeline&nbsp;(tying&nbsp;<i>ape&nbsp;</i>low)&nbsp;<br>
on later processors or&nbsp;retiming the address bus&nbsp;(connecting&nbsp;<i>ale&nbsp;</i>to&nbsp;<i>mclk)&nbsp;</i>on earlier&nbsp;<br>
processors. The address and data buses&nbsp;may&nbsp;then be&nbsp;connected directly&nbsp;to&nbsp;the&nbsp;<br>
memory&nbsp;parts as shown in&nbsp;Figure 8.1 on&nbsp;page 209 which also shows the output&nbsp;<br>
enable&nbsp;signals&nbsp;<i>(RAMoe&nbsp;</i>and&nbsp;<i>ROMoe)&nbsp;</i>and the write&nbsp;enables&nbsp;<i>(RAMwe).</i>&nbsp;<br>
This&nbsp;figure illustrates&nbsp;the connection&nbsp;of 8-bit&nbsp;memory&nbsp;parts,&nbsp;which&nbsp;are&nbsp;a&nbsp;standard&nbsp;<br>
configuration&nbsp;for SRAMs and&nbsp;ROMs. Four&nbsp;parts&nbsp;of&nbsp;each&nbsp;type&nbsp;are required&nbsp;to&nbsp;form&nbsp;a&nbsp;<br>
32-bit&nbsp;memory and an&nbsp;individual device is&nbsp;connected&nbsp;to a&nbsp;single byte&nbsp;section&nbsp;of&nbsp;the&nbsp;<br>
bus. The notation on the figure shows the device's&nbsp;bus numbering inside the device&nbsp;<br>
and&nbsp;the bus wires to which&nbsp;it&nbsp;is&nbsp;connected&nbsp;outside&nbsp;the&nbsp;device, so,&nbsp;for example,&nbsp;the&nbsp;<br>
SRAM&nbsp;shown&nbsp;nearest the&nbsp;ARM has&nbsp;its&nbsp;pins&nbsp;<i>D[7:0]&nbsp;</i>connected to&nbsp;bus&nbsp;pins&nbsp;<i>D[31:24]&nbsp;</i><br>
which are connected&nbsp;to&nbsp;the&nbsp;ARM's pins&nbsp;<i>D[31:24].</i>&nbsp;<br>
Since the bottom&nbsp;two address&nbsp;lines,&nbsp;<i>A [1:0],&nbsp;</i>are used&nbsp;for&nbsp;byte selection, they are&nbsp;<br>
used by&nbsp;the control logic&nbsp;and&nbsp;not connected&nbsp;to&nbsp;the&nbsp;memory.&nbsp;Therefore the address lines&nbsp;<br>
on&nbsp;the&nbsp;memory&nbsp;devices&nbsp;are connected to&nbsp;<i>A [2]&nbsp;</i>and&nbsp;upwards,&nbsp;the precise number&nbsp;used&nbsp;<br>
depending&nbsp;on&nbsp;the&nbsp;size&nbsp;of&nbsp;the&nbsp;memory&nbsp;part&nbsp;(for&nbsp;example,&nbsp;a&nbsp;128&nbsp;Kbyte&nbsp;ROM&nbsp;part&nbsp;will&nbsp;<br>
<i>useA[18:2J).</i>&nbsp;<br>
<hr>
<A name=220></a><IMG src="index-220_1.png"><br>
<b>The&nbsp;ARM memory&nbsp;interface</b>&nbsp;<br>
<b>209</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;8.1 &nbsp; &nbsp;</b>A basic ARM memory&nbsp;system.&nbsp;<br>
Although the&nbsp;ARM&nbsp;performs reads&nbsp;of&nbsp;both bytes and words, the memory&nbsp;system&nbsp;<br>
can ignore the difference&nbsp;(at&nbsp;the cost&nbsp;of some&nbsp;power&nbsp;wastage)&nbsp;and always simply&nbsp;<br>
supply a word quantity. The ARM&nbsp;will extract the addressed byte and&nbsp;ignore the&nbsp;<br>
remainder of the word.&nbsp;Therefore the ROMs&nbsp;do not&nbsp;need individual&nbsp;enables and using&nbsp;<br>
16-bit&nbsp;devices causes no&nbsp;problems.&nbsp;Byte&nbsp;<i>writes,&nbsp;</i>however,&nbsp;do require individual&nbsp;byte&nbsp;<br>
enables,&nbsp;so the&nbsp;control&nbsp;logic&nbsp;must&nbsp;generate&nbsp;four byte&nbsp;write enable&nbsp;controls.&nbsp;This&nbsp;makes&nbsp;<br>
the use of wider RAMs&nbsp;difficult&nbsp;(and inefficient)&nbsp;unless they&nbsp;incorporate separate&nbsp;byte&nbsp;<br>
enables, since&nbsp;writing an individual&nbsp;byte&nbsp;would require a read-modify-write&nbsp;memory&nbsp;<br>
operation. Since&nbsp;many processors require support&nbsp;for&nbsp;writing bytes, it&nbsp;is&nbsp;likely&nbsp;that&nbsp;if&nbsp;<br>
RAMs do&nbsp;become&nbsp;available&nbsp;with&nbsp;a data width&nbsp;greater than&nbsp;a byte, they&nbsp;will&nbsp;incorpo-<br>
rate&nbsp;individual&nbsp;byte&nbsp;enables.&nbsp;<br>
Control&nbsp;logic&nbsp;<br>
The&nbsp;control&nbsp;logic&nbsp;performs the&nbsp;following&nbsp;functions:&nbsp;<br>
• It&nbsp;decides&nbsp;when to activate the&nbsp;RAM&nbsp;and&nbsp;when&nbsp;to&nbsp;activate the&nbsp;ROM.&nbsp;<br>
This logic&nbsp;determines the system&nbsp;memory&nbsp;map. The&nbsp;processor&nbsp;starts&nbsp;from&nbsp;loca-<br>
tion&nbsp;zero after&nbsp;a reset, so&nbsp;it must&nbsp;find&nbsp;ROM&nbsp;there&nbsp;since the RAM is&nbsp;uninitialized.&nbsp;<br>
The simplest&nbsp;memory&nbsp;map therefore enables the ROM&nbsp;<i>ifAf31J&nbsp;&nbsp;</i>is low&nbsp;and&nbsp;the&nbsp;<br>
RAM if it is high.&nbsp;(Most&nbsp;ARM systems change&nbsp;the memory map&nbsp;shortly after&nbsp;<br>
<hr>
<A name=221></a><b>210</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
start-up to put&nbsp;the RAM at the bottom&nbsp;of&nbsp;memory so that the exception vectors&nbsp;<br>
can&nbsp;be&nbsp;modified.)&nbsp;<br>
•&nbsp;&nbsp;It controls&nbsp;the&nbsp;byte&nbsp;write&nbsp;enables during a&nbsp;write operation.&nbsp;<br>
During a word&nbsp;write all&nbsp;the&nbsp;byte enables&nbsp;should&nbsp;be&nbsp;active, during&nbsp;a byte write&nbsp;<br>
only&nbsp;the addressed byte&nbsp;should be activated, and&nbsp;where&nbsp;the&nbsp;ARM&nbsp;supports&nbsp;<br>
half-words&nbsp;a&nbsp;half-word&nbsp;write&nbsp;should&nbsp;activate two&nbsp;of&nbsp;the four enables.&nbsp;<br>
•&nbsp;&nbsp;It ensures that&nbsp;the data is&nbsp;ready before&nbsp;the processor continues.&nbsp;<br>
The&nbsp;simplest solution is to run&nbsp;<i>mclk&nbsp;</i>slowly&nbsp;enough&nbsp;to&nbsp;ensure that all&nbsp;the&nbsp;memory&nbsp;<br>
devices&nbsp;can be&nbsp;accessed&nbsp;within a single clock cycle. More sophisticated&nbsp;systems&nbsp;<br>
may have&nbsp;the&nbsp;clock&nbsp;set to&nbsp;suit RAM accesses and use&nbsp;wait states&nbsp;for&nbsp;(typically&nbsp;<br>
slower) ROM&nbsp;and peripheral&nbsp;accesses.&nbsp;<br>
The logic required for the above functions&nbsp;is quite straightforward and is illus-<br>
trated&nbsp;in&nbsp;Figure&nbsp;8.2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(All this logic&nbsp;can&nbsp;be&nbsp;implemented using a single&nbsp;<br>
program-&nbsp;<br>
<b>Figure 8.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Simple ARM memory&nbsp;system control logic.<br>
<hr>
<A name=222></a><IMG src="index-222_1.png"><br>
&nbsp;<br>
<hr>
<A name=223></a><IMG src="index-223_1.png"><br>
<b>The&nbsp;ARM memory&nbsp;interface</b>&nbsp;<br>
<b>211</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
mable&nbsp;logic&nbsp;device.)&nbsp;Perhaps the&nbsp;trickiest&nbsp;aspect&nbsp;of&nbsp;the&nbsp;design&nbsp;relates to&nbsp;the&nbsp;bidirec-<br>
tional data bus. Here it is very&nbsp;important to&nbsp;ensure that only&nbsp;one device drives the&nbsp;<br>
bus at any time,&nbsp;so care is&nbsp;needed&nbsp;when&nbsp;turning the bus around for a&nbsp;write cycle, or&nbsp;<br>
when switching&nbsp;between reading&nbsp;from&nbsp;the ROM&nbsp;and&nbsp;reading&nbsp;from&nbsp;the RAM.&nbsp;The&nbsp;<br>
solution illustrated&nbsp;in the figure activates&nbsp;the&nbsp;appropriate&nbsp;data source when&nbsp;<i>mclk&nbsp;</i>is&nbsp;<br>
high&nbsp;and turns all sources off when&nbsp;<i>mclk&nbsp;</i>is low,&nbsp;so&nbsp;<i>dbe,&nbsp;</i>the processor's data bus&nbsp;ena-<br>
ble, should&nbsp;also&nbsp;be connected&nbsp;to&nbsp;<i>mclk.&nbsp;</i>This&nbsp;is a very conservative solution which&nbsp;<br>
will often compromise the performance of the system&nbsp;by&nbsp;limiting the&nbsp;maximum&nbsp;<br>
clock&nbsp;frequency that can be used.&nbsp;<br>
Note&nbsp;that&nbsp;this&nbsp;design&nbsp;assumes that&nbsp;the&nbsp;ARM outputs are&nbsp;stable&nbsp;to&nbsp;the&nbsp;end of the&nbsp;<br>
clock cycle,&nbsp;which will be the case on newer processors&nbsp;with the address pipeline&nbsp;<br>
enable&nbsp;<i>(ape)&nbsp;</i>control input tied&nbsp;low.&nbsp;Older processors&nbsp;should&nbsp;use&nbsp;<i>ale =&nbsp;mclk&nbsp;</i>to&nbsp;retime&nbsp;<br>
the&nbsp;address outputs,&nbsp;but&nbsp;will&nbsp;need&nbsp;an&nbsp;external&nbsp;transparent&nbsp;latch&nbsp;which&nbsp;is&nbsp;open&nbsp;when&nbsp;<br>
<i>mclk&nbsp;</i>is low to&nbsp;retime&nbsp;<i>r/w&nbsp;</i>and&nbsp;<i>~b/w&nbsp;</i>(which&nbsp;replaces&nbsp;<i>mas[l],&nbsp;</i>and&nbsp;<i>mas[0]&nbsp;</i>is&nbsp;tied&nbsp;low).&nbsp;<br>
This simple&nbsp;memory&nbsp;system&nbsp;makes no&nbsp;use&nbsp;of&nbsp;<i>mreq&nbsp;</i>(or&nbsp;<i>seq)\&nbsp;</i>it simply activates&nbsp;the&nbsp;<br>
memory on every cycle. This&nbsp;is safe&nbsp;since&nbsp;the ARM&nbsp;will&nbsp;only request&nbsp;a write&nbsp;cycle on&nbsp;<br>
a genuine memory access. The&nbsp;<i>r/w&nbsp;</i>control remains low during all internal and coproc-<br>
essor&nbsp;register&nbsp;transfer cycles.&nbsp;<br>
Wait states&nbsp;<br>
If we&nbsp;try&nbsp;to&nbsp;speed&nbsp;up&nbsp;the clock in&nbsp;this&nbsp;system it&nbsp;will&nbsp;stop&nbsp;working&nbsp;when the slowest&nbsp;<br>
path fails.&nbsp;This&nbsp;will&nbsp;normally be&nbsp;the&nbsp;ROM&nbsp;access.&nbsp;We can get a&nbsp;lot&nbsp;more perform-<br>
ance from&nbsp;the&nbsp;system&nbsp;if&nbsp;the clock is tuned to the RAM access time&nbsp;and&nbsp;wait states&nbsp;<br>
are introduced&nbsp;to&nbsp;allow the ROM more&nbsp;access&nbsp;time. Usually the ROM will&nbsp;be&nbsp;<br>
allowed a&nbsp;fixed number&nbsp;of&nbsp;clock cycles per&nbsp;access, the exact number&nbsp;being deter-<br>
mined&nbsp;by&nbsp;the&nbsp;clock&nbsp;rate&nbsp;and&nbsp;the ROM&nbsp;data&nbsp;sheet. We&nbsp;will assume&nbsp;an&nbsp;access&nbsp;time&nbsp;of&nbsp;<br>
four clock&nbsp;cycles.&nbsp;<br>
The memory control&nbsp;logic must&nbsp;now incorporate&nbsp;a simple&nbsp;finite&nbsp;state machine to&nbsp;<br>
control&nbsp;the ROM access.&nbsp;A suitable&nbsp;state&nbsp;transition diagram&nbsp;is&nbsp;shown&nbsp;in&nbsp;Figure 8.3.&nbsp;<br>
&nbsp;<br>
<b>Figure 8.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ROM wait control state transition diagram.&nbsp;<br>
<hr>
<A name=224></a><IMG src="index-224_1.png"><br>
<b>212</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The three&nbsp;ROM states&nbsp;are used to&nbsp;stretch&nbsp;the ROM access&nbsp;time&nbsp;to&nbsp;four&nbsp;cycles by&nbsp;<br>
asserting the ARM's&nbsp;<i>wait&nbsp;</i>input. A design&nbsp;problem&nbsp;here is that since the addresses have&nbsp;<br>
been retimed to&nbsp;become&nbsp;valid early&nbsp;in the&nbsp;current&nbsp;cycle&nbsp;and&nbsp;<i>wait&nbsp;</i>must&nbsp;be&nbsp;asserted&nbsp;<br>
before&nbsp;<i>mclk&nbsp;</i>rises,&nbsp;<i>wait&nbsp;</i>cannot be generated as a simple&nbsp;state&nbsp;machine&nbsp;output&nbsp;since&nbsp;<br>
there is&nbsp;no clock edge that&nbsp;can&nbsp;be used&nbsp;to&nbsp;generate it. Another problem&nbsp;is to generate&nbsp;a&nbsp;<br>
stretched&nbsp;<i>ROMoe&nbsp;</i>signal that&nbsp;is glitch-free.&nbsp;<br>
A possible circuit is shown&nbsp;in&nbsp;Figure 8.4. The&nbsp;state machine&nbsp;is a synchronous coun-<br>
ter which&nbsp;uses&nbsp;the&nbsp;two&nbsp;edge-triggered&nbsp;flip-flops.&nbsp;Only&nbsp;the&nbsp;state&nbsp;ROM3&nbsp;is&nbsp;of&nbsp;signifi-<br>
cance, since it&nbsp;de-activates&nbsp;<i>wait&nbsp;</i>which is&nbsp;otherwise&nbsp;active&nbsp;whenever&nbsp;a ROM&nbsp;access&nbsp;is&nbsp;<br>
detected. The&nbsp;two level-sensitive&nbsp;latches&nbsp;are used to&nbsp;generate a clean, stretched&nbsp;<br>
<i>ROMoe&nbsp;</i>using&nbsp;<i>wait&nbsp;</i>as&nbsp;the starting&nbsp;point. A&nbsp;timing diagram&nbsp;for this&nbsp;circuit&nbsp;is shown&nbsp;in&nbsp;<br>
Figure 8.5 on&nbsp;page&nbsp;213,&nbsp;which should&nbsp;clarify the operation of&nbsp;the logic.&nbsp;<br>
Sequential&nbsp;<br>
If&nbsp;the&nbsp;system&nbsp;is to operate&nbsp;even&nbsp;faster&nbsp;it&nbsp;may&nbsp;not be&nbsp;possible&nbsp;to&nbsp;decode a new&nbsp;<br>
accesses&nbsp;<br>
address and perform&nbsp;a&nbsp;RAM&nbsp;access in&nbsp;a&nbsp;single clock&nbsp;cycle.&nbsp;Here an&nbsp;extra cycle&nbsp;can&nbsp;<br>
be&nbsp;inserted whenever&nbsp;an&nbsp;unknown address is&nbsp;issued&nbsp;to&nbsp;allow time&nbsp;for&nbsp;address decod-<br>
ing. The only&nbsp;addresses that&nbsp;are not unknown are sequential ones, but these repre-<br>
sent around 75% of all addresses in a&nbsp;typical program.&nbsp;<br>
&nbsp;<br>
<b>Figure 8.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ROM&nbsp;wait state generator circuit.&nbsp;<br>
<hr>
<A name=225></a><IMG src="index-225_1.png"><br>
<IMG src="index-225_2.png"><br>
<b>The&nbsp;ARM memory&nbsp;interface</b>&nbsp;<br>
<b>213</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;8.5&nbsp; &nbsp;</b>The&nbsp;timing&nbsp;diagram&nbsp;for&nbsp;the ROM&nbsp;wait state&nbsp;logic.&nbsp;<br>
We&nbsp;should&nbsp;also now&nbsp;begin to&nbsp;recognize cycles that do not use the memory, since&nbsp;<br>
there is no reason why they should&nbsp;not&nbsp;operate at&nbsp;the full&nbsp;clock&nbsp;rate. A suitable&nbsp;state&nbsp;<br>
transition diagram&nbsp;is&nbsp;shown in&nbsp;Figure&nbsp;8.6.&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;8.6&nbsp; &nbsp;</b>State&nbsp;transition diagram&nbsp;with&nbsp;a&nbsp;wait state&nbsp;for address decoding.&nbsp;<br>
DRAM&nbsp;<br>
The&nbsp;cheapest&nbsp;memory&nbsp;technology (in&nbsp;terms of price per&nbsp;bit)&nbsp;is&nbsp;dynamic random&nbsp;<br>
access memory (DRAM). 'Dynamic'&nbsp;memory&nbsp;stores information as&nbsp;electrical&nbsp;<br>
charge&nbsp;on a capacitor&nbsp;where it&nbsp;gradually leaks away (over&nbsp;a millisecond&nbsp;or&nbsp;so). The&nbsp;<br>
memory data&nbsp;must be&nbsp;read and rewritten&nbsp;('refreshed')&nbsp;before it leaks&nbsp;away. The&nbsp;<br>
responsibility for&nbsp;refreshing&nbsp;the memory usually lies with&nbsp;the memory control logic,&nbsp;<br>
not&nbsp;the&nbsp;processor,&nbsp;so&nbsp;it&nbsp;is&nbsp;not&nbsp;of&nbsp;immediate concern to&nbsp;us&nbsp;here.&nbsp;What&nbsp;is&nbsp;of&nbsp;concern&nbsp;is&nbsp;<br>
the internal&nbsp;organization&nbsp;of&nbsp;the memory&nbsp;which&nbsp;is&nbsp;shown&nbsp;in&nbsp;Figure&nbsp;8.7 on&nbsp;page&nbsp;214.&nbsp;<br>
Like most memory&nbsp;devices, the&nbsp;storage&nbsp;cells in a DRAM&nbsp;are arranged in a&nbsp;matrix&nbsp;<br>
which is&nbsp;approximately&nbsp;square. Unlike most&nbsp;other memory devices, this&nbsp;organization&nbsp;<br>
is&nbsp;exposed to&nbsp;the user. The matrix&nbsp;is&nbsp;addressed by&nbsp;<i>row&nbsp;</i>and by&nbsp;<i>column,&nbsp;</i>and a DRAM&nbsp;<br>
accepts the row and column&nbsp;addresses separately down the&nbsp;same&nbsp;multiplexed&nbsp;<br>
address&nbsp;bus. First the&nbsp;row address is&nbsp;presented&nbsp;and latched using the active-low&nbsp;row&nbsp;<br>
<hr>
<A name=226></a><IMG src="index-226_1.png"><br>
<b>214</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;8.7 &nbsp; &nbsp;</b>DRAM memory&nbsp;organization.&nbsp;<br>
<b>address strobe&nbsp;</b>signal&nbsp;<i>(ras),&nbsp;</i>then&nbsp;the&nbsp;column&nbsp;address&nbsp;is&nbsp;presented&nbsp;and latched&nbsp;using&nbsp;<br>
the active-low&nbsp;<b>column&nbsp;address&nbsp;strobe&nbsp;</b><i>(cas).&nbsp;</i>If the&nbsp;next&nbsp;access is&nbsp;within&nbsp;the same&nbsp;<br>
row,&nbsp;a new column&nbsp;address&nbsp;may be presented without first&nbsp;supplying&nbsp;a new&nbsp;row&nbsp;<br>
address.&nbsp;Since&nbsp;a cos-only&nbsp;access does&nbsp;not activate the&nbsp;cell&nbsp;matrix&nbsp;it can&nbsp;deliver its data&nbsp;<br>
two&nbsp;to&nbsp;three times&nbsp;faster&nbsp;than&nbsp;a&nbsp;full&nbsp;<i>ras-cas&nbsp;</i>access and consumes&nbsp;considerably&nbsp;less&nbsp;<br>
power.&nbsp;It&nbsp;is&nbsp;therefore very advantageous&nbsp;to&nbsp;use&nbsp;<i>cas-on\y&nbsp;</i>accesses whenever&nbsp;possible.&nbsp;<br>
The difficulty&nbsp;is in detecting&nbsp;early&nbsp;enough in the memory&nbsp;access that the new&nbsp;<br>
address&nbsp;is&nbsp;in the same&nbsp;row as the&nbsp;previous&nbsp;address.&nbsp;Performing a comparison&nbsp;of the&nbsp;<br>
relevant&nbsp;bits&nbsp;of&nbsp;the&nbsp;new address with&nbsp;the&nbsp;corresponding&nbsp;bits&nbsp;of the&nbsp;previous&nbsp;address is&nbsp;<br>
almost always too slow.&nbsp;<br>
ARM address&nbsp;<br>
The solution adopted on&nbsp;the&nbsp;ARM exploits the fact that&nbsp;most addresses (typically&nbsp;<br>
incrementer&nbsp;<br>
75%) are generated in the address incrementer. The&nbsp;ARM address selection&nbsp;logic&nbsp;<br>
(shown in&nbsp;Figure 8.8 on page&nbsp;215) picks the address&nbsp;for the next cycle from&nbsp;one of&nbsp;<br>
four&nbsp;sources. One of&nbsp;these&nbsp;sources&nbsp;is the incrementer.&nbsp;The&nbsp;ARM&nbsp;indicates&nbsp;to the&nbsp;out-<br>
side&nbsp;world&nbsp;whenever the next&nbsp;address is&nbsp;coming&nbsp;from&nbsp;the&nbsp;incrementer by&nbsp;asserting&nbsp;<br>
the&nbsp;<i>seq&nbsp;</i>output. External&nbsp;logic can&nbsp;then&nbsp;look&nbsp;at&nbsp;the&nbsp;previous&nbsp;address&nbsp;to&nbsp;check for row&nbsp;<br>
boundaries;&nbsp;if&nbsp;the previous address is&nbsp;<i>not&nbsp;</i>at&nbsp;the&nbsp;end of&nbsp;a&nbsp;row and&nbsp;the&nbsp;<i>seq&nbsp;</i>signal is&nbsp;<br>
asserted then&nbsp;a&nbsp;<i>cas-on\y&nbsp;</i>memory&nbsp;access can&nbsp;be performed.&nbsp;<br>
Although this&nbsp;mechanism&nbsp;will&nbsp;not&nbsp;capture&nbsp;all&nbsp;accesses which fall&nbsp;within&nbsp;the&nbsp;same&nbsp;<br>
DRAM row, it&nbsp;does find most of&nbsp;them&nbsp;and is&nbsp;very simple&nbsp;to&nbsp;implement and&nbsp;exploit.&nbsp;<br>
The&nbsp;<i>seq&nbsp;</i>signal&nbsp;and&nbsp;the previous&nbsp;address&nbsp;are all available&nbsp;over half a&nbsp;clock&nbsp;cycle&nbsp;before&nbsp;<br>
the&nbsp;cycle&nbsp;in question,&nbsp;giving the&nbsp;memory&nbsp;control&nbsp;logic&nbsp;plenty&nbsp;of&nbsp;time.&nbsp;<br>
<hr>
<A name=227></a><IMG src="index-227_1.png"><br>
<IMG src="index-227_2.png"><br>
<b>The&nbsp;ARM memory&nbsp;interface</b>&nbsp;<br>
<b>215</b>&nbsp;<br>
<b>address to&nbsp;</b><br>
&nbsp;<br>
<b>j signal&nbsp;</b><br>
<b>(address + 4)</b>&nbsp;<br>
<b>Figure 8.8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM address register structure.&nbsp;<br>
A typical&nbsp;DRAM&nbsp;timing diagram&nbsp;is&nbsp;shown in&nbsp;Figure&nbsp;8.9.&nbsp;The first,&nbsp;non-sequential&nbsp;<br>
access takes two clock cycles as the row address is strobed in, but&nbsp;subsequent sequen-<br>
tial addresses&nbsp;use&nbsp;a cos-only&nbsp;access and&nbsp;operate in&nbsp;a single clock cycle. (Note that&nbsp;<br>
early&nbsp;address timing is&nbsp;now&nbsp;used, with&nbsp;<i>ape&nbsp;</i>or&nbsp;<i>ale&nbsp;</i>high.)&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;8.9&nbsp; &nbsp;</b>DRAM timing&nbsp;illustration.&nbsp;<br>
The&nbsp;other use of&nbsp;the&nbsp;<i>seq&nbsp;</i>signal, to&nbsp;indicate a&nbsp;cycle which&nbsp;will use the same address&nbsp;<br>
as the&nbsp;preceding internal&nbsp;or coprocessor&nbsp;register transfer cycle, can also&nbsp;be exploited&nbsp;<br>
to improve DRAM access&nbsp;times. The DRAM&nbsp;access is started in the preceding cycle,&nbsp;<br>
which&nbsp;is&nbsp;only&nbsp;possible because&nbsp;<i>seq&nbsp;</i>is available&nbsp;so&nbsp;early.&nbsp;Typical&nbsp;timing&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;<br>
Figure 8.10.&nbsp;<i>(wait&nbsp;</i>is inactive during this sequence.)&nbsp;<br>
<hr>
<A name=228></a><IMG src="index-228_1.png"><br>
<b>216</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 8.10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>DRAM timing&nbsp;after an internal&nbsp;cycle.&nbsp;<br>
Peripheral&nbsp;<br>
Most&nbsp;systems incorporate peripheral&nbsp;devices in&nbsp;addition&nbsp;to the&nbsp;memory components&nbsp;<br>
access&nbsp;<br>
described&nbsp;so far.&nbsp;These often have slow&nbsp;access speeds,&nbsp;but can be interfaced using&nbsp;<br>
techniques&nbsp;similar to those described above for ROM&nbsp;access.&nbsp;<br>
8.2 &nbsp; The&nbsp;Advanced&nbsp;Microcontroller Bus&nbsp;Architecture (AMBA)&nbsp;<br>
ARM processor cores have&nbsp;bus interfaces&nbsp;that are optimized for high-speed cache&nbsp;<br>
interfacing. Where a core is used, with&nbsp;or without a cache, as a component on&nbsp;a&nbsp;<br>
complex&nbsp;system&nbsp;chip,&nbsp;some&nbsp;interfacing&nbsp;is&nbsp;required&nbsp;to&nbsp;allow&nbsp;the&nbsp;ARM&nbsp;to&nbsp;communi-<br>
cate with&nbsp;other on-chip macrocells.&nbsp;<br>
Although this&nbsp;interfacing is&nbsp;not particularly&nbsp;difficult&nbsp;to design,&nbsp;there are&nbsp;many&nbsp;<br>
potential solutions.&nbsp;Making&nbsp;an&nbsp;<i>ad&nbsp;hoc&nbsp;</i>choice&nbsp;in&nbsp;every&nbsp;case&nbsp;consumes design&nbsp;resource&nbsp;<br>
and&nbsp;inhibits&nbsp;the reuse&nbsp;of&nbsp;peripheral&nbsp;macrocells.&nbsp;To&nbsp;avoid&nbsp;this&nbsp;waste,&nbsp;ARM&nbsp;Limited&nbsp;<br>
specified&nbsp;the&nbsp;Advanced&nbsp;Microcontroller Bus&nbsp;Architecture,&nbsp;AMBA, to&nbsp;standardize the&nbsp;<br>
on-chip&nbsp;connection&nbsp;of&nbsp;different&nbsp;macrocells.&nbsp;Macrocells designed to&nbsp;this bus&nbsp;interface&nbsp;<br>
can&nbsp;be viewed&nbsp;as&nbsp;a kit&nbsp;of&nbsp;parts for future system&nbsp;chips,&nbsp;and ultimately&nbsp;designing&nbsp;a&nbsp;<br>
complex system&nbsp;on&nbsp;a chip&nbsp;based&nbsp;on&nbsp;a&nbsp;new combination&nbsp;of&nbsp;existing macrocells&nbsp;could&nbsp;<br>
become&nbsp;a straightforward&nbsp;task.&nbsp;<br>
AMBA buses&nbsp;<br>
Three&nbsp;buses&nbsp;are&nbsp;denned&nbsp;within&nbsp;the AMBA specification:&nbsp;<br>
• The&nbsp;<i>Advanced High-performance Bus&nbsp;</i>(AHB) is used&nbsp;to&nbsp;connect high-performance&nbsp;<br>
system&nbsp;modules.&nbsp;It supports burst&nbsp;mode data&nbsp;transfers and&nbsp;split transactions,&nbsp;and&nbsp;<br>
all timing is&nbsp;reference&nbsp;to a&nbsp;single clock edge.&nbsp;<br>
<hr>
<A name=229></a><IMG src="index-229_1.png"><br>
<b>The&nbsp;Advanced&nbsp;Microcontroller Bus&nbsp;Architecture&nbsp;(AMBA)</b>&nbsp;<br>
<b>217</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;<i>Advanced System Bus&nbsp;</i>(ASB) is&nbsp;used to connect&nbsp;high-performance system&nbsp;<br>
modules. It supports&nbsp;burst&nbsp;mode data&nbsp;transfers.&nbsp;<br>
•&nbsp;&nbsp;<i>The&nbsp;Advanced Peripheral&nbsp;Bus&nbsp;</i><b>(APB)&nbsp;</b>offers&nbsp;a&nbsp;simpler&nbsp;interface for low-performance&nbsp;<br>
peripherals.&nbsp;<br>
A typical AMBA-based&nbsp;microcontroller will&nbsp;incorporate&nbsp;either an AHB or an ASB&nbsp;<br>
together with&nbsp;an APB&nbsp;as&nbsp;illustrated&nbsp;in&nbsp;Figure 8.11.&nbsp;The ASB&nbsp;is the older form&nbsp;of&nbsp;<br>
system&nbsp;bus, with&nbsp;AHB&nbsp;being&nbsp;introduced&nbsp;later to&nbsp;improve&nbsp;support&nbsp;for&nbsp;higher perform-<br>
ance, synthesis&nbsp;and timing verification.&nbsp;<br>
The APB&nbsp;is&nbsp;generally&nbsp;used as a local&nbsp;secondary&nbsp;bus which appears as a single slave&nbsp;<br>
module on the&nbsp;AHB&nbsp;or ASB.&nbsp;<br>
In the following sections we assume&nbsp;the system&nbsp;bus is&nbsp;an ASB.&nbsp;More details on the&nbsp;<br>
AHB are&nbsp;provided at the end&nbsp;of the section.&nbsp;<br>
Arbitration&nbsp;<br>
A bus transaction is&nbsp;initiated by&nbsp;a bus&nbsp;master&nbsp;which requests&nbsp;access from&nbsp;a central arbi-<br>
ter.&nbsp;The arbiter decides&nbsp;priorities&nbsp;when there&nbsp;are&nbsp;conflicting requests, and&nbsp;its design&nbsp;is&nbsp;a&nbsp;<br>
system&nbsp;specific issue.&nbsp;The&nbsp;ASB only specifies&nbsp;the protocol&nbsp;which&nbsp;must&nbsp;be&nbsp;followed:&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;8.11 &nbsp; &nbsp;</b>A typical AMBA-based&nbsp;system.&nbsp;<br>
<hr>
<A name=230></a><b>218 Architectural Support for&nbsp;System Development</b>&nbsp;<br>
i&nbsp;<br>
•&nbsp;&nbsp;The master,&nbsp;<i>x,&nbsp;</i>issues&nbsp;a request&nbsp;<i>(AREQx)&nbsp;</i>to the central arbiter.&nbsp;<br>
•&nbsp;&nbsp;When the&nbsp;bus&nbsp;is&nbsp;available,&nbsp;the&nbsp;arbiter issues&nbsp;a grant&nbsp;<i>(AGNTx)&nbsp;</i>to&nbsp;the&nbsp;master.&nbsp;(The&nbsp;<br>
arbitration&nbsp;must&nbsp;take&nbsp;account of&nbsp;the&nbsp;bus&nbsp;lock&nbsp;signal&nbsp;<i>(BLOK)&nbsp;</i>when&nbsp;deciding&nbsp;which&nbsp;<br>
grant to&nbsp;issue&nbsp;to&nbsp;ensure that atomic bus transactions&nbsp;are not violated.)&nbsp;<br>
Bus&nbsp;transfers&nbsp;<br>
When&nbsp;a&nbsp;master has&nbsp;been&nbsp;granted access&nbsp;to&nbsp;the&nbsp;bus, it&nbsp;issues&nbsp;address&nbsp;and&nbsp;control&nbsp;<br>
information to indicate the&nbsp;type of the transfer and the slave device which should&nbsp;<br>
respond. The&nbsp;following&nbsp;signal is used&nbsp;to define the transaction timing:&nbsp;<br>
•&nbsp;&nbsp;The bus clock,&nbsp;<i>BCLK.&nbsp;</i>This&nbsp;will usually be the same&nbsp;as&nbsp;<i>mclk,&nbsp;</i>the ARM&nbsp;processor&nbsp;<br>
clock.&nbsp;<br>
The&nbsp;bus&nbsp;master&nbsp;which holds the grant&nbsp;then&nbsp;proceeds&nbsp;with&nbsp;the bus&nbsp;transaction using&nbsp;<br>
the following signals:&nbsp;<br>
•&nbsp;&nbsp;Bus transaction,&nbsp;<i>BTRAN[1:0],&nbsp;</i>indicates&nbsp;whether the next bus cycle&nbsp;will be&nbsp;<br>
address-only,&nbsp;sequential or&nbsp;non-sequential.&nbsp;It&nbsp;is&nbsp;enabled&nbsp;by&nbsp;the&nbsp;grant&nbsp;signal&nbsp;and&nbsp;is&nbsp;<br>
ahead of&nbsp;the bus cycle&nbsp;to&nbsp;which it&nbsp;refers.&nbsp;<br>
•&nbsp;&nbsp;The address bus,&nbsp;<i>BA[31:OJ.&nbsp;</i>(Not all address lines need be&nbsp;implemented in sys&nbsp;<br>
tems&nbsp;with&nbsp;modest address-space requirements, and&nbsp;in a&nbsp;multiplexed implementa&nbsp;<br>
tion the address is sent down&nbsp;the data bus.)&nbsp;<br>
•&nbsp;&nbsp;Bus transfer direction,&nbsp;<i>BWRITE.</i>&nbsp;<br>
•&nbsp;&nbsp;Bus protection&nbsp;signals,&nbsp;<i>BPROT[1:0],&nbsp;</i>which indicate&nbsp;instruction&nbsp;or data&nbsp;fetches&nbsp;<br>
and supervisor or user access.&nbsp;<br>
•&nbsp;&nbsp;The transfer&nbsp;size,&nbsp;<i>BSIZE[1:0],&nbsp;</i>specifies&nbsp;a&nbsp;byte,&nbsp;half-word&nbsp;or word&nbsp;transfer.&nbsp;<br>
•&nbsp;&nbsp;Bus lock,&nbsp;<i>BLOK,&nbsp;</i>allows a master to retain the&nbsp;bus to&nbsp;complete an atomic read-&nbsp;<br>
modify-write&nbsp;transaction.&nbsp;<br>
•&nbsp;&nbsp;The data bus,&nbsp;<i>BD[31:0],&nbsp;</i>used&nbsp;to transmit write&nbsp;data&nbsp;and to&nbsp;receive&nbsp;read&nbsp;data.&nbsp;In an&nbsp;<br>
implementation&nbsp;with&nbsp;multiplexed address and&nbsp;data, the&nbsp;address&nbsp;is also&nbsp;transmitted&nbsp;<br>
down this bus.&nbsp;<br>
A&nbsp;slave unit&nbsp;may process the&nbsp;requested transaction immediately, accepting write&nbsp;<br>
data&nbsp;or&nbsp;issuing read&nbsp;data on&nbsp;<i>ED[31:0],&nbsp;</i>or&nbsp;signal&nbsp;one of the&nbsp;following&nbsp;responses:&nbsp;<br>
•&nbsp;&nbsp;Bus wait,&nbsp;<i>BWAIT,&nbsp;</i>allows&nbsp;a slave module to&nbsp;insert&nbsp;wait states when it cannot&nbsp;com&nbsp;<br>
plete the transaction in the&nbsp;current cycle.&nbsp;<br>
•&nbsp;&nbsp;Bus last,&nbsp;<i>BLAST,&nbsp;</i>allows a slave to&nbsp;terminate a sequential&nbsp;burst to force&nbsp;the bus&nbsp;<br>
master to issue a new bus transaction&nbsp;request to continue.&nbsp;<br>
•&nbsp;&nbsp;Bus&nbsp;error,&nbsp;<i>BERROR,&nbsp;</i>indicates&nbsp;a&nbsp;transaction&nbsp;that cannot be completed.&nbsp;If&nbsp;the&nbsp;<br>
master is a processor it&nbsp;should abort the transfer.&nbsp;<br>
<hr>
<A name=231></a><b>The&nbsp;Advanced&nbsp;Microcontroller Bus&nbsp;Architecture&nbsp;(AMBA)</b>&nbsp;<br>
<b>219</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Bus reset&nbsp;<br>
The&nbsp;ASB supports a number&nbsp;of independent&nbsp;on-chip&nbsp;modules,&nbsp;many&nbsp;of&nbsp;which&nbsp;may&nbsp;<br>
be able to&nbsp;drive&nbsp;the data bus (and&nbsp;some&nbsp;control lines). Provided&nbsp;all the modules&nbsp;obey&nbsp;<br>
the bus protocols, there&nbsp;will&nbsp;only be one&nbsp;module driving&nbsp;any bus line at any&nbsp;time.&nbsp;<br>
Immediately after&nbsp;power-on, however,&nbsp;all the&nbsp;modules come up&nbsp;in&nbsp;unknown&nbsp;states.&nbsp;It&nbsp;<br>
takes&nbsp;some&nbsp;time&nbsp;for&nbsp;a clock oscillator to&nbsp;stabilize after power-up,&nbsp;so there may&nbsp;be&nbsp;no&nbsp;<br>
reliable&nbsp;clock&nbsp;available&nbsp;to&nbsp;sequence all&nbsp;the&nbsp;modules&nbsp;into a&nbsp;known&nbsp;state.&nbsp;In any case,&nbsp;<br>
if two or&nbsp;more modules&nbsp;power-up trying to&nbsp;drive bus&nbsp;lines&nbsp;in opposite directions, the&nbsp;<br>
output drive clashes&nbsp;may&nbsp;cause power&nbsp;supply&nbsp;crow-bar&nbsp;problems&nbsp;which&nbsp;may&nbsp;prevent&nbsp;<br>
the chip&nbsp;from&nbsp;powering&nbsp;up properly&nbsp;at&nbsp;all.&nbsp;<br>
Correct ASB&nbsp;power-up is&nbsp;ensured&nbsp;by&nbsp;imposing an&nbsp;asynchronous reset mode that&nbsp;<br>
forces&nbsp;all drivers&nbsp;off the bus independently&nbsp;of&nbsp;the clock.&nbsp;<br>
Test interface&nbsp;<br>
A possible use of the&nbsp;AMBA is to provide support&nbsp;for a&nbsp;modular testing&nbsp;methodol-<br>
ogy&nbsp;through the&nbsp;<i>Test&nbsp;Interface Controller.&nbsp;</i>This&nbsp;approach&nbsp;allows&nbsp;each&nbsp;module&nbsp;on&nbsp;the&nbsp;<br>
AMBA&nbsp;to be&nbsp;tested&nbsp;independently by&nbsp;allowing an external&nbsp;tester to&nbsp;appear&nbsp;as a bus&nbsp;<br>
master&nbsp;on&nbsp;the ASB.&nbsp;<br>
The&nbsp;only requirement for&nbsp;test mode&nbsp;to&nbsp;be&nbsp;supported&nbsp;is&nbsp;that the&nbsp;tester has&nbsp;access to&nbsp;<br>
the ASB through&nbsp;a&nbsp;32-bit bidirectional port.&nbsp;Where a 32-bit&nbsp;bidirectional data bus&nbsp;<br>
interface to&nbsp;external&nbsp;memory or peripheral&nbsp;devices exists,&nbsp;this&nbsp;suffices. Where&nbsp;the&nbsp;<br>
off-chip&nbsp;data&nbsp;interface is only 16&nbsp;or&nbsp;8 bits&nbsp;wide&nbsp;other&nbsp;signals&nbsp;such as address lines&nbsp;are&nbsp;<br>
required&nbsp;to&nbsp;give 32&nbsp;lines&nbsp;for test access.&nbsp;<br>
The test interface&nbsp;allows control of&nbsp;the&nbsp;ASB address and data&nbsp;buses using protocols&nbsp;<br>
defined&nbsp;on the&nbsp;two test request inputs&nbsp;<i>{TREQA&nbsp;</i>and&nbsp;<i>TREQB)&nbsp;</i>and an&nbsp;address latch and&nbsp;<br>
incrementer in the controller. A suitably&nbsp;designed macrocell&nbsp;module&nbsp;can then allow&nbsp;<br>
access&nbsp;to&nbsp;all&nbsp;of&nbsp;its&nbsp;interface&nbsp;signals&nbsp;in&nbsp;groups&nbsp;of&nbsp;up to&nbsp;32 bits.&nbsp;For example, the&nbsp;ARM?&nbsp;<br>
macrocell has a 13-bit control and configuration&nbsp;input, a 32-bit data&nbsp;input,&nbsp;a&nbsp;15-bit&nbsp;<br>
status&nbsp;output and 32-bit address&nbsp;and&nbsp;data outputs.&nbsp;The test vectors are&nbsp;applied&nbsp;and&nbsp;the&nbsp;<br>
responses sensed&nbsp;following&nbsp;a&nbsp;sequence defined by&nbsp;a&nbsp;finite&nbsp;state automata&nbsp;whose&nbsp;state&nbsp;<br>
transitions are&nbsp;controlled&nbsp;by&nbsp;<i>TREQA&nbsp;</i>and&nbsp;<i>TREQB.</i>&nbsp;<br>
The&nbsp;AMBA macrocell&nbsp;test methodology may be compared&nbsp;with the JTAG-based&nbsp;<br>
methodology&nbsp;proposed&nbsp;in&nbsp;'Macrocell&nbsp;testing'&nbsp;on&nbsp;page&nbsp;230.&nbsp;Although&nbsp;perhaps&nbsp;less&nbsp;gen-<br>
eral,&nbsp;the AMBA&nbsp;approach will&nbsp;reduce&nbsp;test&nbsp;cost due its&nbsp;parallel tester&nbsp;interface.&nbsp;<br>
Advanced&nbsp;<br>
The ASB offers a relatively&nbsp;high-performance on-chip interconnect&nbsp;which&nbsp;suits pro-<br>
Peripheral Bus&nbsp;<br>
cessor, memory and peripheral macrocells&nbsp;with some&nbsp;built-in interface sophistication.&nbsp;<br>
For very simple, low-performance peripherals, the&nbsp;overhead of&nbsp;the interface is&nbsp;too&nbsp;<br>
high. The&nbsp;<b>Advanced&nbsp;Peripheral&nbsp;Bus&nbsp;</b>is a simple, static bus&nbsp;which operates as&nbsp;a stub&nbsp;<br>
on an ASB to&nbsp;offer a minimalist&nbsp;interface&nbsp;to&nbsp;very simple&nbsp;peripheral&nbsp;macrocells.&nbsp;<br>
The bus&nbsp;includes address&nbsp;<i>(PADDR[n:0]\&nbsp;</i>the&nbsp;full 32 bits are&nbsp;not usually&nbsp;required)&nbsp;<br>
and read and write&nbsp;data&nbsp;<i>(PRDATA[m:0]&nbsp;</i>and&nbsp;<i>PWDATA[m:0],&nbsp;</i>where&nbsp;<i>m&nbsp;</i>is&nbsp;7, 15 or&nbsp;31)&nbsp;<br>
buses which are&nbsp;no&nbsp;wider than&nbsp;necessary&nbsp;for&nbsp;the connected&nbsp;peripherals, a&nbsp;read/write&nbsp;<br>
direction&nbsp;indicator&nbsp;<i>(PWRITE),&nbsp;</i>individual&nbsp;peripheral select&nbsp;strobes&nbsp;<i>(PSELx)&nbsp;</i>and a&nbsp;<br>
<hr>
<A name=232></a><b>220&nbsp;</b><br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
peripheral&nbsp;timing&nbsp;strobe&nbsp;<i>(PENABLE).&nbsp;</i>APB transfers are&nbsp;timed to&nbsp;<i>PCLK,&nbsp;</i>and&nbsp;all&nbsp;APB&nbsp;<br>
devices&nbsp;are reset with&nbsp;<i>PRESETn.</i>&nbsp;<br>
The&nbsp;address and&nbsp;control signals are&nbsp;all&nbsp;set&nbsp;up&nbsp;and&nbsp;held&nbsp;with&nbsp;respect to&nbsp;the&nbsp;timing&nbsp;<br>
strobe&nbsp;to&nbsp;allow&nbsp;time&nbsp;for local decoding&nbsp;with the&nbsp;select&nbsp;acting as&nbsp;the&nbsp;local&nbsp;enable.&nbsp;<br>
Peripherals which&nbsp;are&nbsp;slave devices based&nbsp;around&nbsp;simple register mapping&nbsp;may be&nbsp;<br>
interfaced directly with&nbsp;minimal logic&nbsp;overhead.&nbsp;<br>
Advanced&nbsp;High- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;AHB&nbsp;is&nbsp;intended&nbsp;to&nbsp;replace the&nbsp;ASB in very&nbsp;high performance&nbsp;systems,&nbsp;<br>
for&nbsp;<br>
performance&nbsp;<br>
example those based on&nbsp;the&nbsp;ARM1020E&nbsp;(described&nbsp;in&nbsp;Section 12.6&nbsp;on page&nbsp;341).&nbsp;<br>
BUS&nbsp;<br>
The following features differentiate&nbsp;the AHB from&nbsp;the ASB:&nbsp;<br>
•&nbsp;&nbsp;It supports split&nbsp;transactions, where&nbsp;a&nbsp;slave with a&nbsp;long response&nbsp;latency&nbsp;can&nbsp;free&nbsp;<br>
up the bus for&nbsp;other transfers&nbsp;while it&nbsp;prepares its data&nbsp;for transmission.&nbsp;<br>
•&nbsp;&nbsp;It uses&nbsp;a single clock edge&nbsp;to&nbsp;control&nbsp;all&nbsp;of&nbsp;its operations, aiding synthesis and&nbsp;<br>
design verification (through&nbsp;the use of&nbsp;static timing&nbsp;analysis&nbsp;and similar&nbsp;tools).&nbsp;<br>
•&nbsp;&nbsp;It uses&nbsp;a centrally&nbsp;multiplexed&nbsp;bus scheme&nbsp;rather than&nbsp;a&nbsp;bidirectional bus with&nbsp;<br>
tristate drivers&nbsp;(see&nbsp;Figure 8.12&nbsp;on page 221).&nbsp;<br>
•&nbsp;&nbsp;It&nbsp;supports&nbsp;wider data bus configurations&nbsp;of&nbsp;64 or 128&nbsp;bits.&nbsp;<br>
The multiplexed&nbsp;bus scheme&nbsp;may appear&nbsp;to&nbsp;introduce&nbsp;a&nbsp;lot of&nbsp;excess wiring,&nbsp;but&nbsp;<br>
bidirectional&nbsp;buses&nbsp;create&nbsp;a&nbsp;number of&nbsp;problems&nbsp;for designers and even&nbsp;more for syn-<br>
thesis&nbsp;systems. For&nbsp;example,&nbsp;as&nbsp;chip&nbsp;feature&nbsp;sizes shrink wire&nbsp;delays&nbsp;begin&nbsp;to&nbsp;domi-<br>
nate&nbsp;performance&nbsp;issues,&nbsp;and&nbsp;unidirectional&nbsp;buses&nbsp;can&nbsp;benefit&nbsp;from&nbsp;the&nbsp;insertion&nbsp;of&nbsp;<br>
repeater&nbsp;drivers that&nbsp;are&nbsp;very hard&nbsp;to add to&nbsp;a&nbsp;bidirectional&nbsp;bus.&nbsp;<br>
8.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The ARM reference peripheral specification&nbsp;<br>
The support&nbsp;for system&nbsp;development described&nbsp;so&nbsp;far in&nbsp;this chapter is principally&nbsp;<br>
aimed at&nbsp;testing and providing low-level&nbsp;access&nbsp;to&nbsp;processor&nbsp;and system&nbsp;state.&nbsp;<br>
AMBA offers&nbsp;a&nbsp;systematic&nbsp;way&nbsp;to&nbsp;connect&nbsp;hardware&nbsp;components&nbsp;together on a&nbsp;chip,&nbsp;<br>
but&nbsp;software&nbsp;development must still start from&nbsp;first&nbsp;principles&nbsp;on each&nbsp;new&nbsp;chip.&nbsp;<br>
If a system&nbsp;developer&nbsp;wishes to start&nbsp;from&nbsp;a higher baseline, for example to base&nbsp;<br>
the software on&nbsp;a particular real-time operating system, then a number of components&nbsp;<br>
must be&nbsp;available&nbsp;to&nbsp;support&nbsp;the&nbsp;basic&nbsp;operating&nbsp;system&nbsp;functions.&nbsp;The&nbsp;<b>ARM refer-</b><br>
<b>ence&nbsp;peripheral&nbsp;specification&nbsp;</b>defines&nbsp;such&nbsp;a&nbsp;basic&nbsp;set&nbsp;of&nbsp;components,&nbsp;providing&nbsp;a&nbsp;<br>
framework within which an&nbsp;operating system&nbsp;can run but&nbsp;leaving full&nbsp;scope&nbsp;for appli-<br>
cation-specific system&nbsp;extensions.&nbsp;<br>
The objective&nbsp;of&nbsp;the reference&nbsp;peripheral&nbsp;specification&nbsp;is&nbsp;to ease the porting&nbsp;of&nbsp;soft-<br>
ware between&nbsp;compliant&nbsp;implementations&nbsp;and thereby raise&nbsp;the&nbsp;level&nbsp;from&nbsp;which soft-<br>
ware development&nbsp;begins on&nbsp;a&nbsp;new system.&nbsp;<br>
<hr>
<A name=233></a><IMG src="index-233_1.png"><br>
<b>The&nbsp;ARM reference peripheral&nbsp;specification</b>&nbsp;<br>
<b>221</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;8.12 &nbsp;&nbsp;</b>AHB multiplexed bus scheme.&nbsp;<br>
Base&nbsp;<br>
The reference peripheral specification&nbsp;defines the&nbsp;following&nbsp;components:&nbsp;<br>
components&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;memory&nbsp;map&nbsp;which allows the base address&nbsp;of&nbsp;the&nbsp;interrupt&nbsp;controller,&nbsp;the&nbsp;<br>
counter timers and&nbsp;the reset&nbsp;controller to&nbsp;vary&nbsp;but defines the offsets of the vari&nbsp;<br>
ous registers from&nbsp;these&nbsp;base addresses.&nbsp;<br>
•&nbsp;&nbsp;An&nbsp;interrupt controller with&nbsp;a&nbsp;defined set of&nbsp;functions, including a defined inter&nbsp;<br>
rupt&nbsp;mechanism&nbsp;for a transmit and receive communications channel (though the&nbsp;<br>
mechanism&nbsp;of&nbsp;the channel&nbsp;itself is not defined).&nbsp;<br>
•&nbsp;&nbsp;A counter timer with&nbsp;various&nbsp;defined&nbsp;functions.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;reset controller&nbsp;with&nbsp;defined boot behaviour,&nbsp;power-on reset&nbsp;detection, a 'wait&nbsp;<br>
for interrupt'&nbsp;pause&nbsp;mode and&nbsp;an identification register.&nbsp;<br>
The particular&nbsp;ARM&nbsp;core used&nbsp;with&nbsp;these components is&nbsp;not specified since this&nbsp;<br>
does&nbsp;not&nbsp;affect&nbsp;the system&nbsp;programmer's&nbsp;model.&nbsp;<br>
<hr>
<A name=234></a><b>222</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Memory map&nbsp;<br>
The system&nbsp;must define the&nbsp;base addresses of the interrupt controller&nbsp;<b>(ICBase),&nbsp;</b>the&nbsp;<br>
counter-timer&nbsp;<b>(CTBase)&nbsp;</b>and&nbsp;the reset and pause controller&nbsp;<b>(RPCBase).</b>&nbsp;<br>
These&nbsp;addresses are&nbsp;not&nbsp;defined&nbsp;by&nbsp;the&nbsp;reference&nbsp;peripheral&nbsp;specification,&nbsp;but&nbsp;all&nbsp;the&nbsp;<br>
addresses of the&nbsp;registers&nbsp;are defined&nbsp;relative&nbsp;to&nbsp;one&nbsp;or&nbsp;other of&nbsp;these&nbsp;base&nbsp;addresses.&nbsp;<br>
Interrupt&nbsp;<br>
The interrupt controller provides a uniform&nbsp;way&nbsp;of&nbsp;enabling, disabling and examin-<br>
controller&nbsp;<br>
ing the status&nbsp;of up to 32 level-sensitive IRQ sources and one FIQ source. Each&nbsp;<br>
interrupt source&nbsp;has a&nbsp;mask&nbsp;bit which enables that source. Memory locations are&nbsp;<br>
defined with fixed&nbsp;offsets from&nbsp;<i>ICBase&nbsp;</i>to examine&nbsp;the unmasked,&nbsp;mask and&nbsp;masked&nbsp;<br>
interrupt&nbsp;status&nbsp;and to&nbsp;set or&nbsp;clear interrupt&nbsp;sources.&nbsp;<br>
Five IRQ sources are&nbsp;defined&nbsp;by&nbsp;the reference peripheral&nbsp;specification,&nbsp;correspond-<br>
ing to&nbsp;the communication&nbsp;receive&nbsp;and transmit&nbsp;functions,&nbsp;one for each counter-timer&nbsp;<br>
and&nbsp;one&nbsp;which&nbsp;can be&nbsp;generated&nbsp;directly&nbsp;by&nbsp;software&nbsp;(principally&nbsp;to enable&nbsp;an FIQ&nbsp;<br>
handler&nbsp;to&nbsp;generate&nbsp;an&nbsp;IRQ).&nbsp;<br>
Counter-timers&nbsp;<br>
Two 16-bit counter-timers are required, though&nbsp;more&nbsp;may be added. These are con-<br>
trolled by&nbsp;registers with&nbsp;fixed&nbsp;offsets relative&nbsp;to&nbsp;<i>CTBase.&nbsp;</i>The&nbsp;counters operate&nbsp;from&nbsp;<br>
the system&nbsp;clock with&nbsp;selectable pre-scaling&nbsp;of 0, 4 or&nbsp;8 bits&nbsp;(so the&nbsp;input frequency&nbsp;<br>
is the system&nbsp;clock frequency divided by&nbsp;1,&nbsp;16 or 256).&nbsp;<br>
Each&nbsp;counter-timer has&nbsp;a&nbsp;control register&nbsp;which selects&nbsp;the&nbsp;pre-scaling,&nbsp;enables&nbsp;or&nbsp;<br>
disables the counter&nbsp;and&nbsp;specifies&nbsp;the&nbsp;mode&nbsp;of&nbsp;operation&nbsp;as&nbsp;free-running&nbsp;or&nbsp;periodic,&nbsp;<br>
and a&nbsp;load&nbsp;register which specifies&nbsp;the value&nbsp;that the&nbsp;count starts&nbsp;from.&nbsp;A&nbsp;write to the&nbsp;<br>
'load'&nbsp;register&nbsp;initializes&nbsp;the&nbsp;count&nbsp;value,&nbsp;which&nbsp;is&nbsp;then&nbsp;decremented&nbsp;to&nbsp;zero&nbsp;when&nbsp;an&nbsp;<br>
interrupt is&nbsp;generated. A&nbsp;write to the 'clear'&nbsp;register clears the&nbsp;interrupt. In&nbsp;<br>
free-running&nbsp;mode&nbsp;the&nbsp;counter&nbsp;continues to&nbsp;decrement past&nbsp;zero,&nbsp;whereas&nbsp;in periodic&nbsp;<br>
mode it&nbsp;is&nbsp;reloaded&nbsp;with&nbsp;the value&nbsp;in&nbsp;the&nbsp;'load'&nbsp;register&nbsp;and&nbsp;decrements&nbsp;from&nbsp;there.&nbsp;<br>
The&nbsp;current&nbsp;count&nbsp;value may&nbsp;be&nbsp;read&nbsp;from&nbsp;the 'value'&nbsp;register&nbsp;at&nbsp;any&nbsp;time.&nbsp;<br>
Reset and&nbsp;pause&nbsp;<br>
The reset and&nbsp;pause&nbsp;controller&nbsp;includes registers which&nbsp;are addressed&nbsp;at&nbsp;fixed&nbsp;offsets&nbsp;<br>
controller&nbsp;<br>
from&nbsp;<i>RPCBase.&nbsp;</i>The&nbsp;readable&nbsp;registers give&nbsp;identification and reset status informa-<br>
tion, including&nbsp;whether or not&nbsp;a power-on reset has&nbsp;occurred.&nbsp;The writeable&nbsp;registers&nbsp;<br>
can set or clear the reset status (though not&nbsp;the power-on reset status bit; this can&nbsp;<br>
only&nbsp;be&nbsp;set&nbsp;by a&nbsp;hardware&nbsp;power-on reset), clear&nbsp;the reset&nbsp;map&nbsp;(for&nbsp;instance to&nbsp;<br>
switch the ROM&nbsp;from&nbsp;location&nbsp;zero,&nbsp;where it&nbsp;is&nbsp;needed after power-on&nbsp;for&nbsp;the&nbsp;ARM&nbsp;<br>
reset&nbsp;vector,&nbsp;to&nbsp;the&nbsp;normal memory&nbsp;map),&nbsp;and&nbsp;put&nbsp;the&nbsp;system&nbsp;into&nbsp;pause mode&nbsp;<br>
where it uses&nbsp;minimal power until an interrupt wakes&nbsp;it up&nbsp;again.&nbsp;<br>
System design&nbsp;<br>
Any&nbsp;ARM system&nbsp;which&nbsp;incorporates&nbsp;this&nbsp;basic set of&nbsp;components&nbsp;can support&nbsp;a suit-<br>
ably configured&nbsp;operating&nbsp;system&nbsp;kernel.&nbsp;System&nbsp;design&nbsp;then&nbsp;consists&nbsp;of adding&nbsp;further&nbsp;<br>
application-specific peripherals&nbsp;and software,&nbsp;building&nbsp;upwards from&nbsp;a functional&nbsp;base.&nbsp;<br>
Since&nbsp;most&nbsp;applications&nbsp;require these components&nbsp;there is&nbsp;little overhead&nbsp;incurred&nbsp;<br>
in using the reference&nbsp;peripheral specification&nbsp;as the starting&nbsp;point for system&nbsp;develop-<br>
ment,&nbsp;and there&nbsp;is&nbsp;considerable&nbsp;benefit&nbsp;in starting from&nbsp;a functional&nbsp;system.&nbsp;<br>
<hr>
<A name=235></a><b>Hardware&nbsp;system&nbsp;prototyping tools&nbsp;</b><br>
<b>223</b>&nbsp;<br>
8.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Hardware system prototyping tools&nbsp;<br>
The task facing today's system-on-chip designer is daunting. The number of gates&nbsp;<br>
on a chip continues to grow at an exponential rate, and is already&nbsp;in the&nbsp;millions.&nbsp;<br>
With the best&nbsp;software design&nbsp;tools available on the&nbsp;market, designers cannot pro-<br>
duce fully tested systems of&nbsp;this complexity&nbsp;within the&nbsp;time-to-market constraints.&nbsp;<br>
The first&nbsp;step&nbsp;towards addressing&nbsp;this&nbsp;problem,&nbsp;as&nbsp;has&nbsp;already been&nbsp;indicated,&nbsp;is to&nbsp;<br>
base&nbsp;a&nbsp;significant&nbsp;proportion&nbsp;of&nbsp;the&nbsp;design&nbsp;on&nbsp;pre-existing&nbsp;design&nbsp;components.&nbsp;Design&nbsp;<br>
reuse can reduce the amount of new design work to a small fraction&nbsp;of the total&nbsp;<br>
number&nbsp;of&nbsp;gates on&nbsp;the&nbsp;chip.&nbsp;A&nbsp;systematic&nbsp;approach&nbsp;to&nbsp;on-chip&nbsp;interconnect&nbsp;through&nbsp;<br>
the&nbsp;use&nbsp;of&nbsp;a&nbsp;bus such&nbsp;as AMBA further reduces&nbsp;the&nbsp;design&nbsp;task. However,&nbsp;there&nbsp;are&nbsp;<br>
still&nbsp;difficult&nbsp;problems to be solved, such as:&nbsp;<br>
•&nbsp;&nbsp;How can the designer&nbsp;be&nbsp;sure&nbsp;that&nbsp;all of&nbsp;the selected&nbsp;re-usable blocks,&nbsp;which&nbsp;may&nbsp;<br>
come&nbsp;from&nbsp;various sources,&nbsp;will&nbsp;really&nbsp;work&nbsp;together&nbsp;correctly?&nbsp;<br>
•&nbsp;&nbsp;How can the designer be sure&nbsp;that the&nbsp;specified system&nbsp;meets the&nbsp;performance&nbsp;<br>
requirements,&nbsp;which often&nbsp;include complex&nbsp;real-time issues?&nbsp;<br>
•&nbsp;&nbsp;How&nbsp;can the&nbsp;software&nbsp;designers&nbsp;progress&nbsp;their&nbsp;work&nbsp;before&nbsp;the chip&nbsp;is&nbsp;available?&nbsp;<br>
Simulating the&nbsp;system&nbsp;using software tools usually results&nbsp;in&nbsp;a&nbsp;performance that&nbsp;is&nbsp;<br>
several orders&nbsp;of&nbsp;magnitude lower than&nbsp;that&nbsp;of&nbsp;the final system, rendering software&nbsp;<br>
development and full system&nbsp;verification&nbsp;impractical.&nbsp;<br>
A solution&nbsp;that&nbsp;goes&nbsp;a considerable&nbsp;way towards addressing all&nbsp;these&nbsp;issues is&nbsp;the&nbsp;<br>
use&nbsp;of&nbsp;hardware&nbsp;prototyping:&nbsp;building a&nbsp;hardware&nbsp;system&nbsp;that&nbsp;combines&nbsp;all&nbsp;of&nbsp;the&nbsp;<br>
required components&nbsp;in&nbsp;a form&nbsp;that makes no attempt to meet&nbsp;the&nbsp;power and size&nbsp;con-<br>
straints of the final system,&nbsp;but&nbsp;does&nbsp;provide a platform&nbsp;for system&nbsp;verification&nbsp;and&nbsp;<br>
software development. The&nbsp;ARM 'Integrator'&nbsp;is one&nbsp;such&nbsp;system; another is the&nbsp;<br>
'Rapid Silicon&nbsp;Prototyping'&nbsp;system&nbsp;from&nbsp;VLSI Technology,&nbsp;Inc.&nbsp;<br>
Rapid&nbsp;Silicon&nbsp;<br>
VLSI&nbsp;Technology,&nbsp;Inc.,&nbsp;have&nbsp;introduced&nbsp;a&nbsp;development&nbsp;system&nbsp;called&nbsp;'Rapid&nbsp;Silicon&nbsp;<br>
Prototyping&nbsp;<br>
Prototyping'.&nbsp;The&nbsp;basis&nbsp;of&nbsp;this&nbsp;system&nbsp;is to use&nbsp;specially&nbsp;developed&nbsp;reference chips,&nbsp;<br>
each offering&nbsp;a particular plentiful&nbsp;set of&nbsp;on-chip&nbsp;components&nbsp;and&nbsp;support&nbsp;for&nbsp;<br>
off-chip extensions,&nbsp;which can&nbsp;be&nbsp;used&nbsp;to&nbsp;prototype&nbsp;a&nbsp;system-on-chip&nbsp;design.&nbsp;The&nbsp;<br>
target&nbsp;system&nbsp;is&nbsp;modelled in&nbsp;two&nbsp;steps:&nbsp;<br>
1.&nbsp;&nbsp;The selected reference chip is&nbsp;'deconfigured'&nbsp;to render those on-chip blocks that&nbsp;<br>
are not&nbsp;required in the target&nbsp;system&nbsp;inactive.&nbsp;<br>
2.&nbsp;&nbsp;The blocks&nbsp;required&nbsp;in the target&nbsp;system&nbsp;that&nbsp;are&nbsp;not available on&nbsp;the&nbsp;reference&nbsp;chip are&nbsp;<br>
implemented as off-chip extensions. These may be either existing integrated circuits&nbsp;<br>
with the necessary&nbsp;functionality&nbsp;or FPGAs configured to&nbsp;the&nbsp;required function (usu&nbsp;<br>
ally&nbsp;by&nbsp;synthesis from&nbsp;a high-level language such as VHDL).&nbsp;<br>
<hr>
<A name=236></a><IMG src="index-236_1.png"><br>
<b>224</b>&nbsp;<br>
<b>Architectural Support for System Development</b>&nbsp;<br>
The use of pre-existing&nbsp;blocks, interconnected using standard buses such as&nbsp;<br>
AMBA,&nbsp;minimizes the technical risk in producing the final chip. All of&nbsp;the blocks&nbsp;<br>
in the reference chip exist as&nbsp;synthesizable&nbsp;components. The high-level language&nbsp;<br>
descriptions of&nbsp;the required&nbsp;functions&nbsp;are taken together&nbsp;with the&nbsp;high-level lan-<br>
guage source&nbsp;used to configure the FPGAs, the deconfigured functions are dis-<br>
carded, and&nbsp;the&nbsp;result&nbsp;resynthesized&nbsp;to&nbsp;give&nbsp;the&nbsp;target&nbsp;chip.&nbsp;This&nbsp;process&nbsp;is&nbsp;<br>
illustrated in Figure 8.13.&nbsp;<br>
It&nbsp;is&nbsp;clear&nbsp;that this&nbsp;approach depends on the reference chip&nbsp;containing&nbsp;appro-<br>
priate&nbsp;key&nbsp;components, such&nbsp;as&nbsp;the CPU&nbsp;core&nbsp;and&nbsp;possibly&nbsp;a&nbsp;signal&nbsp;processing&nbsp;<br>
system&nbsp;(where this is demanded by&nbsp;the target application). Although&nbsp;in&nbsp;principle&nbsp;<br>
it might&nbsp;be&nbsp;possible&nbsp;to&nbsp;build&nbsp;a&nbsp;single&nbsp;reference&nbsp;chip&nbsp;that&nbsp;contains&nbsp;every&nbsp;different&nbsp;<br>
ARM processor&nbsp;core (including&nbsp;all the&nbsp;different&nbsp;cache&nbsp;and&nbsp;MMU&nbsp;configura-<br>
tions),&nbsp;in&nbsp;practice&nbsp;such a chip would not&nbsp;be&nbsp;economic even for prototyping&nbsp;pur-<br>
poses.&nbsp;The success of&nbsp;the&nbsp;approach&nbsp;therefore&nbsp;depends&nbsp;on a&nbsp;careful choice&nbsp;of the&nbsp;<br>
components&nbsp;on&nbsp;the&nbsp;reference chip&nbsp;to&nbsp;ensure&nbsp;that&nbsp;it&nbsp;can&nbsp;cover&nbsp;a wide&nbsp;spread&nbsp;of&nbsp;<br>
systems, and&nbsp;different&nbsp;reference&nbsp;chips with&nbsp;different&nbsp;CPU&nbsp;and other&nbsp;key&nbsp;cores&nbsp;<br>
being&nbsp;built&nbsp;for&nbsp;different&nbsp;application&nbsp;domains.&nbsp;<br>
<b>Figure 8.13&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Rapid Silicon&nbsp;Prototyping&nbsp;principle.<br>
<hr>
<A name=237></a><b>The ARMulator&nbsp;</b><br>
<b>225</b>&nbsp;<br>
8.5 &nbsp; The&nbsp;ARMulator&nbsp;<br>
The ARMulator is part&nbsp;of&nbsp;the cross-development toolkit described in&nbsp;Section 2.4 on&nbsp;<br>
page&nbsp;43. It is a software&nbsp;emulator&nbsp;of&nbsp;the ARM&nbsp;processor which supports&nbsp;the&nbsp;debug-<br>
ging and evaluation&nbsp;of&nbsp;ARM&nbsp;code without&nbsp;requiring&nbsp;an&nbsp;ARM&nbsp;processor&nbsp;chip.&nbsp;<br>
The&nbsp;ARMulator has&nbsp;a&nbsp;role&nbsp;in&nbsp;embedded&nbsp;system&nbsp;design.&nbsp;It&nbsp;supports&nbsp;the high-level&nbsp;<br>
prototyping&nbsp;of various parts of&nbsp;the system&nbsp;to support the development of software and&nbsp;<br>
the&nbsp;evaluation&nbsp;of architectural&nbsp;alternatives.&nbsp;It&nbsp;is made&nbsp;up&nbsp;of four&nbsp;components:&nbsp;<br>
•&nbsp;&nbsp;The processor&nbsp;core&nbsp;model, which can emulate any current&nbsp;ARM core, including&nbsp;<br>
the Thumb instruction&nbsp;set.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;memory interface&nbsp;which&nbsp;allows the characteristics of&nbsp;the target&nbsp;memory&nbsp;<br>
system&nbsp;to be modelled. Various models&nbsp;are supplied&nbsp;to&nbsp;support&nbsp;rapid prototyping,&nbsp;<br>
but the interface is&nbsp;fully customizable&nbsp;to incorporate the level of detail&nbsp;required.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;coprocessor interface&nbsp;that supports&nbsp;custom&nbsp;coprocessor models.&nbsp;<br>
•&nbsp;&nbsp;An&nbsp;operating&nbsp;system&nbsp;interface that&nbsp;allows&nbsp;individual system&nbsp;calls to&nbsp;be&nbsp;handled by&nbsp;<br>
the&nbsp;host&nbsp;or emulated&nbsp;on&nbsp;the&nbsp;ARM&nbsp;model.&nbsp;<br>
The processor core&nbsp;model incorporates the&nbsp;remote debug interface,&nbsp;so the proces-<br>
sor and&nbsp;system&nbsp;state&nbsp;are&nbsp;visible&nbsp;from&nbsp;ARMsd,&nbsp;the&nbsp;ARM&nbsp;symbolic&nbsp;debugger.&nbsp;Programs&nbsp;<br>
can be&nbsp;loaded,&nbsp;run&nbsp;and&nbsp;debugged&nbsp;through this&nbsp;interface.&nbsp;<br>
System&nbsp;<br>
Using the ARMulator it is&nbsp;possible to build a complete, clock-cycle&nbsp;accurate&nbsp;<br>
modelling&nbsp;<br>
software model of&nbsp;a system&nbsp;including a&nbsp;cache,&nbsp;MMU,&nbsp;physical&nbsp;memory, periph-&nbsp;<br>
eral devices,&nbsp;operating system&nbsp;and software. Since this is likely&nbsp;to be the&nbsp;<br>
highest-level&nbsp;model of the system, it is the best&nbsp;place to perform&nbsp;the initial&nbsp;<br>
evaluation&nbsp;of design alternatives.&nbsp;<br>
Once&nbsp;the design&nbsp;is&nbsp;reasonably&nbsp;stable,&nbsp;hardware development&nbsp;will&nbsp;probably&nbsp;move&nbsp;<br>
into a timing-accurate CAD environment,&nbsp;but software development can continue&nbsp;<br>
using the ARMulator-based&nbsp;model (probably&nbsp;moving&nbsp;up&nbsp;from&nbsp;cycle- to&nbsp;<br>
instruction-accurate timing for higher performance).&nbsp;<br>
In the&nbsp;course of&nbsp;the&nbsp;detailed hardware design it&nbsp;is likely&nbsp;that&nbsp;some&nbsp;of&nbsp;the&nbsp;<br>
timing assumptions&nbsp;built&nbsp;into&nbsp;the&nbsp;original&nbsp;software&nbsp;model&nbsp;prove&nbsp;impossible&nbsp;to&nbsp;<br>
meet. As the design evolves it is important to keep&nbsp;the&nbsp;software&nbsp;model in step so&nbsp;<br>
that the software development is based on&nbsp;the&nbsp;most accurate estimates of timing&nbsp;<br>
that are available.&nbsp;<br>
It is now common for complex systems development to be supported&nbsp;by&nbsp;mul-<br>
tiple&nbsp;computer&nbsp;models of the&nbsp;target system&nbsp;built&nbsp;upon&nbsp;different levels&nbsp;of&nbsp;abstrac-<br>
tion. Unless the lower-level&nbsp;models are synthesized automatically from&nbsp;the&nbsp;more&nbsp;<br>
abstract&nbsp;models, maintaining consistency&nbsp;between&nbsp;the&nbsp;models always&nbsp;takes con-<br>
siderable&nbsp;care&nbsp;and effort.&nbsp;<br>
<hr>
<A name=238></a><IMG src="index-238_1.png"><br>
<b>226</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;8.6 &nbsp; The&nbsp;JTAG&nbsp;boundary&nbsp;scan test&nbsp;architecture&nbsp;<br>
&nbsp;<br>
Two&nbsp;difficult&nbsp;areas&nbsp;in&nbsp;the development of&nbsp;a product&nbsp;based&nbsp;around&nbsp;an application&nbsp;<br>
specific embedded&nbsp;system&nbsp;chip&nbsp;are the&nbsp;production testing&nbsp;of&nbsp;the&nbsp;VLSI component&nbsp;<br>
and&nbsp;the production&nbsp;testing&nbsp;of&nbsp;the&nbsp;assembled&nbsp;printed&nbsp;circuit board.&nbsp;<br>
The second of these&nbsp;is&nbsp;addressed by&nbsp;the IEEE standard number 1149, 'Standard Test&nbsp;<br>
Access Port&nbsp;and Boundary-Scan Architecture'. This&nbsp;standard describes a&nbsp;5-pin serial&nbsp;<br>
protocol&nbsp;for accessing and&nbsp;controlling the signal&nbsp;levels&nbsp;on&nbsp;the pins&nbsp;of&nbsp;a&nbsp;digital&nbsp;circuit,&nbsp;<br>
and has extensions for testing the circuitry&nbsp;on the chip&nbsp;itself. The standard was devel-<br>
oped&nbsp;by&nbsp;the&nbsp;<i>Joint Test Action&nbsp;Group&nbsp;</i>(hence&nbsp;JTAG), and the architecture described&nbsp;by&nbsp;<br>
the standard is&nbsp;known either as 'JTAG boundary scan'&nbsp;or as 'IEEE 1149'.&nbsp;<br>
The general structure of the JTAG boundary scan test interface is&nbsp;shown in&nbsp;<br>
Figure&nbsp;8.14.&nbsp;All the signals between&nbsp;the core&nbsp;logic and the&nbsp;pins are intercepted by the&nbsp;<br>
serial&nbsp;scan path&nbsp;which can connect&nbsp;the core&nbsp;logic&nbsp;to&nbsp;the pins&nbsp;in&nbsp;normal operating&nbsp;<br>
mode, or can read out the&nbsp;original value and replace it with&nbsp;a new&nbsp;value in&nbsp;test&nbsp;mode.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;8.14 &nbsp;&nbsp;</b>JTAG boundary&nbsp;scan organization.<br>
<hr>
<A name=239></a><b>The&nbsp;JTAG&nbsp;boundary&nbsp;scan test&nbsp;architecture</b>&nbsp;<br>
<b>227</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Test signals&nbsp;<br>
The interface&nbsp;works with five dedicated&nbsp;signals which must&nbsp;be&nbsp;provided&nbsp;on each&nbsp;<br>
chip that&nbsp;supports the test&nbsp;standard:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
•&nbsp;&nbsp;<i>TRST&nbsp;</i>is&nbsp;a&nbsp;test&nbsp;reset input&nbsp;which initializes&nbsp;the test&nbsp;interface.&nbsp;<br>
•&nbsp;&nbsp;<i>TCK&nbsp;</i>is the&nbsp;test&nbsp;clock which&nbsp;controls&nbsp;the timing of the&nbsp;test interface&nbsp;independ&nbsp;<br>
ently from&nbsp;any system&nbsp;clocks.&nbsp;<br>
•&nbsp;&nbsp;<i>TMS&nbsp;</i>is&nbsp;the&nbsp;test mode&nbsp;select&nbsp;which controls&nbsp;the&nbsp;operation&nbsp;of&nbsp;the&nbsp;test&nbsp;interface state&nbsp;<br>
machine.&nbsp;<br>
•&nbsp;&nbsp;<i>TDI&nbsp;</i>is the&nbsp;test&nbsp;data&nbsp;input&nbsp;line&nbsp;which supplies the data&nbsp;to&nbsp;the&nbsp;boundary&nbsp;scan&nbsp;or&nbsp;<br>
instruction registers.&nbsp;<br>
•&nbsp;&nbsp;<i>TDO&nbsp;</i>is&nbsp;the test data output line which carries&nbsp;the sampled values from&nbsp;the&nbsp;<br>
boundary scan&nbsp;chain&nbsp;and&nbsp;propagates data to the next&nbsp;chip&nbsp;in&nbsp;the&nbsp;serial&nbsp;test circuit.&nbsp;<br>
The normal organization of&nbsp;the test circuit&nbsp;on a board that incorporates&nbsp;several&nbsp;<br>
chips&nbsp;with&nbsp;JTAG support&nbsp;is&nbsp;to&nbsp;connect&nbsp;<i>TRST, TCK&nbsp;</i>and&nbsp;<i>TMS&nbsp;</i>to every chip&nbsp;in&nbsp;parallel&nbsp;<br>
and to&nbsp;connect&nbsp;<i>TDO&nbsp;</i>from&nbsp;one chip&nbsp;to&nbsp;<i>TDI&nbsp;</i>of&nbsp;the next in&nbsp;a single loop,&nbsp;so the board&nbsp;<br>
test&nbsp;interface&nbsp;has the&nbsp;same&nbsp;five&nbsp;signals listed above.&nbsp;<br>
TAP controller&nbsp;<br>
The&nbsp;operation of&nbsp;the&nbsp;test interface&nbsp;is controlled by&nbsp;the&nbsp;Test&nbsp;Access&nbsp;Port&nbsp;(TAP) con-<br>
troller. This is a state&nbsp;machine whose state transitions are controlled by&nbsp;<i>TMS;&nbsp;</i>the&nbsp;<br>
state&nbsp;transition&nbsp;diagram&nbsp;is&nbsp;shown&nbsp;in&nbsp;Figure 8.15&nbsp;on&nbsp;page&nbsp;228. All the&nbsp;states have two&nbsp;<br>
exits&nbsp;so&nbsp;the transitions&nbsp;can&nbsp;be&nbsp;controlled by&nbsp;one&nbsp;signal,&nbsp;<i>TMS.&nbsp;</i>The&nbsp;two&nbsp;main&nbsp;paths&nbsp;in&nbsp;<br>
the state&nbsp;transition diagram&nbsp;control&nbsp;the operation&nbsp;of&nbsp;a&nbsp;data&nbsp;register&nbsp;(DR)&nbsp;and the&nbsp;<br>
instruction register&nbsp;(IR).&nbsp;<br>
Data registers&nbsp;<br>
The behaviour of a&nbsp;particular&nbsp;chip&nbsp;is determined by&nbsp;the&nbsp;contents of the&nbsp;test instruc-<br>
tion register, which can&nbsp;select&nbsp;between&nbsp;various&nbsp;different&nbsp;data&nbsp;registers:&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;device&nbsp;ID&nbsp;register reads&nbsp;out an&nbsp;identification&nbsp;number which&nbsp;is&nbsp;hard-wired&nbsp;<br>
into the&nbsp;chip.&nbsp;<br>
•&nbsp;&nbsp;The bypass register connects&nbsp;<i>TDI to&nbsp;TDO&nbsp;</i>with a 1-clock&nbsp;delay&nbsp;to give the tester&nbsp;<br>
rapid access&nbsp;to&nbsp;another device in&nbsp;the test loop on the&nbsp;same&nbsp;board.&nbsp;<br>
•&nbsp;&nbsp;The boundary&nbsp;scan register intercepts all the signals between the core logic and&nbsp;<br>
the&nbsp;pins&nbsp;and&nbsp;comprises&nbsp;the individual&nbsp;register&nbsp;bits&nbsp;which are shown as&nbsp;the&nbsp;squares&nbsp;<br>
connected to&nbsp;the core logic&nbsp;in Figure 8.14&nbsp;on page 226.&nbsp;<br>
•&nbsp;&nbsp;Other&nbsp;registers&nbsp;may&nbsp;be&nbsp;employed on&nbsp;the chip&nbsp;to&nbsp;test&nbsp;other&nbsp;functions as&nbsp;required.&nbsp;<br>
Instructions&nbsp;<br>
The normal&nbsp;operation&nbsp;of&nbsp;a&nbsp;JTAG&nbsp;test&nbsp;system&nbsp;is&nbsp;to&nbsp;enter an&nbsp;instruction&nbsp;which&nbsp;speci-<br>
fies the sort of&nbsp;test to&nbsp;be&nbsp;carried out next&nbsp;and&nbsp;the&nbsp;data&nbsp;register&nbsp;to be&nbsp;used&nbsp;for&nbsp;that&nbsp;test&nbsp;<br>
into the&nbsp;<i>instruction&nbsp;</i>register, and then to use&nbsp;the data&nbsp;register to&nbsp;carry out the test.&nbsp;<br>
Instructions&nbsp;may&nbsp;be public or private. Public&nbsp;instructions are&nbsp;declared and available&nbsp;<br>
for general test use, and the standard&nbsp;specifies a&nbsp;minimum&nbsp;set of&nbsp;public instructions&nbsp;<br>
<hr>
<A name=240></a><IMG src="index-240_1.png"><br>
<b>228</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 8.15&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Test Access&nbsp;Port (TAP)&nbsp;controller state transition diagram.&nbsp;<br>
that must be supported&nbsp;by&nbsp;all devices&nbsp;that&nbsp;comply with&nbsp;the standard.&nbsp;Private&nbsp;instruc-<br>
tions&nbsp;are for specialized&nbsp;on-chip test&nbsp;purposes and&nbsp;the standard does&nbsp;not specify&nbsp;how&nbsp;<br>
these&nbsp;should&nbsp;operate&nbsp;or how they&nbsp;should&nbsp;be&nbsp;used.&nbsp;<br>
Public&nbsp;<br>
The&nbsp;minimum&nbsp;set of&nbsp;public instructions&nbsp;that&nbsp;all compliant devices&nbsp;must&nbsp;support is:&nbsp;<br>
instructions&nbsp;<br>
•&nbsp;BYPASS:&nbsp;here the device connects&nbsp;<i>TDIto TOO&nbsp;</i>though a single&nbsp;clock delay.&nbsp;This&nbsp;<br>
instruction exists to&nbsp;facilitate&nbsp;the testing of&nbsp;other devices in&nbsp;the same&nbsp;test loop.&nbsp;<br>
<hr>
<A name=241></a><b>The&nbsp;JTAG&nbsp;boundary&nbsp;scan test&nbsp;architecture</b>&nbsp;<br>
<b>229</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
•&nbsp;&nbsp;EXTEST: here&nbsp;the&nbsp;boundary&nbsp;scan register is&nbsp;connected&nbsp;between&nbsp;<i>TDI&nbsp;</i>and&nbsp;<i>TOO&nbsp;</i>and&nbsp;<br>
the pin states are captured and controlled&nbsp;by the register. Referring to the state&nbsp;<br>
transition diagram&nbsp;in&nbsp;Figure&nbsp;8.15 on page 228, the pin states are captured in the&nbsp;<br>
<i>Capture DR&nbsp;</i>state and shifted out of the register via the&nbsp;<i>TDO&nbsp;</i>pin in the&nbsp;<i>Shift DR&nbsp;</i><br>
state. As the captured&nbsp;data is&nbsp;shifted out, new data is shifted in&nbsp;via the&nbsp;<i>TDI&nbsp;</i>pin,&nbsp;<br>
and this data is&nbsp;applied&nbsp;to&nbsp;the boundary&nbsp;scan register outputs&nbsp;(and hence the&nbsp;<br>
output pins) in&nbsp;the&nbsp;<i>Update DR&nbsp;</i>state.&nbsp;This instruction exists to support the&nbsp;testing&nbsp;<br>
of&nbsp;board-level connectivity.&nbsp;<br>
•&nbsp;&nbsp;IDCODE: here the ID register is connected between&nbsp;<i>TDI&nbsp;</i>and&nbsp;<i>TDO.&nbsp;</i>In the&nbsp;<br>
<i>Capture DR&nbsp;</i>state the&nbsp;device&nbsp;ID (a hard-wired identification number giving the&nbsp;<br>
manufacturer,&nbsp;part&nbsp;number and&nbsp;version&nbsp;of&nbsp;the&nbsp;part)&nbsp;is&nbsp;copied&nbsp;into&nbsp;the&nbsp;register&nbsp;<br>
which is then shifted&nbsp;out&nbsp;in&nbsp;the&nbsp;<i>Shift DR&nbsp;</i>state.&nbsp;<br>
Other public&nbsp;instructions may include:&nbsp;<br>
•&nbsp;&nbsp;INTEST: here&nbsp;the boundary&nbsp;scan&nbsp;register&nbsp;is&nbsp;connected&nbsp;between&nbsp;<i>TDI&nbsp;</i>and&nbsp;<i>TDO&nbsp;</i>and&nbsp;<br>
the core logic input and output states&nbsp;are captured and&nbsp;controlled by&nbsp;the&nbsp;register.&nbsp;<br>
Note that the inputs are driven to the complement of&nbsp;the values supplied. Other&nbsp;<br>
wise the operation is similar&nbsp;to EXTEST. This instruction&nbsp;exists to support the&nbsp;<br>
testing of&nbsp;the core logic.&nbsp;<br>
PCB testing&nbsp;<br>
The principal&nbsp;goal of the&nbsp;JTAG test circuit&nbsp;is to enable the continuity&nbsp;of tracks and&nbsp;<br>
the&nbsp;connectivity of&nbsp;solder connections&nbsp;on&nbsp;printed&nbsp;circuit&nbsp;boards&nbsp;<i>(PCBs)&nbsp;</i>to be&nbsp;tested.&nbsp;<br>
This has become&nbsp;difficult since the introduction of surface&nbsp;mount packages which&nbsp;<br>
do not require through-holes in the circuit&nbsp;board. Previously&nbsp;'bed of nails'&nbsp;testers&nbsp;<br>
could contact&nbsp;all the pins on each 1C package from&nbsp;the back of the PCB to check&nbsp;<br>
continuity; surface mount&nbsp;packages&nbsp;typically&nbsp;have the pins closer together and&nbsp;the&nbsp;<br>
tracks accessible&nbsp;only&nbsp;on&nbsp;the&nbsp;component&nbsp;side&nbsp;of the&nbsp;board,&nbsp;making&nbsp;the&nbsp;'bed&nbsp;of nails'&nbsp;<br>
approach inapplicable.&nbsp;<br>
When&nbsp;the surface mount&nbsp;components have&nbsp;a JTAG test&nbsp;interface,&nbsp;this&nbsp;can&nbsp;be&nbsp;used&nbsp;<br>
(using&nbsp;the EXTEST instruction)&nbsp;to&nbsp;control&nbsp;outputs&nbsp;and observe inputs independently&nbsp;<br>
of the&nbsp;normal function&nbsp;of the&nbsp;chip, so&nbsp;board-level&nbsp;connectivity&nbsp;can readily&nbsp;be checked&nbsp;<br>
from&nbsp;chip&nbsp;to&nbsp;chip.&nbsp;If the&nbsp;board also&nbsp;contains&nbsp;components&nbsp;which&nbsp;do&nbsp;not&nbsp;have&nbsp;a&nbsp;JTAG&nbsp;<br>
interface&nbsp;these&nbsp;will&nbsp;require 'bed&nbsp;of&nbsp;nails'&nbsp;contacts,&nbsp;but these&nbsp;can be&nbsp;used&nbsp;together&nbsp;with&nbsp;<br>
the JTAG interfaces where available&nbsp;to&nbsp;minimize the cost and difficulty of building the&nbsp;<br>
production&nbsp;test&nbsp;equipment.&nbsp;<br>
VLSI&nbsp;testing&nbsp;<br>
High-complexity integrated&nbsp;circuits&nbsp;require&nbsp;extensive production testing to identify&nbsp;<br>
faulty&nbsp;devices&nbsp;before&nbsp;they&nbsp;get built&nbsp;into&nbsp;product.&nbsp;A production 1C tester is a very&nbsp;<br>
expensive&nbsp;piece of equipment, and&nbsp;the time&nbsp;each device&nbsp;spends on&nbsp;the&nbsp;tester&nbsp;is&nbsp;an&nbsp;<br>
important&nbsp;factor in its&nbsp;manufacturing&nbsp;cost.&nbsp;Since the JTAG&nbsp;test circuitry operates&nbsp;<br>
through&nbsp;serial access,&nbsp;it is not&nbsp;a high-speed&nbsp;way to&nbsp;apply&nbsp;test&nbsp;vectors to&nbsp;the&nbsp;core&nbsp;<br>
<hr>
<A name=242></a>&nbsp;<br>
<b>230</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
logic.&nbsp;Furthermore, it is not&nbsp;possible to apply&nbsp;test vectors through&nbsp;the JTAG port at&nbsp;<br>
the normal operating&nbsp;speed&nbsp;of the device to check its performance.&nbsp;<br>
Therefore&nbsp;the&nbsp;JTAG architecture&nbsp;is not&nbsp;a generic&nbsp;solution&nbsp;to all&nbsp;the problems&nbsp;of&nbsp;<br>
VLSI production&nbsp;testing. However, it&nbsp;can solve&nbsp;a number of problems:&nbsp;<br>
•&nbsp;&nbsp;The JTAG port can be&nbsp;used for in-circuit functional testing of an 1C&nbsp;(provided&nbsp;<br>
that&nbsp;the INTEST instruction&nbsp;is supported).&nbsp;<br>
•&nbsp;&nbsp;It gives good control of the 1C pins for parametric testing&nbsp;(checking the drive of&nbsp;<br>
the output buffers, leakage, input&nbsp;thresholds, and&nbsp;so on).&nbsp;This uses only&nbsp;the&nbsp;<br>
EXTEST&nbsp;instruction&nbsp;which is required&nbsp;on&nbsp;all JTAG compliant&nbsp;devices.&nbsp;<br>
•&nbsp;&nbsp;It&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;access&nbsp;internal&nbsp;scan&nbsp;paths to&nbsp;improve&nbsp;the&nbsp;controllability and&nbsp;<br>
observability&nbsp;of&nbsp;internal&nbsp;nodes that&nbsp;are hard&nbsp;to access from&nbsp;the pins.&nbsp;<br>
•&nbsp;&nbsp;It can be used&nbsp;to give access&nbsp;to on-chip debug functions with no additional pins&nbsp;<br>
and without interfering&nbsp;with&nbsp;the system&nbsp;functions.&nbsp;This is exploited by&nbsp;the ARM&nbsp;<br>
EmbeddedlCE&nbsp;debug architecture described briefly&nbsp;below and in&nbsp;detail in&nbsp;<br>
Section 8.7 on&nbsp;page&nbsp;232.&nbsp;<br>
•&nbsp;&nbsp;It offers&nbsp;an approach&nbsp;to&nbsp;the functional testing of&nbsp;macrocell-based designs as&nbsp;<br>
described below.&nbsp;<br>
These uses&nbsp;are all in&nbsp;addition to&nbsp;its principal&nbsp;purpose,&nbsp;which is&nbsp;in the production&nbsp;<br>
testing&nbsp;of printed&nbsp;circuit boards.&nbsp;<br>
Embedded-ICE&nbsp;<br>
The&nbsp;ARM&nbsp;debug architecture, described in&nbsp;Section&nbsp;8.7&nbsp;on&nbsp;page 232, is based on&nbsp;an&nbsp;<br>
extension&nbsp;of&nbsp;the JTAG test&nbsp;port. The&nbsp;EmbeddedlCE&nbsp;module introduces breakpoint&nbsp;<br>
and watchpoint&nbsp;registers which&nbsp;are&nbsp;accessed&nbsp;as&nbsp;additional&nbsp;data registers using spe-<br>
cial&nbsp;JTAG&nbsp;instructions,&nbsp;and&nbsp;a&nbsp;trace&nbsp;buffer which&nbsp;is similarly accessed.&nbsp;The scan&nbsp;path&nbsp;<br>
around the ARM core&nbsp;macrocell is used&nbsp;to introduce instructions into&nbsp;the ARM&nbsp;<br>
pipeline&nbsp;without interfering with other parts of&nbsp;the&nbsp;system&nbsp;and&nbsp;these&nbsp;instructions&nbsp;can&nbsp;<br>
be&nbsp;used&nbsp;to&nbsp;access and&nbsp;modify the&nbsp;ARM&nbsp;and&nbsp;system&nbsp;state.&nbsp;<br>
The&nbsp;debug architecture&nbsp;gives&nbsp;most of the functionality&nbsp;of&nbsp;a&nbsp;conventional&nbsp;In-Circuit&nbsp;<br>
Emulation system&nbsp;to&nbsp;debug&nbsp;an&nbsp;ARM&nbsp;macrocell&nbsp;on&nbsp;a&nbsp;complex system&nbsp;chip,&nbsp;and since&nbsp;<br>
the JTAG test&nbsp;access&nbsp;port is&nbsp;used to&nbsp;control&nbsp;the debug&nbsp;hardware, no&nbsp;additional pins are&nbsp;<br>
required on the chip.&nbsp;<br>
Macrocell&nbsp;testing&nbsp;&nbsp;A growing trend in the&nbsp;design&nbsp;of complex&nbsp;system&nbsp;chips is&nbsp;to incorporate a number&nbsp;<br>
of&nbsp;complex, pre-designed macrocells,&nbsp;together with some&nbsp;application-specific&nbsp;<br>
custom&nbsp;logic.&nbsp;The&nbsp;ARM&nbsp;processor core&nbsp;is itself&nbsp;one&nbsp;such&nbsp;macrocell;&nbsp;the&nbsp;others&nbsp;may&nbsp;<br>
come&nbsp;from&nbsp;ARM Limited,&nbsp;a semiconductor partner&nbsp;or some&nbsp;third party&nbsp;supplier.&nbsp;<br>
In such cases&nbsp;the designer of the system&nbsp;chip will have&nbsp;limited knowledge of the&nbsp;<br>
macrocells&nbsp;and will depend&nbsp;on the&nbsp;macrocell suppliers&nbsp;for the production test pat-<br>
terns for&nbsp;each&nbsp;macrocell.&nbsp;<br>
<hr>
<A name=243></a><IMG src="index-243_1.png"><br>
<b>The&nbsp;JTAG&nbsp;boundary&nbsp;scan test&nbsp;architecture</b>&nbsp;<br>
<b>231</b>&nbsp;<br>
Since&nbsp;the macrocells&nbsp;are&nbsp;buried within&nbsp;the&nbsp;system&nbsp;chip,&nbsp;the&nbsp;designer&nbsp;is&nbsp;faced with&nbsp;<br>
the&nbsp;problem&nbsp;of&nbsp;devising a&nbsp;way to apply&nbsp;the supplied test vectors to&nbsp;each&nbsp;of the&nbsp;<br>
macro-cells&nbsp;in&nbsp;turn. Test patterns&nbsp;must also be&nbsp;generated for the custom&nbsp;logic part of&nbsp;<br>
the&nbsp;design, but&nbsp;the designer&nbsp;is&nbsp;assumed&nbsp;to&nbsp;understand&nbsp;that part of&nbsp;the logic.&nbsp;<br>
There are various approaches&nbsp;to&nbsp;getting the test&nbsp;patterns&nbsp;onto the edges of&nbsp;the&nbsp;mac-<br>
rocells:&nbsp;<br>
•&nbsp;&nbsp;Test modes may be provided&nbsp;which multiplex&nbsp;the signals&nbsp;from&nbsp;each macrocell&nbsp;in&nbsp;<br>
turn onto&nbsp;the pins of&nbsp;the&nbsp;system&nbsp;chip.&nbsp;<br>
•&nbsp;&nbsp;An on-chip&nbsp;bus&nbsp;may&nbsp;support direct test&nbsp;access to each&nbsp;macrocell which is&nbsp;<br>
attached to&nbsp;it&nbsp;(see&nbsp;Section 8.2&nbsp;on page 216).&nbsp;<br>
•&nbsp;&nbsp;Each&nbsp;macrocell&nbsp;may&nbsp;have a boundary&nbsp;scan&nbsp;path through&nbsp;which the test&nbsp;patterns&nbsp;<br>
may be&nbsp;applied using an extension&nbsp;of&nbsp;the&nbsp;JTAG architecture.&nbsp;<br>
This last&nbsp;approach&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;Figure&nbsp;8.16. The chip has a&nbsp;peripheral&nbsp;boundary&nbsp;<br>
scan&nbsp;path&nbsp;to&nbsp;support&nbsp;the public&nbsp;EXTEST operation&nbsp;and&nbsp;additional&nbsp;paths&nbsp;around&nbsp;each&nbsp;<br>
macrocell,&nbsp;designed into&nbsp;the&nbsp;macrocell,&nbsp;for&nbsp;applying&nbsp;functional&nbsp;tests as&nbsp;supplied.&nbsp;The&nbsp;<br>
custom&nbsp;logic&nbsp;designed&nbsp;specifically&nbsp;for this chip&nbsp;may&nbsp;have&nbsp;its own&nbsp;scan&nbsp;path or, as&nbsp;<br>
shown in the figure,&nbsp;rely&nbsp;on&nbsp;the fact&nbsp;that&nbsp;all&nbsp;its&nbsp;interface&nbsp;signals must intercept&nbsp;one&nbsp;of&nbsp;<br>
the&nbsp;existing scan&nbsp;paths.&nbsp;<br>
<b>PCB test&nbsp;scan path&nbsp;</b><br>
<b>Figure 8.16&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>A&nbsp;possible&nbsp;JTAG&nbsp;extension&nbsp;for macrocell&nbsp;testing.&nbsp;<br>
<hr>
<A name=244></a><b>232&nbsp;</b><br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
It&nbsp;should be recognized that&nbsp;although&nbsp;perfectly feasible for functional testing,&nbsp;the&nbsp;<br>
scan path approach to macrocell&nbsp;testing&nbsp;has the same drawbacks as using the JTAG&nbsp;<br>
boundary scan&nbsp;path to test&nbsp;the&nbsp;core&nbsp;logic&nbsp;on&nbsp;a chip. The&nbsp;serial access is&nbsp;much slower&nbsp;<br>
than parallel&nbsp;access through the pins and performance testing at speed is not possible.&nbsp;<br>
The&nbsp;most&nbsp;promising production test&nbsp;methodology&nbsp;for&nbsp;macrocell&nbsp;based&nbsp;system&nbsp;chips&nbsp;<br>
appears&nbsp;to&nbsp;be&nbsp;to exploit&nbsp;the on-chip&nbsp;bus to&nbsp;give&nbsp;parallel&nbsp;access&nbsp;to&nbsp;the&nbsp;macrocell's periph-<br>
ery&nbsp;(especially where the macrocell&nbsp;has&nbsp;been&nbsp;designed specifically&nbsp;to&nbsp;give&nbsp;good access&nbsp;<br>
through this route).&nbsp;Multiplexing is&nbsp;used to&nbsp;give external&nbsp;access&nbsp;to&nbsp;peripheral&nbsp;macrocell&nbsp;<br>
signals&nbsp;that&nbsp;are important&nbsp;for&nbsp;performance&nbsp;testing and&nbsp;cannot&nbsp;conveniently be accessed&nbsp;<br>
via&nbsp;the on-chip&nbsp;bus, and the JTAG port&nbsp;is&nbsp;used&nbsp;to&nbsp;access&nbsp;other signals&nbsp;and internal&nbsp;state&nbsp;<br>
where&nbsp;necessary via scan chains.&nbsp;We have&nbsp;seen&nbsp;this approach&nbsp;as it is supported&nbsp;by&nbsp;<br>
ARM's&nbsp;'Advanced Microcontroller&nbsp;Bus Architecture'&nbsp;(AMBA) which is&nbsp;described in&nbsp;<br>
Section 8.2 on page 216;&nbsp;the AMBA&nbsp;testing&nbsp;methodology&nbsp;is&nbsp;described on page 219.&nbsp;<br>
The JTAG system&nbsp;continues&nbsp;to&nbsp;be very&nbsp;important&nbsp;for board-level&nbsp;testing,&nbsp;and can&nbsp;<br>
also be used&nbsp;for in-circuit testing of the&nbsp;core&nbsp;logic and to access on-chip debug facili-<br>
ties. It is&nbsp;incorporated into&nbsp;most&nbsp;ARM&nbsp;designs and is&nbsp;an important&nbsp;component&nbsp;of their&nbsp;<br>
test&nbsp;and debug&nbsp;methodologies.&nbsp;<br>
8.7 &nbsp; The&nbsp;ARM&nbsp;debug&nbsp;architecture&nbsp;<br>
Debugging&nbsp;any&nbsp;computer system&nbsp;can be a complex task. There are two basic&nbsp;<br>
approaches to&nbsp;debugging,&nbsp;the&nbsp;simplest&nbsp;being&nbsp;based&nbsp;on&nbsp;watching&nbsp;a&nbsp;system&nbsp;from&nbsp;the&nbsp;<br>
outside&nbsp;using test&nbsp;equipment&nbsp;such&nbsp;as&nbsp;a logic&nbsp;analyser, and the&nbsp;more&nbsp;powerful being&nbsp;<br>
based&nbsp;on&nbsp;viewing a&nbsp;system&nbsp;from&nbsp;the inside&nbsp;with&nbsp;tools that support&nbsp;single&nbsp;stepping,&nbsp;<br>
the setting of&nbsp;breakpoints, and so on.&nbsp;<br>
Desktop&nbsp;<br>
When&nbsp;the system&nbsp;to&nbsp;be debugged&nbsp;is&nbsp;a piece of&nbsp;software running on&nbsp;a desktop&nbsp;<br>
debugging&nbsp;<br>
machine,&nbsp;all&nbsp;the user&nbsp;interface components are readily available&nbsp;and&nbsp;the debugger&nbsp;<br>
may itself simply&nbsp;be another&nbsp;piece&nbsp;of software&nbsp;running on the&nbsp;same&nbsp;machine. Break-<br>
points&nbsp;are set&nbsp;by&nbsp;replacing&nbsp;an&nbsp;instruction&nbsp;in&nbsp;the&nbsp;object&nbsp;program&nbsp;with a call to the&nbsp;<br>
debugger, remembering&nbsp;the original instruction so&nbsp;that it can be&nbsp;replaced when&nbsp;exe-<br>
cution&nbsp;continues past&nbsp;the&nbsp;breakpoint.&nbsp;<br>
Often&nbsp;compilers&nbsp;have compile-time options&nbsp;to generate extensive debug&nbsp;information&nbsp;<br>
such as symbol&nbsp;tables which the debugger can use to&nbsp;allow the user&nbsp;to&nbsp;debug the pro-<br>
gram&nbsp;from&nbsp;a source-level&nbsp;view,&nbsp;addressing variables by&nbsp;their&nbsp;source names rather&nbsp;than by&nbsp;<br>
their memory&nbsp;address.&nbsp;This&nbsp;'source-level&nbsp;debugging'&nbsp;is more powerful&nbsp;and&nbsp;requires less&nbsp;<br>
detailed&nbsp;knowledge&nbsp;of the machine environment than&nbsp;object-level&nbsp;debugging.&nbsp;<br>
A common weakness in&nbsp;software debuggers is&nbsp;the lack of a&nbsp;'watchpoint' facility.&nbsp;A&nbsp;<br>
watchpoint&nbsp;is&nbsp;a&nbsp;memory&nbsp;address which halts&nbsp;execution if&nbsp;it&nbsp;is accessed as&nbsp;a data&nbsp;trans-<br>
fer address. Since many&nbsp;processors have no&nbsp;support&nbsp;for trapping&nbsp;on&nbsp;a&nbsp;particular&nbsp;<br>
<hr>
<A name=245></a><b>The&nbsp;ARM debug&nbsp;architecture</b>&nbsp;<br>
<b>233</b>&nbsp;<br>
address (apart,&nbsp;perhaps, from&nbsp;a memory&nbsp;management page&nbsp;fault,&nbsp;which&nbsp;is&nbsp;rather&nbsp;<br>
coarse for this&nbsp;purpose)&nbsp;this functionality&nbsp;is&nbsp;often omitted. This&nbsp;is&nbsp;a pity, since a very&nbsp;<br>
common&nbsp;source&nbsp;of error in&nbsp;a&nbsp;C program&nbsp;is&nbsp;corrupted data&nbsp;caused&nbsp;by&nbsp;an&nbsp;errant&nbsp;pointer&nbsp;<br>
in&nbsp;some&nbsp;unrelated&nbsp;part of&nbsp;the program,&nbsp;and&nbsp;this can&nbsp;be&nbsp;very&nbsp;hard&nbsp;to&nbsp;track down&nbsp;with-<br>
out&nbsp;a watchpoint facility.&nbsp;<br>
Embedded&nbsp;<br>
Debugging becomes significantly&nbsp;more difficult when the target system&nbsp;is embed-&nbsp;<br>
debugging&nbsp;<br>
ded.&nbsp;Now&nbsp;there&nbsp;is&nbsp;probably&nbsp;no&nbsp;user&nbsp;interface&nbsp;in&nbsp;the&nbsp;system,&nbsp;so&nbsp;the&nbsp;debugger&nbsp;must&nbsp;<br>
run on a remote&nbsp;host through&nbsp;some&nbsp;sort of communication&nbsp;link to&nbsp;the&nbsp;target. If the&nbsp;<br>
code&nbsp;is in&nbsp;ROM,&nbsp;instructions cannot simply be&nbsp;replaced&nbsp;by&nbsp;calls&nbsp;to the debugger&nbsp;<br>
since&nbsp;the locations are not&nbsp;writeable.&nbsp;<br>
The standard&nbsp;solution here&nbsp;is&nbsp;the&nbsp;<i>In-Circuit&nbsp;Emulator&nbsp;</i>(ICE).&nbsp;The processor in&nbsp;the&nbsp;<br>
target&nbsp;system&nbsp;is removed&nbsp;and&nbsp;replaced&nbsp;by&nbsp;a&nbsp;connection to&nbsp;an&nbsp;emulator.&nbsp;The&nbsp;emulator&nbsp;<br>
may&nbsp;be&nbsp;based&nbsp;around&nbsp;the&nbsp;same&nbsp;processor&nbsp;chip,&nbsp;or&nbsp;a&nbsp;variant with&nbsp;more pins&nbsp;(and&nbsp;more&nbsp;<br>
visibility of&nbsp;its&nbsp;internal&nbsp;state),&nbsp;but&nbsp;it&nbsp;will&nbsp;also&nbsp;incorporate&nbsp;buffers to copy&nbsp;the bus activ-<br>
ity off to a&nbsp;'trace buffer'&nbsp;(which stores&nbsp;the&nbsp;signals on&nbsp;all&nbsp;the pins in each&nbsp;clock cycle&nbsp;<br>
for some&nbsp;number of cycles) and various hardware resources&nbsp;which can watch for par-<br>
ticular&nbsp;events,&nbsp;such&nbsp;as&nbsp;execution&nbsp;passing through a&nbsp;breakpoint.&nbsp;The trace&nbsp;buffer&nbsp;and&nbsp;<br>
hardware resources are managed&nbsp;by&nbsp;software&nbsp;running on&nbsp;a&nbsp;host&nbsp;desktop system.&nbsp;<br>
When&nbsp;a 'trigger' event&nbsp;occurs,&nbsp;the&nbsp;trace buffer&nbsp;is&nbsp;frozen so the&nbsp;user&nbsp;can&nbsp;observe&nbsp;<br>
activity around the point of&nbsp;interest.&nbsp;The host software&nbsp;will present the&nbsp;trace buffer&nbsp;<br>
data, give&nbsp;a view on&nbsp;the processor and&nbsp;system&nbsp;state and allow&nbsp;it&nbsp;to&nbsp;be&nbsp;modified,&nbsp;and&nbsp;<br>
generally&nbsp;attempt&nbsp;to&nbsp;appear as similar&nbsp;to&nbsp;a debugger&nbsp;in&nbsp;a desktop&nbsp;system&nbsp;as&nbsp;possible.&nbsp;<br>
Debugging&nbsp;<br>
The ICE&nbsp;approach&nbsp;depends&nbsp;on&nbsp;the system&nbsp;having an identifiable&nbsp;processor chip&nbsp;which&nbsp;<br>
processor cores&nbsp;<br>
can&nbsp;be&nbsp;removed and&nbsp;replaced&nbsp;by&nbsp;the ICE.&nbsp;Clearly, once&nbsp;the&nbsp;processor has&nbsp;become&nbsp;just&nbsp;<br>
one macrocell&nbsp;of&nbsp;many&nbsp;on a complex system&nbsp;chip, this is no&nbsp;longer possible.&nbsp;<br>
Although&nbsp;simulation&nbsp;using software&nbsp;models such&nbsp;as the ARMulator should&nbsp;remove&nbsp;<br>
many&nbsp;of&nbsp;the design&nbsp;bugs before the physical&nbsp;system&nbsp;is&nbsp;built, it&nbsp;is&nbsp;often impossible&nbsp;to&nbsp;<br>
run&nbsp;the full&nbsp;software system&nbsp;under&nbsp;emulation,&nbsp;and it can&nbsp;be&nbsp;difficult to model all the&nbsp;<br>
real-time constraints&nbsp;accurately. Therefore&nbsp;it&nbsp;is likely&nbsp;that&nbsp;some&nbsp;debugging&nbsp;of the com-<br>
plete&nbsp;hardware&nbsp;and software&nbsp;system&nbsp;will be&nbsp;necessary.&nbsp;How can&nbsp;this be achieved?&nbsp;This&nbsp;<br>
is still an&nbsp;area&nbsp;of active research&nbsp;to&nbsp;identify the best&nbsp;overall strategy with&nbsp;acceptable&nbsp;<br>
hardware&nbsp;overhead costs,&nbsp;but&nbsp;considerable&nbsp;progress&nbsp;has been&nbsp;over the last&nbsp;few years in&nbsp;<br>
developing&nbsp;practical&nbsp;approaches,&nbsp;and&nbsp;the&nbsp;rest&nbsp;of&nbsp;this&nbsp;section&nbsp;presents&nbsp;the&nbsp;approach&nbsp;<br>
developed&nbsp;by&nbsp;ARM Limited.&nbsp;<br>
ARM&nbsp;debug&nbsp;<br>
To&nbsp;provide&nbsp;debug&nbsp;facilities comparable&nbsp;with&nbsp;those&nbsp;offered by a typical&nbsp;ICE,&nbsp;the&nbsp;user&nbsp;<br>
hardware&nbsp;<br>
must be able to&nbsp;set breakpoints and watchpoints (for code running in ROM as&nbsp;well&nbsp;<br>
as RAM),&nbsp;to&nbsp;inspect and&nbsp;modify&nbsp;the&nbsp;processor&nbsp;and&nbsp;system&nbsp;state,&nbsp;to&nbsp;see a trace&nbsp;of&nbsp;<br>
processor activity&nbsp;around the point of interest, and to do all this from&nbsp;the comfort of&nbsp;<br>
a desk-top&nbsp;system&nbsp;with a&nbsp;good&nbsp;user interface. The&nbsp;trace&nbsp;mechanism&nbsp;used in&nbsp;ARM&nbsp;<br>
<hr>
<A name=246></a><IMG src="index-246_1.png"><br>
<b>234</b>&nbsp;<br>
<b>Architectural Support for System Development</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
systems is separate&nbsp;from&nbsp;the&nbsp;other debug&nbsp;facilities, and is&nbsp;discussed in&nbsp;Section 8.8&nbsp;<br>
on page 237. In this section&nbsp;we restrict our attention to the breakpoint,&nbsp;watchpoint&nbsp;<br>
and state&nbsp;inspection&nbsp;resources.&nbsp;<br>
The&nbsp;communication between&nbsp;the target&nbsp;system&nbsp;and&nbsp;the host is&nbsp;achieved&nbsp;by&nbsp;extend-<br>
ing the&nbsp;functionality of&nbsp;the&nbsp;JTAG test port.&nbsp;Since&nbsp;the&nbsp;JTAG&nbsp;test pins&nbsp;are&nbsp;included&nbsp;in&nbsp;<br>
most designs for board testing, accessing&nbsp;the debug&nbsp;hardware through this port&nbsp;<br>
requires no&nbsp;additional dedicated&nbsp;pins, sparing the most precious&nbsp;resource on&nbsp;the&nbsp;chip&nbsp;<br>
from&nbsp;further pressure. JTAG scan chains&nbsp;are used&nbsp;to access&nbsp;the&nbsp;breakpoint and&nbsp;<br>
watch-point registers and also to&nbsp;force instructions&nbsp;into&nbsp;the&nbsp;processor to access&nbsp;<br>
processor&nbsp;and&nbsp;system&nbsp;state.&nbsp;<br>
The breakpoint&nbsp;and watchpoint&nbsp;registers represent a fairly&nbsp;small hardware overhead&nbsp;<br>
that can often be accepted on production parts. The host&nbsp;system&nbsp;runs the standard&nbsp;<br>
ARM development&nbsp;tools,&nbsp;communicating&nbsp;with&nbsp;the target&nbsp;through a&nbsp;serial&nbsp;port&nbsp;and/or a&nbsp;<br>
parallel port.&nbsp;Special protocol conversion&nbsp;hardware sits&nbsp;between the host&nbsp;serial line&nbsp;<br>
and the target JTAG&nbsp;port.&nbsp;<br>
In addition&nbsp;to the breakpoint and watchpoint&nbsp;events, it&nbsp;may&nbsp;also be&nbsp;desirable to&nbsp;halt&nbsp;<br>
the processor&nbsp;when a&nbsp;system-level event&nbsp;occurs.&nbsp;The debug architecture includes&nbsp;<br>
external&nbsp;inputs&nbsp;for&nbsp;this purpose.&nbsp;<br>
The on-chip cell&nbsp;containing&nbsp;these facilities&nbsp;is&nbsp;called the&nbsp;<i>EmbeddedlCE&nbsp;</i>module.&nbsp;<br>
Embedded-ICE&nbsp;<br>
The EmbeddedlCE&nbsp;module consists of two watchpoint&nbsp;registers and control and&nbsp;<br>
status&nbsp;registers. The&nbsp;watchpoint registers&nbsp;can halt the&nbsp;ARM core&nbsp;when&nbsp;the address,&nbsp;<br>
data and&nbsp;control signals&nbsp;match the value&nbsp;programmed&nbsp;into the&nbsp;watchpoint&nbsp;register.&nbsp;<br>
Since the comparison is performed under a&nbsp;mask, either watchpoint register can be&nbsp;<br>
configured&nbsp;to&nbsp;operate&nbsp;as a breakpoint&nbsp;register capable of halting the processor&nbsp;when&nbsp;<br>
an&nbsp;instruction&nbsp;in&nbsp;either&nbsp;ROM&nbsp;or&nbsp;RAM&nbsp;is&nbsp;executed.&nbsp;<br>
The&nbsp;comparison&nbsp;and mask&nbsp;logic&nbsp;is&nbsp;illustrated in&nbsp;Figure&nbsp;8.17.&nbsp;<br>
&nbsp;<br>
<b>Figure 8.17&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>EmbeddedlCE&nbsp;signal comparison logic.&nbsp;<br>
<hr>
<A name=247></a><b>The&nbsp;ARM debug&nbsp;architecture</b>&nbsp;<br>
<b>235</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Chaining&nbsp;<br>
Each watchpoint&nbsp;can&nbsp;look for a particular combination&nbsp;of values on&nbsp;the ARM&nbsp;<br>
address bus, data bus,&nbsp;<i>trans, ope,&nbsp;</i>mo?[l:0]&nbsp;and&nbsp;<i>r/w&nbsp;&nbsp;</i>control&nbsp;signals, and if&nbsp;either&nbsp;<br>
combination&nbsp;is matched&nbsp;the&nbsp;processor is&nbsp;stopped.&nbsp;Alternatively, the two&nbsp;watchpoints&nbsp;<br>
may be&nbsp;chained&nbsp;to&nbsp;halt the&nbsp;processor when the second watchpoint&nbsp;is matched only&nbsp;<br>
after the first has previously been&nbsp;matched.&nbsp;<br>
Registers&nbsp;<br>
EmbeddedlCE registers are&nbsp;programmed&nbsp;via the JTAG test&nbsp;port,&nbsp;using a&nbsp;dedicated&nbsp;<br>
scan chain.&nbsp;The scan&nbsp;chain is 38&nbsp;bits long,&nbsp;with&nbsp;32 data bits,&nbsp;<i>5&nbsp;</i>address&nbsp;bits and a&nbsp;<i>r/w&nbsp;</i><br>
bit&nbsp;which&nbsp;controls whether&nbsp;the register&nbsp;is&nbsp;read or&nbsp;written.&nbsp;The&nbsp;address bits specify&nbsp;<br>
the particular&nbsp;register&nbsp;following&nbsp;the mapping&nbsp;detailed&nbsp;in&nbsp;Table 8.1.&nbsp;<br>
<b>Table&nbsp;8.1 &nbsp; &nbsp;</b>EmbeddedlCE register mapping.&nbsp;<br>
&nbsp;<br>
Address&nbsp;&nbsp;&nbsp;<br>
Width&nbsp;&nbsp;Function&nbsp;&nbsp;&nbsp;<br>
00000&nbsp;&nbsp;&nbsp;<br>
3&nbsp;&nbsp;&nbsp;<br>
Debug control&nbsp;&nbsp;&nbsp;<br>
00001&nbsp;&nbsp;&nbsp;<br>
<i>5</i>&nbsp;&nbsp;&nbsp;<br>
Debug status&nbsp;&nbsp;&nbsp;<br>
00100&nbsp;&nbsp;&nbsp;<br>
<i>6</i>&nbsp;&nbsp;&nbsp;<br>
Debug comms&nbsp;control&nbsp;register&nbsp;&nbsp;&nbsp;<br>
00101&nbsp;&nbsp;&nbsp;<br>
32&nbsp;&nbsp;&nbsp;&nbsp;Debug comms&nbsp;data&nbsp;register&nbsp;&nbsp;&nbsp;<br>
01000&nbsp;&nbsp;&nbsp;<br>
32&nbsp;&nbsp;&nbsp;&nbsp;Watchpoint&nbsp;0 address value&nbsp;&nbsp;&nbsp;<br>
01001&nbsp;&nbsp;&nbsp;<br>
32&nbsp;&nbsp;&nbsp;&nbsp;Watchpoint&nbsp;0 address&nbsp;mask&nbsp;&nbsp;&nbsp;<br>
01010&nbsp;&nbsp;&nbsp;<br>
32&nbsp;&nbsp;&nbsp;&nbsp;Watchpoint 0 data value&nbsp;&nbsp;&nbsp;<br>
01011&nbsp;&nbsp;&nbsp;<br>
32&nbsp;&nbsp;&nbsp;&nbsp;Watchpoint&nbsp;0 data mask&nbsp;&nbsp;&nbsp;<br>
01100&nbsp;&nbsp;&nbsp;<br>
9&nbsp;&nbsp;&nbsp;<br>
Watchpoint&nbsp;0 control value&nbsp;&nbsp;&nbsp;<br>
01101&nbsp;&nbsp;&nbsp;<br>
8&nbsp;&nbsp;&nbsp;<br>
Watchpoint&nbsp;0 control mask&nbsp;&nbsp;&nbsp;<br>
10000&nbsp;&nbsp;&nbsp;<br>
32&nbsp;&nbsp;&nbsp;&nbsp;Watchpoint&nbsp;1 address value&nbsp;&nbsp;&nbsp;<br>
10001&nbsp;&nbsp;&nbsp;<br>
32&nbsp;&nbsp;&nbsp;<br>
Watchpoint&nbsp;1 address&nbsp;mask&nbsp;&nbsp;&nbsp;<br>
10010&nbsp;&nbsp;&nbsp;<br>
32&nbsp;&nbsp;&nbsp;<br>
Watchpoint 1 data value&nbsp;&nbsp;&nbsp;<br>
10011&nbsp;&nbsp;&nbsp;<br>
32&nbsp;&nbsp;&nbsp;&nbsp;Watchpoint&nbsp;1 data mask&nbsp;&nbsp;&nbsp;<br>
10100&nbsp;&nbsp;&nbsp;<br>
9&nbsp;&nbsp;&nbsp;<br>
Watchpoint&nbsp;1 control value&nbsp;&nbsp;&nbsp;<br>
10101&nbsp;&nbsp;&nbsp;<br>
8&nbsp;&nbsp;&nbsp;<br>
Watchpoint&nbsp;1 control mask&nbsp;&nbsp;&nbsp;<br>
The use of the&nbsp;JTAG scan chain is&nbsp;illustrated in&nbsp;Figure 8.18&nbsp;on page 236. The read&nbsp;<br>
or&nbsp;write takes place when the TAP controller enters the 'update DR' state (see&nbsp;<br>
Figure 8.15 on&nbsp;page 228).&nbsp;<br>
Accessing state&nbsp;<br>
The EmbeddedlCE&nbsp;module&nbsp;allows a program&nbsp;to&nbsp;be halted at&nbsp;specific&nbsp;points, but&nbsp;it&nbsp;does&nbsp;<br>
not&nbsp;directly&nbsp;allow the processor or system&nbsp;state&nbsp;to&nbsp;be inspected or&nbsp;modified. This&nbsp;is&nbsp;<br>
achieved via further&nbsp;scan paths which&nbsp;are&nbsp;also&nbsp;accessed through the JTAG&nbsp;port.&nbsp;<br>
<hr>
<A name=248></a><IMG src="index-248_1.png"><br>
<b>236</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>breakpoint&nbsp;Figure&nbsp;8.18&nbsp; &nbsp;</b><br>
EmbeddedlCE register&nbsp;read&nbsp;and write&nbsp;structure.&nbsp;<br>
The mechanism&nbsp;employed to&nbsp;access the&nbsp;processor state&nbsp;is&nbsp;to&nbsp;halt&nbsp;the&nbsp;processor, then&nbsp;<br>
to&nbsp;force&nbsp;an&nbsp;instruction such&nbsp;as&nbsp;a store multiple&nbsp;of&nbsp;all&nbsp;the registers into the&nbsp;processor's&nbsp;<br>
instruction queue.Then&nbsp;clocks&nbsp;are&nbsp;applied&nbsp;to the processor,&nbsp;again&nbsp;via the&nbsp;scan&nbsp;chain,&nbsp;<br>
causing&nbsp;it&nbsp;to&nbsp;write&nbsp;the registers out through its&nbsp;data&nbsp;port. Each&nbsp;register&nbsp;is&nbsp;collected by&nbsp;<br>
the scan chain&nbsp;and shifted&nbsp;out.&nbsp;<br>
System&nbsp;state&nbsp;is&nbsp;harder&nbsp;to&nbsp;glean, since there&nbsp;may be system&nbsp;locations&nbsp;that&nbsp;cannot&nbsp;be&nbsp;<br>
read&nbsp;at&nbsp;the very low speeds that&nbsp;the scan&nbsp;path&nbsp;can&nbsp;generate.&nbsp;Here the&nbsp;processor&nbsp;is&nbsp;pre-<br>
loaded with&nbsp;a&nbsp;suitable&nbsp;instruction,&nbsp;then allowed to&nbsp;access&nbsp;the&nbsp;system&nbsp;location at&nbsp;system&nbsp;<br>
speed. This&nbsp;transfers&nbsp;the required system&nbsp;state into&nbsp;a processor register, whereupon&nbsp;it&nbsp;<br>
Debug comms&nbsp;<br>
may&nbsp;be passed&nbsp;to the&nbsp;external&nbsp;debugger through&nbsp;the&nbsp;JTAG port as&nbsp;described&nbsp;above.&nbsp;<br>
In&nbsp;additions&nbsp;to&nbsp;the breakpoint&nbsp;and&nbsp;watchpoint&nbsp;registers, the EmbeddedlCE&nbsp;module&nbsp;<br>
also includes&nbsp;a&nbsp;<b>debug comms&nbsp;</b>port whereby the software&nbsp;running&nbsp;on&nbsp;the&nbsp;target&nbsp;<br>
system&nbsp;can communicate&nbsp;with the host.&nbsp;The software in the target system&nbsp;sees&nbsp;the&nbsp;<br>
comms&nbsp;port as a 6-bit control&nbsp;register&nbsp;and&nbsp;32-bit&nbsp;data read and write registers which&nbsp;<br>
are accessed using MRC and MCR instructions to coprocessor 14. The host sees&nbsp;<br>
Debugging&nbsp;<br>
these&nbsp;registers&nbsp;in&nbsp;the EmbeddedlCE register&nbsp;map&nbsp;as shown&nbsp;in Table&nbsp;8.1 on page&nbsp;235.&nbsp;<br>
An&nbsp;ARM-based system&nbsp;chip&nbsp;which&nbsp;includes the EmbeddedlCE&nbsp;module&nbsp;connects to&nbsp;<br>
a host computer&nbsp;through&nbsp;the JTAG port and&nbsp;a protocol&nbsp;converter.&nbsp;This configuration&nbsp;<br>
supports the normal breakpoint,&nbsp;watchpoint&nbsp;and processor and&nbsp;system&nbsp;state access&nbsp;<br>
that the programmer&nbsp;is&nbsp;accustomed&nbsp;to&nbsp;using&nbsp;for native or&nbsp;ICE-based&nbsp;debugging&nbsp;(in&nbsp;<br>
addition to&nbsp;the comms&nbsp;port described above),&nbsp;and&nbsp;with&nbsp;suitable host software gives&nbsp;a&nbsp;<br>
full source-level&nbsp;debugging capability&nbsp;with low hardware overhead.&nbsp;<br>
The&nbsp;only facility that&nbsp;is missing&nbsp;is&nbsp;the&nbsp;ability&nbsp;to trace code&nbsp;in&nbsp;real&nbsp;time.&nbsp;This is the&nbsp;<br>
function of&nbsp;the&nbsp;<i>Embedded&nbsp;Trace&nbsp;Macrocell&nbsp;</i>described&nbsp;in&nbsp;the next&nbsp;section.&nbsp;<br>
<hr>
<A name=249></a><b>Embedded Trace</b>&nbsp;<br>
<b>237</b>&nbsp;<br>
8.8 &nbsp; Embedded&nbsp;Trace&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
When debugging&nbsp;real-time systems it is&nbsp;often&nbsp;difficult to&nbsp;debug&nbsp;the application&nbsp;soft-<br>
ware&nbsp;without the capability&nbsp;of&nbsp;observing its operation in real time. The&nbsp;breakpoint&nbsp;<br>
and watchpoint facilities offered&nbsp;by the&nbsp;EmbeddedlCE macrocell&nbsp;are&nbsp;insufficient for&nbsp;<br>
this purpose as using them&nbsp;causes the processor to deviate from&nbsp;its normal&nbsp;execu-<br>
tion&nbsp;sequence, destroying&nbsp;the temporal behaviour of&nbsp;the&nbsp;software.&nbsp;<br>
What&nbsp;is&nbsp;required is&nbsp;an ability&nbsp;to&nbsp;observe&nbsp;the&nbsp;processor&nbsp;operating&nbsp;at&nbsp;full&nbsp;speed&nbsp;by&nbsp;<br>
generating&nbsp;a&nbsp;trace&nbsp;of its&nbsp;address, data&nbsp;and&nbsp;control&nbsp;bus&nbsp;activity&nbsp;as the&nbsp;program&nbsp;executes.&nbsp;<br>
The&nbsp;problem&nbsp;is that&nbsp;this represents&nbsp;a&nbsp;huge&nbsp;data&nbsp;bandwidth - an&nbsp;ARM processor run-<br>
ning at&nbsp;100&nbsp;MHz generates&nbsp;over&nbsp;1 Gbyte/s&nbsp;of interface&nbsp;information.&nbsp;Getting&nbsp;this&nbsp;infor-<br>
mation off the chip would require so&nbsp;many&nbsp;pins that it&nbsp;would be uneconomic to&nbsp;<br>
include the capability on production devices,&nbsp;so special development devices would be&nbsp;<br>
needed, adversely&nbsp;affecting the costs of&nbsp;developing&nbsp;a&nbsp;new system-on-chip&nbsp;application.&nbsp;<br>
Trace&nbsp;<br>
The&nbsp;solution&nbsp;adopted&nbsp;by&nbsp;ARM&nbsp;Limited is&nbsp;to&nbsp;reduce&nbsp;the&nbsp;interface bandwidth&nbsp;using&nbsp;<br>
compression&nbsp;<br>
intelligent&nbsp;trace&nbsp;compression techniques.&nbsp;For&nbsp;example:&nbsp;<br>
•&nbsp;&nbsp;Most&nbsp;ARM&nbsp;addresses are&nbsp;sequential,&nbsp;so it&nbsp;is&nbsp;not necessary to&nbsp;send every address&nbsp;<br>
off chip. Instead, the sequential information can&nbsp;be sent&nbsp;on&nbsp;most cycles and the&nbsp;<br>
full&nbsp;address&nbsp;only&nbsp;when a branch is&nbsp;taken.&nbsp;<br>
•&nbsp;&nbsp;If there&nbsp;is off-chip logic which&nbsp;has access&nbsp;to&nbsp;the code which is&nbsp;running on the&nbsp;<br>
processor, it&nbsp;will know&nbsp;when&nbsp;the processor is&nbsp;executing a branch instruction and&nbsp;<br>
where the&nbsp;target of&nbsp;the branch&nbsp;is.&nbsp;The&nbsp;only&nbsp;information which must be sent&nbsp;off&nbsp;<br>
chip is whether or&nbsp;not&nbsp;the branch is&nbsp;taken.&nbsp;<br>
•&nbsp;&nbsp;Fuller&nbsp;address information&nbsp;is&nbsp;now&nbsp;required only&nbsp;when&nbsp;the&nbsp;branch&nbsp;target is&nbsp;not&nbsp;<br>
known, such as in a subroutine return or jump&nbsp;table instruction. Even here, only&nbsp;<br>
those low-order address bits that change need be issued.&nbsp;<br>
•&nbsp;&nbsp;The address information is&nbsp;now very&nbsp;bursty. A&nbsp;first-in-first-out&nbsp;(FIFO)&nbsp;buffer can&nbsp;<br>
be used to smooth the data rate so that the necessary address information can be&nbsp;<br>
transmitted in&nbsp;4-, 8-&nbsp;or&nbsp;16-bit&nbsp;packets at a&nbsp;steadier rate.&nbsp;<br>
Using a&nbsp;number of techniques&nbsp;similar along&nbsp;these&nbsp;lines,&nbsp;the&nbsp;ARM Embedded Trace&nbsp;<br>
Macrocell can compress&nbsp;the&nbsp;trace information&nbsp;to&nbsp;the extent necessary&nbsp;to allow&nbsp;it to&nbsp;be&nbsp;<br>
communicated off chip through 9, 13 or 21 pins depending on the configuration.&nbsp;<br>
These pins&nbsp;could&nbsp;be used&nbsp;for other purposes when&nbsp;trace output is not&nbsp;required.&nbsp;<br>
Real-time debug&nbsp;<br>
A complete&nbsp;real-time debug&nbsp;solution is as&nbsp;shown&nbsp;in Figure 8.19 on page&nbsp;238. The&nbsp;<br>
EmbeddedlCE&nbsp;unit supports&nbsp;breakpoint&nbsp;and&nbsp;watchpoint functionality,&nbsp;and&nbsp;communi-<br>
cation&nbsp;channels&nbsp;between&nbsp;the&nbsp;host&nbsp;and&nbsp;target&nbsp;software.&nbsp;The&nbsp;Embedded Trace&nbsp;Macrocell&nbsp;<br>
compresses the processor's interface information&nbsp;and&nbsp;sends it off chip&nbsp;through&nbsp;the&nbsp;<br>
Trace&nbsp;port. The&nbsp;JTAG&nbsp;port&nbsp;is&nbsp;used to control both units.&nbsp;The external&nbsp;EmbeddedlCE&nbsp;<br>
<hr>
<A name=250></a><IMG src="index-250_1.png"><br>
<b>238</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>EmbeddedlCE|&nbsp;</b><br>
<b>controller</b>&nbsp;<br>
<b>Embedded</b><br>
<b>trace&nbsp;</b><br>
<b>macrocell</b><br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 8.19&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Real-time&nbsp;debug&nbsp;system organization.&nbsp;<br>
controller is used to&nbsp;connect the host system&nbsp;to the JTAG port, and the external Trace&nbsp;<br>
Port&nbsp;Analyser&nbsp;interfaces&nbsp;the&nbsp;host&nbsp;system&nbsp;to&nbsp;the Trace port. The&nbsp;host&nbsp;may&nbsp;connect&nbsp;to&nbsp;<br>
both&nbsp;the trace port&nbsp;analyser and the&nbsp;EmbeddedlCE controller&nbsp;via a network.&nbsp;<br>
The&nbsp;user&nbsp;has control&nbsp;of&nbsp;the&nbsp;breakpoint&nbsp;and&nbsp;watchpoint&nbsp;settings&nbsp;and various trace&nbsp;<br>
functions. All the&nbsp;application software&nbsp;may&nbsp;be&nbsp;traced,&nbsp;or&nbsp;just particular routines.&nbsp;Trig-<br>
ger conditions can be&nbsp;specified, and the trace&nbsp;can&nbsp;be&nbsp;collected before or after the&nbsp;trig-<br>
ger or&nbsp;with&nbsp;the&nbsp;trigger&nbsp;in&nbsp;the&nbsp;centre of&nbsp;the trace.&nbsp;Data&nbsp;accesses&nbsp;can&nbsp;be&nbsp;selected&nbsp;to&nbsp;be&nbsp;<br>
included in the trace or not,&nbsp;and the trace may collect just the address&nbsp;of the data&nbsp;<br>
access, or&nbsp;just&nbsp;the&nbsp;data&nbsp;itself, or&nbsp;both.&nbsp;<br>
Embedded trace&nbsp;<br>
As noted&nbsp;above, the Embedded Trace Macrocell&nbsp;may&nbsp;be&nbsp;synthesized&nbsp;in&nbsp;several dif-<br>
options&nbsp;<br>
ferent configurations allowing the functionality of the unit to be&nbsp;traded off against&nbsp;<br>
cost&nbsp;(measured&nbsp;in terms of&nbsp;the numbers of gates and&nbsp;pins used).&nbsp;<br>
•&nbsp;&nbsp;The minimal system&nbsp;requires&nbsp;5 pins&nbsp;to&nbsp;issue&nbsp;pipeline&nbsp;information&nbsp;and 4&nbsp;pins&nbsp;to&nbsp;issue&nbsp;<br>
data (in addition to the 5-pin JTAG interface).&nbsp;This is&nbsp;sufficient for execution tracing,&nbsp;<br>
but will&nbsp;only&nbsp;support very&nbsp;limited data&nbsp;tracing&nbsp;and has restricted triggering and filter&nbsp;<br>
ing capabilities.&nbsp;A 9-byte FIFO is used to smooth the data transfer rate, and the hard&nbsp;<br>
ware cost of this&nbsp;implementation is approximately&nbsp;15 Kgates.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;maximal&nbsp;system&nbsp;uses 5 pins to issue pipeline information and 16 pins&nbsp;to issue&nbsp;<br>
data (again, in addition to the&nbsp;5-pin JTAG interface). It is&nbsp;capable of tracing the&nbsp;<br>
flow&nbsp;of&nbsp;execution&nbsp;and&nbsp;all but the very-worst-case data&nbsp;activity.&nbsp;A 40-byte&nbsp;FIFO&nbsp;is&nbsp;<br>
used&nbsp;to&nbsp;smooth&nbsp;the data&nbsp;flow,&nbsp;and&nbsp;the&nbsp;hardware cost&nbsp;is&nbsp;approximately 50&nbsp;Kgates.&nbsp;<br>
<hr>
<A name=251></a><b>Signal&nbsp;processing&nbsp;support</b>&nbsp;<br>
<b>239</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Between these&nbsp;two extremes several intermediate&nbsp;configurations are possible. All&nbsp;<br>
allow for&nbsp;external inputs (that is, inputs from&nbsp;other&nbsp;logic&nbsp;on&nbsp;the&nbsp;chip) to control the&nbsp;<br>
trace&nbsp;triggering,&nbsp;and for triggering&nbsp;from&nbsp;the EmbeddedlCE&nbsp;breakpoint&nbsp;logic.&nbsp;<br>
Trace overflow&nbsp;<br>
With all of the&nbsp;implementations of the Embedded Trace&nbsp;Macrocell there are&nbsp;some&nbsp;<br>
circumstances where the&nbsp;trace&nbsp;FIFO buffer can&nbsp;overflow.&nbsp;The&nbsp;unit&nbsp;can&nbsp;be&nbsp;configured&nbsp;<br>
either to stall the processor or&nbsp;to discontinue tracing when this happens. In either&nbsp;<br>
case, real-time tracing is lost, although&nbsp;only&nbsp;temporarily&nbsp;while&nbsp;the FIFO drains.&nbsp;<br>
Fundamentally what has happened is&nbsp;the&nbsp;information&nbsp;bandwidth has exceeded the&nbsp;<br>
capability&nbsp;of the&nbsp;compression&nbsp;algorithm&nbsp;to&nbsp;reduce&nbsp;it&nbsp;to&nbsp;match the bandwidth capacity&nbsp;<br>
of the&nbsp;trace&nbsp;port. If&nbsp;this&nbsp;happens, the filtering setup must&nbsp;be&nbsp;modified&nbsp;to&nbsp;reduce&nbsp;the&nbsp;<br>
amount of data&nbsp;that&nbsp;is being traced.&nbsp;<br>
N-Trace&nbsp;<br>
The real-time&nbsp;trace technology&nbsp;was developed&nbsp;through&nbsp;a collaboration between&nbsp;<br>
ARM Limited, VLSI&nbsp;Technology, Inc.,&nbsp;and Agilent Technologies&nbsp;(formerly&nbsp;part&nbsp;of&nbsp;<br>
Hewlett-Packard). VLSI&nbsp;Technology, Inc.,&nbsp;offers a&nbsp;synthesizable version&nbsp;of&nbsp;the&nbsp;<br>
Embedded&nbsp;Trace Macrocell under the&nbsp;'N-Trace'&nbsp;product name.&nbsp;<br>
Trace port&nbsp;<br>
The&nbsp;trace port analyser&nbsp;may be&nbsp;a&nbsp;conventional&nbsp;logic analyser,&nbsp;but an ARM-specific&nbsp;<br>
analyser&nbsp;<br>
low-cost&nbsp;trace&nbsp;port analyser&nbsp;has been&nbsp;developed&nbsp;by&nbsp;Agilent&nbsp;Technologies&nbsp;and similar&nbsp;<br>
systems will&nbsp;become&nbsp;available from&nbsp;other vendors.&nbsp;<br>
Trace software&nbsp;<br>
The&nbsp;Embedded&nbsp;Trace Macrocell&nbsp;is&nbsp;configured&nbsp;via the&nbsp;JTAG port using software&nbsp;that&nbsp;<br>
tools&nbsp;<br>
is an extension to the ARM&nbsp;software development tools. The trace data&nbsp;is down-<br>
loaded&nbsp;from&nbsp;the trace&nbsp;port analyser&nbsp;and decompressed&nbsp;using source&nbsp;code&nbsp;informa-<br>
tion. It is&nbsp;then&nbsp;presented as&nbsp;an&nbsp;assembly&nbsp;listing with interspersed data accesses, and&nbsp;<br>
has links&nbsp;back&nbsp;to the&nbsp;source code.&nbsp;<br>
With&nbsp;EmbeddedlCE&nbsp;and&nbsp;the&nbsp;Embedded&nbsp;Trace&nbsp;facility&nbsp;the&nbsp;ARM&nbsp;system-on-chip&nbsp;<br>
designer has all&nbsp;the&nbsp;facilities&nbsp;offered by&nbsp;traditional&nbsp;in-circuit emulation (ICE)&nbsp;tools.&nbsp;<br>
These technologies give&nbsp;full&nbsp;visibility&nbsp;of&nbsp;the real-time behaviour of&nbsp;the application&nbsp;<br>
code&nbsp;with&nbsp;the ability&nbsp;to&nbsp;set&nbsp;breakpoints&nbsp;and&nbsp;inspect&nbsp;and&nbsp;change&nbsp;processor registers&nbsp;and&nbsp;<br>
memory&nbsp;locations, always&nbsp;with firm&nbsp;links back&nbsp;to the&nbsp;high-level language source code.&nbsp;<br>
8.9 &nbsp; Signal&nbsp;processing&nbsp;support&nbsp;<br>
Many&nbsp;applications&nbsp;that&nbsp;use&nbsp;an&nbsp;ARM processor as&nbsp;a&nbsp;controller also&nbsp;require&nbsp;significant&nbsp;<br>
digital signal&nbsp;processing performance.&nbsp;A&nbsp;typical&nbsp;GSM mobile telephone handset is&nbsp;a&nbsp;<br>
case&nbsp;in&nbsp;point;&nbsp;first-generation ARM-based&nbsp;designs&nbsp;typically incorporate&nbsp;a DSP core&nbsp;<br>
on&nbsp;the&nbsp;same&nbsp;chip as the&nbsp;ARM core, and the system&nbsp;designer has to&nbsp;make careful&nbsp;<br>
<hr>
<A name=252></a><b>240&nbsp;</b><br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
choices regarding which system&nbsp;functions are best implemented on the&nbsp;DSP core&nbsp;<br>
and&nbsp;which on the ARM core.&nbsp;<br>
DSP cores have programmers'&nbsp;models that&nbsp;are very different from&nbsp;the&nbsp;ARM's&nbsp;<br>
model.&nbsp;They&nbsp;employ&nbsp;several&nbsp;separate&nbsp;data&nbsp;memories, and&nbsp;often&nbsp;require the&nbsp;program-<br>
mer to schedule&nbsp;their internal&nbsp;pipeline very&nbsp;carefully&nbsp;if&nbsp;maximum&nbsp;throughput is to be&nbsp;<br>
obtained. Synchronizing the&nbsp;DSP code&nbsp;with&nbsp;the ARM&nbsp;code&nbsp;that&nbsp;is running&nbsp;concur-<br>
rently is&nbsp;a complex task.&nbsp;<br>
ARM&nbsp;Limited has introduced&nbsp;two different extensions&nbsp;to&nbsp;the&nbsp;ARM architecture&nbsp;in&nbsp;<br>
attempting&nbsp;to simplify the system&nbsp;design&nbsp;task&nbsp;in&nbsp;applications&nbsp;which&nbsp;require&nbsp;both&nbsp;con-<br>
troller and signal processing&nbsp;functions: the Piccolo coprocessor, and&nbsp;the signal&nbsp;<br>
processing&nbsp;instruction set&nbsp;extensions&nbsp;in&nbsp;ARM architecture&nbsp;v5TE.&nbsp;<br>
Piccolo&nbsp;<br>
The&nbsp;Piccolo&nbsp;coprocessor is a&nbsp;sophisticated&nbsp;16-bit&nbsp;signal processing engine&nbsp;that uses&nbsp;<br>
the ARM coprocessor interface to cooperate with the&nbsp;ARM core in the&nbsp;transfer of&nbsp;<br>
operands&nbsp;and results from&nbsp;and&nbsp;to memory, but&nbsp;also&nbsp;executes its own instruction set.&nbsp;<br>
The&nbsp;organization of&nbsp;Piccolo is&nbsp;illustrated in&nbsp;Figure 8.20&nbsp;on&nbsp;page 241.&nbsp;Operands&nbsp;are&nbsp;<br>
loaded&nbsp;and results&nbsp;stored&nbsp;via&nbsp;the ARM coprocessor interface,&nbsp;so suitable addresses&nbsp;<br>
must&nbsp;be generated by&nbsp;the&nbsp;ARM&nbsp;core. The input and output buffers&nbsp;allow these trans-<br>
fers to&nbsp;move&nbsp;many&nbsp;16-bit&nbsp;values&nbsp;in&nbsp;a&nbsp;single&nbsp;instruction,&nbsp;and values&nbsp;are transferred in&nbsp;<br>
pairs,&nbsp;making&nbsp;full&nbsp;use&nbsp;of&nbsp;the&nbsp;ARM's 32-bit&nbsp;bus&nbsp;width.&nbsp;The&nbsp;input&nbsp;buffer stores&nbsp;values&nbsp;<br>
until&nbsp;they&nbsp;are&nbsp;called&nbsp;upon&nbsp;by&nbsp;the signal&nbsp;processing&nbsp;code,&nbsp;and&nbsp;they&nbsp;may&nbsp;be accessed out&nbsp;<br>
of order from&nbsp;the&nbsp;buffer.&nbsp;<br>
The&nbsp;Piccolo register&nbsp;set&nbsp;holds&nbsp;operands&nbsp;that&nbsp;may&nbsp;be&nbsp;16&nbsp;bits,&nbsp;32&nbsp;bits&nbsp;or&nbsp;48&nbsp;bits wide.&nbsp;<br>
The four 48-bit&nbsp;registers are&nbsp;used to&nbsp;accumulate results&nbsp;such&nbsp;as inner&nbsp;products without&nbsp;<br>
risk of overflow. The processing logic can&nbsp;compute a 16x16 product and add the&nbsp;<br>
result&nbsp;to&nbsp;one of&nbsp;these 48-bit accumulator registers in&nbsp;a&nbsp;single&nbsp;cycle.&nbsp;It&nbsp;also&nbsp;offers good&nbsp;<br>
support&nbsp;for fixed&nbsp;point&nbsp;operations&nbsp;and supports saturating&nbsp;arithmetic.&nbsp;<br>
The signal processing&nbsp;operations&nbsp;that&nbsp;use&nbsp;values&nbsp;held&nbsp;in&nbsp;the register file&nbsp;are speci-<br>
fied in&nbsp;a separate instruction set which Piccolo loads from&nbsp;memory via the&nbsp;AMBA bus&nbsp;<br>
into&nbsp;a local instruction cache.&nbsp;<br>
An objective of the Piccolo architecture is&nbsp;to&nbsp;provide sufficient local storage, in&nbsp;the&nbsp;<br>
form&nbsp;of registers, the instruction&nbsp;cache and the&nbsp;input&nbsp;and output&nbsp;buffers, that&nbsp;a single&nbsp;<br>
AMBA bus can&nbsp;support good&nbsp;throughput.&nbsp;This&nbsp;contrasts with&nbsp;conventional signal&nbsp;<br>
processor designs&nbsp;that&nbsp;use two independent data&nbsp;memories&nbsp;and&nbsp;a separate&nbsp;instruction&nbsp;<br>
memory. As a result, Piccolo&nbsp;offers a much&nbsp;more straightforward programming model&nbsp;<br>
than&nbsp;does&nbsp;a system&nbsp;that&nbsp;combines&nbsp;an ARM&nbsp;core&nbsp;with&nbsp;a conventional&nbsp;signal&nbsp;processing&nbsp;<br>
core.&nbsp;However,&nbsp;some&nbsp;care is still&nbsp;required&nbsp;to&nbsp;synchronize&nbsp;the ARM&nbsp;code&nbsp;with the&nbsp;Pic-<br>
colo code, and&nbsp;in an&nbsp;intensive signal processing&nbsp;application the&nbsp;ARM&nbsp;core is kept&nbsp;<br>
quite&nbsp;busy&nbsp;with&nbsp;the&nbsp;operand&nbsp;and result&nbsp;transfers, and is&nbsp;therefore unable&nbsp;to&nbsp;carry out&nbsp;<br>
extensive control functions at&nbsp;the same&nbsp;time.&nbsp;An even&nbsp;more straightforward program-<br>
ming&nbsp;model is offered by&nbsp;the&nbsp;ARM&nbsp;architecture&nbsp;v5TE instruction&nbsp;set&nbsp;extensions.&nbsp;<br>
<hr>
<A name=253></a><IMG src="index-253_1.png"><br>
Signal&nbsp;<b>processing support</b>&nbsp;<br>
241&nbsp;<br>
&nbsp;<br>
<b>Figure 8.20&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Piccolo organization.&nbsp;<br>
V5TE&nbsp;signal&nbsp;<br>
The signal processing instruction set&nbsp;extension defined by&nbsp;ARM&nbsp;architecture v5TE,&nbsp;<br>
processing&nbsp;<br>
first implemented on the ARM9E-S&nbsp;synthesizable core,&nbsp;represents a very different&nbsp;<br>
instructions&nbsp;<br>
approach to&nbsp;the&nbsp;problem&nbsp;from&nbsp;that&nbsp;used&nbsp;in&nbsp;the design&nbsp;of&nbsp;Piccolo.&nbsp;All&nbsp;that&nbsp;is used&nbsp;here&nbsp;<br>
is&nbsp;a&nbsp;carefully chosen&nbsp;addition&nbsp;to&nbsp;the native&nbsp;ARM&nbsp;instruction set&nbsp;to provide&nbsp;much&nbsp;better&nbsp;<br>
intrinsic support for&nbsp;the&nbsp;data&nbsp;types&nbsp;used&nbsp;in&nbsp;signal&nbsp;processing&nbsp;applications.&nbsp;<br>
The ARM programmers'&nbsp;model is extended in architecture v5TE as shown in&nbsp;<br>
Figure 8.21&nbsp;on page&nbsp;242.&nbsp;The 'Q'&nbsp;flag&nbsp;is&nbsp;added in bit&nbsp;27 of&nbsp;the&nbsp;CPSR, and&nbsp;all&nbsp;SPSRs&nbsp;<br>
also&nbsp;have&nbsp;a Q&nbsp;flag. Q&nbsp;is a&nbsp;'sticky'&nbsp;overflow&nbsp;flag&nbsp;which may&nbsp;be set&nbsp;by&nbsp;certain&nbsp;v5TE&nbsp;<br>
instructions,&nbsp;and&nbsp;then&nbsp;reset&nbsp;by&nbsp;a&nbsp;suitable&nbsp;MSR&nbsp;instruction&nbsp;(see&nbsp;Section&nbsp;5.14&nbsp;on&nbsp;<br>
page 133). The term&nbsp;'sticky'&nbsp;describes the&nbsp;fact that once&nbsp;set, the&nbsp;Q&nbsp;flag&nbsp;remains&nbsp;set&nbsp;<br>
until&nbsp;explicitly&nbsp;reset by&nbsp;an MSR instruction,&nbsp;so a&nbsp;series of&nbsp;instructions&nbsp;may be&nbsp;<br>
<hr>
<A name=254></a><IMG src="index-254_1.png"><br>
<IMG src="index-254_2.png"><br>
<b>242</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
executed&nbsp;and&nbsp;the Q flag&nbsp;inspected only&nbsp;once&nbsp;(using&nbsp;an&nbsp;MRS instruction)&nbsp;at&nbsp;the&nbsp;end&nbsp;to&nbsp;<br>
see if an&nbsp;overflow occurred&nbsp;at&nbsp;any point in&nbsp;the&nbsp;sequence.&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;8.21 &nbsp;&nbsp;&nbsp;</b>ARM v5TE&nbsp;PSR format.&nbsp;<br>
The&nbsp;signal processing&nbsp;instructions&nbsp;fall&nbsp;into&nbsp;two&nbsp;groups:&nbsp;multiplication, and&nbsp;addi-<br>
tion/subtraction. The addition/subtraction instructions use&nbsp;<b>saturating&nbsp;&nbsp;</b>arithmetic,&nbsp;<br>
which means that when&nbsp;the result&nbsp;overflows&nbsp;the&nbsp;range&nbsp;that can&nbsp;be&nbsp;represented in&nbsp;the&nbsp;<br>
data type&nbsp;the&nbsp;nearest value&nbsp;that can&nbsp;be&nbsp;represented&nbsp;is returned&nbsp;(and&nbsp;the&nbsp;Q flag&nbsp;set).&nbsp;<br>
This&nbsp;is&nbsp;in contrast to conventional processor arithmetic&nbsp;(and to the modulo 232&nbsp;arith-<br>
metic&nbsp;data type&nbsp;defined&nbsp;by&nbsp;C),&nbsp;where a&nbsp;result&nbsp;slightly&nbsp;larger&nbsp;than the maximum&nbsp;value&nbsp;<br>
has a&nbsp;value close to&nbsp;the&nbsp;<i>minimum&nbsp;</i>value. Here&nbsp;a result slightly&nbsp;larger&nbsp;than&nbsp;the maxi-<br>
mum&nbsp;value&nbsp;simply&nbsp;returns&nbsp;the maximum&nbsp;value. In typical&nbsp;signal&nbsp;processing&nbsp;algo-<br>
rithms&nbsp;this minimizes the error and gives&nbsp;optimum&nbsp;results.&nbsp;<br>
v5TE&nbsp;multiply&nbsp;<br>
The&nbsp;multiply instructions all&nbsp;improve&nbsp;the ability of&nbsp;the processor to handle 16-bit&nbsp;<br>
instructions&nbsp;<br>
data&nbsp;types, and assume&nbsp;that&nbsp;a&nbsp;32-bit ARM&nbsp;register may hold&nbsp;two 16-bit values. They&nbsp;<br>
therefore give&nbsp;efficient&nbsp;access to&nbsp;values&nbsp;held&nbsp;in the upper or&nbsp;lower&nbsp;half&nbsp;of&nbsp;a&nbsp;register.&nbsp;<br>
The binary&nbsp;encoding of&nbsp;these&nbsp;instructions&nbsp;is&nbsp;shown&nbsp;in&nbsp;Figure 8.22.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure 8.22&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Architecture&nbsp;v5TE multiply instruction&nbsp;binary&nbsp;encoding.&nbsp;<br>
The&nbsp;instructions supported&nbsp;by&nbsp;this format are:&nbsp;<br>
SMLAxy{cond}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Rd,Rm,Rs,Rn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mul&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;00&nbsp;<br>
This&nbsp;instruction computes&nbsp;the&nbsp;16x16&nbsp;product&nbsp;of the&nbsp;two&nbsp;signed&nbsp;16-bit&nbsp;values from&nbsp;<br>
the lower&nbsp;(x&nbsp;= 0) or upper&nbsp;(x&nbsp;= 1) half of Rm&nbsp;and&nbsp;the lower&nbsp;(y&nbsp;=&nbsp;0)&nbsp;or&nbsp;upper (y&nbsp;= 1)&nbsp;<br>
half&nbsp;of&nbsp;Rs. The 32-bit&nbsp;product is&nbsp;added to the 32-bit&nbsp;value in Rn, and&nbsp;the result placed&nbsp;<br>
in Rd. The assembly format replaces x&nbsp;and&nbsp;y with 'B'&nbsp;for the lower (bottom)&nbsp;halfword&nbsp;<br>
or 'T'&nbsp;for&nbsp;the&nbsp;upper&nbsp;(top)&nbsp;halfword.&nbsp;<br>
SMLAWy{cond} Rd,Rm,Rs,Rn&nbsp;<br>
; &nbsp;mul &nbsp;&nbsp;=&nbsp;0&nbsp;1&nbsp;,&nbsp;&nbsp;&nbsp;&nbsp;<br>
x &nbsp;=&nbsp;&nbsp; 0&nbsp;<br>
This instruction computes the 32&nbsp;x&nbsp;16&nbsp;product of&nbsp;the 32-bit&nbsp;value&nbsp;in Rm and&nbsp;<br>
the 16-bit value in the&nbsp;lower (y&nbsp;= 0) or upper (y&nbsp;= 1) half&nbsp;of Rs. The&nbsp;most signif-&nbsp;<br>
<hr>
<A name=255></a><IMG src="index-255_1.png"><br>
<b>Signal processing support&nbsp;</b><br>
<b>243</b>&nbsp;<br>
icant 32 bits of&nbsp;the 48-bit product&nbsp;are added&nbsp;to the 32-bit value in Rn, and the&nbsp;<br>
result&nbsp;placed in&nbsp;Rd.&nbsp;<br>
SMULWy{cond}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Rd,Rm,Rs&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mul&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;01,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
Rn&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;<br>
This instruction computes the 32&nbsp;x 16&nbsp;product of&nbsp;the 32-bit&nbsp;value&nbsp;in&nbsp;Rm&nbsp;and the&nbsp;<br>
16-bit value&nbsp;in&nbsp;the lower&nbsp;(y =&nbsp;0)&nbsp;or&nbsp;upper&nbsp;(y&nbsp;= 1)&nbsp;half of&nbsp;Rs. The&nbsp;most significant 32&nbsp;<br>
bits of the 48-bit product are&nbsp;placed&nbsp;in&nbsp;Rd.&nbsp;<br>
SMLALxy{cond} RdLo,RdHi,Rm,Rs;&nbsp;mul = 10&nbsp;<br>
This instruction&nbsp;computes&nbsp;the&nbsp;16x16 product&nbsp;of&nbsp;the two signed 16-bit&nbsp;values from&nbsp;<br>
the lower&nbsp;(x&nbsp;= 0)&nbsp;or&nbsp;upper&nbsp;(x&nbsp;= 1)&nbsp;half&nbsp;of&nbsp;Rm&nbsp;and&nbsp;the&nbsp;lower&nbsp;(y = 0)&nbsp;or&nbsp;upper&nbsp;(y&nbsp;= 1)&nbsp;<br>
half of&nbsp;Rs. The 32-bit product is added&nbsp;to&nbsp;the 64-bit value in RdHi:RdLo, and&nbsp;the&nbsp;<br>
result&nbsp;placed&nbsp;in&nbsp;RdHi:RdLo.&nbsp;<br>
SMULxy{cond}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Rd,Rm,Rs&nbsp;<br>
;&nbsp;&nbsp;&nbsp;mul&nbsp; &nbsp;<i>•••• &nbsp;&nbsp;</i>11,&nbsp;&nbsp;&nbsp;Rn&nbsp;&nbsp;=&nbsp;&nbsp; 0&nbsp;<br>
This&nbsp;instruction&nbsp;computes&nbsp;the&nbsp;16&nbsp;x 16&nbsp;product of the&nbsp;two&nbsp;signed 16-bit&nbsp;values&nbsp;from&nbsp;<br>
the&nbsp;lower&nbsp;(x&nbsp;=&nbsp;0) or&nbsp;upper&nbsp;(x&nbsp;= 1) half of&nbsp;Rm&nbsp;and the lower&nbsp;(y&nbsp;=&nbsp;0)&nbsp;or upper&nbsp;(y&nbsp;= 1)&nbsp;<br>
half of&nbsp;Rs. The&nbsp;32-bit&nbsp;product&nbsp;is placed&nbsp;in&nbsp;Rd.&nbsp;<br>
In&nbsp;all the&nbsp;above&nbsp;instructions&nbsp;the CPSR flags N,&nbsp;Z,&nbsp;C&nbsp;and&nbsp;V are&nbsp;<i>not&nbsp;</i>affected&nbsp;by&nbsp;the&nbsp;<br>
instruction, and&nbsp;the&nbsp;PC&nbsp;(r15)&nbsp;should not&nbsp;be&nbsp;used&nbsp;for any&nbsp;of the&nbsp;operand or&nbsp;result&nbsp;regis-<br>
ters.&nbsp;If&nbsp;the&nbsp;addition in the accumulation&nbsp;(in SMLA&nbsp;and SMLAW) overflows the Q bit&nbsp;<br>
in the&nbsp;CPSR&nbsp;is&nbsp;set, but&nbsp;the addition uses conventional&nbsp;modulo&nbsp;232&nbsp;rather&nbsp;than&nbsp;saturating&nbsp;<br>
arithmetic.&nbsp;<br>
V5TE&nbsp;add/&nbsp;<br>
The other group of instructions in&nbsp;the architecture v5TE extensions&nbsp;are 32-bit&nbsp;addi-&nbsp;<br>
SUbtract&nbsp;<br>
tion and&nbsp;subtraction instructions that&nbsp;use&nbsp;saturating&nbsp;arithmetic.&nbsp;In each case there&nbsp;is&nbsp;<br>
instructions&nbsp;<br>
an additional instruction&nbsp;which also&nbsp;doubles one of&nbsp;the operands&nbsp;before&nbsp;performing&nbsp;<br>
the addition and subtraction, which improves the efficiency of certain signal&nbsp;<br>
processing algorithms. The binary&nbsp;encoding&nbsp;of these&nbsp;instructions is&nbsp;shown in&nbsp;<br>
Figure 8.23.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;8.23 &nbsp;&nbsp;</b>Architecture&nbsp;v5TE&nbsp;add/subtract instruction&nbsp;binary&nbsp;encoding.&nbsp;<br>
The&nbsp;instructions supported&nbsp;by&nbsp;this format are:&nbsp;<br>
QADD{cond}&nbsp;&nbsp;&nbsp;Rd,Rm,Rn&nbsp;<br>
;&nbsp; &nbsp;op&nbsp; =&nbsp; &nbsp;00&nbsp;<br>
This&nbsp;instruction performs&nbsp;a&nbsp;32-bit&nbsp;saturating addition of&nbsp;Rm&nbsp;and&nbsp;Rn, placing the&nbsp;<br>
result in&nbsp;Rd.&nbsp;<br>
<hr>
<A name=256></a><b>244</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;QSUB{cond} &nbsp;&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;op&nbsp;&nbsp;&nbsp;<br>
Rd,Rm,Rn&nbsp;<br>
= &nbsp; 01&nbsp;<br>
This&nbsp;instruction performs&nbsp;a&nbsp;32-bit&nbsp;saturating subtraction&nbsp;of&nbsp;Rn&nbsp;from&nbsp;Rm, placing&nbsp;<br>
the&nbsp;result&nbsp;in&nbsp;Rd.&nbsp;<br>
QDADD{cond} &nbsp;&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;op&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
Rd,Rm,Rn&nbsp;<br>
10&nbsp;<br>
This&nbsp;instruction&nbsp;doubles&nbsp;Rn&nbsp;(with saturation) and&nbsp;then&nbsp;performs&nbsp;a 32-bit saturating&nbsp;<br>
addition of the result&nbsp;and&nbsp;Rm, placing&nbsp;the result&nbsp;in&nbsp;Rd.&nbsp;<br>
QDSUB{cond)&nbsp;Rd,Rm,Rn&nbsp;<br>
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;op&nbsp;&nbsp;&nbsp;<br>
= &nbsp;&nbsp;11&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
This instruction doubles Rn&nbsp;(with&nbsp;saturation) and&nbsp;then&nbsp;performs&nbsp;a 32-bit&nbsp;saturating&nbsp;<br>
subtraction of&nbsp;the result&nbsp;from&nbsp;Rm, placing the&nbsp;result&nbsp;in&nbsp;Rd.&nbsp;<br>
Again, in&nbsp;all&nbsp;the above instructions&nbsp;the CPSR flags N, Z,&nbsp;C and&nbsp;V&nbsp;are&nbsp;<i>not&nbsp;</i>affected&nbsp;<br>
by the instruction, and&nbsp;the PC&nbsp;(r!5) should&nbsp;not&nbsp;be&nbsp;used for&nbsp;any&nbsp;of the operand&nbsp;or result&nbsp;<br>
registers. If the saturating addition&nbsp;or&nbsp;subtraction overflows, or&nbsp;doubling Rn (where&nbsp;<br>
specified)&nbsp;causes overflow,&nbsp;the Q bit in&nbsp;the&nbsp;CPSR is set.&nbsp;<br>
v5TE code&nbsp;<br>
To illustrate&nbsp;the use of&nbsp;these instructions, consider the&nbsp;problem&nbsp;of&nbsp;generating the&nbsp;<br>
example&nbsp;<br>
inner ('dot')&nbsp;product of two&nbsp;vectors of&nbsp;16-bit signed numbers held&nbsp;memory&nbsp;on an&nbsp;<br>
ARM9E-S core,&nbsp;which&nbsp;supports&nbsp;the&nbsp;architecture&nbsp;v5TE extensions, and&nbsp;an&nbsp;<br>
ARM9TDMI&nbsp;core,&nbsp;which does&nbsp;not. Computing an&nbsp;inner product&nbsp;is&nbsp;a very common&nbsp;<br>
procedure&nbsp;in&nbsp;signal&nbsp;processing&nbsp;applications.&nbsp;To&nbsp;minimize&nbsp;errors, saturating&nbsp;arithme-<br>
tic should&nbsp;be used.&nbsp;The v5TE code&nbsp;for the central loop is as&nbsp;follows:&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
loop&nbsp;<br>
SMULBB&nbsp;&nbsp;r3,rl,r2&nbsp;r4,&nbsp;&nbsp;; 16x16 multiply&nbsp;<br>
SUBS&nbsp;<br>
r4,r2&nbsp;<br>
; decrement&nbsp;loop counter&nbsp;<br>
QDADD&nbsp;<br>
r5,r5,r3&nbsp;<br>
;&nbsp;saturating&nbsp;x2&nbsp;&amp;&nbsp;accumulate&nbsp;<br>
SMULTT&nbsp;&nbsp;r3,rl,r2&nbsp;<br>
; 16x16 multiply&nbsp;<br>
LDR&nbsp;<br>
rl,[r6],#4&nbsp;<br>
; get next two multipliers&nbsp;<br>
QDADD&nbsp;<br>
r5,r5,r3&nbsp;<br>
; saturating x2 &amp; accumulate&nbsp;<br>
LDR&nbsp;<br>
r2,[r7],#4&nbsp;<br>
;&nbsp;get&nbsp;next&nbsp;two&nbsp;multiplicands&nbsp;<br>
BNE&nbsp;<br>
loop&nbsp;<br>
&nbsp;&nbsp;&nbsp;This&nbsp;code&nbsp;example illustrates&nbsp;several&nbsp;important&nbsp;points:&nbsp;<br>
&nbsp;<br>
The instructions are&nbsp;'scheduled'&nbsp;to avoid pipeline stalls.&nbsp;On an&nbsp;ARM9E-S this&nbsp;<br>
means that the result&nbsp;of a load or 16-bit&nbsp;multiply&nbsp;should not be used in the fol-<br>
lowing cycle.&nbsp;<br>
Although the operands are&nbsp;16-bit halfwords,&nbsp;they&nbsp;are loaded in pairs&nbsp;as 32-bit&nbsp;<br>
words.&nbsp;This&nbsp;is&nbsp;a more&nbsp;efficient way to&nbsp;use&nbsp;ARM's&nbsp;32-bit&nbsp;memory interface&nbsp;than&nbsp;<br>
using halfword loads, and&nbsp;the v5TE&nbsp;multiply instructions&nbsp;can access&nbsp;the&nbsp;individ-<br>
ual 16-bit operands directly&nbsp;from&nbsp;the&nbsp;registers.&nbsp;<br>
The saturating&nbsp;'double&nbsp;and&nbsp;accumulate'&nbsp;instructions&nbsp;are used to&nbsp;scale&nbsp;the product&nbsp;<br>
before&nbsp;accumulation. This&nbsp;is&nbsp;useful&nbsp;because the fixed point arithmetic used&nbsp;in&nbsp;<br>
<hr>
<A name=257></a><b>Example and exercises</b>&nbsp;<br>
<b>245</b>&nbsp;<br>
signal&nbsp;processing&nbsp;generally assumes operands&nbsp;in&nbsp;the&nbsp;range -1&nbsp;to&nbsp;+1&nbsp;but&nbsp;certain&nbsp;<br>
algorithms need coefficients&nbsp;greater&nbsp;than 1.&nbsp;The doubling operation gives&nbsp;an&nbsp;<br>
effective range&nbsp;from&nbsp;—2 to +2, which is sufficient for most&nbsp;algorithms.&nbsp;<br>
Performance&nbsp;<br>
The single-cycle 32 x 16 multiplier on the ARM9E-S enables it&nbsp;to&nbsp;complete&nbsp;the above&nbsp;<br>
comparison&nbsp;<br>
loop in&nbsp;10&nbsp;clock cycles, of which 4 are loop&nbsp;overhead&nbsp;(decrementing the loop counter&nbsp;<br>
and branching&nbsp;back at the end of the loop). Each loop computes two products, so each&nbsp;<br>
product requires 5 cycles. With loop unrolling (replicating the code to&nbsp;compute&nbsp;many&nbsp;<br>
more products&nbsp;in&nbsp;a single&nbsp;loop iteration) the cost&nbsp;for each product&nbsp;reduces towards 3&nbsp;<br>
cycles.&nbsp;The best an ARM9TDMI can achieve&nbsp;is&nbsp;one product&nbsp;in&nbsp;10 cycles, over three&nbsp;<br>
times&nbsp;slower.&nbsp;The difference is&nbsp;accounted for partly by&nbsp;the slower&nbsp;multiplier&nbsp;on&nbsp;the&nbsp;<br>
ARM9TDMI,&nbsp;partly&nbsp;by&nbsp;its&nbsp;less efficient&nbsp;handling of 16-bit operands, and&nbsp;the remainder&nbsp;<br>
by&nbsp;the extra instructions&nbsp;required&nbsp;to&nbsp;test&nbsp;and&nbsp;correct&nbsp;for&nbsp;saturation.&nbsp;<br>
8.10 &nbsp; Example&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example&nbsp;8.1&nbsp;</b><br>
<b>Estimate&nbsp;the&nbsp;proportion of&nbsp;the&nbsp;number&nbsp;of&nbsp;test&nbsp;vectors&nbsp;required&nbsp;to&nbsp;test</b>&nbsp;<br>
<b>an ARM core via&nbsp;the JTAG and AMBA interfaces.</b>&nbsp;<br>
An&nbsp;ARM&nbsp;core&nbsp;has&nbsp;in&nbsp;the region&nbsp;of&nbsp;100&nbsp;interface&nbsp;connections&nbsp;(32&nbsp;data, 32&nbsp;address,&nbsp;<br>
control,&nbsp;clock, bus,&nbsp;mode, and so on). The&nbsp;JTAG interface&nbsp;is&nbsp;serial. If&nbsp;the&nbsp;tester&nbsp;<br>
allows&nbsp;one&nbsp;vector to&nbsp;specify&nbsp;a&nbsp;pulse&nbsp;on&nbsp;<i>TCK&nbsp;</i>it will take&nbsp;100&nbsp;vectors to&nbsp;apply a paral-<br>
lel&nbsp;pattern&nbsp;to&nbsp;the ARM core. The AMBA&nbsp;test&nbsp;interface&nbsp;accesses&nbsp;the&nbsp;ARM&nbsp;periphery&nbsp;<br>
in five&nbsp;sections&nbsp;(see&nbsp;'Test interface'&nbsp;on&nbsp;page&nbsp;219), requiring five&nbsp;vectors&nbsp;on a&nbsp;stand-<br>
ard tester.&nbsp;<br>
The JTAG interface therefore appears&nbsp;to require&nbsp;20 times&nbsp;the&nbsp;number of vectors.&nbsp;<br>
(Remember that&nbsp;JTAG is&nbsp;intended&nbsp;for&nbsp;PCB&nbsp;testing, not&nbsp;production VLSI&nbsp;testing.) In&nbsp;<br>
fact both the JTAG-based EmbeddedlCE and AMBA interfaces include optimizations&nbsp;<br>
to&nbsp;improve&nbsp;the&nbsp;efficiency&nbsp;of&nbsp;getting&nbsp;instructions&nbsp;into&nbsp;the ARM core, which&nbsp;is the dom-<br>
inant&nbsp;requirement&nbsp;in&nbsp;testing it, but&nbsp;a very&nbsp;detailed analysis&nbsp;would be required to&nbsp;take&nbsp;<br>
these into&nbsp;account&nbsp;in&nbsp;the estimate.&nbsp;<br>
<b>Exercise 8.1.1&nbsp;</b><br>
Summarize the problem&nbsp;areas&nbsp;in&nbsp;the&nbsp;production VLSI testing&nbsp;of&nbsp;complex&nbsp;macrocell-&nbsp;<br>
based&nbsp;system&nbsp;chips&nbsp;and&nbsp;discuss the&nbsp;relative&nbsp;merits&nbsp;of&nbsp;the&nbsp;various&nbsp;solutions.&nbsp;<br>
<b>Exercise 8.1.2&nbsp;</b><br>
Describe and&nbsp;differentiate&nbsp;between production VLSI&nbsp;testing, printed circuit&nbsp;board&nbsp;<br>
testing and system&nbsp;debugging,&nbsp;and&nbsp;describe&nbsp;how&nbsp;a JTAG&nbsp;test&nbsp;port&nbsp;may&nbsp;be used to&nbsp;<br>
address each of&nbsp;these.&nbsp;Where&nbsp;is&nbsp;the JTAG&nbsp;approach&nbsp;most effective and&nbsp;where is it&nbsp;<br>
least effective?&nbsp;<br>
<hr>
<A name=258></a><b>246</b>&nbsp;<br>
<b>Architectural Support&nbsp;for System Development</b>&nbsp;<br>
<b>Exercise&nbsp;8.1.3&nbsp;</b><br>
What&nbsp;problem&nbsp;does the Advanced&nbsp;Microprocessor Bus&nbsp;Architecture&nbsp;address and&nbsp;<br>
what&nbsp;problem&nbsp;does&nbsp;the ARM reference&nbsp;peripheral specification address?&nbsp;How&nbsp;<br>
might they&nbsp;be&nbsp;related?&nbsp;<br>
<b>Exercise&nbsp;8.1.4&nbsp;</b><br>
Sketch&nbsp;a system&nbsp;development&nbsp;plan for&nbsp;an&nbsp;embedded system&nbsp;chip showing&nbsp;at which&nbsp;<br>
stage the ARMulator, AMBA,&nbsp;the&nbsp;reference peripheral&nbsp;specification,&nbsp;<br>
Embed-dedlCE&nbsp;and&nbsp;JTAG are (i) designed&nbsp;into&nbsp;the&nbsp;chip,&nbsp;and/or (ii) used to&nbsp;assist&nbsp;<br>
in&nbsp;the&nbsp;development&nbsp;process.&nbsp;<br>
<hr>
<A name=259></a><IMG src="index-259_1.png"><br>
ARM Processor Cores&nbsp;<br>
&nbsp;<br>
Summary of chapter contents&nbsp;<br>
An ARM&nbsp;processor core is the&nbsp;engine&nbsp;within&nbsp;a system that fetches ARM (and possibly&nbsp;<br>
Thumb) instructions from&nbsp;memory&nbsp;and executes them.&nbsp;ARM cores are very&nbsp;small,&nbsp;<br>
typically occupying&nbsp;just a few&nbsp;square millimetres of chip&nbsp;area. Modern VLSI tech-<br>
nology&nbsp;allows&nbsp;a large&nbsp;number&nbsp;of&nbsp;additional&nbsp;system components to&nbsp;be&nbsp;incorporated&nbsp;on&nbsp;<br>
the same chip.&nbsp;These may&nbsp;be&nbsp;closely&nbsp;related to the processor core, such as cache&nbsp;<br>
memory&nbsp;and memory&nbsp;management hardware, or they&nbsp;may be&nbsp;unrelated&nbsp;system com-<br>
ponents such&nbsp;as signal processing&nbsp;hardware. They&nbsp;may&nbsp;even include further ARM&nbsp;<br>
processor cores. Among all of&nbsp;these components the processor cores stand out as&nbsp;<br>
being the&nbsp;most densely&nbsp;complex components&nbsp;which place the greatest demand on&nbsp;<br>
software&nbsp;development and debugging tools.&nbsp;The correct choice of processor core is&nbsp;<br>
one of the most&nbsp;critical decisions in&nbsp;the specification&nbsp;of a new&nbsp;system.&nbsp;<br>
In this chapter&nbsp;the principal current ARM processor core products are described.&nbsp;<br>
They&nbsp;offer&nbsp;a choice&nbsp;of cost, complexity&nbsp;and&nbsp;performance points from&nbsp;which the&nbsp;<br>
most effective&nbsp;solution&nbsp;can be&nbsp;selected.&nbsp;<br>
Many&nbsp;applications&nbsp;require&nbsp;the processor&nbsp;core&nbsp;to&nbsp;be&nbsp;supported&nbsp;by&nbsp;closely&nbsp;cou-<br>
pled cache&nbsp;and memory&nbsp;management&nbsp;subsystems. A number of&nbsp;standard configu-<br>
rations combining these components are&nbsp;described in&nbsp;Chapter 12, 'ARM CPU&nbsp;<br>
Cores', on page 317.&nbsp;<br>
Further ARM-compatible&nbsp;processor cores&nbsp;are&nbsp;described in&nbsp;Chapter 14, The&nbsp;<br>
AMULET&nbsp;Asynchronous ARM&nbsp;Processors',&nbsp;on page 374. These processor&nbsp;cores are&nbsp;<br>
research&nbsp;prototypes and not&nbsp;yet commercial&nbsp;products.&nbsp;<br>
<b>247</b>&nbsp;<br>
<hr>
<A name=260></a><b>248</b>&nbsp;<br>
<b>ARM&nbsp;Processor&nbsp;Cores</b>&nbsp;<br>
9.1 &nbsp; &nbsp;ARM7TDMI&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The ARM7TDMI is the current low-end&nbsp;ARM core and is widely used across a&nbsp;<br>
range of&nbsp;applications,&nbsp;most notably in&nbsp;many&nbsp;digital&nbsp;mobile telephones.&nbsp;<br>
It evolved from&nbsp;the first ARM core&nbsp;to&nbsp;implement the 32-bit address space program-<br>
ming&nbsp;model, the ARM6,&nbsp;which it&nbsp;now supersedes. The ARM6 used&nbsp;circuit techniques&nbsp;<br>
that&nbsp;prevented&nbsp;it from&nbsp;operating reliably&nbsp;with&nbsp;a&nbsp;power supply&nbsp;of less than&nbsp;5 volts. The&nbsp;<br>
ARM?&nbsp;corrected this&nbsp;deficiency, and then&nbsp;64-bit multiply&nbsp;instructions, on-chip debug&nbsp;<br>
support,&nbsp;the&nbsp;Thumb instruction&nbsp;set&nbsp;and&nbsp;the&nbsp;EmbeddedlCE&nbsp;watchpoint&nbsp;hardware&nbsp;were&nbsp;<br>
all&nbsp;added&nbsp;over&nbsp;a fairly&nbsp;short&nbsp;period&nbsp;of time&nbsp;to&nbsp;give&nbsp;the ARM7TDMI.&nbsp;<br>
The&nbsp;origins&nbsp;of the&nbsp;name&nbsp;are as follows:&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;ARM7,&nbsp;a 3&nbsp;volt&nbsp;compatible&nbsp;rework of&nbsp;the&nbsp;ARM6 32-bit&nbsp;integer core, with:&nbsp;<br>
•&nbsp;&nbsp;the Thumb 16-bit compressed&nbsp;instruction&nbsp;set;&nbsp;<br>
•&nbsp;&nbsp;on-chip&nbsp;Debug&nbsp;support,&nbsp;enabling&nbsp;the&nbsp;processor&nbsp;to&nbsp;halt&nbsp;in&nbsp;response&nbsp;to&nbsp;a&nbsp;debug&nbsp;<br>
request;&nbsp;<br>
•&nbsp;&nbsp;an&nbsp;enhanced Multiplier,&nbsp;with&nbsp;higher&nbsp;performance&nbsp;than&nbsp;its predecessors&nbsp;and&nbsp;yield&nbsp;<br>
ing a&nbsp;full 64-bit result; and&nbsp;<br>
•&nbsp;&nbsp;EmbeddedlCE hardware&nbsp;to give on-chip&nbsp;breakpoint and&nbsp;watchpoint&nbsp;support.&nbsp;<br>
The ARM7TDMI has been&nbsp;fabricated&nbsp;on&nbsp;a&nbsp;large&nbsp;number of different&nbsp;CMOS pro-<br>
cess&nbsp;technologies, some&nbsp;supporting&nbsp;clock rates over 100 MHz&nbsp;and others&nbsp;enabling&nbsp;<br>
operation at&nbsp;0.9 V (thereby&nbsp;allowing&nbsp;a single-cell&nbsp;battery&nbsp;to&nbsp;be&nbsp;used&nbsp;as&nbsp;the source&nbsp;of&nbsp;<br>
power). Typical applications&nbsp;in&nbsp;production&nbsp;at&nbsp;the&nbsp;time of writing&nbsp;use&nbsp;a&nbsp;3.3&nbsp;V supply&nbsp;on&nbsp;<br>
a 0.35&nbsp;um&nbsp;process&nbsp;yielding&nbsp;a&nbsp;clock&nbsp;rate&nbsp;of up&nbsp;to&nbsp;66&nbsp;MHz,&nbsp;but&nbsp;the trend is, of course,&nbsp;<br>
towards smaller transistors, lower supply&nbsp;voltages&nbsp;and higher&nbsp;clock frequencies.&nbsp;<br>
ARM7TDMI&nbsp;<br>
The&nbsp;organization&nbsp;of the ARM7TDMI&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;Figure 9.1 on page 249. The&nbsp;<br>
organization&nbsp;<br>
ARM7TDMI&nbsp;core is&nbsp;a basic&nbsp;ARM integer&nbsp;core using a 3-stage pipeline&nbsp;(see&nbsp;<br>
Section&nbsp;4.1 on&nbsp;page 75)&nbsp;with&nbsp;a number&nbsp;of&nbsp;important&nbsp;features&nbsp;and extensions:&nbsp;<br>
•&nbsp;&nbsp;It implements&nbsp;ARM&nbsp;architecture version 4T, with support&nbsp;for&nbsp;64-bit result multi&nbsp;<br>
plies, half-word and signed byte loads and&nbsp;stores and the Thumb instruction set.&nbsp;<br>
•&nbsp;&nbsp;It includes the&nbsp;EmbeddedlCE&nbsp;module to support embedded system&nbsp;debugging.&nbsp;<br>
(This was&nbsp;described in&nbsp;Section 8.7 on page&nbsp;232.)&nbsp;<br>
As the debug&nbsp;hardware is accessed via the JTAG test access port, the JTAG&nbsp;<br>
control&nbsp;logic (described&nbsp;in Section 8.6 on&nbsp;page&nbsp;226)&nbsp;is&nbsp;considered&nbsp;part&nbsp;of the&nbsp;<br>
processor macrocell.&nbsp;<br>
Hardware&nbsp;<br>
The&nbsp;ARM7TDMI hardware interface&nbsp;signals&nbsp;are&nbsp;shown&nbsp;in&nbsp;Figure 9.2&nbsp;on&nbsp;page 250.&nbsp;<br>
interface&nbsp;<br>
The apparently&nbsp;bewildering&nbsp;number of&nbsp;signals is rather&nbsp;misleading as&nbsp;it suggests a&nbsp;<br>
<hr>
<A name=261></a><IMG src="index-261_1.png"><br>
ARM7TDMI&nbsp;<br>
249&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;9.1 &nbsp; &nbsp;</b>ARM7TDMI organization.&nbsp;<br>
complexity&nbsp;of&nbsp;behaviour that&nbsp;belies&nbsp;the&nbsp;intrinsic&nbsp;simplicity&nbsp;of the&nbsp;basic&nbsp;ARM&nbsp;inter-<br>
face.&nbsp;Numerically the&nbsp;interface&nbsp;signals&nbsp;are dominated by&nbsp;the principal 32-bit&nbsp;address&nbsp;<br>
and data buses,&nbsp;and a&nbsp;simple memory&nbsp;interface&nbsp;will&nbsp;use these&nbsp;and a&nbsp;few control&nbsp;sig-<br>
nals&nbsp;as described below. The other&nbsp;signals&nbsp;are&nbsp;dedicated to&nbsp;more&nbsp;esoteric&nbsp;functions&nbsp;<br>
such&nbsp;as on-chip&nbsp;debug, JTAG boundary&nbsp;scan&nbsp;extensions,&nbsp;and so on.&nbsp;<br>
In Figure 9.2 on page&nbsp;250 the&nbsp;interface signals are&nbsp;shown&nbsp;grouped by function, and&nbsp;<br>
the role of each&nbsp;group is&nbsp;described&nbsp;below with, where appropriate,&nbsp;information on&nbsp;the&nbsp;<br>
individual&nbsp;signals&nbsp;and&nbsp;the&nbsp;interface&nbsp;timing.&nbsp;<br>
Clock&nbsp;control&nbsp;<br>
All&nbsp;state&nbsp;changes&nbsp;within the&nbsp;processor are&nbsp;controlled&nbsp;by&nbsp;<i>mclk,&nbsp;</i>the&nbsp;memory&nbsp;clock.&nbsp;<br>
Although this&nbsp;clock&nbsp;may&nbsp;be&nbsp;manipulated externally to cause the processor to&nbsp;wait&nbsp;<br>
for a&nbsp;slow access, it is&nbsp;often&nbsp;simpler to supply&nbsp;a&nbsp;free-running clock and&nbsp;to use&nbsp;<i>wait&nbsp;</i><br>
to skip&nbsp;clock cycles. The internal clock is&nbsp;effectively&nbsp;just a&nbsp;logical AND&nbsp;<i>of mclk&nbsp;</i>and&nbsp;<br>
<i>wait,&nbsp;</i>so&nbsp;<i>wait&nbsp;</i>must only change&nbsp;when&nbsp;<i>mclk&nbsp;</i>is low.&nbsp;<br>
The&nbsp;<i>eclh&nbsp;</i>clock&nbsp;output reflects&nbsp;the&nbsp;clock&nbsp;used&nbsp;by&nbsp;the core, so&nbsp;it&nbsp;normally&nbsp;reflects&nbsp;the&nbsp;<br>
behaviour&nbsp;<i>of mclk&nbsp;</i>after&nbsp;<i>wait&nbsp;</i>has been&nbsp;gated in, but it&nbsp;also reflects the behaviour of the&nbsp;<br>
debug&nbsp;clock when&nbsp;in&nbsp;debugging mode.&nbsp;<br>
Memory&nbsp;<br>
The&nbsp;memory interface&nbsp;comprises the 32-bit&nbsp;address&nbsp;<i>(A[31:OJ),&nbsp;</i>a bidirectional data&nbsp;<br>
interface&nbsp;<br>
bus&nbsp;&nbsp;<i>(D[31:OJ),&nbsp;&nbsp;</i>separate data out&nbsp;<i>(Dout[31:OJ)&nbsp;&nbsp;</i>and data&nbsp;in&nbsp;<i>(Din[31:OJ)&nbsp;&nbsp;</i>buses&nbsp;<br>
together&nbsp;with ten control&nbsp;signals.&nbsp;<br>
•&nbsp;&nbsp;<i>mreq&nbsp;</i>indicates a processor cycle&nbsp;which&nbsp;requires&nbsp;a&nbsp;memory&nbsp;access.&nbsp;<br>
•&nbsp;&nbsp;<i>seq&nbsp;</i>indicates that the&nbsp;memory address&nbsp;will&nbsp;be sequential to&nbsp;(or possibly the same&nbsp;<br>
as) that used&nbsp;in&nbsp;the previous cycle.&nbsp;<br>
<hr>
<A name=262></a><IMG src="index-262_1.png"><br>
&nbsp;<br>
<b>Figure 9.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The&nbsp;ARM7TDMI core&nbsp;interface signals.&nbsp;<br>
•&nbsp;&nbsp;<i>lock&nbsp;</i>indicates&nbsp;that the processor should keep&nbsp;the&nbsp;bus to&nbsp;ensure the atomicity&nbsp;of&nbsp;<br>
the read and write&nbsp;phases&nbsp;of&nbsp;a SWAP&nbsp;instruction.&nbsp;<br>
•&nbsp;&nbsp;<i>r/w&nbsp;</i>indicates&nbsp;whether the processor is performing a&nbsp;read&nbsp;or a&nbsp;write cycle.&nbsp;<br>
<hr>
<A name=263></a><b>ARM7TDMI</b>&nbsp;<br>
<b>251</b>&nbsp;<br>
<b>Table&nbsp;9.1 &nbsp;&nbsp;&nbsp;</b>ARM7TDMI cycle types.&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<i>mreq</i>&nbsp;&nbsp;&nbsp;<br>
<i>seq</i>&nbsp;&nbsp;&nbsp;&nbsp;Cycle&nbsp;&nbsp;&nbsp;&nbsp;Use&nbsp;&nbsp;&nbsp;<br>
0 &nbsp;<br>
0 &nbsp;<br>
N&nbsp;&nbsp;&nbsp;<br>
Non-sequential memory&nbsp;access&nbsp;&nbsp;&nbsp;<br>
0 &nbsp;<br>
1 &nbsp;<br>
S&nbsp;&nbsp;&nbsp;<br>
Sequential memory access&nbsp;&nbsp;&nbsp;<br>
1 &nbsp;<br>
0&nbsp;&nbsp;&nbsp;<br>
I&nbsp;&nbsp;&nbsp;<br>
Internal cycle&nbsp;- bus and&nbsp;memory inactive&nbsp;&nbsp;&nbsp;<br>
1 &nbsp;<br>
1&nbsp;&nbsp;&nbsp;<br>
c&nbsp;&nbsp;&nbsp;&nbsp;Coprocessor&nbsp;register transfer - memory&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
inactive&nbsp;&nbsp;&nbsp;<br>
<i>mas[1:0]&nbsp;</i>encode the memory access&nbsp;size,&nbsp;indicating&nbsp;whether the access&nbsp;is for a&nbsp;<br>
byte, half-word&nbsp;or&nbsp;word&nbsp;quantity.&nbsp;<br>
<i>bl[3:0]&nbsp;</i>are externally controlled&nbsp;enables&nbsp;on latches on&nbsp;each&nbsp;of&nbsp;the four&nbsp;bytes&nbsp;on&nbsp;<br>
the data input&nbsp;bus.&nbsp;These make&nbsp;interfacing&nbsp;memories&nbsp;which are less than 32&nbsp;bits&nbsp;<br>
wide easier.&nbsp;<br>
The signals&nbsp;which indicate&nbsp;the type of the&nbsp;memory&nbsp;cycle,&nbsp;<i>mreq&nbsp;&nbsp;</i>and&nbsp;&nbsp;<i>seq,&nbsp;&nbsp;</i>are&nbsp;<br>
issued early to&nbsp;give&nbsp;the memory&nbsp;control logic as long&nbsp;as&nbsp;possible to&nbsp;decide&nbsp;how&nbsp;to&nbsp;<br>
handle&nbsp;the&nbsp;memory access.&nbsp;The&nbsp;interpretation&nbsp;of&nbsp;the four possible&nbsp;combinations&nbsp;of&nbsp;<br>
values&nbsp;on&nbsp;these two&nbsp;signals is&nbsp;given in&nbsp;Table 9.1.&nbsp;When&nbsp;a&nbsp;sequential cycle follows&nbsp;a&nbsp;<br>
non-sequential&nbsp;cycle,&nbsp;the address will&nbsp;be&nbsp;that of&nbsp;the non-sequential&nbsp;cycle plus one&nbsp;<br>
word&nbsp;(four&nbsp;bytes); where the&nbsp;sequential cycle follows&nbsp;an internal or coprocessor reg-<br>
ister transfer cycle, the address&nbsp;will&nbsp;be&nbsp;unchanged&nbsp;from&nbsp;the preceding&nbsp;cycle. In&nbsp;a&nbsp;<br>
typical&nbsp;memory&nbsp;organization&nbsp;the incrementing&nbsp;case can be&nbsp;used, together with&nbsp;infor-<br>
mation about&nbsp;the preceding address,&nbsp;to&nbsp;prepare&nbsp;the&nbsp;memory&nbsp;for a fast&nbsp;sequential&nbsp;<br>
access&nbsp;and where&nbsp;the address remains&nbsp;the&nbsp;same&nbsp;this&nbsp;can&nbsp;be&nbsp;exploited to&nbsp;start a&nbsp;full&nbsp;<br>
memory access in the preceding cycle (since&nbsp;neither the internal nor the&nbsp;coprocessor&nbsp;<br>
register&nbsp;transfer&nbsp;cycles&nbsp;use&nbsp;the&nbsp;memory).&nbsp;<br>
The timing of the critical&nbsp;interface signals is&nbsp;illustrated in Figure&nbsp;9.3 on&nbsp;page 252.&nbsp;<br>
The&nbsp;use&nbsp;of these signals and&nbsp;the design&nbsp;of the memory interface logic&nbsp;was discussed&nbsp;<br>
further in&nbsp;Section 8.1&nbsp;on page&nbsp;208, where specific examples&nbsp;are given.&nbsp;<br>
MMU interface The interface&nbsp;signals to&nbsp;the&nbsp;MMU&nbsp;provide&nbsp;information&nbsp;which&nbsp;is&nbsp;used&nbsp;to&nbsp;control&nbsp;<br>
access to&nbsp;areas&nbsp;of memory. The&nbsp;<i>trans&nbsp;</i>(translation&nbsp;control) signal indicates whether&nbsp;<br>
the&nbsp;processor&nbsp;is&nbsp;in&nbsp;a&nbsp;user&nbsp;<i>(trans =&nbsp;</i>0)&nbsp;or&nbsp;privileged&nbsp;<i>(trans =&nbsp;</i>1)&nbsp;mode&nbsp;so&nbsp;that&nbsp;some&nbsp;<br>
areas&nbsp;of memory can&nbsp;be&nbsp;restricted to supervisor-only access and,&nbsp;where&nbsp;appropriate,&nbsp;<br>
different translation&nbsp;tables can be&nbsp;used&nbsp;for&nbsp;user and&nbsp;supervisor&nbsp;code&nbsp;(though this is&nbsp;<br>
rarely&nbsp;done).&nbsp;Where more detailed information about&nbsp;the operating mode is&nbsp;<br>
required,&nbsp;&nbsp;<i>mode[4:0]&nbsp;&nbsp;</i>reflects&nbsp;the bottom&nbsp;five&nbsp;bits of&nbsp;the CPSR (inverted),&nbsp;though&nbsp;<br>
memory&nbsp;management&nbsp;at this level&nbsp;is&nbsp;rarely&nbsp;used; the&nbsp;detailed&nbsp;mode&nbsp;information&nbsp;is&nbsp;<br>
probably&nbsp;of&nbsp;most&nbsp;use&nbsp;when debugging.&nbsp;<br>
<hr>
<A name=264></a><IMG src="index-264_1.png"><br>
&nbsp;<br>
<b>252</b>&nbsp;<br>
<b>ARM&nbsp;Processor&nbsp;Cores</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;9.3&nbsp; &nbsp;</b>ARM7TDMI core memory&nbsp;and MMU&nbsp;interface&nbsp;timing.&nbsp;<br>
Where&nbsp;an&nbsp;access is&nbsp;disallowed, this&nbsp;is&nbsp;signalled&nbsp;on the&nbsp;<i>abort&nbsp;</i>input.&nbsp;The&nbsp;timing of&nbsp;<br>
<i>abort&nbsp;</i>is&nbsp;such that it&nbsp;must&nbsp;be valid&nbsp;at the end of&nbsp;the cycle, with the data. This&nbsp;is&nbsp;illus-<br>
trated&nbsp;in&nbsp;Figure&nbsp;9.3.&nbsp;<br>
An aborted&nbsp;memory access&nbsp;causes the processor to&nbsp;take&nbsp;a prefetch or&nbsp;data abort,&nbsp;<br>
depending&nbsp;on&nbsp;the&nbsp;value&nbsp;<i>of ope&nbsp;</i>during&nbsp;the access.&nbsp;<br>
The&nbsp;MMU&nbsp;may also&nbsp;use&nbsp;the&nbsp;<i>ope&nbsp;</i>signal&nbsp;where&nbsp;it is&nbsp;desired&nbsp;to&nbsp;support execute-only&nbsp;<br>
areas&nbsp;of&nbsp;memory, but it&nbsp;should&nbsp;be&nbsp;noted that&nbsp;this&nbsp;precludes&nbsp;the&nbsp;use&nbsp;of&nbsp;literal pools&nbsp;held&nbsp;<br>
in&nbsp;the&nbsp;code&nbsp;area&nbsp;for PC-relative access. For&nbsp;this reason&nbsp;execute-only protection&nbsp;is&nbsp;not&nbsp;<br>
widely&nbsp;used&nbsp;in&nbsp;ARM&nbsp;systems (and,&nbsp;in&nbsp;particular,&nbsp;is&nbsp;not&nbsp;supported&nbsp;in&nbsp;the&nbsp;ARM&nbsp;MMU&nbsp;<br>
architecture described in&nbsp;Section 11.6 on&nbsp;page&nbsp;302).&nbsp;<br>
State&nbsp;<br>
The&nbsp;<i>Tbit&nbsp;</i>output tells the environment&nbsp;whether the processor is currently&nbsp;executing&nbsp;<br>
ARM&nbsp;or Thumb instructions.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Configuration&nbsp;<br>
<i>bigend&nbsp;&nbsp;</i>switches the byte&nbsp;ordering between little- and big-endian&nbsp;(see&nbsp;'Memory&nbsp;<br>
organization'&nbsp;on&nbsp;page 106 for an explanation of endianness). This input&nbsp;configures&nbsp;<br>
the&nbsp;way&nbsp;the processor operates and&nbsp;is not&nbsp;expected to&nbsp;change dynamically, although&nbsp;<br>
it can be changed during&nbsp;phase&nbsp;2 of the&nbsp;clock if necessary.&nbsp;<br>
Interrupts&nbsp;<br>
The&nbsp;two interrupt&nbsp;inputs may be&nbsp;asynchronous to&nbsp;the&nbsp;processor clock&nbsp;since they&nbsp;pass&nbsp;<br>
through synchronizing&nbsp;latches&nbsp;before&nbsp;entering&nbsp;the processor's control logic. The fast&nbsp;<br>
interrupt request,^,&nbsp;has&nbsp;higher&nbsp;priority&nbsp;than&nbsp;the&nbsp;normal interrupt request,&nbsp;<i>irq.</i>&nbsp;<br>
The&nbsp;<i>isync&nbsp;</i>input allows the interrupt&nbsp;synchronizers to be bypassed&nbsp;when&nbsp;the envi-<br>
ronment&nbsp;supplies inputs that are already&nbsp;synchronous&nbsp;to&nbsp;<i>mclk',&nbsp;</i>this&nbsp;removes&nbsp;the&nbsp;syn-<br>
chronizing delay from&nbsp;the interrupt&nbsp;latency.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Initialization&nbsp;<br>
<i>reset&nbsp;</i>starts&nbsp;the&nbsp;processor from&nbsp;a&nbsp;known state,&nbsp;executing from&nbsp;address&nbsp;0000000016.&nbsp;<br>
<hr>
<A name=265></a><b>ARM7TDMI</b>&nbsp;<br>
<b>253</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Bus control&nbsp;<br>
Normally,&nbsp;the ARM7TDMI&nbsp;core issues a new&nbsp;address as soon&nbsp;as&nbsp;it is available&nbsp;to&nbsp;<br>
maximize the time&nbsp;the&nbsp;MMU&nbsp;or&nbsp;memory controller&nbsp;has to&nbsp;process&nbsp;it. However, in&nbsp;<br>
simple systems&nbsp;where&nbsp;the&nbsp;address bus is connected&nbsp;directly&nbsp;to&nbsp;ROM&nbsp;or&nbsp;SRAM&nbsp;it&nbsp;is&nbsp;<br>
necessary to&nbsp;hold the&nbsp;old address to the end of the&nbsp;cycle.&nbsp;The&nbsp;core&nbsp;incorporates&nbsp;a&nbsp;<br>
transparent latch controlled by&nbsp;<i>ape,&nbsp;</i>which&nbsp;can retime&nbsp;the address&nbsp;as&nbsp;required by&nbsp;<br>
external logic.&nbsp;<br>
The&nbsp;ARM7TDMI&nbsp;core indicates&nbsp;when it&nbsp;is&nbsp;performing&nbsp;a&nbsp;write cycle by&nbsp;signalling&nbsp;<br>
on&nbsp;&nbsp;<i>enout.&nbsp;&nbsp;</i>Where the&nbsp;external data bus is&nbsp;bidirectional,&nbsp;<i>enout&nbsp;&nbsp;</i>is used&nbsp;to enable&nbsp;<br>
<i>dout[31:0]&nbsp;</i>onto it. Sometimes it is desirable to defer the write operation so that&nbsp;<br>
another device&nbsp;can drive the&nbsp;bus. The data&nbsp;bus enable signal,&nbsp;<i>dbe,&nbsp;</i>can&nbsp;be used to&nbsp;<br>
ensure&nbsp;that&nbsp;<i>enout&nbsp;</i>remains inactive&nbsp;in&nbsp;such&nbsp;circumstances.&nbsp;The&nbsp;core&nbsp;must&nbsp;be stopped&nbsp;<br>
(using&nbsp;<i>wait&nbsp;</i>or&nbsp;clock stretching)&nbsp;until&nbsp;the&nbsp;bus is&nbsp;available,&nbsp;<i>dbe&nbsp;</i>is&nbsp;externally timed as&nbsp;<br>
required&nbsp;by&nbsp;the external&nbsp;logic.&nbsp;<br>
The other bus control signals,&nbsp;<i>enin, enouti, abe, ale,&nbsp;the,&nbsp;busen,&nbsp;highz, busdis&nbsp;</i>and&nbsp;<br>
<i>ecapclk,&nbsp;&nbsp;</i>perform&nbsp;various&nbsp;other&nbsp;functions.&nbsp;The&nbsp;reader should&nbsp;refer to&nbsp;the&nbsp;relevant&nbsp;<br>
ARM7TDMI&nbsp;datasheet&nbsp;for details.&nbsp;<br>
Debug support&nbsp;<br>
The&nbsp;ARM7TDMI implements the&nbsp;ARM debug&nbsp;architecture described&nbsp;in&nbsp;Section 8.7&nbsp;<br>
on&nbsp;page&nbsp;232.&nbsp;The&nbsp;EmbeddedlCE module&nbsp;contains&nbsp;the&nbsp;breakpoint&nbsp;and watchpoint reg-<br>
isters which&nbsp;allow code&nbsp;to&nbsp;be&nbsp;halted&nbsp;for&nbsp;debugging&nbsp;purposes. These registers are&nbsp;con-<br>
trolled through&nbsp;the&nbsp;JTAG test port using&nbsp;scan&nbsp;chain 2&nbsp;(see Figure 9.1&nbsp;on page&nbsp;249).&nbsp;<br>
When&nbsp;a&nbsp;breakpoint&nbsp;or watchpoint&nbsp;is&nbsp;encountered,&nbsp;the&nbsp;processor halts&nbsp;and enters&nbsp;debug&nbsp;<br>
state. Once in&nbsp;debug&nbsp;state, the&nbsp;processor registers may be&nbsp;inspected by&nbsp;forcing&nbsp;<br>
instructions into&nbsp;the&nbsp;instruction pipeline&nbsp;using scan chain 1.&nbsp;A store&nbsp;multiple of all&nbsp;the&nbsp;<br>
registers&nbsp;will present the&nbsp;register values on the data&nbsp;bus, where they&nbsp;can&nbsp;be&nbsp;sampled&nbsp;<br>
and shifted out again&nbsp;using scan&nbsp;chain 1.&nbsp;Accessing&nbsp;the&nbsp;banked&nbsp;registers&nbsp;requires&nbsp;<br>
instructions&nbsp;to&nbsp;be&nbsp;forced&nbsp;in&nbsp;to&nbsp;cause&nbsp;a&nbsp;mode change&nbsp;(note&nbsp;that&nbsp;in&nbsp;debug&nbsp;state&nbsp;the&nbsp;usual&nbsp;<br>
bar&nbsp;against switching into&nbsp;a&nbsp;privileged&nbsp;mode&nbsp;from&nbsp;user mode&nbsp;is&nbsp;removed).&nbsp;<br>
Inspecting system&nbsp;state&nbsp;is&nbsp;achieved by&nbsp;causing&nbsp;the ARM&nbsp;to access memory&nbsp;loca-<br>
tions&nbsp;at&nbsp;system&nbsp;speed&nbsp;and&nbsp;then&nbsp;switch&nbsp;immediately&nbsp;back&nbsp;into&nbsp;debug&nbsp;state.&nbsp;<br>
Debug interface<br>
The debug&nbsp;interface extends the&nbsp;functionality provided by&nbsp;the integrated Embed-<br>
&nbsp;<br>
dedlCE macrocell&nbsp;by allowing external&nbsp;hardware&nbsp;to enable&nbsp;debug&nbsp;support (via&nbsp;<i>dbgen)&nbsp;</i><br>
and&nbsp;make&nbsp;an&nbsp;asynchronous&nbsp;debug request (on&nbsp;<i>dbgrq)&nbsp;</i>or an&nbsp;instruction-synchronous&nbsp;<br>
request (on&nbsp;<i>breakpf).&nbsp;</i>External hardware is&nbsp;informed of&nbsp;when the core&nbsp;is in debug&nbsp;<br>
mode via&nbsp;<i>dbgack.&nbsp;</i>The&nbsp;internal&nbsp;debug&nbsp;request&nbsp;signal&nbsp;is&nbsp;exported&nbsp;on&nbsp;<i>dbgrqi.</i>&nbsp;<br>
External&nbsp;events may contribute&nbsp;to&nbsp;the triggering&nbsp;of&nbsp;watchpoints&nbsp;via&nbsp;<i>externO&nbsp;</i><br>
and&nbsp;<i>externl,&nbsp;</i>and EmbeddedlCE watchpoint&nbsp;matches are signalled&nbsp;on&nbsp;<i>rangeoutO&nbsp;</i><br>
and&nbsp;<i>rangeoutl.</i>&nbsp;<br>
An empty communication transmission buffer is&nbsp;signalled on&nbsp;<i>commtx,&nbsp;</i>and an&nbsp;<br>
empty&nbsp;reception buffer on&nbsp;<i>commrx.</i>&nbsp;<br>
<hr>
<A name=266></a><b>254</b>&nbsp;<br>
<b>ARM&nbsp;Processor&nbsp;Cores</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The processor indicates whether or not&nbsp;the current instruction in the execution&nbsp;<br>
stage is&nbsp;being executed on&nbsp;<i>exec.&nbsp;</i>An&nbsp;instruction&nbsp;is&nbsp;not&nbsp;executed&nbsp;if,&nbsp;for example,&nbsp;it&nbsp;fails&nbsp;<br>
its condition code test.&nbsp;<br>
Coprocessor&nbsp;<br>
The&nbsp;<i>cpi,&nbsp;cpa&nbsp;</i>and&nbsp;<i>cpb&nbsp;</i>coprocessor&nbsp;interface signals were&nbsp;described in&nbsp;Section 4.5&nbsp;on&nbsp;<br>
interface&nbsp;<br>
page 101. The additional&nbsp;signal&nbsp;provided&nbsp;to&nbsp;the coprocessors&nbsp;is&nbsp;<i>ope,&nbsp;</i>which&nbsp;indicates&nbsp;<br>
whether a&nbsp;memory access is to fetch an instruction or a&nbsp;data item.&nbsp;This&nbsp;is used by&nbsp;<br>
the coprocessor pipeline follower to track&nbsp;the ARM instruction execution. Where&nbsp;<br>
there&nbsp;is&nbsp;no&nbsp;requirement&nbsp;to connect a&nbsp;coprocessor,&nbsp;<i>cpa&nbsp;</i>and&nbsp;<i>cpb&nbsp;</i>should be&nbsp;tied&nbsp;high.&nbsp;<br>
This&nbsp;will cause&nbsp;all coprocessor instructions&nbsp;to&nbsp;take the&nbsp;undefined&nbsp;instruction trap.&nbsp;<br>
Power&nbsp;<br>
The&nbsp;ARM7TDMI&nbsp;core&nbsp;is&nbsp;designed&nbsp;to operate&nbsp;with a nominal 5&nbsp;volt or&nbsp;3 volt&nbsp;supply,&nbsp;<br>
though&nbsp;this is dependent on&nbsp;the capabilities&nbsp;of&nbsp;the process technology&nbsp;as well&nbsp;as the&nbsp;<br>
circuit design&nbsp;style employed in&nbsp;the&nbsp;core.&nbsp;<br>
JTAG interface&nbsp;<br>
The&nbsp;JTAG&nbsp;control&nbsp;signals&nbsp;are&nbsp;as&nbsp;prescribed&nbsp;by&nbsp;the&nbsp;standard&nbsp;described&nbsp;in&nbsp;Section 8.6&nbsp;<br>
on page 226 and are connected to an off-chip test controller&nbsp;via dedicated pins.&nbsp;<br>
TAP information&nbsp;<br>
These signals&nbsp;are used&nbsp;to&nbsp;support&nbsp;the addition&nbsp;of further scan chains&nbsp;to&nbsp;the JTAG&nbsp;<br>
system, along&nbsp;with the boundary scan&nbsp;extension&nbsp;signals detailed below.&nbsp;<br>
<i>tapsm[3:0]&nbsp;</i>indicates the&nbsp;state the TAP controller is&nbsp;in;&nbsp;<i>ir[3:0]&nbsp;</i>gives the&nbsp;contents&nbsp;<br>
of the&nbsp;TAP instruction&nbsp;register;&nbsp;<i>screg[3:0]&nbsp;</i>is the address of the scan&nbsp;register cur-<br>
rently&nbsp;selected&nbsp;by&nbsp;the&nbsp;TAP controller;&nbsp;<i>tckl&nbsp;</i>and&nbsp;<i>tck2&nbsp;</i>form&nbsp;a non-overlapping pair of&nbsp;<br>
clocks to&nbsp;control extension&nbsp;scan&nbsp;chains,&nbsp;and&nbsp;<i>tdoen&nbsp;</i>indicates when serial data&nbsp;is&nbsp;<br>
being driven&nbsp;out&nbsp;on&nbsp;<i>tdo.</i>&nbsp;<br>
Boundary scan&nbsp;<br>
The&nbsp;ARM7TDMI&nbsp;cell contains&nbsp;a&nbsp;full&nbsp;JTAG TAP&nbsp;controller to&nbsp;support the&nbsp;<br>
extension&nbsp;<br>
Embed-dedlCE functionality,&nbsp;and this TAP&nbsp;controller is&nbsp;capable of&nbsp;supporting&nbsp;any&nbsp;<br>
other on-chip&nbsp;scan facilities that are accessed through&nbsp;the&nbsp;JTAG port. The&nbsp;<i>drivebs,&nbsp;</i><br>
<i>ecapclkbs,&nbsp;icapclkbs, highz,&nbsp;pclkbs,&nbsp;rstclkbs, sdinbs,&nbsp;sdoutbs, shclkbs&nbsp;</i>and&nbsp;<i>shclk2bs&nbsp;</i><br>
interface signals are therefore&nbsp;made available to allow arbitrary additional scan&nbsp;<br>
paths&nbsp;to be&nbsp;added to&nbsp;the system.&nbsp;The&nbsp;reader should&nbsp;refer&nbsp;to the relevant&nbsp;<br>
ARM7TDMI&nbsp;datasheet&nbsp;for details of the individual&nbsp;functions of&nbsp;these&nbsp;signals.&nbsp;<br>
ARM7TDMI core&nbsp;<br>
A&nbsp;plot&nbsp;of&nbsp;the ARM7TDMI&nbsp;processor&nbsp;core&nbsp;is&nbsp;shown in&nbsp;Figure 9.4&nbsp;on&nbsp;page&nbsp;255.&nbsp;The&nbsp;<br>
characteristics&nbsp;of the&nbsp;0.35 um&nbsp;core&nbsp;when&nbsp;executing 32-bit ARM code&nbsp;are&nbsp;summa-<br>
rized in&nbsp;Table&nbsp;9.2.&nbsp;<br>
On a suitable&nbsp;process technology&nbsp;exceedingly&nbsp;high&nbsp;power-efficiencies have been&nbsp;<br>
obtained&nbsp;with&nbsp;ARM7TDMI&nbsp;cores. One&nbsp;example used&nbsp;a 0.25&nbsp;um&nbsp;process&nbsp;technology&nbsp;<br>
with a 0.9 V&nbsp;power supply&nbsp;to deliver 12,000&nbsp;MIPS/W.&nbsp;<br>
<hr>
<A name=267></a><IMG src="index-267_1.png"><br>
<b>ARM7TDMI</b>&nbsp;<br>
<b>255</b>&nbsp;<br>
1&nbsp;<br>
j&nbsp;<br>
oc&nbsp;<br>
&lt;&nbsp;<br>
©&nbsp;<br>
<b>Figure&nbsp;9.4 &nbsp;&nbsp;</b>The ARM7TDMI processor core.&nbsp;<br>
<b>Table&nbsp;9.2 &nbsp;&nbsp;&nbsp;</b>ARM7TDMI&nbsp;characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.35&nbsp;urn</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>74,209&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>60</b>&nbsp;&nbsp;&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3</b>&nbsp;&nbsp;<b>Core area</b>&nbsp;&nbsp;&nbsp;<br>
<b>2.1 mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>87 mW</b>&nbsp;&nbsp;&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>3.3V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>0-66 MHz&nbsp;MIPSAV</b>&nbsp;<br>
<b>690</b>&nbsp;&nbsp;&nbsp;<br>
ARM7TDMI for&nbsp;<br>
The standard&nbsp;ARM7TDMI&nbsp;processor core&nbsp;is a&nbsp;'hard'&nbsp;macrocell,&nbsp;which is&nbsp;to&nbsp;say&nbsp;that&nbsp;<br>
synthesis&nbsp;<br>
it is delivered&nbsp;as a piece of&nbsp;physical layout, customized to the appropriate process&nbsp;<br>
technology.&nbsp;The&nbsp;ARM7TDMI-S is a synthesizable version of&nbsp;the&nbsp;ARM7TDMI,&nbsp;<br>
delivered&nbsp;as&nbsp;a high-level&nbsp;language&nbsp;module which can be&nbsp;synthesized using&nbsp;any&nbsp;suit-<br>
able cell library&nbsp;in the target&nbsp;technology.&nbsp;It&nbsp;is therefore easier to port to&nbsp;a new pro-<br>
cess technology&nbsp;than is the hard&nbsp;macrocell.&nbsp;<br>
The&nbsp;synthesis&nbsp;process&nbsp;supports a number of&nbsp;optional variations&nbsp;on&nbsp;the processor&nbsp;<br>
core functionality. These&nbsp;include:&nbsp;<br>
•&nbsp;&nbsp;omitting the EmbeddedlCE&nbsp;cell;&nbsp;<br>
•&nbsp;&nbsp;replacing the&nbsp;full&nbsp;64-bit&nbsp;result&nbsp;multiplier&nbsp;with a&nbsp;smaller and&nbsp;simpler multiplier that&nbsp;<br>
supports only the ARM&nbsp;multiply&nbsp;instructions&nbsp;that produce&nbsp;a 32-bit result.&nbsp;<br>
Either&nbsp;of&nbsp;these&nbsp;options&nbsp;will&nbsp;result&nbsp;in&nbsp;a smaller synthesized&nbsp;macrocell with&nbsp;reduced&nbsp;<br>
functionality.&nbsp;The full version is 50% larger and 50%&nbsp;less power-efficient than the&nbsp;<br>
hard macrocell.&nbsp;<br>
ARM7TDMI&nbsp;<br>
The ARM7TDMI processor core has found many&nbsp;applications in&nbsp;systems with&nbsp;<br>
applications&nbsp;<br>
simple&nbsp;memory&nbsp;configurations,&nbsp;usually&nbsp;including&nbsp;a&nbsp;few&nbsp;kilobytes&nbsp;of&nbsp;simple&nbsp;on-chip&nbsp;<br>
RAM.&nbsp;A typical example is&nbsp;a&nbsp;mobile&nbsp;telephone handset&nbsp;(where the&nbsp;same chip usu-<br>
ally&nbsp;incorporates sophisticated&nbsp;digital signal&nbsp;processing&nbsp;hardware and associated&nbsp;<br>
<hr>
<A name=268></a><b>256&nbsp;</b><br>
<b>ARM&nbsp;Processor&nbsp;Cores</b>&nbsp;<br>
memories), where the ARM7TDMI&nbsp;has&nbsp;become&nbsp;the&nbsp;de-facto standard&nbsp;processor&nbsp;for&nbsp;<br>
the control and&nbsp;user&nbsp;interface&nbsp;functions.&nbsp;<br>
Where&nbsp;significantly higher performance is required than&nbsp;can&nbsp;be delivered by&nbsp;a&nbsp;<br>
straightforward&nbsp;ARM7TDMI&nbsp;with a&nbsp;simple&nbsp;memory system, the system&nbsp;complexity&nbsp;<br>
will&nbsp;inevitably&nbsp;increase. The&nbsp;first&nbsp;step&nbsp;is&nbsp;to&nbsp;add a&nbsp;cache&nbsp;memory&nbsp;to&nbsp;the&nbsp;ARM7TDMI,&nbsp;<br>
probably&nbsp;in&nbsp;the form&nbsp;of&nbsp;an&nbsp;ARM&nbsp;CPU macrocell. This&nbsp;will enhance&nbsp;the&nbsp;performance&nbsp;<br>
of&nbsp;the software&nbsp;running from&nbsp;off-chip memory. If&nbsp;this still&nbsp;does not yield sufficient&nbsp;<br>
performance&nbsp;for the application, a&nbsp;more&nbsp;complex&nbsp;ARM&nbsp;core&nbsp;must&nbsp;be&nbsp;used&nbsp;that&nbsp;is&nbsp;<br>
capable of operating at yet higher performance levels. The ARM9TDMI and&nbsp;<br>
ARM10TDMI are&nbsp;such&nbsp;cores&nbsp;and are described&nbsp;later&nbsp;in&nbsp;this&nbsp;chapter.&nbsp;<br>
9.2 &nbsp; ARMS&nbsp;<br>
The ARMS&nbsp;core was developed&nbsp;at ARM Limited from&nbsp;1993&nbsp;to&nbsp;1996&nbsp;to supply&nbsp;the&nbsp;<br>
demand&nbsp;for an&nbsp;ARM core with a higher performance than&nbsp;was achievable&nbsp;with the&nbsp;<br>
ARM?&nbsp;3-stage pipeline.&nbsp;It&nbsp;has now been&nbsp;superseded by&nbsp;the&nbsp;ARM9TDMI&nbsp;and&nbsp;<br>
ARM10TDMI, but its design&nbsp;raises&nbsp;some&nbsp;points of&nbsp;interest.&nbsp;<br>
As&nbsp;was discussed in&nbsp;Section&nbsp;4.2 on page 78, the performance of a processor core&nbsp;<br>
can be improved by:&nbsp;<br>
•&nbsp;&nbsp;Increasing the&nbsp;clock rate.&nbsp;<br>
This&nbsp;requires&nbsp;the logic in&nbsp;each pipeline&nbsp;stage to be&nbsp;simplified and,&nbsp;therefore,&nbsp;the&nbsp;<br>
number of&nbsp;pipeline&nbsp;stages to&nbsp;be increased.&nbsp;<br>
•&nbsp;&nbsp;Reducing the&nbsp;CPI&nbsp;(clock&nbsp;cycles per instruction).&nbsp;<br>
This&nbsp;requires&nbsp;either&nbsp;that&nbsp;instructions&nbsp;which&nbsp;occupy&nbsp;more than&nbsp;one&nbsp;pipeline slot&nbsp;in&nbsp;<br>
an ARM7&nbsp;are&nbsp;re-implemented&nbsp;to&nbsp;occupy&nbsp;fewer&nbsp;slots,&nbsp;or&nbsp;that&nbsp;pipeline&nbsp;stalls&nbsp;caused&nbsp;<br>
by&nbsp;dependencies between instructions&nbsp;are reduced, or&nbsp;a&nbsp;combination&nbsp;of both.&nbsp;<br>
Reducing&nbsp;the&nbsp;<br>
Again&nbsp;repeating the&nbsp;argument presented earlier,&nbsp;the&nbsp;fundamental&nbsp;problem&nbsp;with&nbsp;<br>
CPI&nbsp;<br>
reducing&nbsp;the CPI relative to an&nbsp;ARM7 core&nbsp;is related to&nbsp;the von Neumann bottle-&nbsp;<br>
neck&nbsp;-&nbsp;any&nbsp;stored-program&nbsp;computer&nbsp;with&nbsp;a&nbsp;single&nbsp;instruction&nbsp;and&nbsp;data&nbsp;memory&nbsp;will&nbsp;<br>
have&nbsp;its&nbsp;performance&nbsp;limited&nbsp;by&nbsp;the&nbsp;available memory bandwidth. An&nbsp;ARM7&nbsp;core&nbsp;<br>
accesses&nbsp;memory on&nbsp;(almost)&nbsp;every clock&nbsp;cycle either&nbsp;to&nbsp;fetch an&nbsp;instruction or&nbsp;to&nbsp;<br>
transfer&nbsp;data. To get a&nbsp;significantly better&nbsp;CPI&nbsp;than&nbsp;ARM7&nbsp;the&nbsp;memory&nbsp;system&nbsp;must&nbsp;<br>
deliver&nbsp;more than one&nbsp;value in&nbsp;each clock cycle either&nbsp;by&nbsp;delivering&nbsp;more&nbsp;than&nbsp;<br>
32 bits&nbsp;per cycle from&nbsp;a single memory or&nbsp;by having&nbsp;separate&nbsp;memories&nbsp;for instruc-<br>
tion and data&nbsp;accesses.&nbsp;<br>
<hr>
<A name=269></a><b>ARMS</b>&nbsp;<br>
<b>257</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Double-ban<br>
ARMS&nbsp;retains a unified&nbsp;memory&nbsp;(either&nbsp;in&nbsp;the form&nbsp;of&nbsp;cache or&nbsp;on-chip RAM)&nbsp;but&nbsp;<br>
dwidth&nbsp;<br>
exploits&nbsp;the&nbsp;sequential nature of&nbsp;most&nbsp;memory accesses&nbsp;to achieve&nbsp;<br>
memory&nbsp;<br>
<i>double-bandwidth&nbsp;</i>from&nbsp;a single memory. It assumes that the memory it&nbsp;is&nbsp;connected&nbsp;<br>
to&nbsp;can deliver one word&nbsp;in a&nbsp;clock cycle and deliver the next sequential&nbsp;word half&nbsp;a&nbsp;<br>
cycle later concurrently&nbsp;with&nbsp;starting the next access.&nbsp;Typical&nbsp;memory organizations&nbsp;<br>
are quite capable of&nbsp;supplying the extra data&nbsp;with&nbsp;only&nbsp;a little extra hardware cost.&nbsp;<br>
Restricting the&nbsp;extra bandwidth to sequential accesses&nbsp;may seem&nbsp;to&nbsp;limit&nbsp;its useful-<br>
ness, but instruction fetches&nbsp;are highly&nbsp;sequential and&nbsp;ARM's load&nbsp;multiple instruc-<br>
tions&nbsp;generate&nbsp;sequential&nbsp;addresses (as do&nbsp;the&nbsp;store multiple&nbsp;instructions, though&nbsp;<br>
these&nbsp;do&nbsp;not exploit&nbsp;the double-bandwidth&nbsp;memory on&nbsp;ARMS), so the&nbsp;occurrence&nbsp;of&nbsp;<br>
sequential accesses&nbsp;is quite&nbsp;high in typical&nbsp;ARM&nbsp;code.&nbsp;<br>
A&nbsp;64-bit wide&nbsp;memory&nbsp;has&nbsp;the required&nbsp;characteristics,&nbsp;but&nbsp;delaying&nbsp;the&nbsp;arrival&nbsp;of&nbsp;<br>
the second word by half a&nbsp;clock cycle&nbsp;allows&nbsp;a 32-bit&nbsp;bus to&nbsp;be used&nbsp;and can save&nbsp;area&nbsp;<br>
since routing a&nbsp;32-bit&nbsp;bus requires&nbsp;less&nbsp;area&nbsp;than routing a&nbsp;64-bit&nbsp;bus.&nbsp;<br>
Core&nbsp;<br>
The ARMS&nbsp;processor consists of a&nbsp;prefetch&nbsp;unit and&nbsp;an&nbsp;integer datapath. The&nbsp;<br>
organization&nbsp;<br>
prefetch unit is&nbsp;responsible&nbsp;for fetching instructions from&nbsp;memory&nbsp;and buffering&nbsp;<br>
them&nbsp;(in order to&nbsp;exploit the double-bandwidth&nbsp;memory). It&nbsp;then&nbsp;supplies up to&nbsp;one&nbsp;<br>
instruction per clock cycle to the&nbsp;integer&nbsp;unit, along with its PC&nbsp;value. The&nbsp;prefetch&nbsp;<br>
unit&nbsp;is responsible for&nbsp;branch prediction&nbsp;and&nbsp;uses static&nbsp;prediction&nbsp;based on&nbsp;the&nbsp;<br>
branch&nbsp;direction (backwards branches are predicted 'taken',&nbsp;whereas forwards&nbsp;<br>
branches are predicted&nbsp;'not&nbsp;taken') to&nbsp;attempt to guess&nbsp;where&nbsp;the instruction stream&nbsp;<br>
will&nbsp;go;&nbsp;the&nbsp;integer unit&nbsp;will&nbsp;compute&nbsp;the&nbsp;exact&nbsp;stream&nbsp;and issue&nbsp;corrections&nbsp;to the&nbsp;<br>
prefetch&nbsp;unit&nbsp;where necessary.&nbsp;<br>
The overall&nbsp;organization of&nbsp;the core is shown in Figure 9.5 on&nbsp;page 258.&nbsp;<br>
The double-bandwidth&nbsp;memory will normally be on-chip, in&nbsp;the&nbsp;form&nbsp;of a&nbsp;<br>
cache&nbsp;memory on a general-purpose device such as the ARMS 10 (described in&nbsp;<br>
Section 12.2 on page 323)&nbsp;or&nbsp;as&nbsp;addressable RAM in&nbsp;an embedded&nbsp;application.&nbsp;The&nbsp;<br>
remaining memory&nbsp;may comprise&nbsp;conventional, single-bandwidth&nbsp;devices, but with-<br>
out some&nbsp;fast&nbsp;memory in&nbsp;the system&nbsp;the ARMS&nbsp;core will&nbsp;show&nbsp;little&nbsp;benefit over&nbsp;the&nbsp;<br>
simpler ARM&nbsp;cores.&nbsp;<br>
Pipeline&nbsp;<br>
The processor uses a 5-stage pipeline&nbsp;with&nbsp;the prefetch&nbsp;unit&nbsp;occupying&nbsp;the&nbsp;first&nbsp;stage&nbsp;<br>
organization&nbsp;<br>
and the integer unit using the&nbsp;remaining&nbsp;four&nbsp;stages:&nbsp;<br>
1.&nbsp;&nbsp;Instruction prefetch.&nbsp;<br>
2.&nbsp;&nbsp;Instruction decode&nbsp;and register read.&nbsp;<br>
3.&nbsp;&nbsp;Execute (shift&nbsp;and ALU).&nbsp;<br>
4.&nbsp;&nbsp;Data&nbsp;memory&nbsp;access.&nbsp;<br>
5.&nbsp;Write-back&nbsp;results.&nbsp;<br>
<hr>
<A name=270></a><IMG src="index-270_1.png"><br>
<b>258</b>&nbsp;<br>
<b>ARM&nbsp;Processor&nbsp;Cores</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 9.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARMS processor core organization.&nbsp;<br>
Integer&nbsp;unit&nbsp;<br>
The organization of the&nbsp;ARMS integer unit is&nbsp;illustrated in&nbsp;Figure 9.6 on&nbsp;page 259.&nbsp;<br>
organization&nbsp;<br>
The instruction stream&nbsp;and associated&nbsp;PC values are supplied by&nbsp;the&nbsp;prefetch unit&nbsp;<br>
through the interface&nbsp;shown&nbsp;at the top of the figure; the&nbsp;system&nbsp;control&nbsp;coprocessor&nbsp;<br>
connects through the dedicated coprocessor instruction and data buses to the left of&nbsp;<br>
the figure; the&nbsp;interface to the data&nbsp;memory is to the right of the figure and com-<br>
prises an address bus,&nbsp;a&nbsp;write&nbsp;data bus and a&nbsp;read data bus.&nbsp;<br>
Note&nbsp;that&nbsp;the read&nbsp;memory data&nbsp;bus supports double-bandwidth&nbsp;transfers on&nbsp;load&nbsp;<br>
multiple&nbsp;instructions, and&nbsp;both&nbsp;register&nbsp;write&nbsp;ports are&nbsp;used&nbsp;in&nbsp;load&nbsp;multiple&nbsp;instruc-<br>
tions to store the&nbsp;double-bandwidth&nbsp;data stream. Since load&nbsp;multiple instructions&nbsp;<br>
transfer&nbsp;word&nbsp;quantities only, it does not&nbsp;matter that&nbsp;half of the&nbsp;data&nbsp;stream&nbsp;bypasses&nbsp;<br>
the byte&nbsp;alignment and&nbsp;sign&nbsp;extension logic.&nbsp;<br>
ARMS&nbsp;<br>
ARMS was designed as a&nbsp;general-purpose processor core that can&nbsp;readily&nbsp;be&nbsp;<br>
applications&nbsp;<br>
manufactured by&nbsp;ARM Limited's&nbsp;many&nbsp;licensees, so it is&nbsp;not highly&nbsp;optimized for&nbsp;<br>
a particular process technology. It offers significantly&nbsp;(two to three times) higher&nbsp;<br>
performance than&nbsp;the simpler ARM7&nbsp;cores for a similar increase in&nbsp;silicon&nbsp;area,&nbsp;<br>
and requires the support of&nbsp;double-bandwidth on-chip&nbsp;memory&nbsp;if&nbsp;it is&nbsp;to&nbsp;realize its&nbsp;<br>
full potential.&nbsp;<br>
One application of the ARMS&nbsp;core is to&nbsp;build a&nbsp;high-performance CPU such&nbsp;as the&nbsp;<br>
ARM810,&nbsp;described in&nbsp;Section&nbsp;12.2&nbsp;on&nbsp;page 323. There the&nbsp;double-bandwidth&nbsp;<br>
memory is&nbsp;in&nbsp;the&nbsp;form&nbsp;of a&nbsp;cache,&nbsp;and the chip&nbsp;also incorporates&nbsp;a memory manage-<br>
ment&nbsp;unit&nbsp;and system&nbsp;control&nbsp;coprocessor CP15.&nbsp;<br>
ARMS&nbsp;Silicon&nbsp;<br>
The&nbsp;ARMS&nbsp;core uses 124,554 transistors&nbsp;and operates at&nbsp;speeds up&nbsp;to 72&nbsp;MHz on&nbsp;a&nbsp;<br>
0.5 um&nbsp;CMOS process&nbsp;with three&nbsp;metal layers.&nbsp;<br>
<hr>
<A name=271></a><IMG src="index-271_1.png"><br>
<b>ARMS</b>&nbsp;<br>
<b>259</b>&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;9.6 &nbsp;&nbsp;</b>ARMS integer unit organization.&nbsp;<br>
The core&nbsp;layout&nbsp;can be&nbsp;seen in&nbsp;the ARMS&nbsp;10 die photograph&nbsp;in&nbsp;Figure 12.6 on&nbsp;<br>
page 326&nbsp;in&nbsp;the&nbsp;upper left-hand area of&nbsp;the die.&nbsp;<br>
<hr>
<A name=272></a><b>260</b>&nbsp;<br>
<b>ARM&nbsp;Processor&nbsp;Cores</b>&nbsp;<br>
9.3 &nbsp; ARM9TDMI&nbsp;<br>
The ARM9TDMI&nbsp;core takes the&nbsp;functionality of&nbsp;the&nbsp;ARM7TDMI up&nbsp;to a signifi-<br>
cantly higher performance&nbsp;level. Like the ARM7TDMI&nbsp;(and unlike the&nbsp;ARMS) it&nbsp;<br>
includes support for&nbsp;the Thumb&nbsp;instruction&nbsp;set&nbsp;and an&nbsp;EmbeddedlCE module for&nbsp;<br>
on-chip debug&nbsp;support. The&nbsp;performance improvement is achieved&nbsp;by&nbsp;adopting a&nbsp;<br>
5-stage&nbsp;pipeline to&nbsp;increase&nbsp;the&nbsp;maximum&nbsp;clock&nbsp;rate&nbsp;and&nbsp;by&nbsp;using&nbsp;separate&nbsp;<br>
instruction&nbsp;and data&nbsp;memory&nbsp;ports to&nbsp;allow&nbsp;an improved&nbsp;CPI (Clocks Per&nbsp;<br>
Instruction&nbsp;- a&nbsp;measure&nbsp;of&nbsp;how much work&nbsp;a&nbsp;processor&nbsp;does&nbsp;in&nbsp;a&nbsp;clock&nbsp;cycle).&nbsp;<br>
Improved&nbsp;<br>
The rationale&nbsp;which&nbsp;leads&nbsp;from&nbsp;a requirement for&nbsp;higher performance&nbsp;to the&nbsp;need to&nbsp;<br>
performance&nbsp;<br>
increase the number of pipeline stages&nbsp;from&nbsp;three&nbsp;(as in&nbsp;the ARM7TDMI) to&nbsp;five,&nbsp;<br>
and to&nbsp;change the&nbsp;memory&nbsp;interface to&nbsp;employ&nbsp;separate instruction and data&nbsp;memo-<br>
ries,&nbsp;was discussed&nbsp;in&nbsp;Section&nbsp;4.2 on page 78.&nbsp;<br>
ARM9TDMI&nbsp;<br>
The 5-stage&nbsp;ARM9TDMI pipeline owes&nbsp;a&nbsp;lot to&nbsp;the&nbsp;StrongARM&nbsp;pipeline described&nbsp;<br>
organization&nbsp;<br>
in Section 12.3 on page 327. (The StrongARM has not&nbsp;been included as a core in&nbsp;<br>
this chapter as&nbsp;it has limited applicability as&nbsp;a stand-alone core.)&nbsp;<br>
The&nbsp;ARM9TDMI core&nbsp;organization&nbsp;was&nbsp;illustrated&nbsp;in&nbsp;Figure 4.4 on&nbsp;page&nbsp;81. The&nbsp;<br>
principal&nbsp;difference&nbsp;between the ARM9TDMI&nbsp;and the StrongARM core&nbsp;(illustrated in&nbsp;<br>
Figure 12.8 on&nbsp;page 330) is that while&nbsp;StrongARM has&nbsp;a dedicated branch adder&nbsp;<br>
which operates&nbsp;in parallel&nbsp;with the&nbsp;register&nbsp;read&nbsp;stage,&nbsp;ARM9TDMI uses the&nbsp;main&nbsp;<br>
ALU for branch&nbsp;target&nbsp;calculations. This&nbsp;gives ARM9TDMI&nbsp;an&nbsp;additional clock cycle&nbsp;<br>
penalty&nbsp;for a&nbsp;taken&nbsp;branch,&nbsp;but&nbsp;results&nbsp;in&nbsp;a smaller and&nbsp;simpler&nbsp;core,&nbsp;and&nbsp;avoids&nbsp;a&nbsp;very&nbsp;<br>
critical&nbsp;timing&nbsp;path (illustrated in Figure 12.9&nbsp;on page&nbsp;331) which&nbsp;is&nbsp;present in&nbsp;the&nbsp;<br>
StrongARM&nbsp;design.&nbsp;The&nbsp;StrongARM&nbsp;was&nbsp;designed&nbsp;for a particular&nbsp;process technol-<br>
ogy&nbsp;where&nbsp;this&nbsp;timing&nbsp;path&nbsp;could&nbsp;be&nbsp;carefully&nbsp;managed,&nbsp;whereas&nbsp;the&nbsp;ARM9TDMI&nbsp;is&nbsp;<br>
required&nbsp;to&nbsp;be&nbsp;readily&nbsp;portable&nbsp;to&nbsp;new&nbsp;processes where such&nbsp;a critical&nbsp;path&nbsp;could&nbsp;easily&nbsp;<br>
compromise&nbsp;the&nbsp;maximum usable&nbsp;clock&nbsp;rate.&nbsp;<br>
Pipeline&nbsp;<br>
The operation&nbsp;of the 5-stage&nbsp;ARM9TDMI pipeline is illustrated in Figure 9.7 on&nbsp;<br>
operation&nbsp;<br>
page 261,&nbsp;where it is compared with&nbsp;the 3-stage&nbsp;ARM7TDMI&nbsp;pipeline. The figure&nbsp;<br>
shows how the&nbsp;major processing&nbsp;functions&nbsp;of&nbsp;the processor&nbsp;are redistributed across&nbsp;<br>
the additional&nbsp;pipeline&nbsp;stages in order&nbsp;to&nbsp;allow the clock&nbsp;frequency&nbsp;to&nbsp;be&nbsp;doubled&nbsp;<br>
(approximately) on&nbsp;the same&nbsp;process&nbsp;technology.&nbsp;<br>
Redistributing&nbsp;the execution functions&nbsp;(register&nbsp;read,&nbsp;shift,&nbsp;ALU, register&nbsp;write)&nbsp;is&nbsp;<br>
not all that&nbsp;is required&nbsp;to achieve this higher clock&nbsp;rate. The processor must&nbsp;also be&nbsp;<br>
able&nbsp;to access the instruction&nbsp;memory in half the time that the ARM7TDMI takes,&nbsp;and&nbsp;<br>
the instruction decode&nbsp;logic must also&nbsp;be&nbsp;restructured&nbsp;to&nbsp;allow the register read to&nbsp;take&nbsp;<br>
place concurrently&nbsp;with&nbsp;a&nbsp;substantial&nbsp;part&nbsp;of&nbsp;the&nbsp;decoding.&nbsp;<br>
<hr>
<A name=273></a><IMG src="index-273_1.png"><br>
<b>ARM9TDMI</b>&nbsp;<br>
<b>261</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 9.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM7TDMI and ARM9TDMI&nbsp;pipeline comparison.&nbsp;<br>
Thumb&nbsp;decoding&nbsp;&nbsp;The&nbsp;ARM7TDMI&nbsp;implements&nbsp;the&nbsp;Thumb instruction set&nbsp;by&nbsp;'decompressing'&nbsp;Thumb&nbsp;<br>
instructions&nbsp;into&nbsp;ARM&nbsp;instructions&nbsp;using&nbsp;slack&nbsp;time&nbsp;in&nbsp;the&nbsp;ARM7&nbsp;pipeline. The&nbsp;<br>
ARM9TDMI pipeline is much tighter&nbsp;and does&nbsp;not have sufficient slack&nbsp;time&nbsp;to allow&nbsp;<br>
Thumb&nbsp;instructions&nbsp;to&nbsp;be&nbsp;first&nbsp;translated&nbsp;into&nbsp;ARM&nbsp;instructions&nbsp;and&nbsp;then&nbsp;decoded;&nbsp;<br>
instead it&nbsp;has&nbsp;hardware to&nbsp;decode&nbsp;both&nbsp;ARM&nbsp;and Thumb instructions directly.&nbsp;<br>
The&nbsp;extra 'Memory'&nbsp;stage in the&nbsp;ARM9TDMI&nbsp;pipeline does&nbsp;not have&nbsp;any&nbsp;direct&nbsp;<br>
equivalent in the ARM7TDMI. Its&nbsp;function is performed by&nbsp;additional&nbsp;'Execute'&nbsp;<br>
cycles&nbsp;that&nbsp;interrupt&nbsp;the&nbsp;pipeline&nbsp;flow. This interruption is&nbsp;an&nbsp;inevitable&nbsp;consequence&nbsp;<br>
of&nbsp;the&nbsp;single&nbsp;memory&nbsp;port&nbsp;used&nbsp;by&nbsp;the&nbsp;ARM7TDMI&nbsp;for both&nbsp;instruction&nbsp;and&nbsp;data&nbsp;<br>
accesses.&nbsp;During&nbsp;a data&nbsp;access an&nbsp;instruction&nbsp;fetch&nbsp;cannot&nbsp;take&nbsp;place.&nbsp;The&nbsp;<br>
ARM9TDMI&nbsp;avoids&nbsp;this&nbsp;pipeline&nbsp;interruption&nbsp;through&nbsp;the provision&nbsp;of&nbsp;separate&nbsp;<br>
instruction and&nbsp;data memories.&nbsp;<br>
Coprocessor&nbsp;<br>
The&nbsp;ARM9TDMI has&nbsp;a coprocessor&nbsp;interface which&nbsp;allows&nbsp;on-chip&nbsp;coprocessors&nbsp;for&nbsp;<br>
support&nbsp;<br>
floating-point, digital signal&nbsp;processing&nbsp;or&nbsp;other&nbsp;special-purpose&nbsp;hardware&nbsp;accelera-<br>
tion requirements to be supported. (At the&nbsp;clock speeds it supports there is little&nbsp;<br>
possibility of&nbsp;off-chip coprocessors being&nbsp;useful.)&nbsp;<br>
On-chip&nbsp;debug&nbsp;<br>
The EmbeddedlCE&nbsp;functionality in the ARM9TDMI core gives the&nbsp;same&nbsp;<br>
system-level debug features&nbsp;as&nbsp;that on&nbsp;the ARM7TDMI&nbsp;core (see Section&nbsp;8.7&nbsp;on&nbsp;<br>
page 232), with&nbsp;the following additional features:&nbsp;<br>
•&nbsp;&nbsp;Hardware single-stepping&nbsp;is supported.&nbsp;<br>
•&nbsp;&nbsp;Breakpoints&nbsp;can be&nbsp;set&nbsp;on&nbsp;exceptions in&nbsp;addition to&nbsp;the address/data/control&nbsp;<br>
conditions supported by&nbsp;ARM7TDMI.&nbsp;<br>
<hr>
<A name=274></a><IMG src="index-274_1.png"><br>
<b>262</b>&nbsp;<br>
<b>ARM&nbsp;Processor&nbsp;Cores</b>&nbsp;<br>
<b>Table&nbsp;9.3 &nbsp; &nbsp;</b>ARM9TDMI characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.25 um&nbsp;Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>111,000&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>220</b>&nbsp;&nbsp;&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3&nbsp;Core area</b>&nbsp;&nbsp;&nbsp;<br>
<b>2.1 mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>150mW</b>&nbsp;&nbsp;&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>2.5V&nbsp;Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>0-200&nbsp;MHz&nbsp;MIPS/W</b>&nbsp;<br>
<b>1500</b>&nbsp;&nbsp;&nbsp;<br>
LOW&nbsp;voltage&nbsp;<br>
Although&nbsp;the first ARM9TDMI&nbsp;core&nbsp;was implemented&nbsp;on&nbsp;a 0.35&nbsp;urn 3.3&nbsp;V&nbsp;technol-&nbsp;<br>
operation&nbsp;<br>
ogy, the design&nbsp;has been&nbsp;ported onto 0.25&nbsp;um&nbsp;and 0.18&nbsp;um&nbsp;processes using power&nbsp;<br>
supplies&nbsp;down to&nbsp;1.2&nbsp;V&nbsp;<br>
ARM9TDMI&nbsp;core&nbsp;&nbsp;&nbsp;&nbsp; The&nbsp;characteristics&nbsp;of&nbsp;the&nbsp;0.25&nbsp;um&nbsp;ARM9TDMI core&nbsp;when executing&nbsp;32-bit&nbsp;<br>
ARM&nbsp;code are&nbsp;summarized&nbsp;in&nbsp;Table 9.3.&nbsp;A plot of&nbsp;the core is shown&nbsp;in Figure&nbsp;9.8.&nbsp;<br>
&nbsp;<br>
<b>Figure 9.8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The&nbsp;ARM9TDMI processor&nbsp;core.&nbsp;<br>
ARM9TDMI&nbsp;<br>
An&nbsp;ARM9TDMI&nbsp;core has separate&nbsp;instruction&nbsp;and&nbsp;data&nbsp;memory&nbsp;ports.&nbsp;While&nbsp;in&nbsp;<br>
applications&nbsp;<br>
principle&nbsp;it may&nbsp;be possible&nbsp;to&nbsp;connect these ports to&nbsp;a single&nbsp;unified memory, in&nbsp;<br>
practice doing so&nbsp;would negate&nbsp;many&nbsp;of&nbsp;the reasons for choosing&nbsp;the ARM9TDMI&nbsp;<br>
core over the&nbsp;smaller and cheaper&nbsp;ARM7TDMI&nbsp;core&nbsp;in&nbsp;the first place.&nbsp;Similarly,&nbsp;<br>
although it is not necessary&nbsp;to exploit the higher clock rate supported by&nbsp;the&nbsp;<br>
ARM9TDMI's&nbsp;5-stage pipeline in comparison to the&nbsp;ARMTTDMI's&nbsp;3-stage pipe-<br>
line, not to do so would negate the rationale for using the&nbsp;ARM9TDMI.&nbsp;Therefore,&nbsp;<br>
any&nbsp;application that justifies&nbsp;the use of an ARM9TDMI core is going&nbsp;to have to&nbsp;<br>
cope with&nbsp;a complex&nbsp;high-speed memory subsystem.&nbsp;<br>
<hr>
<A name=275></a><b>ARM10TDMI</b>&nbsp;<br>
<b>263</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The most&nbsp;common&nbsp;way&nbsp;of&nbsp;handling&nbsp;this memory requirement&nbsp;will&nbsp;be&nbsp;to incorpo-<br>
rate separate&nbsp;instruction and&nbsp;data cache memories as&nbsp;exemplified by the various stand-<br>
ard ARM CPU&nbsp;cores&nbsp;based around&nbsp;the ARM9TDMI. The ARM920T&nbsp;and&nbsp;ARM940T&nbsp;<br>
CPU cores are&nbsp;described&nbsp;in Section 12.4&nbsp;on&nbsp;page&nbsp;335. The caches&nbsp;in these CPU cores&nbsp;<br>
satisfy&nbsp;most&nbsp;of the&nbsp;memory&nbsp;bandwidth&nbsp;requirements&nbsp;of&nbsp;the&nbsp;ARM9TDMI&nbsp;and reduce&nbsp;<br>
the external&nbsp;bandwidth requirement to something that can be&nbsp;satisfied&nbsp;by&nbsp;conventional&nbsp;<br>
unified memories&nbsp;connected&nbsp;via a single AMBA bus.&nbsp;<br>
An alternative&nbsp;solution,&nbsp;particularly&nbsp;applicable&nbsp;in&nbsp;embedded&nbsp;systems&nbsp;where the&nbsp;<br>
performance-critical&nbsp;code&nbsp;is&nbsp;relatively well&nbsp;contained,&nbsp;is to&nbsp;use an&nbsp;appropriate&nbsp;amount&nbsp;<br>
of separate&nbsp;directly&nbsp;addressed local instruction and data&nbsp;memory instead&nbsp;of&nbsp;caches.&nbsp;<br>
ARM9E-S&nbsp;<br>
The&nbsp;ARM9E-S is a synthesizable version&nbsp;of&nbsp;the ARM9TDMI core. It&nbsp;implements an&nbsp;<br>
extended&nbsp;version of the ARM instruction&nbsp;set compared&nbsp;with&nbsp;the 'hard'&nbsp;core. In addi-<br>
tion to the&nbsp;ARM architecture v4T instructions supported&nbsp;by&nbsp;the&nbsp;ARM9TDMI,&nbsp;the&nbsp;<br>
ARM9E-S&nbsp;supports the&nbsp;full ARM architecture&nbsp;version v5TE (see Section&nbsp;5.23&nbsp;on&nbsp;<br>
page 147), including the signal processing&nbsp;instruction&nbsp;set extensions&nbsp;described&nbsp;in&nbsp;<br>
Section 8.9 on&nbsp;page&nbsp;239.&nbsp;<br>
The ARM9E-S is&nbsp;30% larger than&nbsp;the&nbsp;ARM9TDMI&nbsp;on&nbsp;the same&nbsp;process.&nbsp;It&nbsp;occu-<br>
pies 2.7&nbsp;mm2&nbsp;on&nbsp;a 0.25 um&nbsp;CMOS process.&nbsp;<br>
9.4 &nbsp; ARM10TDMI&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The&nbsp;ARM10TDMI is&nbsp;the current&nbsp;high-end&nbsp;ARM processor&nbsp;core and&nbsp;is&nbsp;still&nbsp;under&nbsp;<br>
development&nbsp;at&nbsp;the time&nbsp;of&nbsp;writing.&nbsp;Just&nbsp;as&nbsp;the ARM9TDMI&nbsp;delivers&nbsp;approximately&nbsp;<br>
twice the performance of&nbsp;the ARM7TDMI&nbsp;on the&nbsp;same&nbsp;process, the&nbsp;ARM10TDMI&nbsp;<br>
is positioned&nbsp;to&nbsp;operate&nbsp;at&nbsp;twice the performance&nbsp;of&nbsp;the&nbsp;ARM9TDMI.&nbsp;It&nbsp;is intended&nbsp;<br>
to&nbsp;deliver 400&nbsp;dhrystone&nbsp;2.1 MIPS&nbsp;at&nbsp;300 MHz on&nbsp;0.25&nbsp;urn&nbsp;CMOS technology.&nbsp;<br>
In order to&nbsp;achieve&nbsp;this&nbsp;level&nbsp;of performance,&nbsp;starting&nbsp;from&nbsp;the&nbsp;ARM9TDMI, two&nbsp;<br>
approaches&nbsp;have&nbsp;been&nbsp;combined (again, see the&nbsp;discussion&nbsp;in&nbsp;Section&nbsp;4.2&nbsp;on&nbsp;page&nbsp;78):&nbsp;<br>
1.&nbsp;&nbsp;The&nbsp;maximum clock&nbsp;rate has&nbsp;been increased.&nbsp;<br>
2.&nbsp;&nbsp;The CPI&nbsp;(average&nbsp;number of&nbsp;Clocks&nbsp;Per Instruction)&nbsp;has been&nbsp;reduced.&nbsp;<br>
Since the&nbsp;ARM9TDMI pipeline is already&nbsp;fairly&nbsp;optimal,&nbsp;how can these improve-<br>
ments&nbsp;be&nbsp;achieved&nbsp;without&nbsp;resorting&nbsp;to&nbsp;a&nbsp;very&nbsp;complex&nbsp;organization,&nbsp;such&nbsp;as&nbsp;super-<br>
scalar&nbsp;execution, which would compromise the&nbsp;low power&nbsp;and small core&nbsp;size&nbsp;that&nbsp;are&nbsp;<br>
the&nbsp;hallmarks of an ARM&nbsp;core?&nbsp;<br>
Increased clock&nbsp;<br>
The&nbsp;maximum clock&nbsp;rate&nbsp;that an&nbsp;ARM core can&nbsp;support&nbsp;is determined by&nbsp;the slow-<br>
rate&nbsp;<br>
est logic path&nbsp;in any of the pipeline&nbsp;stages.&nbsp;<br>
<hr>
<A name=276></a><IMG src="index-276_1.png"><br>
<b>264</b>&nbsp;<br>
<b>ARM&nbsp;Processor&nbsp;Cores</b>&nbsp;<br>
The 5-stage&nbsp;ARM9TDMI&nbsp;is&nbsp;already&nbsp;well&nbsp;balanced (see Figure&nbsp;9.7 on&nbsp;page&nbsp;261);&nbsp;<br>
four&nbsp;of the&nbsp;five&nbsp;stages&nbsp;are&nbsp;heavily&nbsp;loaded.&nbsp;The pipeline&nbsp;could&nbsp;be&nbsp;extended&nbsp;to&nbsp;spread&nbsp;the&nbsp;<br>
logic over&nbsp;many&nbsp;more&nbsp;stages, but the&nbsp;benefits of&nbsp;such&nbsp;a&nbsp;'super-pipelined'&nbsp;organization&nbsp;<br>
tend to&nbsp;be offset by the worsened&nbsp;CPI that&nbsp;results from&nbsp;the increased&nbsp;pipeline&nbsp;depend-<br>
encies unless very complex mechanisms&nbsp;are employed to&nbsp;minimize these effects.&nbsp;<br>
Instead,&nbsp;the&nbsp;ARM10TDMI&nbsp;approach&nbsp;is&nbsp;to&nbsp;retain&nbsp;a very similar pipeline&nbsp;to&nbsp;the&nbsp;<br>
ARM9TDMI but to support a&nbsp;higher&nbsp;clock rate&nbsp;by&nbsp;optimizing each&nbsp;stage in a particu-<br>
lar way&nbsp;(see Figure 9.9):&nbsp;<br>
•&nbsp;&nbsp;The fetch and&nbsp;memory stages are effectively increased from&nbsp;one to one-and-a-&nbsp;<br>
half&nbsp;clock cycles by&nbsp;providing the address&nbsp;for the next&nbsp;cycle&nbsp;early.&nbsp;To&nbsp;achieve this&nbsp;<br>
in&nbsp;the&nbsp;memory stage, memory addresses&nbsp;are computed&nbsp;in&nbsp;a separate&nbsp;adder that&nbsp;<br>
can&nbsp;produce its&nbsp;result&nbsp;faster&nbsp;than&nbsp;the&nbsp;main&nbsp;ALU (because&nbsp;it&nbsp;implements only a&nbsp;<br>
subset&nbsp;of&nbsp;the ALU's functionality).&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;execute&nbsp;stage uses a&nbsp;combination of&nbsp;improved&nbsp;circuit&nbsp;techniques&nbsp;and restruc&nbsp;<br>
turing&nbsp;to&nbsp;reduce&nbsp;its critical&nbsp;path.&nbsp;For example, the&nbsp;multiplier&nbsp;does not&nbsp;feed&nbsp;into&nbsp;the&nbsp;<br>
main ALU to&nbsp;resolve&nbsp;its&nbsp;partial&nbsp;sum&nbsp;and&nbsp;product&nbsp;terms; instead&nbsp;it&nbsp;has&nbsp;its&nbsp;own adder&nbsp;<br>
in&nbsp;the memory&nbsp;stage (multiplications&nbsp;never access memory,&nbsp;so this&nbsp;stage is&nbsp;free.)&nbsp;<br>
•&nbsp;&nbsp;The instruction decode&nbsp;stage is the only&nbsp;part of&nbsp;the processor logic that could not&nbsp;<br>
be streamlined&nbsp;sufficiently&nbsp;to&nbsp;support the higher clock&nbsp;rate,&nbsp;so here an&nbsp;additional&nbsp;<br>
'Issue'&nbsp;pipeline stage was inserted.&nbsp;<br>
The result&nbsp;is&nbsp;a&nbsp;6-stage&nbsp;pipeline that&nbsp;can&nbsp;operate&nbsp;faster than&nbsp;the 5-stage&nbsp;ARM9TDMI&nbsp;<br>
pipeline, but&nbsp;requires its&nbsp;supporting memories&nbsp;to be&nbsp;little&nbsp;faster&nbsp;than the&nbsp;<br>
ARM9TDMI's&nbsp;memories. This&nbsp;is&nbsp;of&nbsp;significance&nbsp;since&nbsp;very fast&nbsp;memories tend to&nbsp;be&nbsp;<br>
power-hungry. The extra pipeline&nbsp;stage, inserted to allow&nbsp;more&nbsp;time for&nbsp;instruction&nbsp;<br>
decode, only&nbsp;incurs pipeline dependency&nbsp;costs&nbsp;when&nbsp;an unpredicted branch is&nbsp;exe-<br>
cuted.&nbsp;Since the&nbsp;extra stage comes&nbsp;before&nbsp;the&nbsp;register read&nbsp;takes place it&nbsp;introduces no&nbsp;<br>
new&nbsp;operand&nbsp;dependencies and&nbsp;requires no&nbsp;new forwarding paths. With&nbsp;the&nbsp;inclusion&nbsp;<br>
of&nbsp;a branch&nbsp;prediction&nbsp;mechanism&nbsp;this&nbsp;pipeline will give a&nbsp;very similar CPI to the&nbsp;<br>
ARM9TDMI&nbsp;pipeline&nbsp;while supporting&nbsp;the&nbsp;higher clock rate.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;9.9 &nbsp;&nbsp;</b>The ARM10TDMI pipeline.<br>
<hr>
<A name=277></a><b>ARM10TDMI</b>&nbsp;<br>
<b>265</b>&nbsp;<br>
Reduced&nbsp;CPI&nbsp;<br>
The pipeline enhancements described above support a 50% higher clock rate with-&nbsp;<br>
out&nbsp;compromising&nbsp;the CPI. This is a&nbsp;good start,&nbsp;but will&nbsp;not yield&nbsp;the required&nbsp;100%&nbsp;<br>
performance improvement.&nbsp;For this&nbsp;an&nbsp;improved CPI&nbsp;is needed&nbsp;on&nbsp;top of&nbsp;the&nbsp;<br>
increased clock rate.&nbsp;<br>
Any&nbsp;plan to improve the CPI&nbsp;must start from&nbsp;a consideration of&nbsp;memory&nbsp;band-<br>
width.&nbsp;The&nbsp;ARM7TDMI&nbsp;uses&nbsp;its&nbsp;single&nbsp;32-bit&nbsp;memory&nbsp;on (almost) every&nbsp;clock&nbsp;cycle,&nbsp;<br>
so the&nbsp;ARM9TDMI&nbsp;moved&nbsp;to&nbsp;a Harvard&nbsp;memory&nbsp;organization&nbsp;to&nbsp;release&nbsp;more band-<br>
width.&nbsp;The ARM9TDMI&nbsp;uses&nbsp;its&nbsp;instruction&nbsp;memory&nbsp;on (almost) every&nbsp;clock cycle.&nbsp;<br>
Although its data&nbsp;memory&nbsp;is only&nbsp;around&nbsp;50% loaded, it is hard to exploit this to&nbsp;<br>
improve its CPI. The&nbsp;instruction&nbsp;bandwidth&nbsp;must be increased somehow.&nbsp;<br>
The&nbsp;approach&nbsp;adopted&nbsp;in&nbsp;the&nbsp;ARMIOTDMI is to&nbsp;employ&nbsp;64-bit memories. This&nbsp;<br>
effectively&nbsp;removes the&nbsp;instruction&nbsp;bandwidth bottleneck&nbsp;and enables&nbsp;a number of&nbsp;<br>
CPI-improving&nbsp;features&nbsp;to&nbsp;be&nbsp;added to&nbsp;the&nbsp;processor organization:&nbsp;<br>
•&nbsp;&nbsp;Branch&nbsp;prediction: the&nbsp;ARMIOTDMI branch prediction logic goes beyond&nbsp;what&nbsp;<br>
is required simply&nbsp;to&nbsp;maintain the pipeline efficiency&nbsp;as discussed&nbsp;above.&nbsp;<br>
Because instructions are&nbsp;fetched at a&nbsp;rate&nbsp;of&nbsp;two per clock&nbsp;cycle, the&nbsp;branch pre&nbsp;<br>
diction unit (which is in&nbsp;the fetch pipeline stage) can&nbsp;often recognize branches&nbsp;<br>
before they&nbsp;are issued and effectively&nbsp;remove them&nbsp;from the instruction stream,&nbsp;<br>
reducing&nbsp;the cycle&nbsp;cost of&nbsp;the branch to zero.&nbsp;<br>
The ARMIOTDMI&nbsp;employs&nbsp;a&nbsp;<i>static&nbsp;&nbsp;</i>branch&nbsp;prediction&nbsp;mechanism:&nbsp;conditional&nbsp;<br>
branches&nbsp;that&nbsp;branch backwards&nbsp;are predicted to&nbsp;be&nbsp;taken;&nbsp;those&nbsp;that&nbsp;branch&nbsp;for-<br>
wards are predicted not to&nbsp;be taken.&nbsp;<br>
•&nbsp;&nbsp;Non-blocking&nbsp;load&nbsp;and&nbsp;store&nbsp;execution:&nbsp;a&nbsp;load&nbsp;or store&nbsp;instruction that&nbsp;cannot&nbsp;<br>
complete&nbsp;in&nbsp;a&nbsp;single&nbsp;memory&nbsp;cycle,&nbsp;either&nbsp;because it is referencing&nbsp;slow&nbsp;memory&nbsp;<br>
or because it is transferring&nbsp;multiple registers, does not stall the execution pipe&nbsp;<br>
line until an&nbsp;operand dependency&nbsp;arises.&nbsp;<br>
•&nbsp;&nbsp;The 64-bit data&nbsp;memory enables load and store&nbsp;multiple instructions to transfer&nbsp;<br>
two&nbsp;registers in&nbsp;each&nbsp;clock&nbsp;cycle.&nbsp;<br>
The non-blocking&nbsp;load&nbsp;and&nbsp;store&nbsp;logic requires&nbsp;independent&nbsp;register&nbsp;file&nbsp;read&nbsp;and&nbsp;<br>
write ports, and the 64-bit&nbsp;load and store&nbsp;multiple instructions require two of&nbsp;each.&nbsp;<br>
The ARMIOTDMI register bank therefore&nbsp;has four read&nbsp;ports and three&nbsp;write ports.&nbsp;<br>
Taken together&nbsp;these features&nbsp;enable&nbsp;the ARMIOTDMI to achieve a dhrystone 2.1&nbsp;<br>
MIPS per MHz figure of&nbsp;1.25,&nbsp;which may&nbsp;be compared with&nbsp;0.9 for&nbsp;the ARM7TDMI&nbsp;<br>
and 1.1 for the&nbsp;ARM9TDMI.&nbsp;These figures are&nbsp;a direct reflection of the respective&nbsp;CPI&nbsp;<br>
performances&nbsp;when running the dhrystone&nbsp;benchmark; other programs&nbsp;may&nbsp;give&nbsp;<br>
rather&nbsp;different&nbsp;CPI&nbsp;results, and&nbsp;the 64-bit&nbsp;data&nbsp;buses&nbsp;enable&nbsp;the&nbsp;ARMIOTDMI&nbsp;to&nbsp;<br>
deliver&nbsp;a&nbsp;significantly&nbsp;better&nbsp;effective&nbsp;CPI than the&nbsp;ARM9TDMI&nbsp;on&nbsp;complex tasks&nbsp;<br>
such&nbsp;as booting an&nbsp;operation system.&nbsp;<br>
<hr>
<A name=278></a><b>266&nbsp;</b><br>
<b>ARM&nbsp;Processor&nbsp;Cores</b>&nbsp;<br>
ARM10TDMI&nbsp;<br>
It was&nbsp;noted&nbsp;in&nbsp;the&nbsp;discussion&nbsp;of&nbsp;'ARM9TDMI applications'&nbsp;on&nbsp;page&nbsp;262&nbsp;that&nbsp;at&nbsp;<br>
applications&nbsp;<br>
least&nbsp;some&nbsp;local&nbsp;high-speed&nbsp;memory&nbsp;was required to release the&nbsp;performance&nbsp;poten-&nbsp;<br>
tial of&nbsp;the core. The same&nbsp;is true of&nbsp;the ARM10TDMI: without&nbsp;separate local&nbsp;64-bit&nbsp;<br>
instruction&nbsp;and&nbsp;data&nbsp;memories&nbsp;the&nbsp;core&nbsp;will&nbsp;not be&nbsp;able&nbsp;to&nbsp;deliver&nbsp;its full&nbsp;perform-<br>
ance, and&nbsp;it&nbsp;will go no&nbsp;faster&nbsp;than a smaller and cheaper&nbsp;ARM core.&nbsp;<br>
Again, the&nbsp;usual (though&nbsp;not&nbsp;the only) way to&nbsp;resolve&nbsp;this&nbsp;problem&nbsp;is through&nbsp;the&nbsp;<br>
provision&nbsp;of&nbsp;local&nbsp;cache memories&nbsp;as exemplified&nbsp;by&nbsp;the&nbsp;ARM1020E described in&nbsp;<br>
Section 12.6 on page 341.&nbsp;Since the performance of&nbsp;the ARMIOTDMI core is&nbsp;criti-<br>
cally&nbsp;dependent on&nbsp;the availability&nbsp;of fast&nbsp;64-bit&nbsp;local memory, discussion&nbsp;of&nbsp;its&nbsp;per-<br>
formance&nbsp;characteristics will&nbsp;be&nbsp;presented later&nbsp;in the context&nbsp;of&nbsp;the&nbsp;ARM1020E.&nbsp;<br>
9.5 &nbsp; Discussion&nbsp;<br>
All early&nbsp;ARM processor cores, up to and including&nbsp;the ARM7TDMI, were based&nbsp;<br>
on&nbsp;a simple&nbsp;3-stage fetch-decode-execute&nbsp;pipeline.&nbsp;From&nbsp;the&nbsp;first&nbsp;ARM1,&nbsp;developed&nbsp;<br>
at&nbsp;Acorn&nbsp;Computers in&nbsp;the early 1980s,&nbsp;through&nbsp;to&nbsp;the&nbsp;ARM7TDMI&nbsp;cores in&nbsp;most of&nbsp;<br>
today's&nbsp;mobile telephone handsets, the basic principles&nbsp;of operation have barely&nbsp;<br>
changed. The development&nbsp;work carried&nbsp;out&nbsp;in the ARM's&nbsp;first decade focused on&nbsp;<br>
the following aspects of&nbsp;the design:&nbsp;<br>
•&nbsp;&nbsp;performance improvement&nbsp;through critical&nbsp;path optimization and process shrink&nbsp;<br>
age;&nbsp;<br>
•&nbsp;&nbsp;low-power&nbsp;applications&nbsp;through&nbsp;static CMOS&nbsp;logic,&nbsp;power supply&nbsp;voltage reduc&nbsp;<br>
tion and code&nbsp;compression&nbsp;(the Thumb&nbsp;instruction&nbsp;set);&nbsp;<br>
•&nbsp;&nbsp;support&nbsp;for system&nbsp;development through&nbsp;the addition of&nbsp;on-chip debug&nbsp;facilities,&nbsp;<br>
on-chip&nbsp;buses and&nbsp;software tools.&nbsp;<br>
The&nbsp;ARM7TDMI represents&nbsp;the&nbsp;pinnacle&nbsp;of&nbsp;this development process,&nbsp;and&nbsp;its com-<br>
mercial&nbsp;success&nbsp;demonstrates&nbsp;the viability&nbsp;of&nbsp;the original&nbsp;very&nbsp;simple&nbsp;3-stage&nbsp;pipeline&nbsp;<br>
in&nbsp;a&nbsp;world&nbsp;dominated&nbsp;by&nbsp;PCs with&nbsp;ever-increasingly complex superscalar, superpipe-<br>
lined,&nbsp;high-performance (and&nbsp;very&nbsp;power-hungry)&nbsp;microprocessors.&nbsp;<br>
The&nbsp;second decade of&nbsp;ARM development&nbsp;has&nbsp;seen a&nbsp;careful diversification of&nbsp;the&nbsp;<br>
ARM&nbsp;organization&nbsp;in&nbsp;the&nbsp;quest for higher performance levels:&nbsp;<br>
•&nbsp;&nbsp;The first&nbsp;step&nbsp;to&nbsp;a&nbsp;5-stage&nbsp;pipeline&nbsp;yields a&nbsp;doubling&nbsp;of performance (all&nbsp;other&nbsp;<br>
factors being equal) at the cost of some&nbsp;forwarding logic in the core and either a&nbsp;<br>
double-bandwidth&nbsp;memory&nbsp;(as&nbsp;in&nbsp;the&nbsp;ARMS) or&nbsp;separate&nbsp;instruction&nbsp;and&nbsp;data&nbsp;<br>
memories (as&nbsp;in&nbsp;the ARM9TDMI&nbsp;and StrongARM).&nbsp;<br>
•&nbsp;&nbsp;The next doubling of&nbsp;performance,&nbsp;achieved&nbsp;in the&nbsp;ARMIOTDMI, is&nbsp;rather&nbsp;<br>
harder-won.&nbsp;The 6-stage&nbsp;pipeline&nbsp;is&nbsp;quite&nbsp;similar&nbsp;to&nbsp;the 5-stage&nbsp;pipeline used&nbsp;<br>
<hr>
<A name=279></a><b>Example and exercises</b>&nbsp;<br>
<b>267</b>&nbsp;<br>
before, but the time&nbsp;slots allocated to&nbsp;memory access have been extended to&nbsp;<br>
enable&nbsp;the&nbsp;memories&nbsp;to&nbsp;support higher clock rates without burning&nbsp;excessive&nbsp;<br>
power. The processor core also incorporates&nbsp;more decoupling: in the prefetch unit&nbsp;<br>
to&nbsp;allow branches to&nbsp;be&nbsp;predicted and removed from&nbsp;the instruction stream, and in&nbsp;<br>
the&nbsp;data&nbsp;memory&nbsp;interface&nbsp;to&nbsp;allow&nbsp;the&nbsp;processor&nbsp;to&nbsp;continue&nbsp;executing&nbsp;when&nbsp;a&nbsp;<br>
data&nbsp;access takes some&nbsp;time to&nbsp;resolve&nbsp;(for&nbsp;example, due&nbsp;to&nbsp;a cache miss).&nbsp;<br>
Performance improvement&nbsp;is&nbsp;achieved through a combination of&nbsp;increased clock&nbsp;<br>
rate&nbsp;and reduced&nbsp;CPI - the average number&nbsp;of&nbsp;clocks&nbsp;per&nbsp;instruction.&nbsp;The&nbsp;increased&nbsp;<br>
clock&nbsp;rate will&nbsp;usually require a deeper pipeline that will&nbsp;tend&nbsp;to&nbsp;worsen&nbsp;the CPI, so&nbsp;<br>
remedial&nbsp;measures are required to&nbsp;recover&nbsp;the CPI loss and then improve it&nbsp;further.&nbsp;<br>
To&nbsp;date, all&nbsp;ARM processors have been based on organizations&nbsp;that&nbsp;issue&nbsp;at&nbsp;most one&nbsp;<br>
instruction per&nbsp;clock cycle, and always in&nbsp;program&nbsp;order.&nbsp;The ARM10TDMI and&nbsp;the&nbsp;<br>
AMULETS processor (described&nbsp;in&nbsp;Section&nbsp;14.5 on page 387) handle&nbsp;out-of-order&nbsp;com-<br>
pletion in&nbsp;order&nbsp;to&nbsp;be&nbsp;able to&nbsp;keep instructions&nbsp;flowing&nbsp;during&nbsp;a slow&nbsp;data access, and&nbsp;both&nbsp;<br>
of these&nbsp;processors also include branch&nbsp;prediction&nbsp;logic to reduce the cost&nbsp;of&nbsp;refilling&nbsp;their&nbsp;<br>
pipelines on&nbsp;branch&nbsp;instructions. AMULET3&nbsp;suppresses&nbsp;the fetching&nbsp;of predicted&nbsp;branch&nbsp;<br>
instructions but still&nbsp;executes&nbsp;them; ARM10TDMI fetches branch&nbsp;instructions but&nbsp;sup-<br>
presses their execution. But&nbsp;by&nbsp;the&nbsp;standards&nbsp;of today's&nbsp;high-end&nbsp;PC&nbsp;and&nbsp;workstation&nbsp;<br>
processors,&nbsp;these&nbsp;are still very&nbsp;simple&nbsp;machines. This&nbsp;simplicity&nbsp;has direct&nbsp;benefits&nbsp;in&nbsp;<br>
system-on-chip&nbsp;applications in&nbsp;that&nbsp;simple&nbsp;processors require fewer transistors than&nbsp;com-<br>
plex&nbsp;processors&nbsp;and therefore&nbsp;occupy&nbsp;less&nbsp;die&nbsp;area and consume less&nbsp;power.&nbsp;<br>
9.6 &nbsp; Example&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example&nbsp;9.1&nbsp;</b><br>
<b>How&nbsp;should the ARM7TDMI&nbsp;address bus&nbsp;be&nbsp;retimed to&nbsp;interface to</b>&nbsp;<br>
<b>static&nbsp;RAM or ROM&nbsp;devices?</b>&nbsp;<br>
Normally&nbsp;the&nbsp;ARM7TDMI&nbsp;outputs new addresses&nbsp;as soon&nbsp;as they are&nbsp;available, which&nbsp;<br>
is towards the&nbsp;end of the preceding clock cycle. To&nbsp;interface&nbsp;to&nbsp;static&nbsp;memory devices&nbsp;<br>
the address must be&nbsp;held&nbsp;stable until after the end&nbsp;of&nbsp;the cycle, so&nbsp;this&nbsp;pipelining&nbsp;must&nbsp;<br>
be removed. This&nbsp;is&nbsp;most&nbsp;simply&nbsp;achieved by&nbsp;using&nbsp;<i>ape,&nbsp;</i>the address pipeline enable&nbsp;<br>
signal.&nbsp;In systems where some&nbsp;memory&nbsp;devices benefit&nbsp;from&nbsp;early&nbsp;addresses and some&nbsp;<br>
are static, either an&nbsp;external latch&nbsp;should&nbsp;be&nbsp;used&nbsp;to&nbsp;retime&nbsp;the addresses to&nbsp;the static&nbsp;<br>
devices or&nbsp;<i>ape&nbsp;</i>should&nbsp;be controlled to&nbsp;suit&nbsp;the currently&nbsp;addressed device.&nbsp;<br>
<b>Exercise 9.1.1&nbsp;</b><br>
Review the processor cores&nbsp;described in&nbsp;this chapter and discuss the&nbsp;basic tech-&nbsp;<br>
niques&nbsp;used&nbsp;to&nbsp;increase the&nbsp;core&nbsp;performance&nbsp;by&nbsp;a&nbsp;factor&nbsp;of&nbsp;eight&nbsp;in&nbsp;going&nbsp;from&nbsp;the&nbsp;<br>
ARM7TDMI&nbsp;to&nbsp;the&nbsp;ARM10TDMI.&nbsp;<br>
<hr>
<A name=280></a><b>268&nbsp;</b><br>
<b>ARM&nbsp;Processor&nbsp;Cores</b>&nbsp;<br>
<b>Exercise&nbsp;9.1.2&nbsp;</b><br>
In a system&nbsp;where the designer is&nbsp;free to vary the supply&nbsp;voltage to the&nbsp;processor it&nbsp;<br>
is&nbsp;possible&nbsp;to&nbsp;trade&nbsp;off performance (which&nbsp;scales&nbsp;in&nbsp;proportion&nbsp;to&nbsp;Vdd) against&nbsp;<br>
power-efficiency&nbsp;(which&nbsp;scales&nbsp;as&nbsp;1/Vdd2).&nbsp;A measure of&nbsp;architectural&nbsp;<br>
power-efficiency&nbsp;that&nbsp;factors&nbsp;out the effect&nbsp;of power supply&nbsp;variations&nbsp;is&nbsp;therefore&nbsp;<br>
MIP3/W.&nbsp;Compare&nbsp;each&nbsp;of the processor cores presented here&nbsp;on&nbsp;the&nbsp;basis&nbsp;of this&nbsp;<br>
measure.&nbsp;<br>
<b>Exercise&nbsp;9.1.3&nbsp;</b><br>
Following on&nbsp;from&nbsp;the&nbsp;results of the previous&nbsp;exercise, why&nbsp;might&nbsp;the designer of&nbsp;a&nbsp;<br>
low-power system&nbsp;not simply&nbsp;select the&nbsp;most&nbsp;architecturally efficient&nbsp;processor core&nbsp;<br>
and then&nbsp;scale&nbsp;the supply voltage to&nbsp;give the required&nbsp;system&nbsp;performance?&nbsp;<br>
<hr>
<A name=281></a><IMG src="index-281_1.png"><br>
Memory Hierarchy&nbsp;<br>
&nbsp;<br>
Summary of chapter contents&nbsp;<br>
A modern&nbsp;microprocessor can execute instructions at&nbsp;a very high&nbsp;rate.&nbsp;To&nbsp;exploit this&nbsp;<br>
potential performance fully the processor must be connected&nbsp;to&nbsp;a memory&nbsp;system&nbsp;<br>
which is both very large&nbsp;and very fast. If&nbsp;the&nbsp;memory&nbsp;is too&nbsp;small, it&nbsp;will not be able to&nbsp;<br>
hold enough programs to keep the&nbsp;processor busy. If&nbsp;it is&nbsp;too slow, the memory will&nbsp;<br>
not&nbsp;be able&nbsp;to&nbsp;supply&nbsp;instructions as&nbsp;fast&nbsp;as the processor can execute them.&nbsp;<br>
Unfortunately,&nbsp;the&nbsp;larger&nbsp;a&nbsp;memory&nbsp;is&nbsp;the slower&nbsp;it&nbsp;is. It&nbsp;is therefore not&nbsp;possible&nbsp;<br>
to design&nbsp;a&nbsp;single memory&nbsp;which&nbsp;is both&nbsp;large&nbsp;enough and fast&nbsp;enough&nbsp;to&nbsp;keep&nbsp;a&nbsp;<br>
high-performance processor busy.&nbsp;<br>
It&nbsp;is,&nbsp;however,&nbsp;possible to&nbsp;build&nbsp;a&nbsp;composite&nbsp;memory system which combines&nbsp;a&nbsp;<br>
small,&nbsp;fast memory and a large, slow&nbsp;<i>main&nbsp;</i>memory&nbsp;to present an&nbsp;external behaviour&nbsp;<br>
which,&nbsp;with&nbsp;typical program&nbsp;statistics, appears to&nbsp;behave&nbsp;like a large, fast memory&nbsp;<br>
much&nbsp;of the&nbsp;time. The&nbsp;small, fast memory&nbsp;component is the&nbsp;<i>cache,&nbsp;</i>which automati-<br>
cally&nbsp;retains&nbsp;copies&nbsp;of&nbsp;instructions&nbsp;and&nbsp;data that&nbsp;the&nbsp;processor&nbsp;is using most&nbsp;fre-<br>
quently.&nbsp;The effectiveness of&nbsp;the cache&nbsp;depends on&nbsp;the&nbsp;<i>spatial locality&nbsp;</i>and&nbsp;<i>temporal&nbsp;</i><br>
<i>locality&nbsp;</i>properties&nbsp;of&nbsp;the&nbsp;program.&nbsp;<br>
This two-level memory principle&nbsp;can&nbsp;be extended&nbsp;into&nbsp;a&nbsp;memory hierarchy of&nbsp;<br>
many&nbsp;levels,&nbsp;and the computer backup (disk) store can be&nbsp;viewed as&nbsp;part of&nbsp;this&nbsp;<br>
hierarchy.&nbsp;With&nbsp;suitable&nbsp;<i>memory management&nbsp;</i>support, the size&nbsp;of&nbsp;a&nbsp;program is&nbsp;lim-<br>
ited not by the computer's main memory but by the size&nbsp;of the hard disk,&nbsp;which&nbsp;<br>
may&nbsp;be very&nbsp;much larger&nbsp;than&nbsp;the&nbsp;main&nbsp;memory.&nbsp;<br>
<b>269</b>&nbsp;<br>
<hr>
<A name=282></a><b>270</b>&nbsp;<br>
<b>Memory&nbsp;Hierarchy</b>&nbsp;<br>
10.1 &nbsp; Memory&nbsp;size&nbsp;and&nbsp;speed&nbsp;<br>
A typical computer&nbsp;memory&nbsp;hierarchy comprises several levels,&nbsp;each&nbsp;level having a&nbsp;<br>
characteristic size&nbsp;and speed.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;processor&nbsp;registers&nbsp;can&nbsp;be&nbsp;viewed as&nbsp;the&nbsp;top&nbsp;of the&nbsp;memory hierarchy.&nbsp;A&nbsp;<br>
RISC processor will typically&nbsp;have around&nbsp;thirty-two 32-bit registers&nbsp;making&nbsp;a&nbsp;<br>
total of&nbsp;128 bytes,&nbsp;with an access time&nbsp;of&nbsp;a few nanoseconds.&nbsp;<br>
•&nbsp;&nbsp;On-chip cache&nbsp;memory&nbsp;will&nbsp;have a capacity&nbsp;of&nbsp;eight to 32&nbsp;Kbytes&nbsp;with&nbsp;an access&nbsp;<br>
time around&nbsp;ten&nbsp;nanoseconds.&nbsp;<br>
•&nbsp;&nbsp;High-performance desktop&nbsp;systems&nbsp;may have a second-level off-chip cache&nbsp;with&nbsp;a&nbsp;<br>
capacity of a few hundred Kbytes and an&nbsp;access time of a few tens&nbsp;of nanoseconds.&nbsp;<br>
•&nbsp;&nbsp;Main&nbsp;memory&nbsp;will be&nbsp;megabytes to&nbsp;tens of&nbsp;megabytes of&nbsp;dynamic&nbsp;RAM&nbsp;with&nbsp;an&nbsp;<br>
access time&nbsp;around&nbsp;100&nbsp;nanoseconds.&nbsp;<br>
•&nbsp;&nbsp;Backup&nbsp;store,&nbsp;usually&nbsp;on&nbsp;a&nbsp;hard&nbsp;disk, will&nbsp;be&nbsp;hundreds of Mbytes up&nbsp;to&nbsp;a few&nbsp;<br>
Gbytes&nbsp;with an&nbsp;access time&nbsp;of&nbsp;a few&nbsp;tens&nbsp;of&nbsp;milliseconds.&nbsp;<br>
Note that&nbsp;the performance&nbsp;difference&nbsp;between the&nbsp;main memory&nbsp;and&nbsp;the&nbsp;backup&nbsp;<br>
store is&nbsp;very&nbsp;much greater&nbsp;than&nbsp;the&nbsp;difference&nbsp;between&nbsp;any other adjacent&nbsp;levels,&nbsp;even&nbsp;<br>
when&nbsp;there is&nbsp;no&nbsp;secondary cache&nbsp;in&nbsp;the system.&nbsp;<br>
The&nbsp;data&nbsp;which is&nbsp;held&nbsp;in&nbsp;the&nbsp;registers&nbsp;is&nbsp;under&nbsp;the&nbsp;direct&nbsp;control&nbsp;of&nbsp;the compiler or&nbsp;<br>
assembler programmer,&nbsp;but the&nbsp;contents of&nbsp;the&nbsp;remaining levels of the hierarchy&nbsp;are&nbsp;<br>
usually&nbsp;managed automatically. The caches&nbsp;are effectively invisible&nbsp;to&nbsp;the&nbsp;application&nbsp;<br>
program,&nbsp;with&nbsp;blocks&nbsp;or&nbsp;'pages'&nbsp;of instructions&nbsp;and&nbsp;data&nbsp;migrating&nbsp;up&nbsp;and&nbsp;down&nbsp;the&nbsp;<br>
hierarchy&nbsp;under hardware control. Paging&nbsp;between&nbsp;the main&nbsp;memory and&nbsp;the&nbsp;backup&nbsp;<br>
store is&nbsp;controlled&nbsp;by&nbsp;the&nbsp;operating system, and remains transparent&nbsp;to the&nbsp;application&nbsp;<br>
program. Since&nbsp;the&nbsp;performance difference&nbsp;between&nbsp;the main memory&nbsp;and&nbsp;the&nbsp;backup&nbsp;<br>
store is&nbsp;so&nbsp;great,&nbsp;much&nbsp;more&nbsp;sophisticated algorithms&nbsp;are&nbsp;required&nbsp;here to&nbsp;determine&nbsp;<br>
when to&nbsp;migrate&nbsp;data between the levels.&nbsp;<br>
An&nbsp;embedded&nbsp;system&nbsp;will not usually have&nbsp;a backing store&nbsp;and&nbsp;will therefore not&nbsp;<br>
exploit paging. However,&nbsp;many&nbsp;embedded&nbsp;systems incorporate&nbsp;caches,&nbsp;and ARM&nbsp;<br>
CPU chips employ a range of cache organizations. We&nbsp;will&nbsp;therefore look at&nbsp;cache&nbsp;<br>
organizational issues&nbsp;in&nbsp;some&nbsp;detail.&nbsp;<br>
Memory&nbsp;COSt&nbsp;<br>
Fast&nbsp;memory is&nbsp;more&nbsp;expensive&nbsp;per bit&nbsp;than&nbsp;slow&nbsp;memory,&nbsp;so&nbsp;a&nbsp;memory&nbsp;hierarchy&nbsp;<br>
also aims&nbsp;to give a performance close&nbsp;to&nbsp;the fastest&nbsp;memory with an average cost&nbsp;<br>
per&nbsp;bit&nbsp;approaching&nbsp;that&nbsp;of&nbsp;the&nbsp;slowest&nbsp;memory.&nbsp;<br>
<hr>
<A name=283></a><b>On-chip memory&nbsp;</b><br>
<b>271</b>&nbsp;<br>
10.2 &nbsp; On-chip&nbsp;memory&nbsp;<br>
Some&nbsp;form&nbsp;of&nbsp;on-chip memory&nbsp;is&nbsp;essential&nbsp;if&nbsp;a&nbsp;microprocessor&nbsp;is to&nbsp;deliver&nbsp;its&nbsp;<br>
best performance. With today's clock&nbsp;rates, only&nbsp;on-chip&nbsp;memory&nbsp;can support zero&nbsp;<br>
wait state access speeds, and&nbsp;it will also give better power-efficiency&nbsp;and reduced&nbsp;<br>
electromagnetic interference than off-chip&nbsp;memory.&nbsp;<br>
On-chip&nbsp;RAM&nbsp;<br>
In many&nbsp;embedded&nbsp;systems simple&nbsp;on-chip&nbsp;RAM&nbsp;is&nbsp;preferred&nbsp;to&nbsp;cache for a&nbsp;number&nbsp;<br>
benefits&nbsp;of&nbsp;<br>
reasons:&nbsp;<br>
•&nbsp;&nbsp;It&nbsp;is&nbsp;simpler,&nbsp;cheaper, and uses&nbsp;less power.&nbsp;<br>
We will see in the following sections that&nbsp;cache&nbsp;memory carries a significant&nbsp;<br>
overhead in terms of the logic that is&nbsp;required to enable it&nbsp;to operate effectively.&nbsp;<br>
It also incurs&nbsp;a significant design cost if&nbsp;a suitable&nbsp;off-the-shelf cache is una-<br>
vailable.&nbsp;<br>
•&nbsp;&nbsp;It has&nbsp;more deterministic behaviour.&nbsp;<br>
Cache&nbsp;memories have complex behaviours which can&nbsp;make difficult to predict&nbsp;<br>
how&nbsp;well&nbsp;they&nbsp;will&nbsp;operate&nbsp;under particular&nbsp;circumstances.&nbsp;In&nbsp;particular,&nbsp;it&nbsp;can&nbsp;be&nbsp;<br>
hard to&nbsp;guarantee interrupt response&nbsp;time.&nbsp;<br>
The drawback&nbsp;with on-chip RAM&nbsp;<i>vis-d-vis&nbsp;&nbsp;</i>cache is that it requires explicit&nbsp;<br>
management&nbsp;by the programmer, whereas&nbsp;a cache&nbsp;is usually transparent to the&nbsp;<br>
programmer.&nbsp;<br>
Where the program&nbsp;mix is&nbsp;well-defined&nbsp;and under the control of the program-<br>
mer,&nbsp;on-chip&nbsp;RAM can&nbsp;effectively be&nbsp;used&nbsp;as a&nbsp;software-controlled cache. Where&nbsp;<br>
the application&nbsp;mix cannot be predicted this control task becomes very&nbsp;difficult.&nbsp;<br>
Hence&nbsp;a&nbsp;cache&nbsp;is usually preferred in&nbsp;any general-purpose&nbsp;system&nbsp;where&nbsp;the appli-<br>
cation&nbsp;mix is unknown.&nbsp;<br>
One important&nbsp;advantage of on-chip RAM&nbsp;is that it enables the programmer to&nbsp;<br>
allocate space&nbsp;in it using knowledge of the&nbsp;<i>future&nbsp;</i>processing load. A cache left to&nbsp;<br>
its own devices has knowledge only&nbsp;<i>of past&nbsp;</i>program&nbsp;behaviour, and it&nbsp;can there-<br>
fore never prepare in advance for critical future tasks. Again, this is a difference&nbsp;<br>
which is&nbsp;most likely&nbsp;to&nbsp;be&nbsp;significant when critical&nbsp;tasks must meet&nbsp;strict&nbsp;real-<br>
time&nbsp;constraints.&nbsp;<br>
The system&nbsp;designer&nbsp;must decide which&nbsp;is the right&nbsp;approach for a particular&nbsp;<br>
system, taking&nbsp;all these&nbsp;factors into&nbsp;account. Whatever form&nbsp;of&nbsp;on-chip&nbsp;memory&nbsp;is&nbsp;<br>
chosen, it&nbsp;must be specified&nbsp;with great care. It&nbsp;must be fast enough to keep the&nbsp;<br>
processor busy&nbsp;and large enough to&nbsp;contain critical routines, but&nbsp;neither too fast&nbsp;<br>
(or it&nbsp;will&nbsp;consume too much&nbsp;power)&nbsp;nor&nbsp;too&nbsp;large&nbsp;(or&nbsp;it&nbsp;will&nbsp;occupy&nbsp;too much&nbsp;<br>
chip area).&nbsp;<br>
<hr>
<A name=284></a><b>272</b>&nbsp;<br>
<b>Memory&nbsp;Hierarchy</b>&nbsp;<br>
10.3 &nbsp; Caches&nbsp;<br>
The&nbsp;first&nbsp;RISC&nbsp;processors&nbsp;were introduced at a&nbsp;time&nbsp;when standard&nbsp;memory&nbsp;parts&nbsp;<br>
were&nbsp;faster&nbsp;than their contemporary&nbsp;microprocessors, but&nbsp;this&nbsp;situation&nbsp;did not per-<br>
sist&nbsp;for&nbsp;long. Subsequent&nbsp;advances in semiconductor&nbsp;process technology&nbsp;which have&nbsp;<br>
been&nbsp;exploited&nbsp;to make microprocessors faster have been applied differently&nbsp;to&nbsp;<br>
improve&nbsp;memory chips. Standard DRAM&nbsp;parts have got a little faster, but&nbsp;mostly&nbsp;<br>
they&nbsp;have&nbsp;been developed&nbsp;to&nbsp;have&nbsp;a&nbsp;much&nbsp;higher&nbsp;capacity.&nbsp;<br>
Processor and&nbsp;<br>
In 1980 a typical DRAM part could hold 4&nbsp;Kbits of data, with 16 Kbit chips arriv-<br>
memory speeds&nbsp;<br>
ing in 1981 and 1982. These&nbsp;parts would cycle at 3 or 4 MHz&nbsp;for&nbsp;random accesses,&nbsp;<br>
and at about twice this rate&nbsp;for local accesses (in page&nbsp;mode). Microprocessors at&nbsp;<br>
that time&nbsp;could&nbsp;request&nbsp;around two&nbsp;million&nbsp;memory accesses per second.&nbsp;<br>
In 2000&nbsp;DRAM&nbsp;parts&nbsp;have&nbsp;a&nbsp;capacity&nbsp;of 256&nbsp;Mbits&nbsp;per&nbsp;chip, with&nbsp;random&nbsp;accesses&nbsp;<br>
operating at&nbsp;around 30&nbsp;MHz.&nbsp;Microprocessors can request&nbsp;several&nbsp;hundred million&nbsp;<br>
memory accesses&nbsp;per second. If&nbsp;the&nbsp;processor&nbsp;is so much&nbsp;faster&nbsp;than the&nbsp;memory, it&nbsp;<br>
can only&nbsp;deliver&nbsp;its&nbsp;full&nbsp;performance&nbsp;potential with the&nbsp;help&nbsp;of a&nbsp;<b>cache&nbsp;</b>memory.&nbsp;<br>
A&nbsp;cache&nbsp;memory&nbsp;is&nbsp;a&nbsp;small,&nbsp;very&nbsp;fast&nbsp;memory that&nbsp;retains&nbsp;copies&nbsp;of recently used&nbsp;<br>
memory values. It&nbsp;operates&nbsp;transparently&nbsp;to&nbsp;the programmer, automatically deciding&nbsp;<br>
which&nbsp;values to&nbsp;keep&nbsp;and&nbsp;which to&nbsp;overwrite. These&nbsp;days&nbsp;it&nbsp;is usually&nbsp;implemented&nbsp;on&nbsp;<br>
the same&nbsp;chip&nbsp;as the&nbsp;processor. Caches work&nbsp;because&nbsp;programs normally&nbsp;display&nbsp;the&nbsp;<br>
property&nbsp;of&nbsp;<b>locality,&nbsp;</b>which means&nbsp;that&nbsp;at&nbsp;any particular&nbsp;time they tend to&nbsp;execute&nbsp;the&nbsp;<br>
same&nbsp;instructions&nbsp;many&nbsp;times&nbsp;(for&nbsp;instance&nbsp;in&nbsp;a loop) on the same&nbsp;areas of&nbsp;data&nbsp;(for&nbsp;<br>
instance&nbsp;a&nbsp;stack).&nbsp;<br>
Unified and&nbsp;<br>
Caches can be&nbsp;built in&nbsp;many&nbsp;ways.&nbsp;At the highest level a&nbsp;processor can&nbsp;have one of&nbsp;<br>
Harvard caches&nbsp;<br>
the following two&nbsp;organizations:&nbsp;<br>
•&nbsp;A&nbsp;unified&nbsp;cache.&nbsp;<br>
This&nbsp;is&nbsp;a single&nbsp;cache&nbsp;for both&nbsp;instructions&nbsp;and data, as&nbsp;illustrated in&nbsp;Figure 10.1&nbsp;<br>
on&nbsp;page&nbsp;273.&nbsp;<br>
•&nbsp;&nbsp;Separate&nbsp;instruction&nbsp;and&nbsp;data caches.&nbsp;<br>
This&nbsp;organization is sometimes called&nbsp;a&nbsp;<b>modified Harvard&nbsp;</b>architecture as shown&nbsp;<br>
in&nbsp;Figure&nbsp;10.2&nbsp;on&nbsp;page&nbsp;274.&nbsp;<br>
Both&nbsp;these&nbsp;organizations have their&nbsp;merits. The&nbsp;unified cache automatically&nbsp;<br>
adjusts the proportion of&nbsp;the cache&nbsp;memory used by&nbsp;instructions&nbsp;according to&nbsp;<br>
the current&nbsp;program&nbsp;requirements, giving&nbsp;a better performance than&nbsp;a&nbsp;fixed&nbsp;par-<br>
titioning. On&nbsp;the other&nbsp;hand&nbsp;the separate&nbsp;caches&nbsp;allow load&nbsp;and store&nbsp;instruc-<br>
tions to&nbsp;execute in a single&nbsp;clock cycle.&nbsp;<br>
<hr>
<A name=285></a><IMG src="index-285_1.png"><br>
<b>Caches</b>&nbsp;<br>
<b>273</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;10.1 &nbsp;&nbsp;&nbsp;</b>A unified&nbsp;instruction and data&nbsp;cache.&nbsp;<br>
Cache&nbsp;<br>
Since the&nbsp;processor can operate at its high&nbsp;clock&nbsp;rate only when&nbsp;the memory items it&nbsp;<br>
performance&nbsp;<br>
requires&nbsp;are&nbsp;held in&nbsp;the cache, the&nbsp;overall system&nbsp;performance&nbsp;depends strongly&nbsp;on&nbsp;<br>
metrics&nbsp;<br>
the proportion of memory accesses which&nbsp;cannot be satisfied by the cache. An&nbsp;<br>
access to&nbsp;an item&nbsp;which is in&nbsp;the cache&nbsp;is&nbsp;called a&nbsp;hit,&nbsp;and an access&nbsp;to&nbsp;an item&nbsp;<br>
which&nbsp;is&nbsp;not&nbsp;in the cache&nbsp;is a&nbsp;<b>miss.&nbsp;</b>The&nbsp;proportion&nbsp;of all&nbsp;the&nbsp;memory accesses that&nbsp;<br>
are satisfied&nbsp;by the cache&nbsp;is&nbsp;the&nbsp;<b>hit rate,&nbsp;</b>usually&nbsp;expressed as a&nbsp;percentage, and the&nbsp;<br>
proportion that&nbsp;are&nbsp;not is the&nbsp;<b>miss rate.</b>&nbsp;<br>
The miss rate of a&nbsp;well-designed cache should&nbsp;be&nbsp;only a few per cent if&nbsp;a&nbsp;modern&nbsp;<br>
processor&nbsp;is&nbsp;to&nbsp;fulfil&nbsp;its potential.&nbsp;The&nbsp;miss rate&nbsp;depends on&nbsp;a number&nbsp;of&nbsp;cache&nbsp;<br>
parameters, including its size (the number&nbsp;of&nbsp;bytes of memory in the cache) and its&nbsp;<br>
organization.&nbsp;<br>
Cache&nbsp;<br>
Since a&nbsp;cache&nbsp;holds a&nbsp;dynamically varying&nbsp;selection&nbsp;of items&nbsp;from&nbsp;main memory, it&nbsp;<br>
organization&nbsp;<br>
must have storage for both&nbsp;the data&nbsp;and&nbsp;the&nbsp;address at which&nbsp;the data&nbsp;is&nbsp;stored&nbsp;in&nbsp;<br>
main&nbsp;memory.&nbsp;<br>
The&nbsp;<br>
The simplest organization&nbsp;of&nbsp;these components is the direct-mapped cache which is&nbsp;<br>
direct-mapped&nbsp;<br>
illustrated&nbsp;in&nbsp;Figure 10.3 on&nbsp;page&nbsp;275. In&nbsp;the direct-mapped&nbsp;cache&nbsp;a&nbsp;<b>line&nbsp;</b>of data is&nbsp;<br>
cache&nbsp;<br>
stored along&nbsp;with an&nbsp;address&nbsp;<b>tag&nbsp;</b>in&nbsp;a memory&nbsp;which is&nbsp;addressed&nbsp;by&nbsp;some&nbsp;portion&nbsp;<br>
of&nbsp;the&nbsp;memory&nbsp;address&nbsp;(the&nbsp;<b>index).</b>&nbsp;<br>
To check whether or&nbsp;not a particular&nbsp;memory&nbsp;item&nbsp;is stored in the cache, the index&nbsp;<br>
address bits&nbsp;are&nbsp;used to access&nbsp;the cache entry. The top address&nbsp;bits are then&nbsp;compared&nbsp;<br>
<hr>
<A name=286></a><IMG src="index-286_1.png"><br>
<b>274</b>&nbsp;<br>
<b>Memory&nbsp;Hierarchy</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 10.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Separate data and&nbsp;instruction&nbsp;caches.&nbsp;<br>
with&nbsp;the stored tag;&nbsp;if they are equal, the&nbsp;item&nbsp;is in&nbsp;the cache.&nbsp;The lowest&nbsp;address bits&nbsp;<br>
can be used&nbsp;to&nbsp;access the desired item&nbsp;within the line.&nbsp;<br>
This, simplest, cache organization has a number&nbsp;of&nbsp;properties that can be&nbsp;con-<br>
trasted with&nbsp;those of&nbsp;more complex organizations:&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;particular memory&nbsp;item&nbsp;is&nbsp;stored&nbsp;in&nbsp;a&nbsp;unique&nbsp;location in&nbsp;the cache;&nbsp;two items&nbsp;<br>
with&nbsp;the same&nbsp;cache&nbsp;address field will&nbsp;contend for use&nbsp;of&nbsp;that&nbsp;location.&nbsp;<br>
•&nbsp;&nbsp;Only those bits&nbsp;of the address that are&nbsp;not&nbsp;used&nbsp;to&nbsp;select within the line or to&nbsp;<br>
address the&nbsp;cache RAM&nbsp;need&nbsp;be&nbsp;stored in the&nbsp;tag&nbsp;field.&nbsp;<br>
•&nbsp;&nbsp;The tag and data access can&nbsp;be performed&nbsp;at the same&nbsp;time, giving the&nbsp;fastest&nbsp;<br>
cache access time&nbsp;of any&nbsp;organization.&nbsp;<br>
•&nbsp;&nbsp;Since the&nbsp;tag RAM is typically a lot smaller than the&nbsp;data RAM, its access&nbsp;time&nbsp;is&nbsp;<br>
shorter, allowing the tag comparison to&nbsp;be completed&nbsp;within&nbsp;the&nbsp;data&nbsp;access time.&nbsp;<br>
<hr>
<A name=287></a><IMG src="index-287_1.png"><br>
<b>Caches</b>&nbsp;<br>
<b>275</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 10.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Direct-mapped cache organization.&nbsp;<br>
A typical direct-mapped&nbsp;cache&nbsp;might store&nbsp;8&nbsp;Kbytes of&nbsp;data&nbsp;in&nbsp;16-byte lines. There&nbsp;<br>
would&nbsp;therefore be&nbsp;512&nbsp;lines.&nbsp;A 32-bit address would&nbsp;have&nbsp;four bits&nbsp;to&nbsp;address&nbsp;bytes&nbsp;<br>
within&nbsp;the&nbsp;line&nbsp;and&nbsp;nine&nbsp;bits&nbsp;to&nbsp;select&nbsp;the&nbsp;line,&nbsp;leaving&nbsp;a&nbsp;19-bit&nbsp;tag&nbsp;which&nbsp;requires&nbsp;just&nbsp;<br>
over&nbsp;one Kbyte&nbsp;of tag store.&nbsp;<br>
When&nbsp;data&nbsp;is loaded into&nbsp;the&nbsp;cache, a&nbsp;<b>block&nbsp;</b>of data is fetched from&nbsp;memory. There&nbsp;<br>
is&nbsp;little point&nbsp;in&nbsp;having&nbsp;the&nbsp;line size&nbsp;smaller than&nbsp;the&nbsp;block&nbsp;size. If the&nbsp;block&nbsp;size&nbsp;is&nbsp;<br>
smaller than the line&nbsp;size,&nbsp;the&nbsp;tag store must be&nbsp;extended&nbsp;to&nbsp;include&nbsp;a&nbsp;valid&nbsp;bit&nbsp;for&nbsp;each&nbsp;<br>
block within&nbsp;the line. Choosing&nbsp;the line and&nbsp;block sizes to&nbsp;be equal results&nbsp;in the sim-<br>
plest&nbsp;organization.&nbsp;<br>
The&nbsp;<br>
Moving up in complexity,&nbsp;the&nbsp;set-associative cache aims&nbsp;to&nbsp;reduce&nbsp;the problems&nbsp;due&nbsp;<br>
set-associ<br>
to contention&nbsp;by enabling a&nbsp;particular&nbsp;memory&nbsp;item&nbsp;to&nbsp;be stored in&nbsp;more than one&nbsp;<br>
ative&nbsp;<br>
cache&nbsp;location.&nbsp;A&nbsp;2-way set-associative cache&nbsp;is&nbsp;illustrated in Figure&nbsp;10.4&nbsp;on&nbsp;<br>
cache&nbsp;<br>
page&nbsp;276. As&nbsp;the figure suggests,&nbsp;this form&nbsp;of cache&nbsp;is&nbsp;effectively&nbsp;two&nbsp;direct-mapped&nbsp;<br>
caches operating in parallel.&nbsp;An address presented&nbsp;to the&nbsp;cache&nbsp;may&nbsp;find&nbsp;its data in&nbsp;<br>
either half, so&nbsp;each&nbsp;memory&nbsp;address&nbsp;may be&nbsp;stored in either of&nbsp;two places.&nbsp;Each of&nbsp;<br>
two&nbsp;items&nbsp;which&nbsp;were&nbsp;in&nbsp;contention&nbsp;for&nbsp;a&nbsp;single&nbsp;location&nbsp;in&nbsp;the&nbsp;direct-mapped&nbsp;cache&nbsp;<br>
may&nbsp;now&nbsp;occupy&nbsp;one of&nbsp;these&nbsp;places, allowing&nbsp;the cache to&nbsp;hit on&nbsp;both.&nbsp;<br>
The 8&nbsp;Kbyte cache&nbsp;with&nbsp;16&nbsp;byte&nbsp;lines&nbsp;will&nbsp;have&nbsp;256&nbsp;lines&nbsp;in&nbsp;each&nbsp;half&nbsp;of&nbsp;the&nbsp;cache,&nbsp;<br>
so&nbsp;four&nbsp;bits&nbsp;of&nbsp;the&nbsp;32-bit&nbsp;address&nbsp;select&nbsp;a&nbsp;byte&nbsp;from&nbsp;the&nbsp;line&nbsp;and&nbsp;eight&nbsp;bits&nbsp;select&nbsp;one&nbsp;<br>
line&nbsp;from&nbsp;each&nbsp;half&nbsp;of the&nbsp;cache.&nbsp;The address tag&nbsp;must therefore&nbsp;be&nbsp;one&nbsp;bit longer, at&nbsp;<br>
<hr>
<A name=288></a><IMG src="index-288_1.png"><br>
<b>276</b>&nbsp;<br>
<b>Memory&nbsp;Hierarchy</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 10.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Two-way&nbsp;set-associative cache organization.&nbsp;<br>
20 bits. The access time&nbsp;is&nbsp;only&nbsp;very&nbsp;slightly&nbsp;longer than that of the direct-mapped&nbsp;<br>
cache, the increase being due&nbsp;to&nbsp;the&nbsp;need&nbsp;to&nbsp;multiplex the data&nbsp;from&nbsp;the&nbsp;two halves.&nbsp;<br>
When a&nbsp;new data item&nbsp;is&nbsp;to&nbsp;be&nbsp;placed&nbsp;in the&nbsp;cache, a&nbsp;decision&nbsp;must be taken as&nbsp;to&nbsp;<br>
which half&nbsp;to&nbsp;place&nbsp;it&nbsp;in.&nbsp;There are several&nbsp;options here, the most&nbsp;common&nbsp;being:&nbsp;<br>
<hr>
<A name=289></a><IMG src="index-289_1.png"><br>
<b>Caches</b>&nbsp;<br>
<b>277</b>&nbsp;<br>
•&nbsp;Random&nbsp;allocation.&nbsp;<br>
The&nbsp;decision&nbsp;is based&nbsp;on a random&nbsp;or&nbsp;pseudo-random&nbsp;value.&nbsp;<br>
•&nbsp;&nbsp;Least&nbsp;recently&nbsp;used&nbsp;(LRU).&nbsp;<br>
The&nbsp;cache&nbsp;keeps&nbsp;a&nbsp;record&nbsp;of&nbsp;which&nbsp;location&nbsp;of&nbsp;a&nbsp;pair&nbsp;was&nbsp;last&nbsp;accessed&nbsp;and&nbsp;alloc-<br>
ates&nbsp;the new data to the other one.&nbsp;<br>
•&nbsp;&nbsp;Round-robin (also known as&nbsp;'cyclic').&nbsp;<br>
The&nbsp;cache&nbsp;keeps&nbsp;a&nbsp;record&nbsp;of&nbsp;which&nbsp;location&nbsp;of&nbsp;a&nbsp;pair&nbsp;was&nbsp;last&nbsp;allocated and&nbsp;alloc-<br>
ates&nbsp;the new data to the other one.&nbsp;<br>
The set-associative approach&nbsp;extends&nbsp;beyond&nbsp;2-way&nbsp;up to&nbsp;any&nbsp;degree&nbsp;of associativ-<br>
ity,&nbsp;but&nbsp;in&nbsp;practice&nbsp;the&nbsp;benefits&nbsp;of going&nbsp;beyond&nbsp;4-way&nbsp;associativity&nbsp;are&nbsp;small and&nbsp;do&nbsp;<br>
not warrant&nbsp;the&nbsp;extra&nbsp;complexity&nbsp;incurred.&nbsp;<br>
The&nbsp;fully&nbsp;<br>
At&nbsp;the other&nbsp;extreme&nbsp;of&nbsp;associativity, it&nbsp;is&nbsp;possible&nbsp;to design&nbsp;a&nbsp;fully&nbsp;associative&nbsp;cache&nbsp;<br>
associative&nbsp;<br>
in VLSI&nbsp;technology. Rather&nbsp;than continuing&nbsp;to divide&nbsp;the direct-mapped&nbsp;cache into&nbsp;<br>
cache&nbsp;ever&nbsp;<br>
smaller&nbsp;<br>
components,&nbsp;the tag store is&nbsp;designed&nbsp;differently&nbsp;using content&nbsp;<br>
addressed&nbsp;memory (CAM).&nbsp;A CAM cell is a RAM cell&nbsp;with an inbuilt comparator,&nbsp;<br>
so a CAM based tag store can perform&nbsp;a parallel search to locate an&nbsp;address in any&nbsp;<br>
location.&nbsp;The&nbsp;organization of&nbsp;a&nbsp;fully&nbsp;associative&nbsp;cache&nbsp;is illustrated&nbsp;in&nbsp;Figure&nbsp;10.5.&nbsp;<br>
&nbsp;<br>
<hr>
<A name=290></a><b>278</b>&nbsp;<br>
<b>Memory&nbsp;Hierarchy</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Since there are no address&nbsp;bits implicit&nbsp;in&nbsp;the&nbsp;position&nbsp;of&nbsp;data&nbsp;in&nbsp;the cache,&nbsp;the&nbsp;tag&nbsp;<br>
must store&nbsp;all&nbsp;the&nbsp;address&nbsp;bits&nbsp;apart from&nbsp;those&nbsp;used&nbsp;to&nbsp;address bytes within&nbsp;the&nbsp;line.&nbsp;<br>
Write strategies&nbsp;<br>
The above schemes operate in&nbsp;an obvious way&nbsp;for&nbsp;read accesses:&nbsp;when&nbsp;presented&nbsp;<br>
with a new&nbsp;read&nbsp;address the cache&nbsp;checks&nbsp;to&nbsp;see&nbsp;whether it&nbsp;holds the&nbsp;addressed&nbsp;data;&nbsp;<br>
if it does, it supplies the data; if it does not, it fetches a&nbsp;block of data from&nbsp;main&nbsp;<br>
memory, stores&nbsp;it&nbsp;in the&nbsp;cache in some&nbsp;suitable location and supplies the requested&nbsp;<br>
data&nbsp;to&nbsp;the&nbsp;processor.&nbsp;<br>
There are more choices to&nbsp;make when&nbsp;the processor executes a write&nbsp;cycle. In&nbsp;<br>
increasing&nbsp;order of complexity, the&nbsp;commonly used write strategies&nbsp;are:&nbsp;<br>
<b>• Write-through.</b>&nbsp;<br>
All&nbsp;write operations are passed to&nbsp;main&nbsp;memory;&nbsp;if the&nbsp;addressed location is&nbsp;cur-<br>
rently&nbsp;held in the cache,&nbsp;the cache is updated&nbsp;to hold the new value. The&nbsp;proces-<br>
sor&nbsp;must&nbsp;slow&nbsp;down to&nbsp;main&nbsp;memory&nbsp;speed&nbsp;while the&nbsp;write&nbsp;takes place.&nbsp;<br>
<b>•&nbsp;&nbsp;Write-through with buffered write.</b>&nbsp;<br>
Here&nbsp;all&nbsp;write&nbsp;operations&nbsp;are&nbsp;still&nbsp;passed&nbsp;to&nbsp;main&nbsp;memory&nbsp;and the&nbsp;cache&nbsp;updated&nbsp;<br>
as appropriate,&nbsp;but&nbsp;instead&nbsp;of&nbsp;slowing the processor down to&nbsp;main&nbsp;memory&nbsp;speed&nbsp;<br>
the&nbsp;write&nbsp;address and data&nbsp;are stored in a&nbsp;<b>write buffer&nbsp;</b>which&nbsp;can&nbsp;accept&nbsp;the&nbsp;write&nbsp;<br>
information at&nbsp;high&nbsp;speed. The&nbsp;write buffer then transfers the data&nbsp;to&nbsp;main&nbsp;mem-<br>
ory,&nbsp;at&nbsp;main memory speed,&nbsp;while&nbsp;the&nbsp;processor continues with&nbsp;its next&nbsp;task.&nbsp;<br>
<b>• Copy-back&nbsp;</b><br>
(also&nbsp;known&nbsp;as&nbsp;<b>write-back).</b>&nbsp;<br>
A copy-back&nbsp;cache is not kept coherent&nbsp;with&nbsp;main&nbsp;memory. Write operations&nbsp;<br>
update&nbsp;only the cache,&nbsp;so&nbsp;cache&nbsp;lines&nbsp;must&nbsp;remember&nbsp;when&nbsp;they have been&nbsp;modi-<br>
fied&nbsp;(usually&nbsp;using a&nbsp;<b>dirty&nbsp;</b>bit on each line or block).&nbsp;If a&nbsp;dirty cache line is allo-<br>
cated to new data it&nbsp;must be&nbsp;copied back to&nbsp;memory before the line is&nbsp;reused.&nbsp;<br>
The write-through cache&nbsp;is&nbsp;the simplest to&nbsp;implement and&nbsp;has the&nbsp;merit&nbsp;that&nbsp;the&nbsp;<br>
memory&nbsp;is kept&nbsp;up&nbsp;to&nbsp;date; the drawback&nbsp;is&nbsp;that&nbsp;the&nbsp;processor must slow to&nbsp;memory&nbsp;<br>
speeds&nbsp;on&nbsp;every&nbsp;write&nbsp;transfer.&nbsp;The&nbsp;addition of&nbsp;a&nbsp;write buffer allows the&nbsp;processor to&nbsp;<br>
continue&nbsp;until the write traffic&nbsp;exceeds the&nbsp;external write&nbsp;bandwidth.&nbsp;The&nbsp;copy-back&nbsp;<br>
cache reduces the external&nbsp;write bandwidth&nbsp;requirement since a&nbsp;location may be writ-<br>
ten many&nbsp;times before the final value&nbsp;gets written back to&nbsp;memory, but the&nbsp;implemen-<br>
tation is&nbsp;considerably more complex and&nbsp;the&nbsp;loss&nbsp;of&nbsp;coherency is&nbsp;hard to&nbsp;manage.&nbsp;<br>
Cache feature&nbsp;<br>
The various parameters that&nbsp;define&nbsp;the&nbsp;organization&nbsp;of a&nbsp;cache&nbsp;are&nbsp;summarized&nbsp;in&nbsp;<br>
summary&nbsp;<br>
Table&nbsp;10.1&nbsp;on&nbsp;page 279.&nbsp;The first of&nbsp;these&nbsp;is&nbsp;the&nbsp;relationship&nbsp;between the cache&nbsp;and&nbsp;<br>
the&nbsp;memory&nbsp;management unit (MMU) which will be discussed&nbsp;further in&nbsp;'Virtual&nbsp;<br>
and physical caches'&nbsp;on&nbsp;page&nbsp;287; the others have been&nbsp;covered&nbsp;in this&nbsp;section.&nbsp;<br>
<hr>
<A name=291></a><b>Cache design -&nbsp;an example</b>&nbsp;<br>
<b>279</b>&nbsp;<br>
<b>Table&nbsp;10.1 &nbsp; &nbsp;</b>Summary&nbsp;of cache organizational options.&nbsp;<br>
&nbsp;<br>
Organizational feature&nbsp;&nbsp;&nbsp;<br>
Options&nbsp;&nbsp;&nbsp;<br>
Cache-MMU relationship&nbsp;&nbsp;&nbsp;&nbsp;Physical cache&nbsp;&nbsp;&nbsp;<br>
Virtual cache&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
Cache contents&nbsp;&nbsp;&nbsp;<br>
Unified instruction&nbsp;<br>
Separate instruction&nbsp;<br>
&nbsp;<br>
and data cache&nbsp;&nbsp;&nbsp;<br>
and data caches&nbsp;&nbsp;&nbsp;<br>
Associativity&nbsp;&nbsp;&nbsp;<br>
Direct-mapped&nbsp;<br>
Set-associative&nbsp;<br>
Fully&nbsp;associative&nbsp;<br>
RAM-RAM&nbsp;&nbsp;&nbsp;<br>
RAM-RAM&nbsp;&nbsp;&nbsp;<br>
CAM-RAM&nbsp;&nbsp;&nbsp;<br>
Replacement strategy&nbsp;&nbsp;&nbsp;<br>
Round-robin&nbsp;&nbsp;&nbsp;<br>
Random&nbsp;&nbsp;&nbsp;<br>
LRU&nbsp;&nbsp;&nbsp;<br>
Write&nbsp;strategy&nbsp;&nbsp;&nbsp;<br>
Write-through&nbsp;&nbsp;&nbsp;<br>
Write-through&nbsp;with&nbsp;<br>
Copy-back&nbsp;&nbsp;&nbsp;<br>
write&nbsp;buffer&nbsp;&nbsp;&nbsp;<br>
10.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cache design - an example&nbsp;<br>
The choice of organization for a cache requires&nbsp;the consideration of several factors as&nbsp;<br>
discussed in&nbsp;Section&nbsp;10.3&nbsp;on&nbsp;page&nbsp;272, including&nbsp;the size&nbsp;of the cache, the&nbsp;degree&nbsp;of&nbsp;<br>
associativity, the line and&nbsp;block sizes, the&nbsp;replacement&nbsp;algorithm,&nbsp;and the&nbsp;write&nbsp;strat-<br>
egy. Detailed architectural&nbsp;simulations&nbsp;are&nbsp;required&nbsp;to&nbsp;analyse&nbsp;the&nbsp;effects&nbsp;of&nbsp;these&nbsp;<br>
choices on the&nbsp;performance of the cache.&nbsp;<br>
The&nbsp;ARMS&nbsp;<br>
The&nbsp;ARMS,&nbsp;designed in&nbsp;1989,&nbsp;was the first&nbsp;ARM&nbsp;chip&nbsp;to&nbsp;incorporate an&nbsp;on-chip&nbsp;<br>
cache&nbsp;<br>
cache, and detailed studies were carried out&nbsp;into the effects of these parameters on&nbsp;<br>
performance and&nbsp;bus&nbsp;use.&nbsp;These studies used&nbsp;specially&nbsp;designed&nbsp;hardware&nbsp;to&nbsp;capture&nbsp;<br>
address traces&nbsp;while&nbsp;running several&nbsp;benchmark programs on an ARM2;&nbsp;software was&nbsp;<br>
then&nbsp;used to&nbsp;analyse these traces&nbsp;to&nbsp;model&nbsp;the behaviour of the various organizations.&nbsp;<br>
(Today&nbsp;special hardware is&nbsp;generally unnecessary since desktop&nbsp;machines have suffi-<br>
cient&nbsp;performance to&nbsp;simulate large enough&nbsp;programs&nbsp;without&nbsp;hardware support.)&nbsp;<br>
The study&nbsp;started by&nbsp;setting an upper&nbsp;bound&nbsp;on the performance benefit&nbsp;that&nbsp;could&nbsp;<br>
be&nbsp;expected&nbsp;from a cache.&nbsp;A 'perfect' cache,&nbsp;which always&nbsp;contains&nbsp;the&nbsp;requested&nbsp;<br>
data, was modelled&nbsp;to&nbsp;set this bound.&nbsp;Any&nbsp;real cache&nbsp;is&nbsp;bound&nbsp;to&nbsp;miss some&nbsp;of&nbsp;the&nbsp;<br>
time, so&nbsp;it&nbsp;cannot perform&nbsp;any&nbsp;better than&nbsp;one&nbsp;which&nbsp;always hits.&nbsp;<br>
Three forms of perfect cache&nbsp;were modelled&nbsp;using realistic&nbsp;assumptions about the&nbsp;<br>
cache and external memory speeds (which&nbsp;were&nbsp;20 MHz&nbsp;and 8 MHz&nbsp;respectively):&nbsp;<br>
caches which hold&nbsp;either&nbsp;just&nbsp;instructions, mixed instructions and data,&nbsp;or just&nbsp;data.&nbsp;<br>
The results&nbsp;are shown in&nbsp;Table 10.2&nbsp;on&nbsp;page&nbsp;280,&nbsp;normalized to&nbsp;the&nbsp;performance of a&nbsp;<br>
system&nbsp;with&nbsp;no&nbsp;cache. They&nbsp;show&nbsp;that&nbsp;instructions are the most important&nbsp;values to&nbsp;<br>
hold in the cache, but including&nbsp;data values&nbsp;as well can give a further 25% perform-<br>
ance increase.&nbsp;<br>
<hr>
<A name=292></a><IMG src="index-292_1.png"><br>
<b>280</b>&nbsp;<br>
<b>Memory&nbsp;Hierarchy</b>&nbsp;<br>
<b>Table&nbsp;10.2 &nbsp;&nbsp;&nbsp;</b>'Perfect' cache&nbsp;performance.&nbsp;<br>
&nbsp;<br>
Cache form&nbsp;&nbsp;&nbsp;<br>
Performance&nbsp;&nbsp;&nbsp;<br>
No cache&nbsp;&nbsp;&nbsp;<br>
1&nbsp;&nbsp;&nbsp;<br>
Instruction-only cache&nbsp;&nbsp;&nbsp;<br>
1.95&nbsp;&nbsp;&nbsp;<br>
Instruction and&nbsp;data cache&nbsp;&nbsp;&nbsp;<br>
2.5&nbsp;&nbsp;&nbsp;<br>
Data-only&nbsp;cache&nbsp;&nbsp;&nbsp;<br>
1.13&nbsp;&nbsp;&nbsp;<br>
Although a decision was taken early&nbsp;on that&nbsp;the&nbsp;cache&nbsp;write strategy&nbsp;would be&nbsp;<br>
write-through (principally on&nbsp;the grounds&nbsp;of&nbsp;simplicity), it is&nbsp;still possible for the&nbsp;<br>
cache&nbsp;to&nbsp;detect&nbsp;a&nbsp;write&nbsp;miss&nbsp;and&nbsp;load&nbsp;a&nbsp;line&nbsp;of&nbsp;data&nbsp;from&nbsp;the&nbsp;write&nbsp;address.&nbsp;This&nbsp;'allocate&nbsp;<br>
on&nbsp;write&nbsp;miss'&nbsp;strategy&nbsp;was investigated&nbsp;briefly,&nbsp;but proved&nbsp;to offer&nbsp;a negligible&nbsp;<br>
benefit&nbsp;in&nbsp;exchange&nbsp;for a significant increase in&nbsp;complexity,&nbsp;so it&nbsp;was&nbsp;rapidly&nbsp;abandoned.&nbsp;<br>
The&nbsp;problem&nbsp;was reduced&nbsp;to&nbsp;rinding the best&nbsp;organization, consistent&nbsp;with&nbsp;chip&nbsp;area and&nbsp;<br>
power constraints, for a unified instruction and data cache with&nbsp;allocation on a read&nbsp;<br>
miss.&nbsp;<br>
Various&nbsp;different cache organizations and sizes were investigated, with the results&nbsp;<br>
show in Figure&nbsp;10.6. The simplest cache organization is the&nbsp;direct-mapped&nbsp;cache, but&nbsp;<br>
even with a size of 16&nbsp;Kbytes, the cache is significantly&nbsp;worse than the 'perfect'&nbsp;case.&nbsp;<br>
The next&nbsp;step&nbsp;up&nbsp;in&nbsp;complexity&nbsp;is&nbsp;the dual set associative cache; now the performance&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;10.6 &nbsp;&nbsp;</b>Unified cache performance as&nbsp;a function of&nbsp;size and organization.<br>
<hr>
<A name=293></a><IMG src="index-293_1.png"><br>
<b>Cache&nbsp;design&nbsp;-&nbsp;an&nbsp;example</b>&nbsp;<br>
<b>281</b>&nbsp;<br>
of the 16 Kbyte cache is within&nbsp;a per cent or&nbsp;so of the&nbsp;perfect cache. But at&nbsp;the time of&nbsp;<br>
the design of the ARMS (1989) a 16 Kbyte&nbsp;cache required&nbsp;a large chip area, and the 4&nbsp;<br>
Kbyte cache does not&nbsp;perform&nbsp;so well. (The&nbsp;results depend strongly&nbsp;on the program&nbsp;<br>
used to&nbsp;generate&nbsp;the address traces used, but these are typical.)&nbsp;<br>
Going&nbsp;to&nbsp;the other extreme,&nbsp;a&nbsp;fully&nbsp;associative cache performs&nbsp;significantly better&nbsp;at&nbsp;<br>
the smaller size, delivering&nbsp;the 'perfect'&nbsp;performance on the benchmark program&nbsp;used&nbsp;<br>
for the tests.&nbsp;Here the replacement algorithm&nbsp;is random;&nbsp;LRU (least&nbsp;recently used)&nbsp;<br>
gives very&nbsp;similar results.&nbsp;<br>
The cache&nbsp;model was&nbsp;then&nbsp;modified&nbsp;to use&nbsp;a&nbsp;quad-word line which is necessary&nbsp;to&nbsp;<br>
reduce the area&nbsp;cost&nbsp;of&nbsp;the tag&nbsp;store. This&nbsp;change&nbsp;had minimal effect&nbsp;on the&nbsp;performance.&nbsp;<br>
The fully associative cache requires a large CAM (Content Addressable&nbsp;Memory)&nbsp;<br>
tag&nbsp;store&nbsp;which&nbsp;is likely to&nbsp;consume significant power, even&nbsp;with&nbsp;a quad-word&nbsp;line.&nbsp;<br>
The power can be reduced a&nbsp;lot&nbsp;by&nbsp;segmenting the CAM&nbsp;into&nbsp;smaller components, but&nbsp;<br>
this reduces&nbsp;the associativity.&nbsp;An analysis&nbsp;of the sensitivity&nbsp;of the system&nbsp;performance&nbsp;<br>
on the&nbsp;degree&nbsp;of associativity, using a&nbsp;4&nbsp;Kbyte cache, is shown in Figure 10.7. This&nbsp;<br>
shows the performance of the system&nbsp;for all&nbsp;associativities from&nbsp;fully&nbsp;(256-way)&nbsp;asso-<br>
ciative down to&nbsp;direct-mapped (1-way). Although the biggest performance&nbsp;increase is&nbsp;<br>
in going from&nbsp;direct-mapped&nbsp;to dual-set&nbsp;associative,&nbsp;there are&nbsp;noticeable&nbsp;improve-<br>
ments all&nbsp;the way up&nbsp;to&nbsp;64-way associativity.&nbsp;<br>
It would therefore appear that a 64-way associative CAM-RAM cache provides the&nbsp;<br>
same&nbsp;performance as the fully associative&nbsp;cache while allowing&nbsp;the 256&nbsp;CAM entries&nbsp;<br>
to&nbsp;be&nbsp;split into&nbsp;four sections&nbsp;to&nbsp;save&nbsp;power.&nbsp;The external memory bandwidth&nbsp;require-<br>
ment&nbsp;of&nbsp;each&nbsp;level&nbsp;of&nbsp;associativity is also&nbsp;shown in Figure&nbsp;10.7 (relative to&nbsp;an&nbsp;<br>
<b>Figure&nbsp;10.7 &nbsp;&nbsp;</b>The&nbsp;effect of&nbsp;associativity&nbsp;on&nbsp;performance&nbsp;and&nbsp;bandwidth&nbsp;requirement.<br>
<hr>
<A name=294></a><IMG src="index-294_1.png"><br>
<b>282</b>&nbsp;<br>
<b>Memory&nbsp;Hierarchy</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 10.8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARMS cache&nbsp;organization.&nbsp;<br>
uncached&nbsp;processor), and&nbsp;note&nbsp;how the&nbsp;highest&nbsp;performance corresponds&nbsp;to&nbsp;the&nbsp;lowest&nbsp;<br>
external&nbsp;bandwidth requirement. Since each&nbsp;external access&nbsp;costs a lot of energy com-<br>
pared&nbsp;with&nbsp;internal&nbsp;activity, the&nbsp;cache&nbsp;is&nbsp;simultaneously increasing&nbsp;performance&nbsp;and&nbsp;<br>
reducing system&nbsp;power requirements.&nbsp;<br>
The organization of the cache&nbsp;is&nbsp;therefore that&nbsp;shown in&nbsp;Figure 10.8.&nbsp;The bottom&nbsp;<br>
two bits of&nbsp;the&nbsp;virtual address select&nbsp;a byte&nbsp;within a 32-bit word, the next two&nbsp;bits&nbsp;<br>
select&nbsp;a word&nbsp;within&nbsp;a&nbsp;cache&nbsp;line&nbsp;and the next&nbsp;two&nbsp;bits select&nbsp;one of&nbsp;the four 64-entry&nbsp;<br>
CAM tag&nbsp;stores. The&nbsp;rest of&nbsp;the virtual address&nbsp;is presented&nbsp;to&nbsp;the&nbsp;selected&nbsp;tag&nbsp;store&nbsp;<br>
(the&nbsp;other tag stores&nbsp;are disabled to&nbsp;save&nbsp;power)&nbsp;to check&nbsp;whether&nbsp;the data is&nbsp;in&nbsp;the&nbsp;<br>
cache,&nbsp;and&nbsp;the&nbsp;result&nbsp;is either&nbsp;a&nbsp;miss, or&nbsp;a&nbsp;hit&nbsp;together&nbsp;with&nbsp;the&nbsp;address of&nbsp;the data&nbsp;in&nbsp;<br>
the cache data RAM.&nbsp;<br>
ARM600 cache&nbsp;<br>
To illustrate the sort&nbsp;of control logic required to&nbsp;manage a cache, the&nbsp;ARM600&nbsp;<br>
control FSM&nbsp;<br>
cache control&nbsp;finite state&nbsp;machine is described below. The&nbsp;ARM600 cache borrows&nbsp;<br>
its design&nbsp;from&nbsp;the&nbsp;ARM3&nbsp;described in Section 10.4&nbsp;on page&nbsp;279&nbsp;and&nbsp;it&nbsp;also&nbsp;<br>
includes a translation system&nbsp;similar to the scheme&nbsp;described in Section 10.5 on&nbsp;<br>
page&nbsp;283.&nbsp;<br>
The ARM600&nbsp;operates with&nbsp;two clocks. The&nbsp;fast clock&nbsp;defines&nbsp;the&nbsp;processor cycle&nbsp;<br>
time&nbsp;when&nbsp;it&nbsp;is&nbsp;operating&nbsp;from&nbsp;the&nbsp;cache&nbsp;or&nbsp;writing to the&nbsp;write buffer;&nbsp;the memory&nbsp;<br>
clock&nbsp;defines the speed when the&nbsp;processor&nbsp;is accessing external&nbsp;memory.&nbsp;The&nbsp;clock&nbsp;<br>
<hr>
<A name=295></a><b>Memory&nbsp;management&nbsp;</b><br>
<b>283</b>&nbsp;<br>
supplied&nbsp;to the core&nbsp;switches&nbsp;dynamically&nbsp;between&nbsp;these&nbsp;two clock&nbsp;sources,&nbsp;which&nbsp;<br>
may be asynchronous&nbsp;with&nbsp;respect to each&nbsp;other. There&nbsp;is&nbsp;no requirement for the&nbsp;<br>
memory&nbsp;clock to be a&nbsp;simple subdivision of&nbsp;the&nbsp;fast&nbsp;clock, though&nbsp;if it is&nbsp;the&nbsp;processor&nbsp;<br>
can&nbsp;be&nbsp;configured to&nbsp;avoid&nbsp;the&nbsp;synchronization overhead.&nbsp;<br>
Normally&nbsp;the&nbsp;processor&nbsp;runs&nbsp;from&nbsp;the&nbsp;cache using&nbsp;the&nbsp;fast clock.&nbsp;When&nbsp;a cache&nbsp;<br>
miss occurs (or a reference&nbsp;is&nbsp;made&nbsp;to&nbsp;uncacheable&nbsp;memory), the&nbsp;processor synchro-<br>
nizes to&nbsp;the&nbsp;memory&nbsp;clock&nbsp;and&nbsp;either&nbsp;performs&nbsp;a&nbsp;single&nbsp;external&nbsp;access or&nbsp;a&nbsp;cache&nbsp;<br>
line-fill. Because switching between&nbsp;the clocks incurs an&nbsp;overhead for the&nbsp;synchroni-<br>
zation&nbsp;(to&nbsp;reduce the&nbsp;risk&nbsp;of metastability to&nbsp;an&nbsp;acceptable&nbsp;level), the processor&nbsp;checks&nbsp;<br>
the&nbsp;next&nbsp;address before&nbsp;deciding&nbsp;whether&nbsp;or&nbsp;not&nbsp;to&nbsp;switch&nbsp;back&nbsp;to&nbsp;the&nbsp;fast&nbsp;clock.&nbsp;<br>
The finite state&nbsp;machine that&nbsp;controls this&nbsp;activity&nbsp;is shown in Figure&nbsp;10.9&nbsp;on&nbsp;<br>
page&nbsp;284.&nbsp;Following&nbsp;initialization,&nbsp;the&nbsp;processor enters the&nbsp;<i>Check tag&nbsp;</i>state running&nbsp;<br>
from&nbsp;the fast&nbsp;clock.&nbsp;Depending&nbsp;on&nbsp;whether&nbsp;or&nbsp;not&nbsp;the&nbsp;addressed&nbsp;data is found&nbsp;in&nbsp;the&nbsp;<br>
cache,&nbsp;the&nbsp;processor can&nbsp;proceed&nbsp;in&nbsp;one&nbsp;of&nbsp;the&nbsp;following ways:&nbsp;<br>
•&nbsp;&nbsp;So&nbsp;long as the address&nbsp;is&nbsp;non-sequential,&nbsp;does not&nbsp;fault in the MMU and is either&nbsp;<br>
a read found in&nbsp;the&nbsp;cache&nbsp;or&nbsp;a buffered write,&nbsp;the&nbsp;state machine&nbsp;remains in&nbsp;the&nbsp;<br>
<i>Check tag&nbsp;</i>state and a&nbsp;data&nbsp;value&nbsp;is&nbsp;returned&nbsp;or&nbsp;written every clock cycle.&nbsp;<br>
•&nbsp;&nbsp;When the&nbsp;next&nbsp;address is&nbsp;a&nbsp;sequential&nbsp;read in&nbsp;the same&nbsp;cache line or&nbsp;a&nbsp;sequential&nbsp;<br>
buffered&nbsp;write, the state&nbsp;machine moves to&nbsp;the&nbsp;<i>Sequential&nbsp;fast&nbsp;</i>state&nbsp;where the&nbsp;<br>
data may&nbsp;be&nbsp;accessed without checking&nbsp;the&nbsp;tag&nbsp;and without activating the&nbsp;MMU.&nbsp;<br>
This saves power, and exploits the&nbsp;<i>seq&nbsp;</i>signal from&nbsp;the processor core.&nbsp;Again a&nbsp;<br>
data&nbsp;value is read&nbsp;or&nbsp;written every&nbsp;clock&nbsp;cycle.&nbsp;<br>
•&nbsp;&nbsp;If the address is not in&nbsp;the cache or is an&nbsp;unbuffered write an external access is&nbsp;<br>
required. This&nbsp;begins&nbsp;in&nbsp;the&nbsp;<i>Start external&nbsp;</i>state.&nbsp;Reads from&nbsp;uncacheable&nbsp;memory&nbsp;<br>
and unbuffered writes are completed&nbsp;as&nbsp;single&nbsp;memory&nbsp;transactions&nbsp;in&nbsp;the&nbsp;<i>Exter&nbsp;</i><br>
<i>nal&nbsp;</i>state.&nbsp;Cacheable&nbsp;reads perform&nbsp;a&nbsp;quad-word&nbsp;line&nbsp;fetch,&nbsp;after&nbsp;fetching&nbsp;the nec&nbsp;<br>
essary translation&nbsp;information&nbsp;if&nbsp;this&nbsp;was not&nbsp;already in&nbsp;the MMU.&nbsp;<br>
•&nbsp;&nbsp;Cycles&nbsp;where the processor does not&nbsp;use&nbsp;memory&nbsp;are&nbsp;executed&nbsp;in&nbsp;the&nbsp;<i>Idle&nbsp;</i>state.&nbsp;<br>
At&nbsp;several points in the translation process it&nbsp;may become clear that the access&nbsp;<br>
cannot be&nbsp;completed and&nbsp;<i>the Abort&nbsp;</i>state is entered. Uncacheable&nbsp;reads and unbuffered&nbsp;<br>
writes&nbsp;may&nbsp;also&nbsp;be&nbsp;aborted by&nbsp;external&nbsp;hardware.&nbsp;<br>
10.5 &nbsp; Memory&nbsp;management&nbsp;<br>
Modern&nbsp;computer systems typically&nbsp;have&nbsp;many&nbsp;programs&nbsp;active&nbsp;at&nbsp;the same&nbsp;time. A&nbsp;<br>
single processor can, of&nbsp;course, only&nbsp;execute instructions&nbsp;from&nbsp;one program&nbsp;at any&nbsp;<br>
instant, but by&nbsp;switching&nbsp;rapidly between the&nbsp;active&nbsp;programs&nbsp;they&nbsp;all appear&nbsp;to&nbsp;be&nbsp;<br>
executing&nbsp;at&nbsp;once,&nbsp;at&nbsp;least&nbsp;when&nbsp;viewed&nbsp;on a&nbsp;human&nbsp;timescale.&nbsp;<br>
<hr>
<A name=296></a><IMG src="index-296_1.png"><br>
<b>284</b>&nbsp;<br>
<b>Memory&nbsp;Hierarchy</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
1 MMU hit&nbsp;<br>
section OK<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;10.9 &nbsp;&nbsp;</b>ARM600&nbsp;cache control&nbsp;state machine.&nbsp;<br>
The rapid switching is managed&nbsp;by&nbsp;the&nbsp;operating&nbsp;system, so the application pro-<br>
grammer can&nbsp;write&nbsp;his or&nbsp;her program&nbsp;as&nbsp;though&nbsp;it&nbsp;owns&nbsp;the&nbsp;whole machine.&nbsp;The&nbsp;<br>
mechanism&nbsp;used&nbsp;to&nbsp;support this&nbsp;illusion is&nbsp;described by&nbsp;the term&nbsp;<b>memory manage-</b><br>
<b>ment&nbsp;unit&nbsp;</b>(MMU).&nbsp;There are two&nbsp;principal approaches&nbsp;to&nbsp;memory&nbsp;management,&nbsp;<br>
called&nbsp;<b>segmentation and&nbsp;paging.</b>&nbsp;<br>
Segments&nbsp;<br>
The&nbsp;simplest&nbsp;form&nbsp;of&nbsp;memory&nbsp;management&nbsp;allows an application to view&nbsp;its&nbsp;<br>
memory as&nbsp;a&nbsp;set of&nbsp;segments,&nbsp;where each&nbsp;segment contains a particular&nbsp;sort of&nbsp;<br>
information. For instance,&nbsp;a&nbsp;program&nbsp;may&nbsp;have a&nbsp;code segment containing all its&nbsp;<br>
<hr>
<A name=297></a><IMG src="index-297_1.png"><br>
<b>Memory&nbsp;management</b>&nbsp;<br>
<b>285</b>&nbsp;<br>
instructions, a&nbsp;data segment and a stack&nbsp;segment.&nbsp;Every&nbsp;memory access&nbsp;provides a&nbsp;<br>
segment selector and a logical address to&nbsp;the MMU. Each segment has a base&nbsp;<br>
address&nbsp;and a limit&nbsp;associated with&nbsp;it.&nbsp;The logical&nbsp;address is an offset&nbsp;from&nbsp;the&nbsp;seg-<br>
ment base address,&nbsp;and&nbsp;must&nbsp;be no greater&nbsp;than the limit or&nbsp;an access violation will&nbsp;<br>
occur,&nbsp;usually&nbsp;causing an&nbsp;exception.&nbsp;Segments may also&nbsp;have&nbsp;other access controls,&nbsp;<br>
for instance the code segment&nbsp;may&nbsp;be read-only&nbsp;and an&nbsp;attempt to write to it&nbsp;will&nbsp;<br>
also&nbsp;cause an exception.&nbsp;<br>
The access mechanism&nbsp;for a segmented MMU&nbsp;is illustrated&nbsp;in Figure&nbsp;10.10.&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 10.10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Segmented&nbsp;memory&nbsp;management scheme.&nbsp;<br>
Segmentation&nbsp;allows a program&nbsp;to have&nbsp;its&nbsp;own private view of&nbsp;memory&nbsp;and to&nbsp;<br>
coexist transparently with other programs in the same&nbsp;memory space. It runs into diffi-<br>
culty, however,&nbsp;when the coexisting&nbsp;programs&nbsp;vary and&nbsp;the&nbsp;available&nbsp;memory is lim-<br>
ited. Since&nbsp;the segments&nbsp;are&nbsp;of&nbsp;variable size,&nbsp;the free memory becomes fragmented&nbsp;<br>
over time&nbsp;and a new program&nbsp;may&nbsp;be&nbsp;unable&nbsp;to&nbsp;start,&nbsp;not because there&nbsp;is&nbsp;insufficient&nbsp;<br>
free memory, but because the&nbsp;free&nbsp;memory&nbsp;is&nbsp;all in small&nbsp;pieces&nbsp;none&nbsp;of&nbsp;which is&nbsp;big&nbsp;<br>
enough&nbsp;to&nbsp;hold&nbsp;a segment of the size&nbsp;required&nbsp;by&nbsp;the&nbsp;new&nbsp;program.&nbsp;<br>
The&nbsp;crisis&nbsp;can&nbsp;be&nbsp;alleviated&nbsp;by&nbsp;the operating system&nbsp;moving&nbsp;segments around&nbsp;in&nbsp;<br>
memory to&nbsp;coalesce&nbsp;the&nbsp;free&nbsp;memory into&nbsp;one&nbsp;large&nbsp;piece,&nbsp;but&nbsp;this&nbsp;is&nbsp;inefficient,&nbsp;and&nbsp;<br>
most&nbsp;processors now&nbsp;incorporate a&nbsp;memory&nbsp;mapping&nbsp;scheme&nbsp;based on&nbsp;fixed-size&nbsp;<br>
chunks&nbsp;of&nbsp;memory called&nbsp;<b>pages.&nbsp;</b>Some&nbsp;architectures&nbsp;include&nbsp;segmentation and&nbsp;pag-<br>
ing, but many, including the ARM,&nbsp;just&nbsp;support paging without segmentation.&nbsp;<br>
Paging&nbsp;<br>
In&nbsp;a paging&nbsp;memory&nbsp;management&nbsp;scheme&nbsp;both&nbsp;the&nbsp;logical&nbsp;and&nbsp;the physical&nbsp;ad-<br>
dress spaces are divided&nbsp;into&nbsp;fixed-size&nbsp;components called&nbsp;pages. A&nbsp;page&nbsp;is&nbsp;usually&nbsp;<br>
a few&nbsp;kilobytes in&nbsp;size,&nbsp;but&nbsp;different&nbsp;architectures&nbsp;use&nbsp;different&nbsp;page sizes.&nbsp;The&nbsp;<br>
<hr>
<A name=298></a><IMG src="index-298_1.png"><br>
<b>286</b>&nbsp;<br>
<b>Memory&nbsp;Hierarchy</b>&nbsp;<br>
relationship&nbsp;between&nbsp;the logical and physical pages is&nbsp;stored in&nbsp;<b>page tables,&nbsp;</b>which&nbsp;<br>
are&nbsp;held&nbsp;in&nbsp;main&nbsp;memory.&nbsp;<br>
A&nbsp;simple&nbsp;sum&nbsp;shows that&nbsp;storing the translation in a single table requires a very&nbsp;<br>
large&nbsp;table:&nbsp;if a&nbsp;page is&nbsp;4 Kbytes, 20 bits&nbsp;of a&nbsp;32-bit address&nbsp;must be translated, which&nbsp;<br>
requires 220&nbsp;x&nbsp;20&nbsp;bits&nbsp;of&nbsp;data&nbsp;in&nbsp;the table,&nbsp;or&nbsp;a&nbsp;table of&nbsp;at&nbsp;least&nbsp;2.5 Mbytes.&nbsp;This&nbsp;is&nbsp;an&nbsp;<br>
unreasonable&nbsp;overhead&nbsp;to impose on&nbsp;a small system.&nbsp;<br>
Instead,&nbsp;most paging&nbsp;systems&nbsp;use two or&nbsp;more levels&nbsp;of page&nbsp;table. For example, the&nbsp;<br>
top ten bits of&nbsp;the address can be used to identify&nbsp;the appropriate&nbsp;second-level page&nbsp;<br>
table&nbsp;in&nbsp;the&nbsp;first-level&nbsp;page&nbsp;table&nbsp;directory,&nbsp;and&nbsp;the second&nbsp;ten&nbsp;bits&nbsp;of&nbsp;the&nbsp;address&nbsp;then&nbsp;<br>
identify the&nbsp;page&nbsp;table&nbsp;entry&nbsp;which contains&nbsp;the physical&nbsp;page&nbsp;number. This translation&nbsp;<br>
scheme&nbsp;is illustrated&nbsp;in&nbsp;Figure&nbsp;10.11.&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;10.11 &nbsp;&nbsp;&nbsp;</b>Paging memory management scheme.&nbsp;<br>
Note that with&nbsp;the particular&nbsp;numbers suggested here, if&nbsp;32 bits are allocated to&nbsp;<br>
each directory and page table entry, the directory and each page table&nbsp;happen to&nbsp;<br>
occupy&nbsp;exactly&nbsp;4 Kbytes&nbsp;each,&nbsp;or&nbsp;exactly&nbsp;one&nbsp;memory&nbsp;page.&nbsp;The&nbsp;minimum&nbsp;overhead&nbsp;<br>
for a small system&nbsp;is 4 Kbytes&nbsp;for the&nbsp;page&nbsp;directory&nbsp;plus&nbsp;4&nbsp;Kbytes for one&nbsp;page&nbsp;table;&nbsp;<br>
this is&nbsp;sufficient to&nbsp;manage&nbsp;up to 4 Mbytes of physical&nbsp;memory. A fully&nbsp;populated&nbsp;<br>
32&nbsp;gigabyte&nbsp;memory&nbsp;would&nbsp;require&nbsp;4&nbsp;Mbytes&nbsp;of&nbsp;page&nbsp;tables,&nbsp;but&nbsp;this&nbsp;overhead&nbsp;is&nbsp;prob-<br>
ably acceptable&nbsp;with&nbsp;this&nbsp;much&nbsp;memory&nbsp;to&nbsp;work&nbsp;in.&nbsp;<br>
The&nbsp;ARM MMU, described in&nbsp;Section&nbsp;11.6 on&nbsp;page 302, uses&nbsp;a&nbsp;slightly&nbsp;different&nbsp;<br>
allocation&nbsp;of bits from&nbsp;the&nbsp;one&nbsp;described here&nbsp;(and&nbsp;also&nbsp;supports the single-level&nbsp;trans-<br>
lation&nbsp;of&nbsp;larger blocks&nbsp;of&nbsp;memory), but the principle is the&nbsp;same.&nbsp;<br>
Virtual&nbsp;memory&nbsp;<br>
One possibility with either&nbsp;memory&nbsp;management scheme is to allow a segment or&nbsp;<br>
page to&nbsp;be&nbsp;marked as absent and an&nbsp;exception&nbsp;to&nbsp;be generated&nbsp;whenever&nbsp;it&nbsp;is&nbsp;<br>
accessed. Then&nbsp;an operating system&nbsp;which has run out of&nbsp;memory to allocate can&nbsp;<br>
transparently&nbsp;move a page&nbsp;or a segment out of&nbsp;main memory&nbsp;into backup&nbsp;store,&nbsp;<br>
which for this purpose is usually&nbsp;a hard disk, and mark it as absent. The physical&nbsp;<br>
memory can then be allocated to a different use. If the program&nbsp;attempts to access&nbsp;<br>
<hr>
<A name=299></a><b>Memory&nbsp;management</b>&nbsp;<br>
<b>287</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
an absent page or segment the exception is&nbsp;raised&nbsp;and the operating system&nbsp;can&nbsp;<br>
bring&nbsp;the&nbsp;page&nbsp;or segment&nbsp;back&nbsp;into&nbsp;main&nbsp;memory, then&nbsp;allow&nbsp;the&nbsp;program&nbsp;to&nbsp;<br>
retry the access.&nbsp;<br>
When&nbsp;implemented with&nbsp;the&nbsp;paged memory&nbsp;management&nbsp;scheme, this&nbsp;process is&nbsp;<br>
known as&nbsp;<b>demand-paged virtual memory.&nbsp;</b>A&nbsp;program&nbsp;can&nbsp;be&nbsp;written&nbsp;to&nbsp;occupy&nbsp;a&nbsp;<br>
virtual&nbsp;memory space&nbsp;that&nbsp;is&nbsp;larger&nbsp;than&nbsp;the available&nbsp;physical&nbsp;memory space&nbsp;in&nbsp;the&nbsp;<br>
computer where&nbsp;it&nbsp;is&nbsp;run,&nbsp;since&nbsp;the&nbsp;operating system&nbsp;can wheel&nbsp;bits&nbsp;of&nbsp;program&nbsp;and&nbsp;<br>
data&nbsp;in&nbsp;as they&nbsp;are needed. Typical programs&nbsp;work some&nbsp;parts of their code&nbsp;very&nbsp;hard&nbsp;<br>
and&nbsp;rarely touch&nbsp;others;&nbsp;leaving the infrequently used&nbsp;routines out on disk&nbsp;will&nbsp;not&nbsp;<br>
noticeably affect performance.&nbsp;However,&nbsp;over-exploiting this&nbsp;facility causes&nbsp;the oper-<br>
ating system&nbsp;to switch&nbsp;pages in&nbsp;and out&nbsp;of memory&nbsp;at a high&nbsp;rate. This is&nbsp;described&nbsp;as&nbsp;<br>
<b>thrashing,&nbsp;</b>and&nbsp;<i>will&nbsp;</i>adversely&nbsp;affect&nbsp;performance.&nbsp;<br>
Restartable&nbsp;<br>
An important requirement in a virtual memory&nbsp;system&nbsp;is&nbsp;that any&nbsp;instruction&nbsp;that&nbsp;<br>
instructions&nbsp;<br>
can cause a&nbsp;memory access fault&nbsp;must leave the processor in a&nbsp;state&nbsp;that&nbsp;allows the&nbsp;<br>
operating&nbsp;system&nbsp;to&nbsp;page-in&nbsp;the&nbsp;requested&nbsp;memory&nbsp;and resume&nbsp;the&nbsp;original&nbsp;program&nbsp;<br>
as though the&nbsp;fault had not happened. This&nbsp;is often achieved by&nbsp;making&nbsp;all instruc-<br>
tions that access&nbsp;memory&nbsp;<b>restartable.&nbsp;</b>The processor&nbsp;must retain&nbsp;enough state to&nbsp;<br>
allow&nbsp;the operating&nbsp;system&nbsp;to&nbsp;recover enough&nbsp;of&nbsp;the register values so&nbsp;that, when&nbsp;the&nbsp;<br>
page is in&nbsp;main&nbsp;memory, the&nbsp;faulting instruction is&nbsp;retried&nbsp;with identical&nbsp;results to&nbsp;<br>
those that&nbsp;would&nbsp;have&nbsp;been&nbsp;obtained had&nbsp;the&nbsp;page been resident at&nbsp;the first attempt.&nbsp;<br>
This requirement is&nbsp;usually the&nbsp;most&nbsp;difficult one to&nbsp;satisfy&nbsp;in the design&nbsp;of a&nbsp;pro-<br>
cessor while retaining high-performance and&nbsp;minimum&nbsp;hardware redundancy.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Translation&nbsp;<br>
The paging&nbsp;scheme&nbsp;described&nbsp;above gives&nbsp;the programmer complete&nbsp;freedom&nbsp;and&nbsp;<br>
look-aside&nbsp;<br>
transparency&nbsp;in the use of&nbsp;memory,&nbsp;but&nbsp;it would&nbsp;seem&nbsp;that&nbsp;this&nbsp;has&nbsp;been achieved&nbsp;at&nbsp;<br>
buffers&nbsp;<br>
considerable&nbsp;cost&nbsp;in&nbsp;performance since&nbsp;each memory access&nbsp;appears to have&nbsp;<br>
incurred an&nbsp;overhead&nbsp;of&nbsp;two&nbsp;additional&nbsp;memory accesses,&nbsp;one to the page&nbsp;directory&nbsp;<br>
and one to the&nbsp;page table,&nbsp;before the data&nbsp;itself&nbsp;is&nbsp;accessed.&nbsp;<br>
This&nbsp;overhead&nbsp;is usually&nbsp;avoided&nbsp;by&nbsp;implementing&nbsp;a&nbsp;translation&nbsp;look-aside&nbsp;buffer&nbsp;<br>
(TLB),&nbsp;which&nbsp;is&nbsp;a&nbsp;cache&nbsp;of&nbsp;recently used&nbsp;page&nbsp;translations.&nbsp;As&nbsp;with&nbsp;instruction&nbsp;and&nbsp;<br>
data&nbsp;caches&nbsp;(described in&nbsp;Section&nbsp;10.3&nbsp;on&nbsp;page&nbsp;272),&nbsp;there are organizational&nbsp;options&nbsp;<br>
relating&nbsp;to the&nbsp;degree&nbsp;of associativity&nbsp;and the&nbsp;replacement strategy. The line&nbsp;and&nbsp;block&nbsp;<br>
sizes usually&nbsp;equate to&nbsp;a single&nbsp;page table entry,&nbsp;and&nbsp;the size&nbsp;of a typical TLB is much&nbsp;<br>
smaller than a&nbsp;data&nbsp;cache&nbsp;at&nbsp;around&nbsp;64&nbsp;entries. The locality properties&nbsp;of&nbsp;typical&nbsp;pro-<br>
grams&nbsp;enable&nbsp;a&nbsp;TLB of&nbsp;this size to achieve&nbsp;a&nbsp;miss&nbsp;rate of&nbsp;a per cent or&nbsp;so. The&nbsp;misses&nbsp;<br>
incur the table-walking&nbsp;overhead&nbsp;of two&nbsp;additional memory&nbsp;accesses.&nbsp;<br>
The&nbsp;operation&nbsp;of a TLB&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;Figure&nbsp;10.12&nbsp;on&nbsp;page&nbsp;288.&nbsp;<br>
When a system&nbsp;incorporates both&nbsp;an MMU and a cache, the&nbsp;cache&nbsp;may operate&nbsp;<br>
Virtual and&nbsp;<br>
either&nbsp;with&nbsp;virtual (pre-MMU)&nbsp;or&nbsp;physical&nbsp;(post-MMU)&nbsp;addresses.&nbsp;<br>
physical caches&nbsp;<br>
A&nbsp;virtual&nbsp;cache&nbsp;has the&nbsp;advantage&nbsp;that&nbsp;the cache&nbsp;access may&nbsp;start immediately the&nbsp;<br>
processor produces an&nbsp;address, and,&nbsp;indeed,&nbsp;there&nbsp;is no need&nbsp;to activate the MMU if&nbsp;<br>
<hr>
<A name=300></a><IMG src="index-300_1.png"><br>
<b>288</b>&nbsp;<br>
<b>Memory&nbsp;Hierarchy</b>&nbsp;<br>
&nbsp;<br>
<b>31&nbsp;1211&nbsp;</b><br>
<b>0</b>&nbsp;<br>
<b>Figure 10.12&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The operation of a&nbsp;translation look-aside buffer.&nbsp;<br>
the data&nbsp;is found in the&nbsp;cache.&nbsp;The drawback is&nbsp;that the&nbsp;cache may&nbsp;contain&nbsp;<b>synonyms,&nbsp;</b><br>
which are&nbsp;duplicate copies of the same&nbsp;main memory data item&nbsp;in the cache. Syno-<br>
nyms arise because address translation&nbsp;mechanisms&nbsp;generally&nbsp;allow overlapping trans-<br>
lations. If the&nbsp;processor modifies the&nbsp;data item&nbsp;through&nbsp;one address&nbsp;route it is&nbsp;not&nbsp;<br>
possible for the cache&nbsp;to update the second copy, leading to inconsistency&nbsp;in the cache.&nbsp;<br>
A&nbsp;physical&nbsp;cache&nbsp;avoids the synonym&nbsp;problem&nbsp;since&nbsp;physical memory&nbsp;addresses&nbsp;<br>
are associated&nbsp;with unique&nbsp;data items. However the MMU&nbsp;must&nbsp;now be activated on&nbsp;<br>
every&nbsp;cache&nbsp;access,&nbsp;and with&nbsp;some&nbsp;MMU and cache organizations&nbsp;the address&nbsp;transla-<br>
tion must&nbsp;be&nbsp;completed by&nbsp;the MMU&nbsp;before the&nbsp;cache access can&nbsp;begin,&nbsp;leading&nbsp;to&nbsp;<br>
much longer cache latencies.&nbsp;<br>
A physical&nbsp;cache arrangement that&nbsp;neatly&nbsp;avoids the&nbsp;sequential access cost exploits&nbsp;<br>
the fact that&nbsp;a paging MMU&nbsp;only&nbsp;affects&nbsp;the&nbsp;high-order address bits,&nbsp;while&nbsp;the cache&nbsp;is&nbsp;<br>
accessed by the low-order address bits. Provided these sets do&nbsp;not&nbsp;overlap, the cache&nbsp;<br>
and MMU accesses&nbsp;can&nbsp;proceed in&nbsp;parallel.&nbsp;The&nbsp;physical&nbsp;address&nbsp;from&nbsp;the MMU&nbsp;<br>
arrives at&nbsp;the right time&nbsp;to be&nbsp;compared with&nbsp;the physical address&nbsp;tags from&nbsp;the cache,&nbsp;<br>
hiding&nbsp;the&nbsp;address translation&nbsp;time&nbsp;behind&nbsp;the cache&nbsp;tag access. This&nbsp;optimization is&nbsp;<br>
not applicable to fully associative caches, and only works if&nbsp;the page size used by the&nbsp;<br>
MMU is&nbsp;larger than each&nbsp;directly&nbsp;addressed portion of&nbsp;the&nbsp;cache.&nbsp;A 4 Kbyte&nbsp;page,&nbsp;for&nbsp;<br>
example, limits a direct-mapped cache to&nbsp;a&nbsp;maximum&nbsp;size of 4 Kbytes, a 2-way&nbsp;<br>
set-associative cache to&nbsp;a maximum size of 8 Kbytes, and so&nbsp;on.&nbsp;<br>
In practice both virtual&nbsp;and physical&nbsp;caches&nbsp;are in commercial use, the former rely-<br>
ing on&nbsp;software&nbsp;conventions&nbsp;to&nbsp;contain the&nbsp;synonym&nbsp;problem&nbsp;and the latter either&nbsp;<br>
exploiting&nbsp;the above optimization&nbsp;or accepting the performance cost.&nbsp;<br>
<hr>
<A name=301></a><b>Examples and exercises</b>&nbsp;<br>
<b>289</b>&nbsp;<br>
10.6 &nbsp; Examples&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example&nbsp;10.1&nbsp;</b><br>
<b>How&nbsp;big&nbsp;can a 4-way&nbsp;physical cache&nbsp;be&nbsp;in a&nbsp;system&nbsp;with</b>&nbsp;<br>
<b>1 Kbyte pages?</b>&nbsp;<br>
Assume&nbsp;we&nbsp;want to perform&nbsp;the TLB and&nbsp;cache accesses in&nbsp;parallel&nbsp;as described in&nbsp;<br>
'Virtual&nbsp;and physical&nbsp;caches'&nbsp;on page 287.&nbsp;<br>
Each&nbsp;section&nbsp;of&nbsp;the&nbsp;cache&nbsp;can&nbsp;be&nbsp;at&nbsp;most 1 Kbyte,&nbsp;so&nbsp;the maximum&nbsp;total&nbsp;cache size&nbsp;<br>
is 4 Kbytes.&nbsp;<br>
<b>Exercise 10.1.1&nbsp;</b><br>
How&nbsp;much&nbsp;memory does the tag store require in&nbsp;this&nbsp;cache if the&nbsp;line size is&nbsp;<br>
16 bytes?&nbsp;<br>
<b>Exercise&nbsp;10.1.2&nbsp;</b><br>
Estimate the&nbsp;proportions of&nbsp;the areas of&nbsp;the&nbsp;TLB and&nbsp;the&nbsp;data&nbsp;cache&nbsp;tag&nbsp;and data&nbsp;<br>
memories&nbsp;in&nbsp;the&nbsp;above&nbsp;example.&nbsp;<br>
<b>Example&nbsp;10.2&nbsp;</b><br>
<b>How&nbsp;big&nbsp;would a&nbsp;TLB&nbsp;have to&nbsp;be&nbsp;to&nbsp;contain&nbsp;the&nbsp;translations&nbsp;for all&nbsp;of</b>&nbsp;<br>
<b>the physical pages?</b>&nbsp;<br>
With 4&nbsp;Kbyte pages, a 1&nbsp;Mbyte&nbsp;memory&nbsp;contains&nbsp;256 pages so&nbsp;the TLB needs 256&nbsp;<br>
entries. The TLB need no longer be an automatic cache.&nbsp;Since a TLB miss&nbsp;means&nbsp;<br>
that the page is absent from&nbsp;physical&nbsp;memory&nbsp;a disk transfer is&nbsp;required, and&nbsp;the&nbsp;<br>
overhead&nbsp;of&nbsp;maintaining&nbsp;the&nbsp;TLB&nbsp;by&nbsp;software&nbsp;is negligible&nbsp;compared&nbsp;with the&nbsp;cost&nbsp;<br>
of the disk&nbsp;transfer.&nbsp;<br>
A TLB which&nbsp;covers&nbsp;all&nbsp;physical&nbsp;memory&nbsp;is&nbsp;a form&nbsp;of&nbsp;<b>inverted page table,&nbsp;</b>and&nbsp;<br>
just&nbsp;such&nbsp;a&nbsp;translation scheme&nbsp;was&nbsp;used&nbsp;on&nbsp;the early ARM memory controller&nbsp;chips&nbsp;<br>
used in&nbsp;the Acorn Archimedes machines.&nbsp;Referring to&nbsp;Figure&nbsp;10.12 on page&nbsp;288, the&nbsp;<br>
translation hardware can&nbsp;be a&nbsp;CAM; the&nbsp;physical&nbsp;page&nbsp;number store is a simple hard-<br>
wired encoder,&nbsp;and the CAM&nbsp;has one entry for each&nbsp;physical&nbsp;page.&nbsp;<br>
The Acorn&nbsp;memory controller chips had&nbsp;CAMs&nbsp;with&nbsp;128&nbsp;entries and a page&nbsp;size&nbsp;<br>
that&nbsp;varied&nbsp;according&nbsp;to&nbsp;the&nbsp;amount&nbsp;of&nbsp;physical&nbsp;memory&nbsp;in&nbsp;the&nbsp;system. A 1&nbsp;Mbyte&nbsp;<br>
system&nbsp;had&nbsp;8&nbsp;Kbyte pages,&nbsp;a&nbsp;4&nbsp;Mbyte&nbsp;system&nbsp;had&nbsp;32&nbsp;Kbyte pages. To&nbsp;extend beyond&nbsp;<br>
4 Mbytes,&nbsp;the&nbsp;page&nbsp;size&nbsp;stayed at&nbsp;32&nbsp;Kbytes&nbsp;and a&nbsp;second&nbsp;memory controller&nbsp;was&nbsp;<br>
added.&nbsp;The&nbsp;CAMs were&nbsp;maintained&nbsp;by&nbsp;software,&nbsp;so&nbsp;no&nbsp;complex&nbsp;table-walking&nbsp;hard-<br>
ware was required. The full&nbsp;translation tables&nbsp;were entirely defined by&nbsp;software.&nbsp;<br>
<b>Exercise&nbsp;10.2.1&nbsp;</b><br>
Estimate the die area of a 128-entry inverted page&nbsp;table&nbsp;compared with a 64 entry&nbsp;<br>
TLB,&nbsp;assuming&nbsp;that&nbsp;one bit&nbsp;of&nbsp;CAM&nbsp;requires twice the&nbsp;area&nbsp;of&nbsp;one&nbsp;bit&nbsp;of&nbsp;RAM.&nbsp;<br>
<hr>
<A name=302></a><IMG src="index-302_1.png"><br>
Architectural Support&nbsp;<br>
for Operating Systems&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Summary of chapter contents&nbsp;<br>
The role&nbsp;of an operating&nbsp;system is&nbsp;to&nbsp;provide an environment&nbsp;where several pro-<br>
grams may&nbsp;run concurrently&nbsp;with a&nbsp;minimal risk of&nbsp;unwanted&nbsp;interference between&nbsp;<br>
them&nbsp;but&nbsp;with&nbsp;support for safe&nbsp;data&nbsp;sharing. The operating&nbsp;system should&nbsp;also&nbsp;<br>
provide a clean interface to&nbsp;the hardware facilities of&nbsp;the machine.&nbsp;<br>
Interference between processes is minimized by&nbsp;memory&nbsp;management and pro-<br>
tection schemes&nbsp;which enable&nbsp;each process&nbsp;to access only&nbsp;its own area of&nbsp;memory.&nbsp;<br>
The process is&nbsp;given&nbsp;its own&nbsp;view&nbsp;of the&nbsp;system memory,&nbsp;and&nbsp;when a&nbsp;process switch&nbsp;<br>
takes place the memory&nbsp;view&nbsp;is dynamically&nbsp;transformed to that of the new&nbsp;process,&nbsp;<br>
with all the memory&nbsp;used by&nbsp;the previous&nbsp;process being removed&nbsp;from&nbsp;sight.&nbsp;This&nbsp;<br>
requires sophisticated hardware support if it is to operate efficiently.&nbsp;<br>
Data sharing implies&nbsp;a loophole&nbsp;in the protection&nbsp;scheme&nbsp;which must be&nbsp;control&nbsp;ed&nbsp;<br>
with great care. Haphazard access to shared&nbsp;structures can&nbsp;lead&nbsp;to the most obscure&nbsp;<br>
forms of program&nbsp;misbehaviour, so a disciplined approach must be applied.&nbsp;<br>
Access to&nbsp;hardware&nbsp;facilities&nbsp;often involves&nbsp;a lot&nbsp;of low-level&nbsp;bit manipulation,&nbsp;<br>
and rather&nbsp;than&nbsp;require each&nbsp;process&nbsp;to&nbsp;do&nbsp;this independently, the details are&nbsp;usu-<br>
ally&nbsp;handled&nbsp;centrally&nbsp;by&nbsp;the operating&nbsp;system. Processes&nbsp;can&nbsp;then&nbsp;access input/&nbsp;<br>
output functions at&nbsp;a&nbsp;higher&nbsp;level through system&nbsp;calls.&nbsp;<br>
The&nbsp;ARM architecture&nbsp;incorporates&nbsp;features specifically&nbsp;to support all&nbsp;these&nbsp;<br>
aspects&nbsp;of&nbsp;the operating system.&nbsp;<br>
<b>290</b>&nbsp;<br>
<hr>
<A name=303></a><b>An&nbsp;introduction&nbsp;to&nbsp;operating&nbsp;systems</b>&nbsp;<br>
<b>291</b>&nbsp;<br>
11.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;An introduction to operating systems&nbsp;<br>
The role of an&nbsp;operating system&nbsp;is to present a uniform&nbsp;and clean interface between the&nbsp;<br>
underlying&nbsp;hardware resources of the&nbsp;machine and the application&nbsp;programs that run on&nbsp;<br>
it. The&nbsp;most&nbsp;sophisticated operating systems are those that provide facilities for&nbsp;multiple&nbsp;<br>
general-purpose programs run&nbsp;by&nbsp;several different users at the same&nbsp;time.&nbsp;<br>
Multi-user&nbsp;<br>
It is very inconvenient if a multi-user&nbsp;system&nbsp;requires&nbsp;each program&nbsp;to&nbsp;make allow-<br>
systems&nbsp;<br>
ances&nbsp;for&nbsp;the&nbsp;presence&nbsp;of&nbsp;other programs&nbsp;in the&nbsp;same&nbsp;machine,&nbsp;since&nbsp;the&nbsp;number and&nbsp;<br>
type&nbsp;of&nbsp;concurrent&nbsp;programs&nbsp;is&nbsp;unknown&nbsp;and&nbsp;will&nbsp;vary&nbsp;from&nbsp;one&nbsp;run&nbsp;to&nbsp;the next.&nbsp;<br>
Therefore&nbsp;a multi-user&nbsp;operating system&nbsp;presents each&nbsp;program&nbsp;with a&nbsp;complete&nbsp;<b>vir-</b><br>
<b>tual&nbsp;machine&nbsp;</b>in&nbsp;which&nbsp;to operate.&nbsp;Each&nbsp;program&nbsp;can be&nbsp;written&nbsp;as&nbsp;though it&nbsp;is the&nbsp;<br>
only&nbsp;program&nbsp;running&nbsp;at&nbsp;the time; the only&nbsp;noticeable&nbsp;effect&nbsp;of the presence&nbsp;of other&nbsp;<br>
programs&nbsp;is that the program typically&nbsp;takes longer to&nbsp;run.&nbsp;<br>
Although several programs&nbsp;may be present&nbsp;in&nbsp;the machine&nbsp;at one&nbsp;time, the proces-<br>
sor has&nbsp;only&nbsp;one set&nbsp;of registers (we are&nbsp;not&nbsp;concerned with&nbsp;multi-processor systems&nbsp;<br>
here), so&nbsp;only&nbsp;one&nbsp;program&nbsp;is executing&nbsp;at&nbsp;any&nbsp;particular time. The&nbsp;apparent&nbsp;concur-<br>
rency is achieved by&nbsp;<b>time-slicing,&nbsp;</b>which means&nbsp;that&nbsp;each program&nbsp;takes&nbsp;a&nbsp;turn in&nbsp;the&nbsp;<br>
processor.&nbsp;Since the&nbsp;processor&nbsp;operates at&nbsp;very&nbsp;high&nbsp;speeds&nbsp;by&nbsp;human standards,&nbsp;the&nbsp;<br>
effect is that over a period of, say,&nbsp;a second each program&nbsp;will have&nbsp;had several goes in&nbsp;<br>
the&nbsp;processor so&nbsp;all&nbsp;programs make some&nbsp;progress.&nbsp;The&nbsp;operating system&nbsp;is responsi-<br>
ble for&nbsp;<b>scheduling&nbsp;</b>(deciding&nbsp;which&nbsp;program&nbsp;runs when),&nbsp;and&nbsp;it may&nbsp;give&nbsp;each&nbsp;pro-<br>
gram&nbsp;an&nbsp;equal share of&nbsp;the&nbsp;CPU&nbsp;time&nbsp;or&nbsp;it&nbsp;may use&nbsp;<b>priority&nbsp;</b>information to&nbsp;favour&nbsp;<br>
some&nbsp;programs over others.&nbsp;<br>
A program&nbsp;is switched&nbsp;out&nbsp;of&nbsp;the processor&nbsp;either because the operating&nbsp;system&nbsp;is&nbsp;<br>
invoked by&nbsp;a timer interrupt&nbsp;and decides&nbsp;the&nbsp;program&nbsp;has had&nbsp;enough&nbsp;time for now, or&nbsp;<br>
because&nbsp;the&nbsp;program&nbsp;has requested&nbsp;a&nbsp;slow&nbsp;peripheral&nbsp;access&nbsp;(such&nbsp;as&nbsp;a&nbsp;disk access)&nbsp;<br>
and&nbsp;cannot do&nbsp;any&nbsp;more useful work until it&nbsp;gets a response.&nbsp;Rather than leave the pro-<br>
gram&nbsp;idling in&nbsp;the processor, the operating&nbsp;system&nbsp;switches it out&nbsp;and schedules&nbsp;<br>
another&nbsp;program&nbsp;that can make useful&nbsp;progress.&nbsp;<br>
Memory &nbsp;&nbsp;&nbsp;&nbsp;<br>
In order to create the virtual machine in&nbsp;which a program&nbsp;runs,&nbsp;the operating&nbsp;system&nbsp;<br>
must&nbsp;establish an&nbsp;environment&nbsp;where&nbsp;the program&nbsp;has&nbsp;access to&nbsp;its code&nbsp;and data&nbsp;at&nbsp;<br>
v&nbsp;<br>
the memory&nbsp;locations where it&nbsp;expects&nbsp;to&nbsp;find them.&nbsp;Since one program's expecta-<br>
management&nbsp;<br>
tions of the&nbsp;addresses it&nbsp;will&nbsp;use&nbsp;may conflict&nbsp;with&nbsp;another's, the operating system&nbsp;<br>
uses&nbsp;memory&nbsp;translation to&nbsp;present the&nbsp;<b>physical&nbsp;</b>memory&nbsp;locations where it has&nbsp;<br>
loaded the&nbsp;code&nbsp;and&nbsp;data&nbsp;to the program&nbsp;at&nbsp;appropriate&nbsp;<b>logical&nbsp;</b>addresses.&nbsp;The&nbsp;pro-<br>
gram&nbsp;sees the&nbsp;memory through a&nbsp;logical-to-physical address translation mechanism&nbsp;<br>
which&nbsp;is&nbsp;managed&nbsp;by&nbsp;the&nbsp;operating system.&nbsp;<br>
Where several users are&nbsp;running programs&nbsp;on the same&nbsp;machine it is&nbsp;highly&nbsp;desir-<br>
able&nbsp;to ensure that&nbsp;an error&nbsp;in one user's&nbsp;program&nbsp;cannot interfere&nbsp;with&nbsp;the&nbsp;operation&nbsp;<br>
Protection&nbsp;<br>
of any&nbsp;of the&nbsp;other programs. It is also,&nbsp;unfortunately, necessary&nbsp;to protect against&nbsp;<br>
malicious&nbsp;attempts to interfere&nbsp;with&nbsp;other programs.&nbsp;<br>
<hr>
<A name=304></a><b>292</b>&nbsp;<br>
<b>Architectural&nbsp;Support for Operating&nbsp;Systems</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The&nbsp;memory-mapping hardware&nbsp;which gives each program&nbsp;its own virtual&nbsp;machine&nbsp;<br>
can also&nbsp;ensure&nbsp;that&nbsp;a program&nbsp;cannot see any&nbsp;memory&nbsp;belonging&nbsp;to&nbsp;another program,&nbsp;<br>
thereby providing&nbsp;a measure&nbsp;of protection. It&nbsp;is&nbsp;not&nbsp;efficient&nbsp;to&nbsp;enforce&nbsp;this&nbsp;too far,&nbsp;<br>
however,&nbsp;since&nbsp;sharing areas&nbsp;of memory that&nbsp;contain,&nbsp;for&nbsp;example,&nbsp;libraries&nbsp;of&nbsp;useful&nbsp;<br>
functions can save&nbsp;on memory&nbsp;use. A solution&nbsp;here is to&nbsp;make these areas&nbsp;<i>read-only&nbsp;</i>or&nbsp;<br>
<i>execute-only&nbsp;</i>so one program&nbsp;cannot&nbsp;corrupt&nbsp;code&nbsp;that will be used by&nbsp;another.&nbsp;<br>
An&nbsp;obvious route for&nbsp;a malicious&nbsp;user to&nbsp;cause&nbsp;damage to&nbsp;another is to&nbsp;overcome&nbsp;<br>
the&nbsp;protection&nbsp;afforded&nbsp;by&nbsp;the memory-management&nbsp;system&nbsp;by&nbsp;assuming&nbsp;operating&nbsp;<br>
system&nbsp;status&nbsp;and&nbsp;then&nbsp;changing&nbsp;the translation&nbsp;tables.&nbsp;Most&nbsp;systems address this&nbsp;by&nbsp;<br>
providing&nbsp;a&nbsp;privileged&nbsp;system&nbsp;mode which&nbsp;has controlled&nbsp;access and&nbsp;making the&nbsp;trans-<br>
lation tables&nbsp;accessible&nbsp;only from&nbsp;this mode.&nbsp;<br>
Designing a&nbsp;computer system&nbsp;to&nbsp;be&nbsp;secure against&nbsp;malicious&nbsp;attacks by&nbsp;clever indi-<br>
viduals is a complex issue&nbsp;which requires&nbsp;some&nbsp;architectural&nbsp;support. On the ARM&nbsp;<br>
this support is provided by&nbsp;privileged&nbsp;processor modes&nbsp;with&nbsp;controlled access and&nbsp;<br>
various forms&nbsp;of&nbsp;memory&nbsp;protection in&nbsp;the&nbsp;memory&nbsp;management units. However, few&nbsp;<br>
ARMs are used&nbsp;in&nbsp;systems&nbsp;where&nbsp;protection&nbsp;against&nbsp;malicious users is&nbsp;required,&nbsp;so&nbsp;<br>
most of the time these facilities are used&nbsp;to&nbsp;catch&nbsp;inadvertent programming errors and&nbsp;<br>
thereby&nbsp;help&nbsp;debug the software.&nbsp;<br>
Resource&nbsp;<br>
Two programs&nbsp;which are&nbsp;running concurrently&nbsp;may&nbsp;place conflicting demands on&nbsp;<br>
allocation&nbsp;<br>
system&nbsp;resources. For example, one program&nbsp;may&nbsp;request data from&nbsp;one part of&nbsp;a&nbsp;<br>
disk. It will be switched out&nbsp;while the disk drive seeks the data, and the program&nbsp;<br>
that&nbsp;gets&nbsp;switched in&nbsp;may immediately request&nbsp;data&nbsp;from&nbsp;a&nbsp;different&nbsp;part&nbsp;of&nbsp;the disk.&nbsp;<br>
If the disk drive&nbsp;responds directly&nbsp;to these&nbsp;requests&nbsp;a situation can easily&nbsp;arise where&nbsp;<br>
the programs alternately have&nbsp;control and&nbsp;the disk&nbsp;drive oscillates between the two&nbsp;<br>
seeks, never&nbsp;having long enough to find either data area, and the system&nbsp;will&nbsp;<br>
live-lock&nbsp;until&nbsp;the disk drive wears out.&nbsp;<br>
In order&nbsp;to&nbsp;avoid this&nbsp;sort&nbsp;of scenario,&nbsp;all&nbsp;requests for&nbsp;input/output&nbsp;activity&nbsp;are chan-<br>
nelled through&nbsp;the&nbsp;operating system. It will&nbsp;accept the&nbsp;request&nbsp;from&nbsp;the first&nbsp;program&nbsp;<br>
and&nbsp;then queue&nbsp;up the request&nbsp;from&nbsp;the second&nbsp;program&nbsp;to receive attention once&nbsp;the&nbsp;<br>
first has&nbsp;been satisfied.&nbsp;<br>
Single-user&nbsp;<br>
Where a system&nbsp;serves a&nbsp;single user, still&nbsp;possibly&nbsp;running&nbsp;several&nbsp;programs&nbsp;at the&nbsp;<br>
systems<br>
same&nbsp;time,&nbsp;much of&nbsp;the above continues&nbsp;to&nbsp;apply.&nbsp;Although&nbsp;the threat of&nbsp;a&nbsp;malicious&nbsp;<br>
&nbsp;<br>
user&nbsp;sharing&nbsp;the&nbsp;same&nbsp;machine&nbsp;is&nbsp;removed,&nbsp;it&nbsp;is&nbsp;still&nbsp;very useful&nbsp;for&nbsp;each&nbsp;program&nbsp;to&nbsp;<br>
run in&nbsp;its&nbsp;own space&nbsp;so&nbsp;that&nbsp;an&nbsp;error in&nbsp;one&nbsp;program&nbsp;does&nbsp;not&nbsp;cause errors&nbsp;in&nbsp;<br>
another. The simplification that arises&nbsp;from&nbsp;removing the concern about the&nbsp;mali-<br>
cious user is that it is no longer necessary&nbsp;to&nbsp;make it impossible for a&nbsp;program&nbsp;to&nbsp;<br>
assume&nbsp;system&nbsp;privileges, it should&nbsp;merely&nbsp;be extremely&nbsp;unlikely&nbsp;that this will&nbsp;<br>
happen&nbsp;inadvertently.&nbsp;<br>
However, desktop&nbsp;machines that appear to&nbsp;belong to one user are increasingly&nbsp;<br>
being&nbsp;connected&nbsp;to&nbsp;computer networks that&nbsp;allow&nbsp;other users to run&nbsp;programs&nbsp;on them&nbsp;<br>
<hr>
<A name=305></a><b>The&nbsp;ARM system&nbsp;control&nbsp;coprocessor</b>&nbsp;<br>
<b>293</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
remotely. Such&nbsp;machines&nbsp;should&nbsp;clearly&nbsp;be viewed as&nbsp;multi-user&nbsp;and incorporate&nbsp;<br>
appropriate levels&nbsp;of protection.&nbsp;<br>
Embedded&nbsp;<br>
An embedded system&nbsp;is&nbsp;quite different from&nbsp;the single- and&nbsp;multi-user&nbsp;<br>
systems&nbsp;<br>
general-purpose system&nbsp;discussed&nbsp;above.&nbsp;It typically&nbsp;runs&nbsp;a fixed&nbsp;set of&nbsp;programs&nbsp;<br>
and has&nbsp;no mechanism&nbsp;for introducing new programs.&nbsp;Presumably, then, the&nbsp;<br>
problem&nbsp;of&nbsp;the&nbsp;malicious&nbsp;user&nbsp;has&nbsp;been&nbsp;removed.&nbsp;<br>
The operating&nbsp;system&nbsp;continues to play&nbsp;a similar role, giving each active&nbsp;program&nbsp;a&nbsp;<br>
clean virtual&nbsp;machine&nbsp;in&nbsp;which to&nbsp;run,&nbsp;providing protection for one program&nbsp;from&nbsp;<br>
errors&nbsp;in&nbsp;another and&nbsp;scheduling the&nbsp;use&nbsp;of&nbsp;CPU time.&nbsp;<br>
Many&nbsp;embedded systems operate&nbsp;within&nbsp;real-time&nbsp;constraints which must&nbsp;be&nbsp;<br>
allowed to determine&nbsp;scheduling priorities.&nbsp;Cost&nbsp;issues&nbsp;also&nbsp;preclude&nbsp;the&nbsp;use&nbsp;of the&nbsp;<br>
operating systems that&nbsp;are&nbsp;popular&nbsp;on&nbsp;general-purpose&nbsp;machines,&nbsp;since&nbsp;these tend to&nbsp;<br>
demand&nbsp;large&nbsp;memory&nbsp;resources.&nbsp;This&nbsp;has&nbsp;led&nbsp;to&nbsp;the&nbsp;development&nbsp;of&nbsp;the real-time&nbsp;<br>
operating system&nbsp;<b>(RTOS)&nbsp;</b>which provides the scheduling and hardware interface facil-<br>
ities&nbsp;required by an embedded system&nbsp;using&nbsp;just a few kilobytes of memory.&nbsp;<br>
Smaller embedded systems&nbsp;may not even&nbsp;be&nbsp;able to&nbsp;bear this&nbsp;cost, or they may have&nbsp;<br>
such simple scheduling requirements (for example, one&nbsp;fixed program&nbsp;that&nbsp;runs all&nbsp;the&nbsp;<br>
time) that&nbsp;they&nbsp;do&nbsp;not&nbsp;need&nbsp;an&nbsp;'operating system'&nbsp;at all.&nbsp;Here a&nbsp;simple 'monitor'&nbsp;pro-<br>
gram&nbsp;suffices,&nbsp;providing&nbsp;a few system&nbsp;functions such&nbsp;as sanitized&nbsp;interfaces to&nbsp;input/&nbsp;<br>
output&nbsp;functions. Such&nbsp;systems almost&nbsp;certainly&nbsp;dispense&nbsp;with&nbsp;the&nbsp;memory manage-<br>
ment hardware&nbsp;and&nbsp;use&nbsp;the&nbsp;processor's logical&nbsp;address&nbsp;to&nbsp;access memory&nbsp;directly.&nbsp;If an&nbsp;<br>
embedded&nbsp;system&nbsp;includes&nbsp;a&nbsp;cache memory some&nbsp;mechanism&nbsp;is required to&nbsp;define&nbsp;<br>
which areas of memory&nbsp;are&nbsp;cacheable&nbsp;(since I/O&nbsp;areas&nbsp;should&nbsp;not&nbsp;be&nbsp;cached),&nbsp;but&nbsp;this&nbsp;<br>
can be&nbsp;far&nbsp;simpler than&nbsp;a&nbsp;full&nbsp;memory&nbsp;management&nbsp;system.&nbsp;<br>
Chapter&nbsp;<br>
The general principles of&nbsp;memory&nbsp;management were described in the previous&nbsp;<br>
structure&nbsp;<br>
chapter. Subsequent sections&nbsp;in&nbsp;this&nbsp;chapter&nbsp;introduce the ARM system&nbsp;control&nbsp;<br>
coprocessor and&nbsp;the&nbsp;memory&nbsp;management&nbsp;systems&nbsp;it controls,&nbsp;which include a&nbsp;full&nbsp;<br>
MMU with&nbsp;address translation and&nbsp;a simpler 'protection&nbsp;unit'&nbsp;for embedded&nbsp;sys-<br>
tems&nbsp;that&nbsp;do not require&nbsp;address translation.&nbsp;<br>
Following this&nbsp;there&nbsp;are&nbsp;sections&nbsp;on&nbsp;the important operating&nbsp;system&nbsp;related issues&nbsp;<br>
of synchronization, context switching&nbsp;and the handling of input/output devices,&nbsp;<br>
including&nbsp;the use of&nbsp;interrupts.&nbsp;<br>
11.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The ARM system control coprocessor&nbsp;<br>
The ARM system&nbsp;control coprocessor is&nbsp;an on-chip coprocessor, using logical&nbsp;<br>
coprocessor&nbsp;number 15, which&nbsp;controls&nbsp;the&nbsp;operation of&nbsp;the on-chip&nbsp;cache or&nbsp;<br>
caches, memory&nbsp;management&nbsp;or protection&nbsp;unit,&nbsp;write&nbsp;buffer,&nbsp;prefetch&nbsp;buffer,&nbsp;<br>
branch&nbsp;target cache&nbsp;and&nbsp;system&nbsp;configuration&nbsp;signals.&nbsp;<br>
<hr>
<A name=306></a><IMG src="index-306_1.png"><br>
<b>294</b>&nbsp;<br>
<b>Architectural&nbsp;Support for Operating&nbsp;Systems</b>&nbsp;<br>
CP15&nbsp;<br>
The control is&nbsp;effected through the&nbsp;reading&nbsp;and writing&nbsp;of the CP15 registers. The&nbsp;<br>
instructions&nbsp;<br>
registers are all 32 bits&nbsp;long,&nbsp;and access is restricted&nbsp;to MRC and MCR&nbsp;instructions&nbsp;<br>
(see&nbsp;Section 5.19 on page 139)&nbsp;which&nbsp;must be executed&nbsp;in supervisor&nbsp;mode.&nbsp;Use of&nbsp;<br>
other coprocessor instructions or any attempted access in&nbsp;user&nbsp;mode&nbsp;will&nbsp;cause the&nbsp;<br>
undefined instruction trap to&nbsp;be taken. The format of&nbsp;these instructions&nbsp;is shown in&nbsp;<br>
Figure&nbsp;11.1. In most&nbsp;cases the&nbsp;CRm&nbsp;and Cop2&nbsp;fields are unused&nbsp;and&nbsp;should be zero,&nbsp;<br>
though they&nbsp;<i>are&nbsp;</i>used&nbsp;in certain operations.&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 11.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>CP15&nbsp;register transfer&nbsp;instructions.&nbsp;<br>
Protection&nbsp;unit&nbsp;<br>
ARM&nbsp;CPUs which are used&nbsp;in&nbsp;embedded systems with&nbsp;fixed&nbsp;or&nbsp;controlled&nbsp;applica-<br>
tion programs&nbsp;do not require&nbsp;a full&nbsp;memory&nbsp;management&nbsp;unit with address transla-<br>
tion capabilities. For&nbsp;such systems a&nbsp;simpler protection unit is adequate.&nbsp;The CP15&nbsp;<br>
register organization&nbsp;for the&nbsp;ARM protection&nbsp;units is described&nbsp;in&nbsp;Section 11.3, and&nbsp;<br>
the operation of&nbsp;the protection unit is&nbsp;described in&nbsp;Section&nbsp;11.4 on page 297.&nbsp;<br>
The CPUs which&nbsp;use a&nbsp;protection&nbsp;unit&nbsp;are&nbsp;the&nbsp;ARM740T&nbsp;described in&nbsp;Section 12.1&nbsp;<br>
on&nbsp;page&nbsp;318 and the ARM940T described in&nbsp;Section&nbsp;12.4&nbsp;on&nbsp;page&nbsp;335.&nbsp;<br>
MMU&nbsp;<br>
ARM&nbsp;CPUs&nbsp;for use in&nbsp;general-purpose applications&nbsp;where the&nbsp;range&nbsp;and number of&nbsp;<br>
application programs is&nbsp;unknown at design&nbsp;time&nbsp;will usually&nbsp;require a full&nbsp;memory&nbsp;<br>
management unit&nbsp;with&nbsp;address translation.&nbsp;The CP15&nbsp;register&nbsp;organization for&nbsp;the&nbsp;<br>
ARM&nbsp;MMU&nbsp;is described in Section 11.5&nbsp;on&nbsp;page 298&nbsp;and the operation&nbsp;of&nbsp;the&nbsp;<br>
MMU is&nbsp;described in&nbsp;Section 11.6 on&nbsp;page 302.&nbsp;<br>
CPUs which&nbsp;use the full&nbsp;MMU include all&nbsp;the&nbsp;other&nbsp;CPUs described in Chapter 12.&nbsp;<br>
11.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CP15 protection unit registers&nbsp;<br>
The protection&nbsp;unit register structure is illustrated in Table 11.1&nbsp;on&nbsp;page&nbsp;295. The&nbsp;<br>
registers are&nbsp;read and&nbsp;written&nbsp;using the&nbsp;CP15&nbsp;instruction&nbsp;shown in&nbsp;Figure 11.1,&nbsp;with&nbsp;<br>
CRn specifying&nbsp;the&nbsp;register&nbsp;to&nbsp;be accessed.&nbsp;In&nbsp;detail,&nbsp;the&nbsp;register&nbsp;functions&nbsp;are&nbsp;as&nbsp;<br>
follows:&nbsp;<br>
<hr>
<A name=307></a><IMG src="index-307_1.png"><br>
<IMG src="index-307_2.png"><br>
<b>CP15&nbsp;protection&nbsp;unit&nbsp;registers</b>&nbsp;<br>
<b>295</b>&nbsp;<br>
<b>Table&nbsp;11.1 &nbsp; &nbsp;</b>CP15 protection&nbsp;unit register structure.&nbsp;<br>
&nbsp;<br>
Register&nbsp;&nbsp;&nbsp;<br>
Purpose&nbsp;&nbsp;&nbsp;<br>
0&nbsp;&nbsp;&nbsp;<br>
ID Register&nbsp;&nbsp;&nbsp;<br>
1&nbsp;&nbsp;&nbsp;<br>
Configuration&nbsp;&nbsp;&nbsp;<br>
2&nbsp;&nbsp;&nbsp;<br>
Cache Control&nbsp;&nbsp;&nbsp;<br>
3&nbsp;&nbsp;&nbsp;<br>
Write&nbsp;Buffer Control&nbsp;&nbsp;&nbsp;<br>
5&nbsp;&nbsp;&nbsp;<br>
Access Permissions&nbsp;&nbsp;&nbsp;<br>
6&nbsp;&nbsp;&nbsp;<br>
Region Base and Size&nbsp;&nbsp;&nbsp;<br>
7&nbsp;&nbsp;&nbsp;<br>
Cache Operations&nbsp;&nbsp;&nbsp;<br>
9&nbsp;&nbsp;&nbsp;<br>
Cache Lock Down&nbsp;&nbsp;&nbsp;<br>
15&nbsp;&nbsp;&nbsp;<br>
Test&nbsp;&nbsp;&nbsp;<br>
4,8,10-14&nbsp;&nbsp;&nbsp;&nbsp;UNUSED&nbsp;&nbsp;&nbsp;<br>
<b>Register&nbsp;0&nbsp;</b>(which&nbsp;is read-only)&nbsp;returns&nbsp;device&nbsp;identification&nbsp;information.&nbsp;<br>
&nbsp;<br>
Bits [3:0] contain a&nbsp;revision&nbsp;number, bits&nbsp;[15:4] contain&nbsp;a 3-digit part number in&nbsp;<br>
binary-coded&nbsp;decimal, bits [23:16] contain the architecture version&nbsp;(0&nbsp;for&nbsp;version&nbsp;<br>
3,&nbsp;1&nbsp;for version&nbsp;4,&nbsp;2&nbsp;for version&nbsp;4T, 4&nbsp;for version&nbsp;5T) and&nbsp;bits [31:24] contain&nbsp;the&nbsp;<br>
ASCII&nbsp;code&nbsp;of an&nbsp;implementer's&nbsp;trademark (ASCII&nbsp;'A'&nbsp;=&nbsp;4116&nbsp;indicates&nbsp;ARM&nbsp;<br>
Limited,&nbsp;'D'&nbsp;=&nbsp;44I6&nbsp;indicates&nbsp;Digital, and&nbsp;so&nbsp;on).&nbsp;<br>
Some&nbsp;CPUs&nbsp;do&nbsp;not follow&nbsp;the&nbsp;above register 0 format&nbsp;exactly, and recent&nbsp;CPUs&nbsp;<br>
have a second register 0 (accessed by changing the Cop2 field in the MRC&nbsp;<br>
instruction)&nbsp;which gives&nbsp;details on&nbsp;the&nbsp;cache organization.&nbsp;<br>
<b>Register 1&nbsp;</b>(which is read-write) contains&nbsp;several bits of control information&nbsp;<br>
which enable&nbsp;system&nbsp;functions&nbsp;and control system&nbsp;parameters.&nbsp;<br>
&nbsp;<br>
All bits&nbsp;are cleared on&nbsp;reset.&nbsp;If&nbsp;subsequently&nbsp;set,&nbsp;M&nbsp;enables the protection&nbsp;unit, C&nbsp;<br>
enables&nbsp;the&nbsp;data&nbsp;or&nbsp;unified&nbsp;cache, W&nbsp;enables&nbsp;the write&nbsp;buffer, B&nbsp;switches&nbsp;from&nbsp;lit-<br>
tle- to&nbsp;big-endian byte ordering,&nbsp;I enables the instruction cache&nbsp;when&nbsp;this&nbsp;is sepa-<br>
rate&nbsp;from&nbsp;the&nbsp;data cache,&nbsp;V causes the exception vectors to&nbsp;move to near&nbsp;the top&nbsp;<br>
<hr>
<A name=308></a><IMG src="index-308_1.png"><br>
<IMG src="index-308_2.png"><br>
<IMG src="index-308_3.png"><br>
<b>296</b>&nbsp;<br>
<b>Architectural&nbsp;Support for Operating&nbsp;Systems</b>&nbsp;<br>
of&nbsp;the&nbsp;address space,&nbsp;S,&nbsp;Lck,&nbsp;F&nbsp;and Bnk&nbsp;are&nbsp;used&nbsp;to&nbsp;control&nbsp;the&nbsp;cache&nbsp;(on&nbsp;the&nbsp;<br>
ARM740T), and nf and iA&nbsp;control various clock&nbsp;mechanisms&nbsp;(on the&nbsp;<br>
ARM940T).&nbsp;<br>
Note&nbsp;that not&nbsp;all bits are provided in all&nbsp;implementations.&nbsp;<br>
<b>• Register&nbsp;</b>2&nbsp;(which is read-write) controls the cacheability of the eight&nbsp;individual&nbsp;<br>
protection regions.&nbsp;<br>
&nbsp;<br>
Bit 0&nbsp;enables the cache&nbsp;for loads&nbsp;within&nbsp;region 0,&nbsp;bit&nbsp;1 likewise&nbsp;for region&nbsp;1,&nbsp;and&nbsp;<br>
so on. The ARM940T has separate protection units on its instruction&nbsp;and data&nbsp;<br>
ports, and Cop2&nbsp;(see&nbsp;Figure 11.1 on&nbsp;page 294)&nbsp;is&nbsp;used to&nbsp;determine&nbsp;which unit&nbsp;is&nbsp;<br>
accessed: Cop2&nbsp;= 0&nbsp;gives access to&nbsp;the protection unit on&nbsp;the&nbsp;data port; Cop2&nbsp;= 1&nbsp;<br>
gives access to&nbsp;the protection&nbsp;unit on the&nbsp;instruction&nbsp;port.&nbsp;<br>
•&nbsp;&nbsp;<b>Register&nbsp;</b>3 (which&nbsp;is read-write)&nbsp;defines whether&nbsp;or&nbsp;not the write&nbsp;buffer&nbsp;should&nbsp;be&nbsp;<br>
used for each&nbsp;of the protection regions. Its&nbsp;format&nbsp;is the same&nbsp;as that for register&nbsp;<br>
2, but&nbsp;note that&nbsp;as the ARM940T instruction port is read-only,&nbsp;the write&nbsp;buffer&nbsp;<br>
can&nbsp;only&nbsp;be enabled&nbsp;for&nbsp;the data port&nbsp;and so&nbsp;Cop2 should&nbsp;always be zero.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Register&nbsp;</b>5 (which is read-write) defines the access permissions for each of the&nbsp;<br>
protection regions.<b>&nbsp;</b><br>
&nbsp;<br>
The access permissions cover no access&nbsp;(00), privileged&nbsp;modes only&nbsp;(01), privi-<br>
leged&nbsp;full&nbsp;access and user&nbsp;read only&nbsp;(10) and&nbsp;full&nbsp;access&nbsp;(11).&nbsp;Again the&nbsp;<br>
ARM940T uses the Cop2&nbsp;field to differentiate the instruction&nbsp;(1) and&nbsp;data&nbsp;(0)&nbsp;<br>
protection units.&nbsp;<br>
<b>• Register&nbsp;<i>6&nbsp;</i></b>(which is read-write) defines&nbsp;the start address and size of&nbsp;each of the&nbsp;<br>
eight regions.&nbsp;<br>
&nbsp;<br>
The&nbsp;region base address&nbsp;must&nbsp;be a&nbsp;multiple&nbsp;of the&nbsp;size.&nbsp;The encoding of&nbsp;the size&nbsp;<br>
field&nbsp;is&nbsp;shown&nbsp;in&nbsp;Table 11.2 on&nbsp;page&nbsp;298.&nbsp;E enables the&nbsp;region.&nbsp;<br>
The&nbsp;particular region is specified in&nbsp;the CRm&nbsp;field (see Figure&nbsp;11.1&nbsp;on&nbsp;page&nbsp;294)&nbsp;<br>
which&nbsp;should&nbsp;be set from&nbsp;0 to 7.&nbsp;For a&nbsp;Harvard core such&nbsp;as the&nbsp;ARM940T there&nbsp;<br>
<hr>
<A name=309></a><b>ARM&nbsp;protection&nbsp;unit</b>&nbsp;<br>
<b>297</b>&nbsp;<br>
are&nbsp;separate region registers for&nbsp;the&nbsp;instruction and&nbsp;data memory ports, and Cop2&nbsp;<br>
specifies&nbsp;which&nbsp;memory&nbsp;port&nbsp;is&nbsp;to&nbsp;be&nbsp;addressed as described above for&nbsp;register&nbsp;2.&nbsp;<br>
<b>Register&nbsp;</b>7&nbsp;controls various cache&nbsp;operations&nbsp;and&nbsp;its operation is different&nbsp;for the&nbsp;<br>
ARM740T&nbsp;and the ARM940T.&nbsp;<br>
<b>Register 9&nbsp;</b>is used in the ARM940T to&nbsp;lock down areas of the cache. (The&nbsp;<br>
ARM740T uses certain&nbsp;bits in&nbsp;register&nbsp;1&nbsp;for this purpose.)&nbsp;<br>
<b>Register 15&nbsp;</b>is&nbsp;used in the&nbsp;ARM940T to&nbsp;modify&nbsp;the&nbsp;cache allocation&nbsp;algorithm&nbsp;<br>
from&nbsp;random&nbsp;to&nbsp;round-robin.&nbsp;This is&nbsp;intended&nbsp;for use only during&nbsp;silicon produc-<br>
tion testing.&nbsp;<br>
11.4 &nbsp; ARM&nbsp;protection&nbsp;unit&nbsp;<br>
ARM CPUs intended for embedded applications incorporate&nbsp;a&nbsp;memory&nbsp;protection&nbsp;<br>
unit&nbsp;which&nbsp;defines various protection and&nbsp;cache functions&nbsp;for different regions&nbsp;of&nbsp;<br>
memory&nbsp;so&nbsp;that, for&nbsp;example,&nbsp;I/O regions&nbsp;can&nbsp;be&nbsp;restricted&nbsp;to supervisor&nbsp;access&nbsp;only&nbsp;<br>
and&nbsp;made uncacheable. Protection units do not translate&nbsp;addresses.&nbsp;Systems&nbsp;which&nbsp;<br>
require&nbsp;address translation&nbsp;should use a&nbsp;full&nbsp;memory&nbsp;management&nbsp;unit, described in&nbsp;<br>
Section&nbsp;11.6 on&nbsp;page 302. CPUs&nbsp;which incorporate the protection unit include the&nbsp;<br>
ARM740T&nbsp;and the ARM940T.&nbsp;<br>
Protection&nbsp;unit&nbsp;<br>
The&nbsp;protection&nbsp;unit&nbsp;allows the ARM&nbsp;4 Gbyte address&nbsp;space&nbsp;to&nbsp;be&nbsp;mapped into&nbsp;eight&nbsp;<br>
structure&nbsp;<br>
regions, each&nbsp;with a programmable start address and&nbsp;size&nbsp;and with programmable protec-<br>
tion and&nbsp;cache&nbsp;properties.&nbsp;The&nbsp;regions&nbsp;may overlap.&nbsp;A fixed priority&nbsp;scheme&nbsp;defines&nbsp;those&nbsp;<br>
characteristics&nbsp;which apply to&nbsp;an address&nbsp;which falls into&nbsp;more than one region.&nbsp;<br>
Region&nbsp;definition&nbsp;&nbsp;Each of&nbsp;the eight regions has a&nbsp;start&nbsp;address and&nbsp;a&nbsp;size&nbsp;defined&nbsp;by&nbsp;writing to CP15&nbsp;<br>
register 6. The&nbsp;format of this register was defined&nbsp;on&nbsp;page&nbsp;296.&nbsp;The&nbsp;minimum region&nbsp;<br>
size&nbsp;is&nbsp;4 Kbytes, the&nbsp;maximum&nbsp;4&nbsp;Gbytes. Rd[5:l],&nbsp;when written&nbsp;to&nbsp;CP15 register&nbsp;6,&nbsp;<br>
defines the&nbsp;size, which can&nbsp;be&nbsp;set to any&nbsp;power&nbsp;of&nbsp;two&nbsp;bytes between the maximum&nbsp;<br>
and minimum&nbsp;as shown in&nbsp;Table 11.2&nbsp;on&nbsp;page&nbsp;298.&nbsp;The start address&nbsp;must be&nbsp;a&nbsp;mul-<br>
tiple&nbsp;of the&nbsp;selected&nbsp;size&nbsp;and&nbsp;is&nbsp;defined&nbsp;by&nbsp;Rd[31:12]. The region&nbsp;will&nbsp;have&nbsp;no&nbsp;effect&nbsp;<br>
unless it is&nbsp;enabled by&nbsp;setting&nbsp;Rd[0].&nbsp;<br>
Region&nbsp;priorities&nbsp;<br>
The&nbsp;regions&nbsp;may legitimately&nbsp;be&nbsp;programmed so&nbsp;that&nbsp;they&nbsp;overlap.&nbsp;When&nbsp;an&nbsp;address&nbsp;<br>
that falls&nbsp;into&nbsp;more than one region is presented to the protection unit a fixed prior-<br>
ity&nbsp;scheme&nbsp;determines which region&nbsp;defines its attributes: region&nbsp;7 has the&nbsp;highest&nbsp;<br>
priority,&nbsp;region 0 the lowest, and the other regions have&nbsp;intermediate priorities in&nbsp;<br>
order&nbsp;of&nbsp;their&nbsp;number.&nbsp;<br>
<hr>
<A name=310></a><b>298</b>&nbsp;<br>
<b>Architectural&nbsp;Support for Operating&nbsp;Systems</b>&nbsp;<br>
<b>Table&nbsp;11.2 &nbsp; &nbsp;</b>Protection unit&nbsp;region size encoding.&nbsp;<br>
&nbsp;<br>
Rd[5:l] &nbsp;<br>
Region size&nbsp;&nbsp;&nbsp;<br>
01011 &nbsp;<br>
4 Kbytes&nbsp;&nbsp;&nbsp;<br>
01100 &nbsp;<br>
8 Kbytes&nbsp;&nbsp;&nbsp;<br>
01101 &nbsp;<br>
16 Kbytes&nbsp;&nbsp;&nbsp;<br>
01110&nbsp;&nbsp;&nbsp;<br>
32 Kbytes&nbsp;&nbsp;&nbsp;<br>
11100&nbsp;&nbsp;&nbsp;<br>
5 12&nbsp;Mbytes&nbsp;&nbsp;&nbsp;<br>
11101&nbsp;&nbsp;&nbsp;<br>
1 Gbyte&nbsp;&nbsp;&nbsp;<br>
11110&nbsp;&nbsp;&nbsp;<br>
2 Gbytes&nbsp;&nbsp;&nbsp;<br>
11111&nbsp;&nbsp;&nbsp;<br>
4 Gbytes&nbsp;&nbsp;&nbsp;<br>
The restriction&nbsp;on&nbsp;the start of&nbsp;a region,&nbsp;which&nbsp;must be&nbsp;a multiple of&nbsp;its size, means&nbsp;<br>
that checking&nbsp;whether or&nbsp;not&nbsp;an address falls within a region&nbsp;is&nbsp;simply&nbsp;a matter of&nbsp;<br>
comparing some&nbsp;number (up to&nbsp;20) of&nbsp;the&nbsp;most&nbsp;significant&nbsp;bits&nbsp;of the address against&nbsp;<br>
the corresponding&nbsp;bits&nbsp;of&nbsp;the&nbsp;region start&nbsp;address.&nbsp;If&nbsp;they match, the address&nbsp;falls&nbsp;<br>
inside&nbsp;that region. If they don't&nbsp;match, the&nbsp;address falls outside the region. No addition&nbsp;<br>
or&nbsp;subtraction&nbsp;is&nbsp;required,&nbsp;so&nbsp;the process&nbsp;can be fast.&nbsp;The&nbsp;organization of&nbsp;the protec-<br>
tion unit&nbsp;is&nbsp;therefore as shown&nbsp;in&nbsp;Figure 11.2&nbsp;on page&nbsp;299. In&nbsp;this&nbsp;illustration region&nbsp;0&nbsp;<br>
cover&nbsp;the&nbsp;complete 4 Gbyte address space and therefore&nbsp;all addresses fall into it.&nbsp;<br>
Regions 1,&nbsp;2&nbsp;and 4&nbsp;are 4&nbsp;Kbytes,&nbsp;and regions 3,&nbsp;6,&nbsp;7&nbsp;and 5 have&nbsp;increasing&nbsp;sizes.&nbsp;The&nbsp;<br>
example address&nbsp;falls in regions 0,&nbsp;3 and&nbsp;6&nbsp;(as&nbsp;denoted&nbsp;by&nbsp;the&nbsp;black arrows),&nbsp;so&nbsp;the&nbsp;<br>
priority&nbsp;encoder selects the attributes for the&nbsp;highest&nbsp;priority&nbsp;region, region&nbsp;6.&nbsp;<br>
If an&nbsp;address does not fall into&nbsp;any enabled&nbsp;region&nbsp;the&nbsp;protection&nbsp;unit will generate&nbsp;<br>
an abort.&nbsp;<br>
Harvard cores&nbsp;<br>
ARM&nbsp;cores&nbsp;that&nbsp;use a Harvard architecture&nbsp;(such as the ARM940T) have separate&nbsp;pro-<br>
tection units on&nbsp;their&nbsp;instruction and data ports, so they&nbsp;have a total&nbsp;of 16 regions.&nbsp;<br>
11.5 &nbsp; CP15&nbsp;MMU&nbsp;registers&nbsp;<br>
The&nbsp;MMU register&nbsp;structure is&nbsp;illustrated&nbsp;in&nbsp;Table 11.3 on page 299. The registers&nbsp;<br>
are&nbsp;read&nbsp;and written using&nbsp;the&nbsp;CP15&nbsp;instruction shown&nbsp;in&nbsp;Figure 11.1 on page&nbsp;294,&nbsp;<br>
with CRn&nbsp;specifying the&nbsp;register to&nbsp;be&nbsp;accessed.&nbsp;<br>
In&nbsp;detail,&nbsp;the register functions&nbsp;are as shown&nbsp;on&nbsp;page 300.&nbsp;<br>
<hr>
<A name=311></a><IMG src="index-311_1.png"><br>
<IMG src="index-311_2.png"><br>
<b>CP15 MMU registers&nbsp;</b><br>
<b>299</b>&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<hr>
<A name=312></a><IMG src="index-312_1.png"><br>
<IMG src="index-312_2.png"><br>
<IMG src="index-312_3.png"><br>
<b>300</b>&nbsp;<br>
<b>Architectural&nbsp;Support for Operating&nbsp;Systems</b>&nbsp;<br>
Bits [3:0] contain a revision&nbsp;number, bits [15:4]&nbsp;contain&nbsp;a 3-digit part number in&nbsp;<br>
<b>• Register&nbsp;0&nbsp;</b>(which is&nbsp;read-only) returns&nbsp;identification information.&nbsp;<br>
binary-coded decimal, bits [23:16] contain the architecture version ('A'&nbsp;= 0 for&nbsp;<br>
version 3,&nbsp;'A'&nbsp;= 1&nbsp;for version 4) and bits&nbsp;[31:24] contain&nbsp;the&nbsp;ASCII code of an&nbsp;<br>
implementer's&nbsp;trademark (ASCII 'A'&nbsp;=&nbsp;41&nbsp;]6&nbsp;indicates ARM&nbsp;Limited,&nbsp;’Ď’ =&nbsp;4416&nbsp;<br>
indicates Digital, and&nbsp;so&nbsp;on).&nbsp;<br>
Some&nbsp;CPUs do&nbsp;not follow the above register 0&nbsp;format exactly, and&nbsp;recent CPUs&nbsp;<br>
have a second&nbsp;register 0&nbsp;(accessed by&nbsp;changing the Cop2 field in&nbsp;the MRC&nbsp;<br>
instruction)&nbsp;which gives details on&nbsp;the cache organization.&nbsp;<br>
<b>• Register 1&nbsp;</b>(which is&nbsp;write-only in architecture&nbsp;version&nbsp;3 but read-write&nbsp;in version&nbsp;<br>
4) contains several bits of&nbsp;control information which enable system&nbsp;functions&nbsp;<br>
and control&nbsp;system&nbsp;parameters.&nbsp;<br>
&nbsp;<br>
All bits&nbsp;are&nbsp;cleared&nbsp;on&nbsp;reset.&nbsp;If subsequently&nbsp;set,&nbsp;M&nbsp;enables the&nbsp;MMU,&nbsp;A enables&nbsp;<br>
address alignment&nbsp;fault checking,&nbsp;C enables the data or&nbsp;unified cache,&nbsp;W enables&nbsp;<br>
the write&nbsp;buffer,&nbsp;P switches from&nbsp;26- to 32-bit exception handling, D switches&nbsp;<br>
from&nbsp;26-&nbsp;to&nbsp;32-bit address range,&nbsp;L switches to late&nbsp;abort&nbsp;timing,&nbsp;B&nbsp;switches from&nbsp;<br>
little- to big-endian byte ordering, S and R&nbsp;modify the&nbsp;MMU&nbsp;system&nbsp;and ROM&nbsp;<br>
protection&nbsp;states,&nbsp;F&nbsp;controls the&nbsp;speed of&nbsp;external&nbsp;coprocessor&nbsp;communications,&nbsp;Z&nbsp;<br>
enables branch&nbsp;prediction, I enables the&nbsp;instruction cache when this&nbsp;is&nbsp;separate&nbsp;<br>
from&nbsp;the&nbsp;data&nbsp;cache, V moves the exception&nbsp;vector&nbsp;base&nbsp;from&nbsp;0x00000000&nbsp;to&nbsp;<br>
OxfffroOOO and&nbsp;RR&nbsp;controls the cache replacement algorithm&nbsp;(pseudo-random&nbsp;or&nbsp;<br>
round-robin).&nbsp;Note&nbsp;that not all bits&nbsp;are provided in all implementations.&nbsp;<br>
Bits [31:15] are unpredictable on read and should be preserved using&nbsp;<br>
read-modify-write&nbsp;accesses.&nbsp;Bits [31:30] are used in&nbsp;the&nbsp;ARM920 and&nbsp;ARM940&nbsp;<br>
for clock&nbsp;control functions,&nbsp;for example.&nbsp;<br>
<b>• Register&nbsp;</b>2&nbsp;(which is&nbsp;write-only in architecture&nbsp;version&nbsp;3 but read-write in version&nbsp;<br>
4) contains&nbsp;the address of&nbsp;the start of the&nbsp;currently active first-level translation&nbsp;<br>
table. This must be aligned&nbsp;on&nbsp;a&nbsp;16&nbsp;Kbyte boundary.&nbsp;<br>
&nbsp;<br>
<hr>
<A name=313></a><IMG src="index-313_1.png"><br>
<IMG src="index-313_2.png"><br>
<IMG src="index-313_3.png"><br>
<b>CP15&nbsp;MMU&nbsp;registers</b>&nbsp;<br>
<b>301</b>&nbsp;<br>
<b>• Register&nbsp;</b>3 (which is write-only in architecture version&nbsp;3 but&nbsp;read-write in ver-<br>
sion 4) contains sixteen 2-bit fields, each specifying the access permissions for&nbsp;<br>
one of&nbsp;the 16 domains.&nbsp;See&nbsp;'Domains'&nbsp;on page&nbsp;302 for&nbsp;further details.&nbsp;<br>
&nbsp;<br>
<b>• Register&nbsp;</b>5 (which is read-write&nbsp;in&nbsp;architecture version&nbsp;4, but in version 3 it is&nbsp;<br>
read-only and&nbsp;writing&nbsp;to it flushes&nbsp;the whole&nbsp;TLB) indicates the type&nbsp;of&nbsp;fault and&nbsp;<br>
the domain&nbsp;of&nbsp;the last data&nbsp;access that&nbsp;aborted.&nbsp;D is&nbsp;set on&nbsp;a data breakpoint.&nbsp;<br>
&nbsp;<br>
<b>• Register 6&nbsp;</b>(which is read-write&nbsp;in&nbsp;architecture version&nbsp;4, but in&nbsp;version 3 it is&nbsp;<br>
read-only&nbsp;and&nbsp;writing&nbsp;to&nbsp;it&nbsp;flushes a&nbsp;particular&nbsp;TLB&nbsp;entry)&nbsp;contains&nbsp;the&nbsp;address of&nbsp;<br>
the last data&nbsp;access that&nbsp;aborted.&nbsp;<br>
&nbsp;<br>
<b>• Register&nbsp;</b>7 (which&nbsp;is&nbsp;read-write in&nbsp;architecture&nbsp;version&nbsp;4,&nbsp;but in&nbsp;version&nbsp;3 it&nbsp;is&nbsp;<br>
write-only and&nbsp;simply&nbsp;flushes the cache) is&nbsp;used to perform&nbsp;a number of&nbsp;cache,&nbsp;<br>
write&nbsp;buffer,&nbsp;prefetch buffer and branch&nbsp;target&nbsp;cache clean and/or&nbsp;flush&nbsp;oper&nbsp;<br>
ations. The data supplied&nbsp;should be either&nbsp;zero&nbsp;or&nbsp;a relevant&nbsp;virtual&nbsp;address.&nbsp;<br>
Accesses to&nbsp;register 7 use the Cop2 and CRm&nbsp;fields to specify&nbsp;particular opera-<br>
tions; the&nbsp;available&nbsp;functions&nbsp;vary from&nbsp;implementation&nbsp;to&nbsp;implementation.&nbsp;<br>
•&nbsp;&nbsp;<b>Register 8&nbsp;</b>(which is read-write in architecture version 4&nbsp;and unavailable in ver&nbsp;<br>
sion 3)&nbsp;is used&nbsp;to perform&nbsp;a number of&nbsp;TLB&nbsp;operations,&nbsp;flushing&nbsp;single entries or&nbsp;<br>
the whole&nbsp;TLB and supporting&nbsp;unified or&nbsp;separate&nbsp;instruction&nbsp;and&nbsp;data&nbsp;TLBs.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Register 9&nbsp;</b>is&nbsp;used&nbsp;to&nbsp;control&nbsp;the&nbsp;read buffer, if&nbsp;one&nbsp;is&nbsp;present.&nbsp;In&nbsp;some&nbsp;CPUs&nbsp;it&nbsp;is&nbsp;<br>
used to&nbsp;control&nbsp;cache lockdown&nbsp;functions.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Register 10&nbsp;is&nbsp;</b>used to&nbsp;control&nbsp;TLB&nbsp;lockdown functions&nbsp;where&nbsp;these&nbsp;are sup&nbsp;<br>
ported.<b>&nbsp;</b><br>
•&nbsp;&nbsp;Register 13&nbsp;is used&nbsp;to&nbsp;remap&nbsp;virtual addresses through a process&nbsp;ID&nbsp;register.&nbsp;This&nbsp;<br>
mechanism&nbsp;is&nbsp;used&nbsp;to&nbsp;support Windows CE and&nbsp;is&nbsp;only&nbsp;present&nbsp;on&nbsp;particular&nbsp;<br>
<hr>
<A name=314></a><IMG src="index-314_1.png"><br>
<b>302</b>&nbsp;<br>
<b>Architectural Support for Operating&nbsp;Systems</b>&nbsp;<br>
CPUs such&nbsp;as the ARM720T, the&nbsp;ARM920T and the&nbsp;S&nbsp;A-1100. If bits [31:25] of&nbsp;<br>
the virtual address&nbsp;are zero they&nbsp;are&nbsp;replaced&nbsp;with&nbsp;bits&nbsp;[31:25] of&nbsp;this&nbsp;register.&nbsp;<br>
&nbsp;<br>
•&nbsp;&nbsp;<b>Register&nbsp;</b>14&nbsp;<b>is&nbsp;</b>used&nbsp;for debug&nbsp;support.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Register 15&nbsp;</b>is&nbsp;used&nbsp;for test and&nbsp;in some&nbsp;CPUs for&nbsp;clock control&nbsp;purposes.<b>&nbsp;</b><br>
11.6 &nbsp; ARM&nbsp;MMU&nbsp;architecture&nbsp;<br>
An&nbsp;MMU&nbsp;performs&nbsp;two&nbsp;primary&nbsp;functions:&nbsp;<br>
•&nbsp;&nbsp;It translates virtual addresses into&nbsp;physical&nbsp;addresses.&nbsp;<br>
•&nbsp;&nbsp;It controls&nbsp;memory access permissions, aborting illegal&nbsp;accesses.&nbsp;<br>
The ARM MMU&nbsp;uses a 2-level page table&nbsp;with table-walking hardware and a TLB&nbsp;<br>
which stores&nbsp;recently used page translations. Where the processor has separate&nbsp;<br>
instruction and&nbsp;data&nbsp;caches&nbsp;it&nbsp;is&nbsp;likely also&nbsp;to have&nbsp;separate instruction&nbsp;and data&nbsp;TLBs.&nbsp;<br>
Memory&nbsp;<br>
The&nbsp;memory&nbsp;mapping is&nbsp;performed at&nbsp;several different&nbsp;granularities by the&nbsp;same&nbsp;<br>
granularity&nbsp;<br>
basic&nbsp;mechanism.&nbsp;The&nbsp;units&nbsp;that&nbsp;can be&nbsp;used&nbsp;are:&nbsp;<br>
•&nbsp;&nbsp;<b>Sections.&nbsp;</b>These are 1&nbsp;Mbyte&nbsp;blocks&nbsp;of&nbsp;memory.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Large pages.&nbsp;</b>These&nbsp;are 64&nbsp;Kbyte blocks&nbsp;of&nbsp;memory, and within&nbsp;a large&nbsp;page&nbsp;<br>
access control&nbsp;is applied&nbsp;to individual&nbsp;16&nbsp;Kbyte&nbsp;<b>subpages.&nbsp;</b><br>
•&nbsp;&nbsp;<b>Small pages.&nbsp;</b>These are 4&nbsp;Kbyte&nbsp;blocks of&nbsp;memory, and within&nbsp;a small&nbsp;page&nbsp;<br>
access control&nbsp;is applied to individual 1&nbsp;Kbyte subpages.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Tiny pages.&nbsp;</b>Some&nbsp;of&nbsp;the latest CPUs also&nbsp;support 1&nbsp;Kbyte&nbsp;'tiny'&nbsp;pages.<b>&nbsp;</b><br>
The&nbsp;normal granularity&nbsp;is&nbsp;the&nbsp;4 Kbyte small&nbsp;page.&nbsp;Large&nbsp;pages&nbsp;and sections&nbsp;exist&nbsp;to&nbsp;<br>
allow&nbsp;the&nbsp;mapping&nbsp;of&nbsp;large&nbsp;data areas with&nbsp;a&nbsp;single TLB entry. Forcing&nbsp;a large&nbsp;data&nbsp;<br>
area&nbsp;to&nbsp;be mapped in&nbsp;small pages can,&nbsp;under certain&nbsp;circumstances,&nbsp;cause the&nbsp;TLB&nbsp;to&nbsp;<br>
perform&nbsp;inefficiently.&nbsp;<br>
Domains&nbsp;<br>
Domains are an unusual feature of the ARM&nbsp;MMU architecture. A domain&nbsp;is a group&nbsp;<br>
of&nbsp;sections and/or pages&nbsp;which have particular access permissions.&nbsp;This allows a&nbsp;<br>
number of&nbsp;different&nbsp;processes&nbsp;to run with&nbsp;the same&nbsp;translation&nbsp;tables while retaining&nbsp;<br>
some&nbsp;protection&nbsp;from&nbsp;each other. It&nbsp;gives&nbsp;a&nbsp;much more lightweight&nbsp;process switch&nbsp;<br>
mechanism&nbsp;than&nbsp;is possible if each&nbsp;process&nbsp;must&nbsp;have its own translation&nbsp;tables.&nbsp;<br>
<hr>
<A name=315></a><b>ARM MMU architecture</b>&nbsp;<br>
<b>303</b>&nbsp;<br>
The access&nbsp;control&nbsp;is based on&nbsp;two&nbsp;sorts&nbsp;of&nbsp;programs:&nbsp;<br>
•&nbsp;&nbsp;<b>Clients&nbsp;</b>are&nbsp;users of domains&nbsp;and&nbsp;must&nbsp;observe the access&nbsp;permissions&nbsp;of the&nbsp;<br>
individual sections&nbsp;and&nbsp;pages that&nbsp;make&nbsp;up&nbsp;the domain.<b>&nbsp;</b><br>
•&nbsp;&nbsp;<b>Managers &nbsp;</b>are&nbsp;the &nbsp;controllers &nbsp;of&nbsp;the &nbsp;domain&nbsp;and&nbsp;can&nbsp;bypass&nbsp;the &nbsp;<br>
access&nbsp;<br>
permissions of&nbsp;individual&nbsp;sections or&nbsp;pages.<b>&nbsp;</b><br>
<b>Table&nbsp;11.4 &nbsp; &nbsp;</b>Domain access control bits.&nbsp;<br>
&nbsp;<br>
Value&nbsp;&nbsp;&nbsp;&nbsp;Status&nbsp;&nbsp;&nbsp;<br>
Description&nbsp;&nbsp;&nbsp;<br>
00&nbsp;&nbsp;&nbsp;<br>
No access&nbsp;<br>
Any access&nbsp;will&nbsp;generate&nbsp;a&nbsp;domain&nbsp;fault&nbsp;&nbsp;&nbsp;<br>
01&nbsp;&nbsp;&nbsp;<br>
Client&nbsp;&nbsp;&nbsp;<br>
Page and section&nbsp;permission bits&nbsp;are checked&nbsp;&nbsp;&nbsp;<br>
10&nbsp;&nbsp;&nbsp;<br>
Reserved&nbsp;<br>
Do not use&nbsp;&nbsp;&nbsp;<br>
11&nbsp;&nbsp;&nbsp;<br>
Manager&nbsp;&nbsp;&nbsp;&nbsp;Page and section&nbsp;permission bits&nbsp;are&nbsp;not&nbsp;checked&nbsp;&nbsp;&nbsp;<br>
At any&nbsp;one&nbsp;time a&nbsp;program&nbsp;may&nbsp;be&nbsp;a client&nbsp;of some&nbsp;domains,&nbsp;a manager&nbsp;of some&nbsp;<br>
other domains and&nbsp;have&nbsp;no&nbsp;access at all to&nbsp;the&nbsp;remaining&nbsp;domains. This&nbsp;is controlled&nbsp;<br>
by&nbsp;CP15 register 3 which contains two bits for each of the&nbsp;16 domains describing&nbsp;the&nbsp;<br>
status&nbsp;of&nbsp;the&nbsp;current&nbsp;program&nbsp;with&nbsp;respect&nbsp;to&nbsp;each&nbsp;domain.&nbsp;The&nbsp;interpretation&nbsp;of&nbsp;the&nbsp;<br>
two bits is given in Table 11.4. The relationship of a&nbsp;program&nbsp;to all of the domains can&nbsp;<br>
be&nbsp;changed&nbsp;by&nbsp;writing&nbsp;a single&nbsp;new value&nbsp;into&nbsp;CP15&nbsp;register&nbsp;3.&nbsp;<br>
Translatio<br>
The&nbsp;translation&nbsp;of&nbsp;a&nbsp;new&nbsp;virtual&nbsp;address&nbsp;always&nbsp;begins&nbsp;with&nbsp;a first-level&nbsp;fetch.&nbsp;(We&nbsp;<br>
n&nbsp;process&nbsp;<br>
ignore&nbsp;for now the&nbsp;TLB,&nbsp;which is&nbsp;only a&nbsp;cache to&nbsp;accelerate the&nbsp;process described&nbsp;<br>
below.)&nbsp;This uses&nbsp;the translation base address held in CP15&nbsp;register 2. Bits [31:14]&nbsp;<br>
of the&nbsp;translation&nbsp;base register are concatenated&nbsp;with&nbsp;bits [31:20] of&nbsp;the&nbsp;virtual&nbsp;<br>
address&nbsp;to&nbsp;form&nbsp;a memory&nbsp;address which is&nbsp;used to&nbsp;access the&nbsp;first-level&nbsp;descriptor&nbsp;<br>
as shown in&nbsp;Figure 11.3&nbsp;on page 304.&nbsp;<br>
The first-level descriptor&nbsp;may&nbsp;be either&nbsp;a section descriptor or&nbsp;a pointer to a&nbsp;<br>
second-level page table depending on&nbsp;its bottom&nbsp;two&nbsp;bits. '01'&nbsp;indicates a&nbsp;pointer&nbsp;to&nbsp;<br>
a second-level&nbsp;coarse&nbsp;page table;&nbsp;'10'&nbsp;indicates&nbsp;a section&nbsp;descriptor;&nbsp;'11'&nbsp;indicates&nbsp;a&nbsp;<br>
pointer to&nbsp;a&nbsp;second-level fine page&nbsp;table&nbsp;(only&nbsp;supported by&nbsp;certain&nbsp;CPUs).&nbsp;'00'&nbsp;<br>
should be used&nbsp;to indicate a descriptor&nbsp;that causes a translation fault.&nbsp;<br>
Section&nbsp;<br>
Where the&nbsp;first-level descriptor indicates&nbsp;that the virtual&nbsp;address translates into a&nbsp;<br>
translation&nbsp;<br>
section, the domain&nbsp;('Domain'&nbsp;in the section descriptor) is&nbsp;checked and,&nbsp;if the cur-<br>
rent&nbsp;process is&nbsp;a client of&nbsp;the domain, the&nbsp;access permissions&nbsp;('AP' in&nbsp;the section&nbsp;<br>
descriptor) are&nbsp;also checked. If the access&nbsp;is permissible,&nbsp;the&nbsp;memory&nbsp;address is&nbsp;<br>
formed&nbsp;by&nbsp;concatenating bits [31:20] of&nbsp;the&nbsp;section descriptor&nbsp;with&nbsp;bits [19:0]&nbsp;of&nbsp;the&nbsp;<br>
<hr>
<A name=316></a><IMG src="index-316_1.png"><br>
<b>304</b>&nbsp;<br>
<b>Architectural Support for Operating&nbsp;Systems</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;11.3 &nbsp;&nbsp;</b>First-level translation fetch.&nbsp;<br>
virtual&nbsp;address. This&nbsp;address&nbsp;is used&nbsp;to&nbsp;access the&nbsp;data&nbsp;in&nbsp;memory.&nbsp;The&nbsp;full&nbsp;section&nbsp;<br>
translation&nbsp;sequence is shown in Figure 11.4 on page 305.&nbsp;<br>
The&nbsp;operation&nbsp;of&nbsp;the&nbsp;access&nbsp;permission&nbsp;bits&nbsp;(AP) is&nbsp;described&nbsp;in&nbsp;'Access&nbsp;permis-<br>
sions'&nbsp;on&nbsp;page&nbsp;305,&nbsp;and the operation of the&nbsp;bufferable&nbsp;(B)&nbsp;and&nbsp;cacheable&nbsp;(C) bits is&nbsp;<br>
described in&nbsp;'Cache and&nbsp;write&nbsp;buffer control'&nbsp;on&nbsp;page&nbsp;308.&nbsp;<br>
Page translation&nbsp;<br>
Where the&nbsp;first-level descriptor indicates that the virtual address translates into a&nbsp;<br>
page,&nbsp;a&nbsp;further access&nbsp;is&nbsp;required&nbsp;to a second-level&nbsp;page&nbsp;table.&nbsp;The address&nbsp;of&nbsp;a&nbsp;<br>
second-level coarse page descriptor&nbsp;is&nbsp;formed by concatenating bits [31:10] of&nbsp;the&nbsp;<br>
first-level descriptor&nbsp;to bits [19:12] of&nbsp;the virtual address.&nbsp;The address of&nbsp;a&nbsp;<br>
second-level&nbsp;fine page descriptor&nbsp;is&nbsp;formed by&nbsp;concatenating bits [31:12] of the&nbsp;<br>
first-level descriptor&nbsp;to bits&nbsp;[19:10] of&nbsp;the virtual address.&nbsp;<br>
The&nbsp;second-level&nbsp;coarse&nbsp;page&nbsp;descriptor may be&nbsp;a&nbsp;large (64&nbsp;Kbyte)&nbsp;page&nbsp;descriptor&nbsp;<br>
or&nbsp;a small (4&nbsp;Kbyte)&nbsp;page&nbsp;descriptor,&nbsp;depending&nbsp;on&nbsp;its&nbsp;bottom&nbsp;two bits.&nbsp;'01'&nbsp;indicates&nbsp;a&nbsp;<br>
large page;&nbsp;'10'&nbsp;indicates a&nbsp;small page. Other values are trapped, and&nbsp;'00'&nbsp;should be&nbsp;<br>
used&nbsp;to&nbsp;generate&nbsp;a&nbsp;translation&nbsp;fault;&nbsp;'11'&nbsp;should&nbsp;not&nbsp;be&nbsp;used.&nbsp;A&nbsp;second-level&nbsp;fine&nbsp;page&nbsp;<br>
descriptor&nbsp;may also&nbsp;be&nbsp;a&nbsp;tiny&nbsp;(1&nbsp;Kbyte)&nbsp;page&nbsp;descriptor,&nbsp;indicated&nbsp;by&nbsp;'&nbsp;11'&nbsp;in its bottom&nbsp;<br>
two bits,&nbsp;or it&nbsp;may&nbsp;be a large&nbsp;or small page&nbsp;descriptor as&nbsp;above.&nbsp;<br>
A&nbsp;small page&nbsp;base&nbsp;address&nbsp;is&nbsp;held&nbsp;in&nbsp;bits&nbsp;[31:12]&nbsp;of&nbsp;the page&nbsp;descriptor. Bits [11:4]&nbsp;<br>
contain two access&nbsp;permission&nbsp;bits ('APO-3') for&nbsp;each&nbsp;of&nbsp;the four&nbsp;subpages, where&nbsp;a&nbsp;<br>
subpage is&nbsp;a quarter of&nbsp;the&nbsp;size of&nbsp;the page. Bits&nbsp;[3:2] contain&nbsp;the&nbsp;'bufferable'&nbsp;and&nbsp;<br>
'cacheable'&nbsp;bits. (Bits&nbsp;marked&nbsp;'?'&nbsp;have&nbsp;implementation-specific&nbsp;uses.)&nbsp;<br>
<hr>
<A name=317></a><IMG src="index-317_1.png"><br>
<b>ARM MMU architecture</b>&nbsp;<br>
<b>305</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure 11.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Section translation sequence.&nbsp;<br>
The&nbsp;overall&nbsp;translation&nbsp;sequence&nbsp;for&nbsp;a small&nbsp;page&nbsp;is shown in&nbsp;Figure&nbsp;11.5&nbsp;on&nbsp;<br>
page 306.&nbsp;The&nbsp;translation&nbsp;sequence&nbsp;for a large page is&nbsp;similar except bits [15:12] of&nbsp;<br>
the virtual&nbsp;address are used&nbsp;both&nbsp;in&nbsp;the page&nbsp;table&nbsp;index and in&nbsp;the&nbsp;page&nbsp;offset.&nbsp;Each&nbsp;<br>
page table entry&nbsp;for&nbsp;a large page&nbsp;must therefore&nbsp;be copied 16&nbsp;times in&nbsp;the page table&nbsp;<br>
for&nbsp;every value&nbsp;of these bits in&nbsp;the page table index.&nbsp;<br>
The tiny page translation&nbsp;scheme&nbsp;is also&nbsp;similar,&nbsp;but&nbsp;must start from&nbsp;a fine&nbsp;<br>
first-level descriptor. Tiny&nbsp;pages do not support subpages&nbsp;and therefore there is only&nbsp;<br>
one&nbsp;set&nbsp;of&nbsp;access permissions&nbsp;in&nbsp;the second-level&nbsp;descriptor.&nbsp;<br>
Access&nbsp;<br>
The AP&nbsp;bits for each section&nbsp;or&nbsp;subpage&nbsp;are&nbsp;used&nbsp;together with&nbsp;the domain&nbsp;informa-<br>
permissions&nbsp;<br>
tion in the&nbsp;first-level&nbsp;descriptor,&nbsp;the domain&nbsp;control information&nbsp;in CP15&nbsp;register&nbsp;3,&nbsp;<br>
the S and R control bits in CP15 register&nbsp;1&nbsp;and the user/supervisor&nbsp;state of the pro-<br>
cessor&nbsp;to determine&nbsp;whether&nbsp;a read or&nbsp;write&nbsp;access to&nbsp;the&nbsp;addressed location is per-<br>
missible. The permission checking&nbsp;operation&nbsp;proceeds&nbsp;as&nbsp;follows:&nbsp;<br>
<hr>
<A name=318></a><IMG src="index-318_1.png"><br>
<b>306</b>&nbsp;<br>
<b>Architectural Support for Operating&nbsp;Systems</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 11.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Small&nbsp;page&nbsp;translation sequence.&nbsp;<br>
1.&nbsp;&nbsp;If alignment&nbsp;checking is enabled&nbsp;(bit 1 of&nbsp;CP15 register&nbsp;1 is set) check&nbsp;the&nbsp;<br>
address alignment&nbsp;and&nbsp;fault if misaligned&nbsp;(that is, if a&nbsp;word is&nbsp;not aligned&nbsp;on&nbsp;a&nbsp;4-&nbsp;<br>
byte boundary&nbsp;or a half-word&nbsp;is not&nbsp;aligned&nbsp;on a 2-byte boundary).&nbsp;<br>
2.&nbsp;&nbsp;Identify&nbsp;the&nbsp;domain of&nbsp;the&nbsp;addressed location&nbsp;from&nbsp;bits&nbsp;[8:5]&nbsp;of the first-level&nbsp;<br>
descriptor.&nbsp;(Fetching&nbsp;the first-level&nbsp;descriptor&nbsp;will&nbsp;fault if&nbsp;the descriptor is&nbsp;invalid.)&nbsp;<br>
3.&nbsp;&nbsp;Check&nbsp;in&nbsp;CP15&nbsp;register&nbsp;3,&nbsp;the&nbsp;domain&nbsp;access control&nbsp;register,&nbsp;whether the current&nbsp;<br>
process is a client or&nbsp;manager of this domain; if neither, fault here.&nbsp;<br>
<hr>
<A name=319></a><IMG src="index-319_1.png"><br>
&nbsp;<br>
<b>Figure 11.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Access permission checking&nbsp;scheme.&nbsp;<br>
<b>Table 11.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Access permissions.&nbsp;<br>
&nbsp;<br>
AP&nbsp;&nbsp;&nbsp;<br>
s&nbsp;&nbsp;&nbsp;&nbsp;R&nbsp;<br>
Supervisor&nbsp;&nbsp;&nbsp;<br>
User&nbsp;&nbsp;&nbsp;<br>
00&nbsp;&nbsp;&nbsp;<br>
0 &nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;<br>
No access&nbsp;&nbsp;&nbsp;<br>
No access&nbsp;&nbsp;&nbsp;<br>
00&nbsp;&nbsp;<br>
1&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;Read only&nbsp;&nbsp;&nbsp;<br>
No access&nbsp;&nbsp;&nbsp;<br>
00&nbsp;&nbsp;<br>
0 &nbsp;&nbsp;1&nbsp;&nbsp;Read only&nbsp;&nbsp;&nbsp;<br>
Read only&nbsp;&nbsp;&nbsp;<br>
00&nbsp;&nbsp;<br>
1&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;<br>
Do not use&nbsp;&nbsp;&nbsp;<br>
01&nbsp;&nbsp;<br>
-&nbsp;&nbsp;&nbsp;<br>
-&nbsp;&nbsp;&nbsp;<br>
Read/write&nbsp;&nbsp;&nbsp;<br>
No access&nbsp;&nbsp;&nbsp;<br>
10&nbsp;&nbsp;<br>
-&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;&nbsp;&nbsp;&nbsp;Read/write&nbsp;&nbsp;&nbsp;<br>
Read only&nbsp;&nbsp;&nbsp;<br>
11&nbsp;&nbsp;&nbsp;<br>
- &nbsp;&nbsp;- &nbsp;<br>
Read/write&nbsp;&nbsp;&nbsp;<br>
Read/ write&nbsp;&nbsp;&nbsp;<br>
<hr>
<A name=320></a><b>308</b>&nbsp;<br>
<b>Architectural&nbsp;Support for Operating&nbsp;Systems</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
4. If a&nbsp;manager of this domain, proceed ignoring&nbsp;access permissions. If a client,&nbsp;<br>
check the&nbsp;access permissions against&nbsp;Table&nbsp;11.5 on page&nbsp;307 using&nbsp;the&nbsp;S and R&nbsp;<br>
bits from&nbsp;CP15&nbsp;register&nbsp;1. Fault&nbsp;if&nbsp;access is not&nbsp;permitted,&nbsp;otherwise continue to&nbsp;<br>
access data.&nbsp;<br>
The&nbsp;permission&nbsp;checking&nbsp;scheme&nbsp;is&nbsp;illustrated in&nbsp;Figure 11.6 on&nbsp;page&nbsp;307&nbsp;which&nbsp;<br>
shows&nbsp;the&nbsp;various&nbsp;faults that&nbsp;can be generated in&nbsp;the&nbsp;course&nbsp;of&nbsp;an&nbsp;address&nbsp;translation.&nbsp;<br>
The MMU&nbsp;may&nbsp;generate&nbsp;alignment,&nbsp;translation,&nbsp;domain and&nbsp;permission&nbsp;faults. In&nbsp;<br>
addition,&nbsp;the&nbsp;external&nbsp;memory system&nbsp;may&nbsp;fault on&nbsp;cache&nbsp;line&nbsp;fetches (though&nbsp;not all&nbsp;<br>
CPUs&nbsp;support this), uncached&nbsp;or&nbsp;unbuffered accesses&nbsp;(aborts&nbsp;on&nbsp;buffered&nbsp;writes&nbsp;are&nbsp;<br>
not&nbsp;supported)&nbsp;and&nbsp;translation&nbsp;table&nbsp;accesses.&nbsp;These faults are all called&nbsp;<i>aborts&nbsp;</i>and are&nbsp;<br>
handled&nbsp;by&nbsp;the&nbsp;processor&nbsp;as&nbsp;prefetch&nbsp;or&nbsp;data&nbsp;abort&nbsp;exceptions, depending&nbsp;on&nbsp;whether&nbsp;<br>
the&nbsp;access&nbsp;was&nbsp;for an&nbsp;instruction or&nbsp;for&nbsp;data.&nbsp;<br>
A&nbsp;fault on&nbsp;a&nbsp;data access causes the&nbsp;fault&nbsp;status&nbsp;register (CP15&nbsp;register 5) and&nbsp;the&nbsp;<br>
fault address&nbsp;register&nbsp;(CP15&nbsp;register 6) to&nbsp;be updated&nbsp;to&nbsp;provide information&nbsp;on&nbsp;the&nbsp;<br>
cause and location of&nbsp;the fault.&nbsp;A fault&nbsp;on&nbsp;an&nbsp;instruction&nbsp;access&nbsp;only&nbsp;causes&nbsp;an excep-<br>
tion&nbsp;if&nbsp;and&nbsp;when the&nbsp;instruction&nbsp;is&nbsp;executed (it may not be executed&nbsp;since&nbsp;it may be&nbsp;<br>
fetched just after&nbsp;a taken branch), and&nbsp;it does not update the&nbsp;fault&nbsp;status&nbsp;and&nbsp;address&nbsp;<br>
registers. The fault address&nbsp;may&nbsp;be deduced&nbsp;from&nbsp;the return address in the&nbsp;link register.&nbsp;<br>
Cache and&nbsp;write&nbsp;<br>
The C and B&nbsp;bits in the section and second-level page descriptors control whether&nbsp;<br>
buffer control&nbsp;<br>
the data&nbsp;in the section or&nbsp;page&nbsp;may be copied into a cache and/or&nbsp;written back&nbsp;to&nbsp;<br>
memory through&nbsp;a write&nbsp;buffer.&nbsp;<br>
Where the cache uses a write-through scheme, C controls&nbsp;whether or not&nbsp;the&nbsp;data&nbsp;is&nbsp;<br>
cacheable and B&nbsp;controls&nbsp;whether or&nbsp;not writes&nbsp;may be buffered. Where the cache&nbsp;uses&nbsp;<br>
a copy-back&nbsp;scheme&nbsp;the 'cached,&nbsp;unbuffered'&nbsp;combination&nbsp;may&nbsp;alternatively be used&nbsp;<br>
to&nbsp;specify&nbsp;a&nbsp;'write-through,&nbsp;buffered'&nbsp;behaviour. (This cache terminology&nbsp;is&nbsp;described&nbsp;<br>
in&nbsp;'Write strategies'&nbsp;on&nbsp;page 278.)&nbsp;<br>
External faults&nbsp;<br>
Note&nbsp;that the processor cannot recover&nbsp;from&nbsp;external&nbsp;faults signalled on&nbsp;buffered&nbsp;<br>
writes, because by the time&nbsp;the fault is signalled the processor&nbsp;may have executed&nbsp;<br>
several&nbsp;instructions and&nbsp;is therefore&nbsp;unable&nbsp;to&nbsp;recover its state&nbsp;to&nbsp;retry the faulting&nbsp;<br>
store instruction.&nbsp;Where&nbsp;recovery is&nbsp;required&nbsp;(for example,&nbsp;to&nbsp;allow the processor to&nbsp;<br>
retry&nbsp;a store instruction&nbsp;following a bus&nbsp;fault) unbuffered&nbsp;writes&nbsp;must be used.&nbsp;<br>
In typical ARM applications&nbsp;there&nbsp;are&nbsp;no&nbsp;potentially recoverable&nbsp;sources&nbsp;of external&nbsp;<br>
faults, so&nbsp;this&nbsp;is&nbsp;not&nbsp;an&nbsp;issue.&nbsp;<br>
<hr>
<A name=321></a><b>Synchronization</b>&nbsp;<br>
<b>309</b>&nbsp;<br>
11.7 &nbsp; Synchronization&nbsp;<br>
A standard&nbsp;problem&nbsp;in&nbsp;a system&nbsp;which runs&nbsp;multiple processes that&nbsp;share data&nbsp;struc-<br>
tures is&nbsp;to&nbsp;control accesses to&nbsp;the shared&nbsp;data&nbsp;to ensure&nbsp;correct behaviour.&nbsp;<br>
For example,&nbsp;consider&nbsp;a system&nbsp;where a set of&nbsp;sensor values&nbsp;is sampled and&nbsp;<br>
stored in&nbsp;memory by one process and used at arbitrary&nbsp;times by&nbsp;another.&nbsp;If it is&nbsp;<br>
important that&nbsp;the second process always&nbsp;sees&nbsp;a single snapshot&nbsp;of the&nbsp;values, care&nbsp;<br>
must be taken&nbsp;to ensure that&nbsp;the first process does not&nbsp;get swapped&nbsp;out and the&nbsp;<br>
second swapped in when the values are only&nbsp;partially&nbsp;updated.&nbsp;The&nbsp;mechanisms&nbsp;<br>
used to achieve&nbsp;this&nbsp;are called&nbsp;<b>process synchronization.&nbsp;</b>What is&nbsp;required is&nbsp;<i>mutu-</i><br>
<i>ally exclusive&nbsp;</i>access to the data structure.&nbsp;<br>
Mutual&nbsp;exclusion&nbsp;<br>
A process&nbsp;which is about to&nbsp;perform&nbsp;an operation on&nbsp;a shared data structure,&nbsp;where&nbsp;<br>
the operation&nbsp;requires that no other&nbsp;process is accessing&nbsp;the structure,&nbsp;must wait&nbsp;<br>
until&nbsp;no other process&nbsp;<i>is&nbsp;</i>accessing&nbsp;the&nbsp;data&nbsp;and then&nbsp;set&nbsp;some&nbsp;sort of&nbsp;lock&nbsp;to prevent&nbsp;<br>
another process&nbsp;from&nbsp;accessing it until&nbsp;it has&nbsp;finished the&nbsp;operation.&nbsp;<br>
One way to&nbsp;achieve mutual&nbsp;exclusion&nbsp;is to&nbsp;use&nbsp;a particular memory&nbsp;location to&nbsp;con-<br>
trol access to&nbsp;a data structure.&nbsp;For example, the location could contain a Boolean value&nbsp;<br>
indicating whether or not the data structure is currently&nbsp;in use. A process&nbsp;which&nbsp;<br>
wishes to&nbsp;use the&nbsp;data structure&nbsp;must wait&nbsp;until it&nbsp;is free,&nbsp;then&nbsp;mark it as&nbsp;busy while it&nbsp;<br>
uses&nbsp;the&nbsp;data, then&nbsp;mark&nbsp;it&nbsp;as free again&nbsp;when&nbsp;it&nbsp;has&nbsp;finished&nbsp;using it.&nbsp;The problem&nbsp;is&nbsp;<br>
that an interrupt&nbsp;can&nbsp;arise between the&nbsp;structure&nbsp;becoming free and it&nbsp;being marked as&nbsp;<br>
busy.&nbsp;The&nbsp;interrupt&nbsp;causes&nbsp;a&nbsp;process switch,&nbsp;the&nbsp;new&nbsp;process&nbsp;sees&nbsp;the&nbsp;structure&nbsp;is&nbsp;free,&nbsp;<br>
marks it&nbsp;as&nbsp;busy, changes&nbsp;it&nbsp;a&nbsp;bit and&nbsp;then another interrupt returns&nbsp;control to the&nbsp;first&nbsp;<br>
process which is&nbsp;in&nbsp;a state where it&nbsp;believes,&nbsp;now incorrectly,&nbsp;that&nbsp;the structure is free.&nbsp;<br>
A standard&nbsp;solution to&nbsp;this&nbsp;problem&nbsp;is&nbsp;to&nbsp;disable&nbsp;interrupts while the Boolean&nbsp;is&nbsp;<br>
tested&nbsp;and set.&nbsp;This&nbsp;works,&nbsp;but&nbsp;on&nbsp;a&nbsp;processor with&nbsp;a&nbsp;protected supervisor&nbsp;mode (such&nbsp;<br>
as the ARM)&nbsp;user-level&nbsp;code&nbsp;cannot&nbsp;disable&nbsp;interrupts,&nbsp;so&nbsp;a system&nbsp;call&nbsp;is&nbsp;required,&nbsp;<br>
which takes several&nbsp;clock cycles to&nbsp;complete&nbsp;and return&nbsp;control&nbsp;to the&nbsp;user&nbsp;process.&nbsp;<br>
SWAP&nbsp;<br>
A&nbsp;more&nbsp;efficient solution is&nbsp;to&nbsp;use an&nbsp;<b>atomic&nbsp;</b>(that is, uninterruptable)&nbsp;'test and&nbsp;set'&nbsp;<br>
instruction. The ARM 'SWAP'&nbsp;instruction (see Section&nbsp;5.13&nbsp;on&nbsp;page&nbsp;132) is&nbsp;just&nbsp;<br>
such an&nbsp;instruction&nbsp;which&nbsp;is&nbsp;included in&nbsp;the&nbsp;instruction&nbsp;set&nbsp;for exactly&nbsp;this&nbsp;purpose.&nbsp;<br>
A&nbsp;register&nbsp;is set to the&nbsp;'busy' value, then this&nbsp;register&nbsp;is&nbsp;swapped&nbsp;with&nbsp;the&nbsp;memory&nbsp;<br>
location containing the Boolean. If the loaded value is 'free'&nbsp;the process can con-<br>
tinue; if&nbsp;it is&nbsp;'busy'&nbsp;the&nbsp;process&nbsp;must&nbsp;wait, often by&nbsp;<b>spinning&nbsp;</b>(repeating&nbsp;the test until&nbsp;<br>
it gets the&nbsp;'free'&nbsp;result) on the&nbsp;lock.&nbsp;<br>
Note that this is&nbsp;the&nbsp;<i>only&nbsp;</i>reason for including&nbsp;SWAP in the&nbsp;ARM instruction set.&nbsp;It&nbsp;<br>
does&nbsp;not contribute to&nbsp;the&nbsp;processor's performance and its&nbsp;dynamic frequency&nbsp;of&nbsp;use is&nbsp;<br>
negligible. It&nbsp;is&nbsp;there just&nbsp;to&nbsp;provide&nbsp;this&nbsp;functionality.&nbsp;<br>
<hr>
<A name=322></a><b>310</b>&nbsp;<br>
<b>Architectural&nbsp;Support for Operating&nbsp;Systems</b>&nbsp;<br>
11.8 &nbsp; Context&nbsp;switching&nbsp;<br>
A process runs&nbsp;in a&nbsp;<b>context,&nbsp;</b>which is all the system&nbsp;state that&nbsp;must be established&nbsp;<br>
&nbsp;<br>
for the process to run&nbsp;correctly.&nbsp;This&nbsp;state&nbsp;includes:&nbsp;<br>
•&nbsp;&nbsp;the values of&nbsp;all of the processor's&nbsp;registers, including&nbsp;the&nbsp;program&nbsp;counter, stack&nbsp;<br>
pointer, and so on;&nbsp;<br>
•&nbsp;&nbsp;the values in the floating-point registers, if&nbsp;the process uses&nbsp;them;&nbsp;<br>
•&nbsp;&nbsp;the translation&nbsp;tables&nbsp;in&nbsp;memory&nbsp;(but not&nbsp;the contents&nbsp;of&nbsp;the TLB&nbsp;since it&nbsp;is just&nbsp;a&nbsp;<br>
cache of&nbsp;the&nbsp;values&nbsp;in&nbsp;memory&nbsp;and&nbsp;will&nbsp;automatically&nbsp;reload&nbsp;active&nbsp;values&nbsp;as&nbsp;they&nbsp;<br>
are used);&nbsp;<br>
•&nbsp;&nbsp;data values&nbsp;used&nbsp;by&nbsp;the process&nbsp;in&nbsp;memory&nbsp;(but not the values in&nbsp;the cache since&nbsp;<br>
they will automatically&nbsp;be&nbsp;reloaded&nbsp;when&nbsp;required).&nbsp;<br>
When a process switch takes&nbsp;place, the&nbsp;context of the old&nbsp;process&nbsp;must be&nbsp;saved&nbsp;<br>
and that&nbsp;of the&nbsp;new&nbsp;process restored&nbsp;(if&nbsp;it&nbsp;is&nbsp;resuming rather than&nbsp;starting for the first&nbsp;<br>
time).&nbsp;<br>
When to&nbsp;switch&nbsp;<br>
Context&nbsp;switching&nbsp;may occur&nbsp;as a&nbsp;result&nbsp;of an&nbsp;external interrupt,&nbsp;for example:&nbsp;<br>
•&nbsp;&nbsp;A timer interrupt&nbsp;causes the operating system&nbsp;to&nbsp;make a new process active&nbsp;<br>
according&nbsp;to a&nbsp;time-slicing algorithm.&nbsp;<br>
•&nbsp;&nbsp;A high-priority&nbsp;process which is waiting for a particular event&nbsp;is reactivated&nbsp;in&nbsp;<br>
response to&nbsp;that&nbsp;event.&nbsp;<br>
Alternatively,&nbsp;a&nbsp;process may&nbsp;run&nbsp;out of&nbsp;useful&nbsp;work&nbsp;and call&nbsp;the&nbsp;operating system&nbsp;to&nbsp;<br>
be&nbsp;made&nbsp;dormant&nbsp;until&nbsp;an&nbsp;external&nbsp;event occurs.&nbsp;<br>
In&nbsp;all cases, the operating&nbsp;system&nbsp;is given or&nbsp;takes control and&nbsp;is&nbsp;responsible&nbsp;for&nbsp;<br>
saving the old&nbsp;and restoring&nbsp;the new context. In an&nbsp;ARM-based system, this will&nbsp;<br>
normally&nbsp;take&nbsp;place while&nbsp;the&nbsp;processor&nbsp;is&nbsp;in&nbsp;supervisor mode.&nbsp;<br>
Register state&nbsp;<br>
If all&nbsp;context switches&nbsp;take place&nbsp;in&nbsp;response&nbsp;to&nbsp;IRQs or&nbsp;internal&nbsp;faults&nbsp;or&nbsp;supervisor&nbsp;<br>
calls,&nbsp;and the supervisor code does not re-enable interrupts,&nbsp;the&nbsp;process register&nbsp;<br>
state may be restricted&nbsp;to the&nbsp;user-mode&nbsp;registers. If&nbsp;context switches may&nbsp;take&nbsp;place&nbsp;<br>
in response&nbsp;to&nbsp;FIQs or supervisor code&nbsp;does re-enable interrupts, it&nbsp;may be neces-<br>
sary&nbsp;to save and&nbsp;restore some&nbsp;of&nbsp;the privileged&nbsp;mode&nbsp;registers as&nbsp;well.&nbsp;<br>
The 'architectural support'&nbsp;for register saving and restoring offered&nbsp;on the ARM&nbsp;<br>
recognizes&nbsp;the&nbsp;difficulty&nbsp;of saving&nbsp;and&nbsp;restoring&nbsp;user registers from&nbsp;a privileged mode&nbsp;<br>
and provides&nbsp;special instructions to assist&nbsp;in this task.&nbsp;These instructions are the&nbsp;<br>
special&nbsp;forms of&nbsp;the load and store&nbsp;multiple&nbsp;instructions&nbsp;(see&nbsp;Section 5.12 on&nbsp;<br>
page 130)&nbsp;which allow code&nbsp;running&nbsp;in&nbsp;a&nbsp;non-user&nbsp;mode to&nbsp;save&nbsp;and&nbsp;restore the user&nbsp;<br>
registers from&nbsp;an&nbsp;area&nbsp;of memory&nbsp;addressed&nbsp;by&nbsp;a&nbsp;non-user&nbsp;mode&nbsp;register.&nbsp;<br>
<hr>
<A name=323></a><b>Context&nbsp;switching</b>&nbsp;<br>
<b>311</b>&nbsp;<br>
Without&nbsp;these&nbsp;instructions,&nbsp;an operating&nbsp;system&nbsp;would have&nbsp;to&nbsp;switch into&nbsp;user&nbsp;<br>
mode&nbsp;to&nbsp;save or&nbsp;restore&nbsp;the banked user&nbsp;registers and then&nbsp;get&nbsp;back through&nbsp;the&nbsp;protec-<br>
tion barrier&nbsp;into&nbsp;supervisor&nbsp;mode. Though&nbsp;possible,&nbsp;this solution is&nbsp;inefficient.&nbsp;<br>
Floating-point&nbsp;<br>
The floating-point&nbsp;registers,&nbsp;whether held&nbsp;in&nbsp;a hardware coprocessor or&nbsp;maintained&nbsp;in&nbsp;<br>
state&nbsp;<br>
memory&nbsp;by&nbsp;a&nbsp;software&nbsp;emulator,&nbsp;represent&nbsp;part of the&nbsp;state of any&nbsp;process that&nbsp;uses&nbsp;<br>
them. Rather than add to&nbsp;the context&nbsp;switching overhead by&nbsp;saving and restoring them&nbsp;<br>
on every&nbsp;process swap,&nbsp;the&nbsp;operating system&nbsp;simply&nbsp;disables user-level&nbsp;use&nbsp;of the&nbsp;<br>
floating-point&nbsp;system&nbsp;when&nbsp;a&nbsp;process&nbsp;that&nbsp;uses&nbsp;floating-point&nbsp;is&nbsp;swapped&nbsp;out.&nbsp;If&nbsp;the&nbsp;<br>
new process attempts&nbsp;to&nbsp;use the floating-point system, the&nbsp;first use will&nbsp;trap. At that&nbsp;<br>
point&nbsp;the operating system&nbsp;will&nbsp;save the old process state and restore the new, then&nbsp;it&nbsp;<br>
will&nbsp;re-enable the floating-point&nbsp;system&nbsp;and the new process can use it&nbsp;freely.&nbsp;<br>
Thus&nbsp;the floating-point&nbsp;context&nbsp;switch overhead&nbsp;is&nbsp;incurred only&nbsp;when strictly&nbsp;<br>
necessary.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Translation state&nbsp;&nbsp;Where&nbsp;the&nbsp;old&nbsp;and&nbsp;new&nbsp;processes have&nbsp;independent&nbsp;translation tables a&nbsp;<i>heavy-weight&nbsp;</i><br>
process switch is required. The complete translation table structure can&nbsp;be switched&nbsp;<br>
simply&nbsp;by&nbsp;changing&nbsp;the&nbsp;base&nbsp;address&nbsp;of&nbsp;the&nbsp;first-level&nbsp;page&nbsp;table in&nbsp;CP15&nbsp;register&nbsp;2,&nbsp;<br>
but since this&nbsp;will invalidate existing TLB&nbsp;and&nbsp;(virtually addressed) cache&nbsp;entries,&nbsp;<br>
these&nbsp;must be flushed. The TLB&nbsp;and an&nbsp;instruction or write-through data&nbsp;cache can&nbsp;be&nbsp;<br>
flushed simply&nbsp;by&nbsp;marking all entries as invalid,&nbsp;which on an&nbsp;ARM&nbsp;processor chip&nbsp;<br>
requires a single CP15 instruction for each&nbsp;TLB or cache, but a copy-back cache&nbsp;must&nbsp;<br>
be purged&nbsp;of all&nbsp;dirty&nbsp;lines which may&nbsp;take many&nbsp;instructions.&nbsp;<br>
(Note that a&nbsp;physically addressed cache avoids this problem, but to&nbsp;date all ARM&nbsp;<br>
CPUs have&nbsp;used&nbsp;virtually addressed caches.)&nbsp;<br>
Where&nbsp;the&nbsp;old&nbsp;and&nbsp;new&nbsp;processes share&nbsp;the&nbsp;same&nbsp;translation tables a&nbsp;<i>light-weight&nbsp;</i><br>
process&nbsp;switch&nbsp;is&nbsp;required.&nbsp;The 'domain'&nbsp;mechanism&nbsp;in&nbsp;the&nbsp;ARM MMU&nbsp;architecture&nbsp;<br>
allows the&nbsp;protection state&nbsp;of&nbsp;16&nbsp;different subsets of&nbsp;the&nbsp;virtual address&nbsp;space to be&nbsp;<br>
reconfigured with&nbsp;a single update&nbsp;of CP15 register 3.&nbsp;<br>
In order to&nbsp;ensure that&nbsp;the cache does&nbsp;not&nbsp;represent a leak in the protection system,&nbsp;<br>
a cache access&nbsp;must be accompanied&nbsp;by a permission check. This could&nbsp;be&nbsp;achieved&nbsp;<br>
by storing the&nbsp;domain and access permission&nbsp;information along with the&nbsp;data in each&nbsp;<br>
cache line, but&nbsp;current ARM&nbsp;processors check permissions using information in the&nbsp;<br>
MMU concurrently with the cache access.&nbsp;<br>
<hr>
<A name=324></a>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<b>312</b>&nbsp;<br>
<b>Architectural&nbsp;Support for Operating&nbsp;Systems</b>&nbsp;<br>
11.9 &nbsp; Input/Output&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The&nbsp;input/output (I/O) functions&nbsp;are&nbsp;implemented&nbsp;in&nbsp;an ARM system&nbsp;using&nbsp;a&nbsp;combi-<br>
nation&nbsp;of&nbsp;memory-mapped addressable peripheral&nbsp;registers and the interrupt inputs.&nbsp;<br>
Some&nbsp;ARM systems&nbsp;may also&nbsp;include&nbsp;direct&nbsp;memory access (DMA)&nbsp;hardware.&nbsp;<br>
Memory-mapp<br>
A peripheral&nbsp;device,&nbsp;such&nbsp;as&nbsp;a serial&nbsp;line&nbsp;controller,&nbsp;contains a&nbsp;number&nbsp;of&nbsp;registers.&nbsp;<br>
ed&nbsp;peripherals&nbsp;<br>
In a&nbsp;memory-mapped system, each of these registers appears like a&nbsp;memory loca-<br>
tion at a particular address. (An alternative system&nbsp;organization&nbsp;might have I/O&nbsp;<br>
functions&nbsp;in a&nbsp;separate&nbsp;address space&nbsp;from&nbsp;memory&nbsp;devices.)&nbsp;A serial&nbsp;line controller&nbsp;<br>
may&nbsp;have&nbsp;a&nbsp;set&nbsp;of&nbsp;registers&nbsp;as&nbsp;follows:&nbsp;<br>
•&nbsp;&nbsp;A transmit&nbsp;data&nbsp;register&nbsp;(write&nbsp;only);&nbsp;data&nbsp;written&nbsp;to this&nbsp;location gets&nbsp;sent&nbsp;down&nbsp;<br>
the serial&nbsp;line.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;receive data register&nbsp;(read only); data&nbsp;arriving&nbsp;along the&nbsp;serial&nbsp;line is presented&nbsp;here.&nbsp;<br>
•&nbsp;&nbsp;A control register (read/write); this register&nbsp;sets the&nbsp;data&nbsp;rate and&nbsp;manages the&nbsp;<br>
RTS&nbsp;(request to&nbsp;send)&nbsp;and similar signals.&nbsp;<br>
•&nbsp;&nbsp;An interrupt enable register (read/write);&nbsp;this register controls which hardware&nbsp;<br>
events&nbsp;will&nbsp;generate&nbsp;an interrupt.&nbsp;<br>
•&nbsp;&nbsp;A status&nbsp;register (read&nbsp;only);&nbsp;this&nbsp;register&nbsp;indicates&nbsp;whether read&nbsp;data&nbsp;is&nbsp;available,&nbsp;<br>
whether&nbsp;the write&nbsp;buffer is full,&nbsp;and so&nbsp;on.&nbsp;<br>
To receive&nbsp;data, the&nbsp;software&nbsp;must set&nbsp;up&nbsp;the&nbsp;device&nbsp;appropriately,&nbsp;usually&nbsp;to&nbsp;gener-<br>
ate an interrupt when&nbsp;data&nbsp;is&nbsp;available&nbsp;or&nbsp;an&nbsp;error&nbsp;condition is&nbsp;detected. The interrupt&nbsp;<br>
routine must&nbsp;then&nbsp;copy&nbsp;the data&nbsp;into&nbsp;a&nbsp;buffer and check&nbsp;for error&nbsp;conditions.&nbsp;<br>
Memory-mapp<br>
ed issues&nbsp;<br>
Note that a&nbsp;memory-mapped peripheral&nbsp;register behaves differently&nbsp;from&nbsp;memory.&nbsp;<br>
Two&nbsp;consecutive reads to the read data&nbsp;register&nbsp;will probably&nbsp;deliver&nbsp;different results&nbsp;<br>
even though no&nbsp;write&nbsp;to that location has&nbsp;taken&nbsp;place. Whereas reads&nbsp;to true&nbsp;<br>
memory are idempotent (the read can be&nbsp;repeated&nbsp;many times, with&nbsp;identical&nbsp;<br>
results) a&nbsp;read to&nbsp;a peripheral may&nbsp;clear the current value&nbsp;and&nbsp;the next&nbsp;value&nbsp;may&nbsp;be&nbsp;<br>
different. Such&nbsp;locations are termed&nbsp;read-sensitive.&nbsp;<br>
Programs&nbsp;must be&nbsp;written&nbsp;very&nbsp;carefully&nbsp;where read-sensitive&nbsp;locations&nbsp;are&nbsp;<br>
involved, and, in&nbsp;particular,&nbsp;such locations must&nbsp;<i>not&nbsp;</i>be&nbsp;copied&nbsp;into&nbsp;a&nbsp;cache&nbsp;memory.&nbsp;<br>
In&nbsp;many&nbsp;ARM&nbsp;systems&nbsp;I/O locations are&nbsp;made inaccessible to user&nbsp;code, so the&nbsp;<br>
only&nbsp;way&nbsp;the&nbsp;devices can&nbsp;be&nbsp;accessed is&nbsp;through supervisor&nbsp;calls&nbsp;(SWIs) or through&nbsp;C&nbsp;<br>
library functions written&nbsp;to&nbsp;use&nbsp;those calls.&nbsp;<br>
Direct Memory&nbsp;<br>
Access&nbsp;<br>
Where&nbsp;I/O&nbsp;functions have&nbsp;a&nbsp;high&nbsp;data&nbsp;bandwidth, a considerable&nbsp;share&nbsp;of&nbsp;the proces-<br>
sor's&nbsp;performance may&nbsp;be&nbsp;consumed handling interrupts from&nbsp;the I/O system.&nbsp;Many&nbsp;<br>
systems employ DMA hardware&nbsp;to&nbsp;handle&nbsp;the lowest&nbsp;level I/O data&nbsp;transfers without&nbsp;<br>
<hr>
<A name=325></a><IMG src="index-325_1.png"><br>
<b>Input/Output</b>&nbsp;<br>
<b>313</b>&nbsp;<br>
processor assistance.&nbsp;Typically,&nbsp;the&nbsp;DMA hardware&nbsp;will&nbsp;handle&nbsp;the transfer of&nbsp;<br>
&nbsp;<br>
blocks of data from&nbsp;the peripheral into&nbsp;a&nbsp;buffer area&nbsp;in&nbsp;memory, interrupting&nbsp;the&nbsp;<br>
processor only&nbsp;if&nbsp;an&nbsp;error occurs&nbsp;or&nbsp;when&nbsp;the buffer becomes&nbsp;full. Thus&nbsp;the proces-<br>
sor sees&nbsp;an interrupt once per buffer&nbsp;rather&nbsp;than once per byte.&nbsp;<br>
Note,&nbsp;however, that the DMA data&nbsp;traffic&nbsp;will occupy some&nbsp;of the memory bus&nbsp;<br>
bandwidth,&nbsp;so&nbsp;the&nbsp;processor performance&nbsp;will&nbsp;still&nbsp;be&nbsp;reduced by&nbsp;the&nbsp;I/O&nbsp;activity&nbsp;<br>
(though&nbsp;far less&nbsp;than&nbsp;it&nbsp;would&nbsp;be&nbsp;if&nbsp;it&nbsp;were&nbsp;handling the data&nbsp;traffic on&nbsp;interrupts).&nbsp;<br>
Fast Interrupt&nbsp;<br>
The ARM&nbsp;fast&nbsp;interrupt (FIQ) architecture&nbsp;includes more banked registers&nbsp;than&nbsp;the&nbsp;<br>
Request&nbsp;<br>
other&nbsp;exception&nbsp;modes (see&nbsp;Figure&nbsp;2.1 on&nbsp;page&nbsp;39)&nbsp;in&nbsp;order to&nbsp;minimize the register&nbsp;<br>
save and restore overhead associated with&nbsp;handling&nbsp;one&nbsp;of these interrupts. The&nbsp;<br>
number of&nbsp;registers&nbsp;was&nbsp;chosen to&nbsp;be&nbsp;the&nbsp;number&nbsp;required&nbsp;to&nbsp;implement a software&nbsp;<br>
emulation&nbsp;of a DMA channel.&nbsp;<br>
If an&nbsp;ARM&nbsp;system&nbsp;with&nbsp;no&nbsp;DMA support&nbsp;has one&nbsp;source&nbsp;of&nbsp;I/O&nbsp;data&nbsp;traffic&nbsp;that&nbsp;has&nbsp;<br>
a significantly&nbsp;higher&nbsp;bandwidth requirement than&nbsp;the&nbsp;others, it&nbsp;is&nbsp;worth&nbsp;considering&nbsp;<br>
allocating the FIQ interrupt&nbsp;to this source&nbsp;and using IRQ to support&nbsp;all the other&nbsp;<br>
sources. It&nbsp;is far less effective&nbsp;to use FIQ for&nbsp;several&nbsp;different&nbsp;data&nbsp;sources at&nbsp;the same&nbsp;<br>
time, though switching it&nbsp;on a&nbsp;coarse&nbsp;granularity&nbsp;between sources may&nbsp;be appropriate.&nbsp;<br>
Interrupt&nbsp;latency&nbsp;<br>
An important&nbsp;parameter&nbsp;of a&nbsp;processor&nbsp;is&nbsp;its&nbsp;<b>interrupt latency.&nbsp;</b>This&nbsp;is a&nbsp;measure of&nbsp;<br>
how long&nbsp;it takes to&nbsp;respond&nbsp;to an interrupt in&nbsp;the&nbsp;worst case.&nbsp;For the ARM6 the&nbsp;<br>
worst-case&nbsp;FIQ latency&nbsp;is&nbsp;determined&nbsp;by&nbsp;the following&nbsp;components:&nbsp;<br>
1.&nbsp;&nbsp;The time&nbsp;for the request signal to&nbsp;pass through&nbsp;the FIQ synchronizing&nbsp;latches;&nbsp;<br>
this is&nbsp;three&nbsp;clock cycles&nbsp;(worst case).&nbsp;<br>
2.&nbsp;&nbsp;The time&nbsp;for the longest instruction (which&nbsp;is a load&nbsp;multiple of 16 registers) to&nbsp;<br>
complete; this&nbsp;is 20 clock cycles.&nbsp;<br>
3.&nbsp;&nbsp;The&nbsp;time&nbsp;for&nbsp;the&nbsp;data&nbsp;abort&nbsp;entry sequence;&nbsp;this&nbsp;is&nbsp;three&nbsp;clock&nbsp;cycles. (Remember&nbsp;<br>
that data abort has a higher priority&nbsp;than FIQ but does&nbsp;not&nbsp;mask FIQs out; see&nbsp;<br>
'Exception priorities'&nbsp;on page 111.)&nbsp;<br>
4.&nbsp;&nbsp;The time&nbsp;for the FIQ entry&nbsp;sequence; this&nbsp;is&nbsp;two clock cycles.&nbsp;<br>
The total worst-case latency is therefore&nbsp;28&nbsp;clock&nbsp;cycles. After this time&nbsp;the ARM6&nbsp;<br>
is executing&nbsp;the&nbsp;instruction at&nbsp;Ox 1C, the FIQ entry point. These cycles&nbsp;may&nbsp;be sequen-<br>
tial&nbsp;or&nbsp;non-sequential,&nbsp;and&nbsp;memory accesses&nbsp;may&nbsp;be&nbsp;further delayed if they&nbsp;address&nbsp;<br>
slow memory devices.&nbsp;The best-case&nbsp;latency is&nbsp;four clock cycles.&nbsp;<br>
The&nbsp;IRQ latency&nbsp;calculation is similar but&nbsp;must&nbsp;include&nbsp;an&nbsp;arbitrary delay&nbsp;for the&nbsp;<br>
longest FIQ routine&nbsp;to complete&nbsp;(since FIQ&nbsp;is&nbsp;higher priority&nbsp;than IRQ).&nbsp;<br>
Cache-l/O&nbsp;<br>
The usual&nbsp;assumption is&nbsp;that&nbsp;a cache&nbsp;makes a processor go&nbsp;faster.&nbsp;Normally&nbsp;this is&nbsp;<br>
interactions<br>
true,&nbsp;if&nbsp;the performance&nbsp;is&nbsp;averaged&nbsp;over a&nbsp;reasonable&nbsp;period.&nbsp;But&nbsp;in many&nbsp;cases&nbsp;<br>
&nbsp;<br>
interrupts&nbsp;are used&nbsp;where worst-case real-time&nbsp;response is&nbsp;critical; in these cases a&nbsp;<br>
<hr>
<A name=326></a><b>314</b>&nbsp;<br>
<b>Architectural&nbsp;Support for Operating&nbsp;Systems</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
cache&nbsp;can make&nbsp;the&nbsp;performance significantly worse.&nbsp;An MMU can&nbsp;make things&nbsp;<br>
worse still!&nbsp;<br>
Here is&nbsp;the worst-case interrupt&nbsp;latency&nbsp;sum&nbsp;for&nbsp;the&nbsp;ARM?&nbsp;10&nbsp;which&nbsp;we&nbsp;will&nbsp;meet&nbsp;<br>
in the&nbsp;next&nbsp;chapter. The&nbsp;latency is the&nbsp;sum&nbsp;of:&nbsp;<br>
1.&nbsp;&nbsp;The time&nbsp;for the request signal to&nbsp;pass through&nbsp;the FIQ synchronizing&nbsp;latches;&nbsp;<br>
this&nbsp;is&nbsp;three clock cycles&nbsp;(worst&nbsp;case)&nbsp;as&nbsp;before.&nbsp;<br>
2.&nbsp;&nbsp;The time&nbsp;for the longest instruction (which&nbsp;is a load&nbsp;multiple of 16 registers) to&nbsp;<br>
complete; this&nbsp;is 20 clock cycles as&nbsp;before,&nbsp;but...&nbsp;<br>
...this could cause the&nbsp;write buffer&nbsp;to&nbsp;flush,&nbsp;which can take&nbsp;up to 12 cycles, then&nbsp;<br>
incur three MMU&nbsp;TLB&nbsp;misses, adding 18&nbsp;clock cycles,&nbsp;and six&nbsp;cache&nbsp;misses,&nbsp;<br>
adding a further 24 cycles. The original 20 cycles overlap the&nbsp;line fetches, but&nbsp;<br>
the total&nbsp;cost&nbsp;for this&nbsp;stage&nbsp;can still&nbsp;reach 66&nbsp;cycles.&nbsp;<br>
3.&nbsp;&nbsp;The&nbsp;time&nbsp;for data&nbsp;abort&nbsp;entry sequence;&nbsp;this&nbsp;is&nbsp;three clock&nbsp;cycles&nbsp;as before,&nbsp;but...&nbsp;<br>
...the&nbsp;fetches&nbsp;from&nbsp;the vector&nbsp;space could&nbsp;add an MMU&nbsp;miss and a cache&nbsp;miss,&nbsp;<br>
increasing&nbsp;the&nbsp;cost to&nbsp;12 cycles.&nbsp;<br>
4.&nbsp;&nbsp;The time&nbsp;for&nbsp;the&nbsp;FIQ&nbsp;entry&nbsp;sequence;&nbsp;this&nbsp;is&nbsp;two clock cycles as&nbsp;before, but...&nbsp;<br>
...it could incur another cache&nbsp;miss,&nbsp;costing six cycles.&nbsp;<br>
The total is now 87 clock&nbsp;cycles,&nbsp;many&nbsp;of which are&nbsp;non-sequential&nbsp;memory&nbsp;<br>
accesses.&nbsp;So note&nbsp;that&nbsp;automatic&nbsp;mechanisms&nbsp;which&nbsp;support&nbsp;a memory hierarchy to&nbsp;<br>
speed&nbsp;up&nbsp;general-purpose&nbsp;programs&nbsp;<i>on average&nbsp;</i>often&nbsp;have&nbsp;the&nbsp;opposite effect on&nbsp;<br>
<i>worst-case&nbsp;</i>calculations&nbsp;for critical code&nbsp;segments.&nbsp;<br>
Reducing&nbsp;<br>
How can&nbsp;the latency be&nbsp;reduced when&nbsp;real-time&nbsp;constraints&nbsp;simply&nbsp;must be&nbsp;met?&nbsp;<br>
latency&nbsp;<br>
•&nbsp;&nbsp;A fixed area of fast on-chip&nbsp;RAM (for example, containing the&nbsp;vector space at&nbsp;<br>
the&nbsp;bottom&nbsp;of&nbsp;memory) will&nbsp;speed up exception&nbsp;entry.&nbsp;<br>
•&nbsp;&nbsp;Sections of the TLB and cache can&nbsp;be&nbsp;<b>locked down&nbsp;</b>to ensure that critical code&nbsp;<br>
segments&nbsp;never&nbsp;incur the&nbsp;miss penalty.&nbsp;<br>
Note&nbsp;that&nbsp;even&nbsp;in general-purpose&nbsp;systems&nbsp;where the&nbsp;cache&nbsp;and&nbsp;MMU&nbsp;are&nbsp;gener-<br>
ally&nbsp;beneficial&nbsp;there are often&nbsp;critical&nbsp;real-time constraints,&nbsp;for example for servicing&nbsp;<br>
disk&nbsp;data&nbsp;traffic or for&nbsp;managing&nbsp;the local&nbsp;area network.&nbsp;This is&nbsp;especially true in&nbsp;<br>
low-cost&nbsp;systems&nbsp;with&nbsp;little&nbsp;DMA&nbsp;hardware&nbsp;support.&nbsp;<br>
Other cache&nbsp;<br>
There are other things&nbsp;to&nbsp;watch out&nbsp;for when&nbsp;a cache&nbsp;is present,&nbsp;for&nbsp;example:&nbsp;<br>
issues&nbsp;<br>
•&nbsp;&nbsp;Caching assumes that an address will return the same&nbsp;data value each time&nbsp;it is&nbsp;<br>
read until&nbsp;a new value is written. I/O devices&nbsp;do not&nbsp;behave&nbsp;like this; each&nbsp;time&nbsp;<br>
you&nbsp;read them&nbsp;they&nbsp;give the next piece of&nbsp;data.&nbsp;<br>
<hr>
<A name=327></a><b>Input/Output</b>&nbsp;<br>
<b>315</b>&nbsp;<br>
• A cache&nbsp;fetches a&nbsp;block (which&nbsp;is typically&nbsp;around&nbsp;four&nbsp;words)&nbsp;of&nbsp;data at a time&nbsp;<br>
from&nbsp;sequential&nbsp;addresses.&nbsp;I/O&nbsp;devices&nbsp;often&nbsp;have&nbsp;different&nbsp;register&nbsp;functions&nbsp;at&nbsp;<br>
consecutive&nbsp;addresses; reading them&nbsp;all&nbsp;can&nbsp;give&nbsp;unpredictable&nbsp;results.&nbsp;<br>
Therefore the I/O area of&nbsp;memory is&nbsp;normally marked&nbsp;as uncacheable, and&nbsp;<br>
accesses bypass the cache.&nbsp;In general,&nbsp;caches&nbsp;interact badly with any&nbsp;<i>read-sensitive&nbsp;</i><br>
devices. Display&nbsp;frame&nbsp;buffers also&nbsp;need&nbsp;careful&nbsp;consideration and&nbsp;are&nbsp;often made&nbsp;<br>
uncacheable.&nbsp;<br>
Operating&nbsp;<br>
Normally,&nbsp;all the&nbsp;low-level&nbsp;detail of&nbsp;the I/O device&nbsp;registers and&nbsp;the handling&nbsp;of&nbsp;<br>
system issues&nbsp;<br>
interrupts is&nbsp;the responsibility of the operating&nbsp;system. A typical process&nbsp;will send&nbsp;<br>
data&nbsp;to&nbsp;the serial&nbsp;port&nbsp;by&nbsp;loading the&nbsp;next&nbsp;byte&nbsp;into&nbsp;r0&nbsp;and then making the appropriate&nbsp;<br>
supervisor call;&nbsp;the operating system&nbsp;will&nbsp;call&nbsp;a subroutine called&nbsp;a&nbsp;<b>device driver&nbsp;</b><br>
to&nbsp;check for&nbsp;the transmit buffer&nbsp;being&nbsp;empty, that the line is&nbsp;active, that&nbsp;no&nbsp;<br>
transmission&nbsp;errors&nbsp;occur,&nbsp;and&nbsp;so&nbsp;on.&nbsp;There may even&nbsp;be a&nbsp;call&nbsp;which allows&nbsp;the&nbsp;<br>
process to&nbsp;pass a&nbsp;pointer to the&nbsp;operating system&nbsp;which&nbsp;will then&nbsp;output a complete&nbsp;<br>
buffer of&nbsp;values.&nbsp;<br>
Since it&nbsp;takes some&nbsp;time to&nbsp;send a&nbsp;buffer&nbsp;full&nbsp;of&nbsp;data&nbsp;down&nbsp;a serial&nbsp;line, the operat-<br>
ing system&nbsp;may return control to the process until the transmit buffer&nbsp;has space&nbsp;for&nbsp;<br>
more data. An interrupt&nbsp;from&nbsp;the serial&nbsp;line&nbsp;hardware&nbsp;device returns control to&nbsp;the&nbsp;<br>
operating&nbsp;system, which&nbsp;refills&nbsp;the transmit&nbsp;buffer&nbsp;before returning&nbsp;control to&nbsp;the&nbsp;<br>
interrupted&nbsp;process. Further interrupts result in&nbsp;further transfers until the whole buffer&nbsp;<br>
has been sent.&nbsp;<br>
It&nbsp;may be the case that&nbsp;the process which&nbsp;requested the serial&nbsp;line activity&nbsp;runs&nbsp;out&nbsp;<br>
of&nbsp;useful&nbsp;work,&nbsp;or&nbsp;an&nbsp;interrupt&nbsp;from&nbsp;a timer or another&nbsp;source causes a&nbsp;different&nbsp;pro-<br>
cess to become active. The operating system&nbsp;must&nbsp;be careful, when modifying the&nbsp;<br>
translation tables, to ensure that it does not&nbsp;make the data buffer inaccessible to itself.&nbsp;<br>
It&nbsp;must&nbsp;also treat&nbsp;any&nbsp;requests from&nbsp;the second&nbsp;process to&nbsp;output&nbsp;data&nbsp;down&nbsp;the serial&nbsp;<br>
line with&nbsp;caution;&nbsp;they&nbsp;must&nbsp;not&nbsp;interfere with&nbsp;the ongoing&nbsp;transfer from&nbsp;the first pro-<br>
cess.&nbsp;<b>Resource allocation&nbsp;</b>is used&nbsp;to ensure that there are no&nbsp;conflicts in&nbsp;the&nbsp;use&nbsp;of&nbsp;<br>
shared resources.&nbsp;<br>
A process&nbsp;may request&nbsp;an output&nbsp;function and then go inactive until&nbsp;the output&nbsp;has&nbsp;<br>
completed, or it&nbsp;may go inactive until a particular input arrives. It&nbsp;can lodge a request&nbsp;<br>
with&nbsp;the operating&nbsp;system&nbsp;to&nbsp;be reactivated&nbsp;when&nbsp;the input/output&nbsp;<i>event&nbsp;</i>occurs.&nbsp;<br>
<hr>
<A name=328></a><b>316</b>&nbsp;<br>
<b>Architectural&nbsp;Support for Operating&nbsp;Systems</b>&nbsp;<br>
11.10 &nbsp; Example&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example&nbsp;11.1&nbsp;</b><br>
<b>Why,&nbsp;on&nbsp;the&nbsp;ARM, can&nbsp;user-level code not&nbsp;disable interrupts?</b>&nbsp;<br>
To allow a user to disable interrupts&nbsp;would&nbsp;make building a protected operating&nbsp;<br>
system&nbsp;impossible.&nbsp;The following code&nbsp;illustrates&nbsp;how&nbsp;a&nbsp;malicious&nbsp;user could&nbsp;<br>
destroy&nbsp;all&nbsp;the currently&nbsp;active&nbsp;programs:&nbsp;<br>
MSR&nbsp;<br>
CPSR_f,&nbsp;#&amp;cO&nbsp;<br>
; disable IRQ and FIQ ;&nbsp;<br>
HERE&nbsp;<br>
B&nbsp;<br>
HERE&nbsp;<br>
loop forever&nbsp;<br>
Once interrupts&nbsp;are disabled&nbsp;there is&nbsp;no way&nbsp;for the operating system&nbsp;to regain&nbsp;con-<br>
trol, so&nbsp;the&nbsp;program&nbsp;will&nbsp;loop forever.&nbsp;The&nbsp;only&nbsp;way&nbsp;out&nbsp;is a hard&nbsp;reset,&nbsp;which will&nbsp;<br>
destroy all&nbsp;currently active&nbsp;programs.&nbsp;<br>
If&nbsp;the&nbsp;user&nbsp;cannot&nbsp;disable&nbsp;interrupts&nbsp;the&nbsp;operating system&nbsp;can establish&nbsp;a regular&nbsp;<br>
periodic interrupt from&nbsp;a&nbsp;timer, so&nbsp;the&nbsp;infinite&nbsp;loop will&nbsp;be&nbsp;interrupted and the&nbsp;operat-<br>
ing system&nbsp;can schedule&nbsp;other&nbsp;programs. This&nbsp;program&nbsp;will&nbsp;either time-out,&nbsp;if the&nbsp;<br>
operating system&nbsp;has an&nbsp;upper limit on&nbsp;the&nbsp;amount&nbsp;of&nbsp;CPU&nbsp;time&nbsp;it&nbsp;is&nbsp;allowed&nbsp;to&nbsp;con-<br>
sume, or&nbsp;it&nbsp;will&nbsp;continue&nbsp;to&nbsp;loop&nbsp;whenever it&nbsp;gets switched&nbsp;in,&nbsp;running&nbsp;up&nbsp;a large bill&nbsp;<br>
on&nbsp;a system&nbsp;with&nbsp;accounting.&nbsp;<br>
<b>Exercise 11.1.1&nbsp;</b><br>
What minimum&nbsp;level&nbsp;of&nbsp;protection must&nbsp;be&nbsp;applied to&nbsp;the&nbsp;bottom&nbsp;of&nbsp;memory (where&nbsp;<br>
the exceptions&nbsp;vectors are&nbsp;located) in a&nbsp;secure operating system?&nbsp;<br>
<b>Exercise&nbsp;11.1.2&nbsp;</b><br>
If the ARM had no SWAP instruction,&nbsp;devise a hardware peripheral that&nbsp;could&nbsp;be&nbsp;<br>
used&nbsp;to&nbsp;support&nbsp;synchronization.&nbsp;(Hint:&nbsp;standard memory will not work;&nbsp;the location&nbsp;<br>
must&nbsp;be read-sensitive.)&nbsp;<br>
<hr>
<A name=329></a><IMG src="index-329_1.png"><br>
ARM CPU Cores&nbsp;<br>
&nbsp;<br>
Summary of chapter contents&nbsp;<br>
Although some&nbsp;ARM&nbsp;applications&nbsp;use a&nbsp;simple&nbsp;integer processor core&nbsp;as&nbsp;the&nbsp;basic&nbsp;<br>
processing&nbsp;component,&nbsp;others require&nbsp;tightly&nbsp;coupled&nbsp;functions&nbsp;such&nbsp;as&nbsp;cache&nbsp;<br>
memory&nbsp;and&nbsp;memory&nbsp;management&nbsp;hardware.&nbsp;ARM&nbsp;Limited offers&nbsp;a range of&nbsp;such&nbsp;<br>
'CPU' configurations&nbsp;based around&nbsp;its&nbsp;integer cores.&nbsp;<br>
The&nbsp;ARM CPU cores&nbsp;described&nbsp;here&nbsp;include&nbsp;the&nbsp;ARM710T,&nbsp;720T&nbsp;and&nbsp;740T,&nbsp;the&nbsp;<br>
ARM810 (now&nbsp;superseded&nbsp;by&nbsp;the&nbsp;ARM9 series), the StrongARM, the ARM920T&nbsp;and&nbsp;<br>
940T, and&nbsp;the&nbsp;ARM1020E.&nbsp;These&nbsp;CPUs encompass&nbsp;a&nbsp;range of&nbsp;pipeline and&nbsp;cache&nbsp;<br>
organizations&nbsp;and form a useful&nbsp;illustration&nbsp;of the issues&nbsp;which&nbsp;arise&nbsp;when design-<br>
ing&nbsp;high-performance&nbsp;processors&nbsp;for low-power&nbsp;applications.&nbsp;<br>
The primary&nbsp;role of a&nbsp;cache memory is&nbsp;to&nbsp;satisfy the processor core's instruction and&nbsp;<br>
data bandwidth&nbsp;requirements,&nbsp;so the&nbsp;cache&nbsp;organization&nbsp;is&nbsp;tightly&nbsp;coupled to&nbsp;the partic-<br>
ular processor&nbsp;core that it is to&nbsp;serve. In the context of system-on-chip designs the goal&nbsp;<br>
is for the cache to reduce the external memory bandwidth requirements&nbsp;of the CPU&nbsp;<br>
core to a&nbsp;level&nbsp;that can be&nbsp;handled by an&nbsp;on-chip bus.&nbsp;The&nbsp;higher-performance ARM&nbsp;<br>
processor cores would run little faster&nbsp;than the ARM7TDMI&nbsp;if they were connected&nbsp;<br>
directly to an AMBA bus,&nbsp;so they&nbsp;will always be&nbsp;used&nbsp;with fast&nbsp;local memory or cache.&nbsp;<br>
Memory management is another&nbsp;complex&nbsp;system&nbsp;function&nbsp;that&nbsp;must&nbsp;be&nbsp;tightly&nbsp;<br>
coupled to&nbsp;the&nbsp;processor&nbsp;core,&nbsp;whether&nbsp;it&nbsp;is a full translation-based system or&nbsp;a&nbsp;<br>
simpler protection unit.&nbsp;The ARM CPU cores&nbsp;integrate&nbsp;the processor core,&nbsp;cache(s),&nbsp;<br>
MMU(s) and (usually)&nbsp;an AMBA&nbsp;interface in&nbsp;a&nbsp;single&nbsp;macrocell.&nbsp;<br>
<b>317</b>&nbsp;<br>
<hr>
<A name=330></a><IMG src="index-330_1.png"><br>
<b>318</b>&nbsp;<br>
<b>ARM&nbsp;CPU Cores</b>&nbsp;<br>
12.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The ARM710T, ARM720T and ARM740T&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The ARM710T, ARM720T&nbsp;and&nbsp;ARM740T are&nbsp;based&nbsp;upon&nbsp;the ARM7TDMI&nbsp;proces-<br>
sor core&nbsp;(see&nbsp;Section&nbsp;9.1&nbsp;on&nbsp;page&nbsp;248),&nbsp;to&nbsp;which&nbsp;an&nbsp;8&nbsp;Kbyte&nbsp;mixed&nbsp;instruction&nbsp;cache&nbsp;<br>
and data cache&nbsp;has been added. External&nbsp;memory and peripherals are accessed via&nbsp;<br>
an AMBA bus master&nbsp;unit, and&nbsp;a write&nbsp;buffer&nbsp;and&nbsp;memory&nbsp;management&nbsp;(ARM71OT&nbsp;<br>
and 720T) unit or&nbsp;memory&nbsp;protection&nbsp;(ARM740T) unit are also&nbsp;incorporated.&nbsp;<br>
The organization of the ARM710T and ARM720T CPUs is similar and is illus-<br>
trated&nbsp;in Figure&nbsp;12.1.&nbsp;<br>
ARM710T&nbsp;cache&nbsp;<br>
Since&nbsp;the&nbsp;ARM7TDMI&nbsp;processor&nbsp;core has a&nbsp;single&nbsp;memory port it&nbsp;is&nbsp;logical&nbsp;for it&nbsp;to&nbsp;<br>
be paired with&nbsp;a unified instruction and data cache. The ARM710T incorporates&nbsp;<br>
such&nbsp;a cache, with a&nbsp;capacity&nbsp;of&nbsp;8&nbsp;Kbytes. The&nbsp;cache is&nbsp;organized&nbsp;with 16-byte&nbsp;lines&nbsp;<br>
and is 4-way&nbsp;set associative.&nbsp;A random&nbsp;replacement algorithm&nbsp;selects&nbsp;which of the&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;12.1 &nbsp;&nbsp;&nbsp;</b>ARM710T&nbsp;and ARM720T&nbsp;organization.&nbsp;<br>
<hr>
<A name=331></a><IMG src="index-331_1.png"><br>
<b>The&nbsp;ARM710T, ARM720T and&nbsp;ARM740T</b>&nbsp;<br>
<b>319</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
tag&nbsp;RAM&nbsp;I &nbsp;&nbsp;&nbsp;&nbsp;tag&nbsp;RAM&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tag&nbsp;RAM<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;12.2 &nbsp;&nbsp;</b>The ARM71OT&nbsp;cache organization.&nbsp;<br>
four possible locations will&nbsp;be overwritten&nbsp;by new&nbsp;data&nbsp;on a cache miss. The&nbsp;cache&nbsp;<br>
uses a&nbsp;write-through strategy&nbsp;as the target clock&nbsp;rate is only&nbsp;a few times&nbsp;higher than&nbsp;<br>
the&nbsp;rate&nbsp;at&nbsp;which standard&nbsp;off-chip memory&nbsp;devices&nbsp;can cycle.&nbsp;<br>
The organization of the ARM710T cache is illustrated in Figure 12.2.&nbsp;Bits&nbsp;[10:4] of&nbsp;<br>
the virtual address are used to index into each&nbsp;of the four tag stores. The tags contain&nbsp;<br>
bits&nbsp;[31:11]&nbsp;of&nbsp;the virtual&nbsp;addresses of the corresponding data, so these tags are com-<br>
pared&nbsp;with&nbsp;bits&nbsp;[31:11]&nbsp;of&nbsp;the&nbsp;current&nbsp;virtual&nbsp;address.&nbsp;If&nbsp;one of&nbsp;the&nbsp;tags&nbsp;matches,&nbsp;the&nbsp;<br>
cache has&nbsp;hit and the corresponding line can be&nbsp;accessed from&nbsp;the data RAM using&nbsp;<br>
the same&nbsp;index&nbsp;(bits&nbsp;[10:4]&nbsp;of&nbsp;the virtual&nbsp;address) together with&nbsp;two bits&nbsp;which encode&nbsp;<br>
the number of&nbsp;the&nbsp;tag&nbsp;store which&nbsp;produced&nbsp;the&nbsp;matching&nbsp;tag. Virtual&nbsp;address bits&nbsp;<br>
[3:2] select the&nbsp;word&nbsp;from&nbsp;the&nbsp;line and, if a&nbsp;byte or half-word access is requested, bits&nbsp;<br>
[1:0] select&nbsp;the&nbsp;byte or&nbsp;half-word&nbsp;from&nbsp;the word.&nbsp;<br>
It is interesting&nbsp;to&nbsp;compare&nbsp;the&nbsp;ARM710T cache&nbsp;organization&nbsp;with that of the&nbsp;<br>
ARM3&nbsp;and&nbsp;ARM610&nbsp;(described&nbsp;in&nbsp;detail in&nbsp;Section&nbsp;10.4 on&nbsp;page&nbsp;279) since they&nbsp;<br>
illustrate the sorts of issues that arise&nbsp;in&nbsp;designing a cache for&nbsp;both good&nbsp;performance&nbsp;<br>
and low-power&nbsp;operation. Although there&nbsp;is,&nbsp;as yet, no final&nbsp;word on the correct&nbsp;way&nbsp;to&nbsp;<br>
design a&nbsp;cache&nbsp;for this sort&nbsp;of&nbsp;application,&nbsp;the&nbsp;designer can be&nbsp;guided by the&nbsp;following&nbsp;<br>
observations on the examples&nbsp;presented in&nbsp;these ARM&nbsp;chips.&nbsp;<br>
<hr>
<A name=332></a><b>320</b>&nbsp;<br>
<b>ARM CPU Cores</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Cache speed&nbsp;<br>
High-associativity caches give the best hit&nbsp;rate,&nbsp;but require&nbsp;sequential&nbsp;CAM then&nbsp;<br>
RAM accesses which limits how fast the&nbsp;cycle time&nbsp;can become. Caches with a&nbsp;<br>
lower associativity&nbsp;can perform&nbsp;parallel tag&nbsp;and data accesses to give&nbsp;faster&nbsp;cycle&nbsp;<br>
times,&nbsp;and although a direct&nbsp;mapped&nbsp;cache&nbsp;has a&nbsp;significantly lower hit&nbsp;rate&nbsp;than a&nbsp;<br>
fully associative one,&nbsp;most&nbsp;of the associativity benefits&nbsp;accrue going&nbsp;from&nbsp;<br>
direct-mapped&nbsp;to&nbsp;2-&nbsp;or&nbsp;4-way&nbsp;associative;&nbsp;beyond&nbsp;4-way&nbsp;the&nbsp;benefits&nbsp;of&nbsp;increased&nbsp;<br>
associativity are small. However, a fully associative CAM-RAM cache is&nbsp;much&nbsp;<br>
simpler&nbsp;than&nbsp;a&nbsp;4-way associative RAM-RAM cache.&nbsp;<br>
Cache power&nbsp;<br>
CAM is somewhat power-hungry,&nbsp;requiring&nbsp;a parallel comparison&nbsp;with&nbsp;every&nbsp;entry&nbsp;<br>
on each&nbsp;cycle.&nbsp;Segmenting the cache&nbsp;by&nbsp;reducing the&nbsp;associativity a little and&nbsp;acti-<br>
vating&nbsp;only a subsection of&nbsp;the CAM&nbsp;reduces&nbsp;the&nbsp;power&nbsp;cost significantly for&nbsp;a small&nbsp;<br>
increase in&nbsp;complexity.&nbsp;<br>
In a&nbsp;static RAM the&nbsp;main&nbsp;users of power are the&nbsp;analogue&nbsp;sense-amplifiers.&nbsp;A&nbsp;<br>
4-way&nbsp;cache&nbsp;must activate&nbsp;four&nbsp;times as many sense-amplifiers&nbsp;in&nbsp;the&nbsp;tag store&nbsp;as&nbsp;a&nbsp;<br>
direct-mapped cache;&nbsp;if it exploits&nbsp;the&nbsp;speed&nbsp;advantage&nbsp;offered&nbsp;by parallel&nbsp;tag&nbsp;and&nbsp;data&nbsp;<br>
accesses,&nbsp;it&nbsp;will&nbsp;also&nbsp;uses&nbsp;four&nbsp;times as&nbsp;many&nbsp;sense-amplifiers&nbsp;in&nbsp;the&nbsp;data&nbsp;store.&nbsp;<br>
(RAM-RAM&nbsp;caches&nbsp;can, alternatively, perform&nbsp;serial&nbsp;tag&nbsp;and data&nbsp;accesses&nbsp;to&nbsp;save&nbsp;<br>
power, only&nbsp;activating a&nbsp;particular data&nbsp;RAM&nbsp;when&nbsp;a hit is&nbsp;detected in the correspond-<br>
ing tag store.)&nbsp;Waste power can be minimized by&nbsp;using&nbsp;self-timed power-down circuits&nbsp;<br>
to&nbsp;turn&nbsp;off the&nbsp;sense-amplifiers&nbsp;as soon as&nbsp;the&nbsp;data&nbsp;is valid, but&nbsp;the power used&nbsp;in&nbsp;the&nbsp;<br>
sense-amplifiers is still significant.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Sequential&nbsp;<br>
Where the processor is accessing memory locations which fall within&nbsp;the&nbsp;same&nbsp;cache&nbsp;<br>
accesses&nbsp;<br>
line it&nbsp;should&nbsp;be possible to&nbsp;bypass the&nbsp;tag&nbsp;look-up&nbsp;for all but&nbsp;the&nbsp;first&nbsp;access. The&nbsp;<br>
ARM generates a&nbsp;signal which indicates when the next&nbsp;memory access&nbsp;will be&nbsp;<br>
sequential&nbsp;to&nbsp;the&nbsp;current&nbsp;one,&nbsp;and&nbsp;this&nbsp;can&nbsp;be&nbsp;used,&nbsp;with&nbsp;the&nbsp;current&nbsp;address,&nbsp;to&nbsp;deduce&nbsp;<br>
that&nbsp;the access will&nbsp;fall&nbsp;in&nbsp;the&nbsp;same&nbsp;line.&nbsp;(This does&nbsp;not&nbsp;catch every access within&nbsp;the&nbsp;<br>
same&nbsp;line,&nbsp;but&nbsp;it&nbsp;catches&nbsp;nearly all&nbsp;of&nbsp;them&nbsp;and&nbsp;is&nbsp;very simple to&nbsp;implement.)&nbsp;<br>
Where&nbsp;an&nbsp;access&nbsp;will&nbsp;be&nbsp;in&nbsp;the&nbsp;same&nbsp;line, bypassing the tag&nbsp;look-up increases&nbsp;the&nbsp;<br>
access speed&nbsp;and saves&nbsp;power. Potentially, sequential&nbsp;accesses&nbsp;could use slower&nbsp;<br>
sense-amplifiers&nbsp;(possibly&nbsp;using&nbsp;standard&nbsp;logic&nbsp;rather&nbsp;than analogue circuits) and&nbsp;save&nbsp;<br>
considerable power, though care&nbsp;must be&nbsp;taken&nbsp;to ensure&nbsp;that&nbsp;an&nbsp;increased&nbsp;voltage&nbsp;<br>
swing&nbsp;on&nbsp;the&nbsp;bit lines&nbsp;does&nbsp;not&nbsp;cost&nbsp;more energy&nbsp;than&nbsp;is&nbsp;saved&nbsp;in&nbsp;the&nbsp;sense-amplifiers.&nbsp;<br>
Power&nbsp;<br>
The cache designer&nbsp;must&nbsp;remember that&nbsp;the goal is&nbsp;to&nbsp;minimize&nbsp;the&nbsp;overall&nbsp;system&nbsp;<br>
optimization&nbsp;<br>
power, not&nbsp;just the&nbsp;cache power.&nbsp;Off-chip&nbsp;accesses cost a lot&nbsp;more&nbsp;energy&nbsp;than&nbsp;<br>
on-chip&nbsp;accesses, so&nbsp;the first priority&nbsp;must be&nbsp;to&nbsp;find&nbsp;a&nbsp;cache organization&nbsp;which&nbsp;<br>
gives&nbsp;a good&nbsp;hit rate. Deciding&nbsp;between a&nbsp;highly&nbsp;associative&nbsp;CAM—RAM&nbsp;<br>
organization&nbsp;or&nbsp;a&nbsp;set-associative RAM—RAM&nbsp;organization requires&nbsp;a&nbsp;detailed&nbsp;<br>
investigation&nbsp;of&nbsp;all&nbsp;of&nbsp;the&nbsp;design&nbsp;issues,&nbsp;and&nbsp;may be&nbsp;strongly influenced&nbsp;by low-level&nbsp;<br>
circuit issues&nbsp;such as novel ways&nbsp;to build&nbsp;power-efficient&nbsp;sense-amplifiers&nbsp;or&nbsp;CAM&nbsp;<br>
hit detectors.&nbsp;<br>
<hr>
<A name=333></a><b>The&nbsp;ARM710T, ARM720T and&nbsp;</b>ARM740T&nbsp;<br>
<b>321</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Exploiting sequential accesses to save&nbsp;power&nbsp;and to&nbsp;increase&nbsp;performance&nbsp;is always&nbsp;<br>
a good idea. Typical dynamic execution statistics from&nbsp;the ARM show&nbsp;that&nbsp;75% of all&nbsp;<br>
accesses&nbsp;are sequential,&nbsp;and since sequential&nbsp;accesses&nbsp;are fundamentally easier to deal&nbsp;<br>
with, this seems to be a&nbsp;statistic&nbsp;that&nbsp;should not&nbsp;be overlooked. Where&nbsp;<br>
power-efficiency&nbsp;is&nbsp;paramount,&nbsp;it&nbsp;may&nbsp;be worth&nbsp;sacrificing&nbsp;performance by&nbsp;making&nbsp;<br>
nonsequential&nbsp;accesses&nbsp;take&nbsp;two clock cycles; this&nbsp;will&nbsp;only reduce&nbsp;performance&nbsp;by&nbsp;<br>
about&nbsp;25% and&nbsp;may&nbsp;reduce the cache&nbsp;power requirements by&nbsp;a factor of two or&nbsp;three.&nbsp;<br>
An&nbsp;interesting&nbsp;question for research&nbsp;into&nbsp;low&nbsp;power&nbsp;is&nbsp;to ask whether&nbsp;the&nbsp;best cache&nbsp;<br>
organization for power-efficiency&nbsp;is&nbsp;necessarily&nbsp;the same&nbsp;as the&nbsp;best&nbsp;organization for&nbsp;<br>
high&nbsp;performance&nbsp;<br>
ARM710TMMU&nbsp;<br>
The ARM710T memory management&nbsp;unit&nbsp;implements&nbsp;the ARM memory manage-<br>
ment&nbsp;architecture described&nbsp;in Section 11.6 on page 302&nbsp;using&nbsp;the&nbsp;system&nbsp;control&nbsp;<br>
coprocessor described in&nbsp;Section 11.5 on page 298.&nbsp;<br>
The translation look-aside&nbsp;buffer (TLB)&nbsp;is&nbsp;a&nbsp;64-entry associative&nbsp;cache&nbsp;of&nbsp;recently&nbsp;<br>
used&nbsp;translations&nbsp;which&nbsp;accelerates the&nbsp;translation process by&nbsp;removing&nbsp;the need&nbsp;for&nbsp;<br>
the 2-stage table&nbsp;look-up&nbsp;in&nbsp;a&nbsp;high&nbsp;proportion of accesses.&nbsp;<br>
ARM710T write&nbsp;<br>
The&nbsp;write buffer holds&nbsp;four&nbsp;addresses and&nbsp;eight&nbsp;data&nbsp;words.&nbsp;The&nbsp;memory&nbsp;manage-<br>
buffer&nbsp;<br>
ment unit defines&nbsp;which addresses are bufferable. Each address&nbsp;may be&nbsp;associated&nbsp;<br>
with&nbsp;any&nbsp;number of the data&nbsp;words,&nbsp;so&nbsp;the&nbsp;write&nbsp;buffer may hold&nbsp;one word&nbsp;(or&nbsp;byte)&nbsp;<br>
of data to&nbsp;write to one address&nbsp;and seven&nbsp;words to write&nbsp;to&nbsp;another address, or two&nbsp;<br>
blocks&nbsp;of&nbsp;four&nbsp;words&nbsp;to&nbsp;write to&nbsp;different&nbsp;addresses,&nbsp;and so on. The&nbsp;data&nbsp;words asso-<br>
ciated with a particular address are&nbsp;written to&nbsp;sequential&nbsp;memory locations starting&nbsp;<br>
at&nbsp;that&nbsp;address.&nbsp;<br>
(Clearly&nbsp;multiple&nbsp;data&nbsp;words associated&nbsp;with&nbsp;one address are generated principally&nbsp;<br>
by store&nbsp;multiple&nbsp;register instructions,&nbsp;the only&nbsp;other potential&nbsp;source being&nbsp;a data&nbsp;<br>
transfer from&nbsp;an&nbsp;external&nbsp;coprocessor.)&nbsp;<br>
The&nbsp;mapping&nbsp;is illustrated in&nbsp;Figure 12.3&nbsp;on page 322,&nbsp;which shows the first&nbsp;<br>
address mapping six data words and&nbsp;the second&nbsp;and third addresses mapping one&nbsp;data&nbsp;<br>
word each. The fourth address is&nbsp;currently unused.&nbsp;The&nbsp;write buffer&nbsp;becomes&nbsp;full&nbsp;<br>
either when&nbsp;all&nbsp;four&nbsp;addresses&nbsp;are&nbsp;used&nbsp;or&nbsp;when all&nbsp;eight&nbsp;data&nbsp;words&nbsp;are&nbsp;full.&nbsp;<br>
The processor can&nbsp;write&nbsp;into&nbsp;the buffer at&nbsp;the&nbsp;fast (cache) clock speed and&nbsp;continue&nbsp;<br>
executing&nbsp;instructions from&nbsp;the cache while&nbsp;the&nbsp;write&nbsp;buffer&nbsp;stores the data&nbsp;to&nbsp;memory&nbsp;<br>
at&nbsp;the&nbsp;memory&nbsp;clock rate. The&nbsp;processor is&nbsp;therefore fully decoupled from&nbsp;the memory&nbsp;<br>
speed&nbsp;so&nbsp;long&nbsp;as the&nbsp;instructions&nbsp;and data&nbsp;it&nbsp;needs&nbsp;are in&nbsp;the cache&nbsp;and the write&nbsp;buffer&nbsp;<br>
is not full when&nbsp;it&nbsp;comes to&nbsp;perform&nbsp;a write operation.&nbsp;The&nbsp;write buffer gives&nbsp;a per-<br>
formance benefit of&nbsp;around&nbsp;15%&nbsp;for a modest&nbsp;hardware&nbsp;cost.&nbsp;<br>
The&nbsp;principal&nbsp;drawback of&nbsp;the&nbsp;write&nbsp;buffer is&nbsp;that&nbsp;it&nbsp;is not&nbsp;possible&nbsp;to recover from&nbsp;<br>
external memory faults&nbsp;caused by&nbsp;buffered writes since&nbsp;the&nbsp;processor state is&nbsp;not&nbsp;<br>
recoverable.&nbsp;The&nbsp;processor&nbsp;can still&nbsp;support&nbsp;virtual memory&nbsp;since translation faults&nbsp;are&nbsp;<br>
detected in the on-chip MMU, so the exception is raised&nbsp;before the data&nbsp;gets to the&nbsp;<br>
<hr>
<A name=334></a><IMG src="index-334_1.png"><br>
<b>322</b>&nbsp;<br>
<b>ARM&nbsp;CPU&nbsp;Cores</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;12.3 &nbsp;&nbsp;</b>Write&nbsp;buffer&nbsp;mapping example.&nbsp;<br>
write&nbsp;buffer.&nbsp;But,&nbsp;for example,&nbsp;a&nbsp;memory&nbsp;error correction&nbsp;scheme&nbsp;based&nbsp;on&nbsp;software&nbsp;<br>
error&nbsp;recovery cannot&nbsp;be&nbsp;supported&nbsp;if&nbsp;buffered&nbsp;writes are&nbsp;enabled.&nbsp;<br>
ARM710T&nbsp;Silicon &nbsp;&nbsp; &nbsp;The&nbsp;characteristics&nbsp;of&nbsp;an&nbsp;ARM710T implemented on&nbsp;a 0.35&nbsp;urn CMOS process&nbsp;<br>
are&nbsp;summarized&nbsp;in&nbsp;Table 12.1.&nbsp;<br>
<b>Table&nbsp;12.1 &nbsp; &nbsp;</b>ARM710T characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.35&nbsp;<i>\im</i></b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>N/A&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>53</b>&nbsp;&nbsp;&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3</b>&nbsp;&nbsp;<b>Core area</b>&nbsp;&nbsp;&nbsp;<br>
<b>11.7mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>240 mW</b>&nbsp;&nbsp;&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>3.3V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>0-59&nbsp;MHz&nbsp;MIPSAV</b>&nbsp;<br>
<b>220</b>&nbsp;&nbsp;&nbsp;<br>
ARM720T&nbsp;<br>
The&nbsp;ARM720T is&nbsp;very similar to&nbsp;the&nbsp;ARM710T&nbsp;with&nbsp;the following extensions:&nbsp;<br>
•&nbsp;&nbsp;Virtual&nbsp;addresses&nbsp;in the&nbsp;bottom&nbsp;32&nbsp;Mbytes&nbsp;of the&nbsp;address space&nbsp;can&nbsp;be&nbsp;relocated&nbsp;to&nbsp;<br>
the 32 Mbyte&nbsp;memory area specified in&nbsp;the&nbsp;ProcessID&nbsp;register (CP15 register 13).&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;exception vectors can be moved&nbsp;from&nbsp;the&nbsp;bottom&nbsp;of memory&nbsp;to OxffffOOOO,&nbsp;<br>
thereby&nbsp;preventing&nbsp;them&nbsp;from&nbsp;being&nbsp;translated&nbsp;by&nbsp;the&nbsp;above&nbsp;mechanism.&nbsp;This&nbsp;<br>
function is controlled by&nbsp;the&nbsp;'V bit in CP15&nbsp;register 1.&nbsp;<br>
These extensions&nbsp;are intended&nbsp;to enhance the&nbsp;ability of&nbsp;the&nbsp;CPU core to&nbsp;support the&nbsp;<br>
Windows CE operating system. They are implemented in&nbsp;the CP15 MMU control reg-<br>
isters&nbsp;described&nbsp;in&nbsp;Section&nbsp;11.5&nbsp;on&nbsp;page&nbsp;298.&nbsp;<br>
ARM740T&nbsp;<br>
The ARM740T&nbsp;differs from&nbsp;the ARM710T&nbsp;only in&nbsp;having&nbsp;a&nbsp;simpler memory&nbsp;pro-<br>
tection unit in&nbsp;place of the 710T's&nbsp;memory&nbsp;management unit. The&nbsp;memory&nbsp;protec-<br>
tion unit implements the architecture described in Section 11.4 on&nbsp;page&nbsp;297 using&nbsp;<br>
the system&nbsp;control&nbsp;coprocessor described in&nbsp;Section 11.3 on&nbsp;page 294.&nbsp;<br>
The protection&nbsp;unit&nbsp;does not support&nbsp;virtual&nbsp;to&nbsp;physical memory&nbsp;address translation,&nbsp;<br>
but&nbsp;provides&nbsp;basic protection and&nbsp;cache&nbsp;control functionality&nbsp;in&nbsp;a lower cost&nbsp;form. This&nbsp;<br>
<hr>
<A name=335></a><b>TheARMSIO</b>&nbsp;<br>
<b>323</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
is&nbsp;of&nbsp;benefit&nbsp;to&nbsp;embedded applications that&nbsp;run fixed&nbsp;software&nbsp;systems where&nbsp;the over-<br>
head of full&nbsp;address&nbsp;translation cannot be&nbsp;justified. There&nbsp;are&nbsp;also performance and&nbsp;<br>
power-efficiency&nbsp;advantages in&nbsp;omitting&nbsp;address&nbsp;translation&nbsp;hardware (where it&nbsp;is&nbsp;not&nbsp;<br>
needed), since a&nbsp;TLB miss&nbsp;results in&nbsp;several&nbsp;external&nbsp;memory&nbsp;accesses.&nbsp;<br>
The organization of the ARM740T is&nbsp;illustrated in&nbsp;Figure 12.4 on&nbsp;page 324.&nbsp;<br>
ARM740T&nbsp;silicon&nbsp;<br>
The characteristics of an ARM740T implemented on a 0.35 um&nbsp;CMOS process are&nbsp;<br>
summarized in Table&nbsp;12.2.&nbsp;<br>
As can&nbsp;be&nbsp;seen&nbsp;from&nbsp;Table&nbsp;12.2,&nbsp;the&nbsp;general&nbsp;characteristics&nbsp;of&nbsp;the&nbsp;ARM740T are&nbsp;<br>
the same&nbsp;as those of the ARM710T and 720T&nbsp;as&nbsp;listed&nbsp;in&nbsp;Table 12.1 on page&nbsp;322. The&nbsp;<br>
only&nbsp;significant&nbsp;differences are the saving of&nbsp;just&nbsp;under 2 mm2&nbsp;of core area&nbsp;due to the&nbsp;<br>
omission of the MMU, and the reduced power&nbsp;consumption.&nbsp;<br>
<b>Table&nbsp;12.2 &nbsp;&nbsp;&nbsp;</b>ARM740T characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.35 um</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;<br>
<b>N/A&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>53</b>&nbsp;&nbsp;&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3</b>&nbsp;&nbsp;<b>Core area</b>&nbsp;&nbsp;&nbsp;<br>
<b>9.8 mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>175 mW</b>&nbsp;&nbsp;&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>3.3V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>0-59 MHz&nbsp;MIPS/W</b>&nbsp;&nbsp;&nbsp;<br>
<b>300</b>&nbsp;&nbsp;&nbsp;<br>
12.2 &nbsp; TheARMSIO&nbsp;<br>
The ARMS&nbsp;10&nbsp;is&nbsp;a high-performance ARM&nbsp;CPU chip&nbsp;with&nbsp;an&nbsp;on-chip&nbsp;cache&nbsp;and&nbsp;<br>
memory&nbsp;management&nbsp;unit.&nbsp;It&nbsp;was the first implementation of the&nbsp;ARM instruction&nbsp;<br>
set&nbsp;developed&nbsp;by&nbsp;ARM&nbsp;Limited to&nbsp;use&nbsp;a&nbsp;fundamentally&nbsp;different&nbsp;pipeline structure&nbsp;<br>
from&nbsp;that used on the original ARM chip&nbsp;designed at&nbsp;Acorn Computers&nbsp;and carried&nbsp;<br>
through to&nbsp;ARM6&nbsp;and ARM7. The ARMS&nbsp;10 has now been superseded by&nbsp;the&nbsp;<br>
ARM9&nbsp;series.&nbsp;<br>
The ARMS&nbsp;core&nbsp;is&nbsp;the&nbsp;integer processing unit&nbsp;used&nbsp;in&nbsp;the ARMS 10. It&nbsp;was&nbsp;<br>
described&nbsp;in&nbsp;Section 9.2 on page 256. The ARMS&nbsp;10 adds&nbsp;the following on-chip&nbsp;sup-<br>
port to&nbsp;the&nbsp;basic CPU:&nbsp;<br>
• An&nbsp;8 Kbyte virtually addressed&nbsp;unified&nbsp;instruction&nbsp;and&nbsp;data cache using&nbsp;a&nbsp;<br>
copy-back (or write-through,&nbsp;controlled by&nbsp;the page&nbsp;table entry) write strategy&nbsp;<br>
and&nbsp;offering&nbsp;a double-bandwidth&nbsp;capability&nbsp;as&nbsp;required&nbsp;by the&nbsp;ARMS core. The&nbsp;<br>
cache is&nbsp;64-way associative,&nbsp;and constructed&nbsp;from&nbsp;1 Kbyte components to&nbsp;<br>
simplify&nbsp;the future development&nbsp;of&nbsp;a smaller cache&nbsp;for an&nbsp;embedded&nbsp;system&nbsp;chip&nbsp;<br>
or&nbsp;a&nbsp;larger&nbsp;cache&nbsp;on&nbsp;a more&nbsp;advanced&nbsp;process technology.&nbsp;It&nbsp;is&nbsp;designed&nbsp;so&nbsp;that&nbsp;<br>
areas of&nbsp;the&nbsp;<br>
<hr>
<A name=336></a><IMG src="index-336_1.png"><br>
<b>324</b>&nbsp;<br>
<b>ARM CPU Cores</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;12.4 &nbsp;&nbsp;</b>ARM740T&nbsp;organization.&nbsp;<br>
cache can be&nbsp;'locked down'&nbsp;to&nbsp;ensure that speed-critical sections of code, which&nbsp;<br>
arise&nbsp;in&nbsp;many&nbsp;embedded&nbsp;applications,&nbsp;do&nbsp;not&nbsp;get&nbsp;flushed.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;memory&nbsp;management&nbsp;unit&nbsp;conforming&nbsp;to&nbsp;the&nbsp;ARM&nbsp;MMU&nbsp;architecture&nbsp;<br>
described in&nbsp;Section 11.6 on&nbsp;page 302&nbsp;using&nbsp;the system&nbsp;control coprocessor&nbsp;<br>
described in&nbsp;Section 11.5 on&nbsp;page 298.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;write&nbsp;buffer&nbsp;to&nbsp;allow the processor to&nbsp;continue&nbsp;while&nbsp;the&nbsp;write to&nbsp;external&nbsp;<br>
memory&nbsp;completes.&nbsp;<br>
The&nbsp;organization&nbsp;of the ARM810&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;Figure&nbsp;12.5 on&nbsp;page&nbsp;325.&nbsp;<br>
Double-ba<br>
The&nbsp;core's double-bandwidth&nbsp;requirement is&nbsp;satisfied&nbsp;by&nbsp;the cache;&nbsp;external&nbsp;memory&nbsp;<br>
ndwidth&nbsp;<br>
accesses&nbsp;use conventional line&nbsp;refill&nbsp;and&nbsp;individual data&nbsp;transfer protocols.&nbsp;<br>
cache&nbsp;<br>
Double-bandwidth is available from&nbsp;the&nbsp;cache only for&nbsp;sequential&nbsp;memory accesses,&nbsp;<br>
so it&nbsp;is&nbsp;exploited by the prefetch unit&nbsp;for instruction&nbsp;fetches and by&nbsp;the core&nbsp;for load&nbsp;<br>
multiple register instructions.&nbsp;<br>
Since the pipeline organization&nbsp;used&nbsp;on&nbsp;ARM7TDMI&nbsp;uses&nbsp;the memory&nbsp;interface&nbsp;<br>
almost every cycle, some&nbsp;way&nbsp;must be found&nbsp;to&nbsp;increase&nbsp;the available memory&nbsp;band-<br>
width&nbsp;if&nbsp;the&nbsp;CPI (the&nbsp;number of&nbsp;clocks&nbsp;per&nbsp;instruction)&nbsp;of&nbsp;the&nbsp;processor is&nbsp;to&nbsp;be&nbsp;<br>
<hr>
<A name=337></a><IMG src="index-337_1.png"><br>
<b>The ARM810</b>&nbsp;<br>
<b>325</b>&nbsp;<br>
&nbsp;<br>
improved. The&nbsp;StrongARM&nbsp;(described in&nbsp;the next section) achieves an increased&nbsp;<br>
bandwidth&nbsp;by&nbsp;incorporating separate&nbsp;instruction&nbsp;and data&nbsp;caches,&nbsp;thereby&nbsp;making&nbsp;<br>
double&nbsp;the&nbsp;bandwidth&nbsp;potentially&nbsp;available (though&nbsp;not&nbsp;all&nbsp;of this&nbsp;bandwidth can&nbsp;be&nbsp;<br>
used since the ARM&nbsp;generates instruction traffic with&nbsp;around twice the bandwidth&nbsp;of&nbsp;<br>
the&nbsp;data traffic,&nbsp;so&nbsp;the&nbsp;effective increase in&nbsp;bandwidth is approximately&nbsp;50%). The&nbsp;<br>
ARMS 10 delivers an increased bandwidth&nbsp;by&nbsp;returning&nbsp;two&nbsp;sequential&nbsp;words&nbsp;per&nbsp;<br>
clock cycle which, since typically around 75% of an ARM's&nbsp;memory&nbsp;accesses&nbsp;are&nbsp;<br>
sequential,&nbsp;increases the usable&nbsp;bandwidth&nbsp;by&nbsp;about&nbsp;60%. Although the ARMS&nbsp;10&nbsp;<br>
approach gives&nbsp;more bandwidth, it&nbsp;also creates&nbsp;more opportunity&nbsp;for conflict&nbsp;between&nbsp;<br>
instruction and data accesses; evaluating the&nbsp;relative&nbsp;merits&nbsp;of the two approaches is&nbsp;<br>
not&nbsp;straightforward.&nbsp;<br>
As the cache uses a copy-back write strategy&nbsp;and is virtually addressed, evicting&nbsp;a&nbsp;<br>
dirty line requires an address&nbsp;translation.&nbsp;The&nbsp;mechanism&nbsp;used on the ARMS 10 is to&nbsp;<br>
send&nbsp;the&nbsp;virtual tag&nbsp;to&nbsp;the MMU for translation.&nbsp;<br>
<hr>
<A name=338></a><IMG src="index-338_1.png"><br>
<b>326</b>&nbsp;<br>
<b>ARM CPU Cores</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure 12.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM810 die photograph.&nbsp;<br>
ARM810 silicon&nbsp;<br>
A photograph&nbsp;of&nbsp;an&nbsp;ARM810&nbsp;die&nbsp;is&nbsp;shown&nbsp;in&nbsp;Figure 12.6.&nbsp;The ARMS&nbsp;core&nbsp;datapath&nbsp;<br>
is visible&nbsp;at the&nbsp;top&nbsp;of&nbsp;the photograph&nbsp;with&nbsp;its control logic&nbsp;immediately below. The&nbsp;<br>
MMU&nbsp;TLB&nbsp;is&nbsp;in the&nbsp;top right-hand&nbsp;corner&nbsp;and&nbsp;the&nbsp;eight 1 Kbyte&nbsp;cache blocks&nbsp;<br>
occupy&nbsp;the bottom&nbsp;area&nbsp;of&nbsp;the&nbsp;chip.&nbsp;<br>
The characteristics of the ARMS 10 are summarized in Table 12.3.&nbsp;<br>
<b>Table&nbsp;12.3 &nbsp; &nbsp;</b>ARMS 10&nbsp;characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.5 u.m</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>836,022&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>86</b>&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3</b>&nbsp;&nbsp;<b>Die area</b>&nbsp;&nbsp;&nbsp;<br>
<b>76 mm</b>&nbsp;&nbsp;&nbsp;&nbsp;<b>Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>500 mW</b>&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>3.3V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>0-72 MHz&nbsp;MIPSAV</b>&nbsp;<br>
<b>172</b>&nbsp;<br>
<hr>
<A name=339></a><b>The StrongARM&nbsp;SA-110</b>&nbsp;<br>
<b>327</b>&nbsp;<br>
12.3 &nbsp; The&nbsp;StrongARM SA-110&nbsp;<br>
The&nbsp;StrongARM&nbsp;CPU was&nbsp;developed&nbsp;by&nbsp;Digital&nbsp;Equipment&nbsp;Corporation&nbsp;in&nbsp;collabo-<br>
ration with ARM Limited. It&nbsp;was the first ARM&nbsp;processor&nbsp;to&nbsp;use a&nbsp;<i>modified-Harvard&nbsp;</i><br>
(separate instruction and data&nbsp;cache)&nbsp;architecture.&nbsp;<br>
The SA-110&nbsp;is&nbsp;now manufactured&nbsp;by&nbsp;Intel&nbsp;Corporation&nbsp;following&nbsp;their take-over&nbsp;of&nbsp;<br>
Digital Semiconductor in&nbsp;1998.&nbsp;<br>
Digital&nbsp;Alpha&nbsp;<br>
Digital&nbsp;were, perhaps, best known&nbsp;in&nbsp;the&nbsp;microprocessor business&nbsp;for their range of&nbsp;<br>
background&nbsp;<br>
'Alpha'&nbsp;microprocessors&nbsp;which&nbsp;are&nbsp;64-bit&nbsp;RISC&nbsp;processors&nbsp;that&nbsp;operate&nbsp;at&nbsp;very&nbsp;high&nbsp;<br>
clock rates. The ability to&nbsp;sustain these clock frequencies is a&nbsp;result&nbsp;of advanced&nbsp;<br>
CMOS process technology, carefully&nbsp;balanced pipeline&nbsp;design,&nbsp;a very thoroughly&nbsp;<br>
engineered clocking scheme&nbsp;and in-house design tools that give unusually&nbsp;good&nbsp;<br>
control of all these&nbsp;factors.&nbsp;<br>
The same&nbsp;approach&nbsp;has been&nbsp;applied to&nbsp;the&nbsp;design&nbsp;of StrongARM, with&nbsp;the added&nbsp;<br>
objective of achieving exceptional power-efficiency.&nbsp;<br>
StrongARM&nbsp;<br>
The organization of&nbsp;StrongARM&nbsp;is shown&nbsp;in&nbsp;Figure 12.7 on&nbsp;page&nbsp;328.&nbsp;Its main&nbsp;fea-&nbsp;<br>
organization&nbsp;<br>
tures are:&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;5-stage&nbsp;pipeline with register forwarding.&nbsp;<br>
•&nbsp;&nbsp;Single-cycle&nbsp;execution of&nbsp;all common&nbsp;instructions&nbsp;except&nbsp;64-bit&nbsp;multiplies,&nbsp;mul&nbsp;<br>
tiple&nbsp;register transfers&nbsp;and the swap&nbsp;memory and register instruction.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;16&nbsp;Kbyte 32-way associative instruction cache&nbsp;with 32-byte&nbsp;line.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;16&nbsp;Kbyte 32-way associative copy-back data&nbsp;cache&nbsp;with&nbsp;32-byte line.&nbsp;<br>
•&nbsp;&nbsp;Separate 32-entry&nbsp;instruction&nbsp;and data translation look-aside&nbsp;buffers.&nbsp;<br>
•&nbsp;&nbsp;An&nbsp;8-entry&nbsp;write buffer&nbsp;with up&nbsp;to&nbsp;16&nbsp;bytes per entry.&nbsp;<br>
•&nbsp;&nbsp;Pseudo-static&nbsp;operation&nbsp;with&nbsp;low power consumption.&nbsp;<br>
The processor uses&nbsp;system&nbsp;control&nbsp;coprocessor&nbsp;15 to&nbsp;manage&nbsp;the on-chip MMU&nbsp;<br>
and cache resources, and&nbsp;incorporates&nbsp;JTAG boundary scan&nbsp;test circuitry for testing&nbsp;<br>
printed circuit board connectivity&nbsp;(the JTAG&nbsp;'in-test',&nbsp;for in-circuit testing of the&nbsp;<br>
device&nbsp;itself,&nbsp;is&nbsp;not supported).&nbsp;<br>
The first StrongARM chips are implemented on&nbsp;Digital's 0.35&nbsp;um&nbsp;CMOS process,&nbsp;<br>
using three&nbsp;layers of&nbsp;metal. They use&nbsp;around 2.5&nbsp;million transistors on&nbsp;a 50&nbsp;mm2&nbsp;die&nbsp;<br>
(which&nbsp;is very&nbsp;small&nbsp;for a processor of&nbsp;this performance)&nbsp;and&nbsp;deliver 200&nbsp;to&nbsp;250&nbsp;<br>
Dhrystone&nbsp;MIPS with&nbsp;a&nbsp;160&nbsp;to&nbsp;200&nbsp;MHz clock,&nbsp;dissipating&nbsp;half&nbsp;to&nbsp;just&nbsp;under one watt&nbsp;<br>
using a&nbsp;1.65 V&nbsp;to&nbsp;2 V&nbsp;supply.&nbsp;<br>
<hr>
<A name=340></a><IMG src="index-340_1.png"><br>
<b>328</b>&nbsp;<br>
<b>ARM&nbsp;CPU&nbsp;Cores</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 12.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>StrongARM organization.&nbsp;<br>
The StrongARM&nbsp;<br>
The&nbsp;processor core&nbsp;employs&nbsp;a 'classic'&nbsp;5-stage pipeline&nbsp;with full bypassing (register&nbsp;<br>
processor core&nbsp;<br>
forwarding) and hardware interlocks.&nbsp;The ARM instruction set&nbsp;requires some&nbsp;<br>
instruction decoding to take place before the register&nbsp;bank&nbsp;read accesses&nbsp;can begin,&nbsp;<br>
and it also&nbsp;requires&nbsp;a&nbsp;shift operation&nbsp;in&nbsp;series&nbsp;with the&nbsp;ALU, but&nbsp;both of&nbsp;these&nbsp;addi-&nbsp;<br>
<hr>
<A name=341></a>The Strong&nbsp;ARM&nbsp;<b>SA-110</b>&nbsp;<br>
<b>329</b>&nbsp;<br>
tional logic functions&nbsp;are fitted within&nbsp;their respective&nbsp;pipeline stages&nbsp;and&nbsp;do&nbsp;not add&nbsp;<br>
to&nbsp;the pipeline depth.&nbsp;The pipeline&nbsp;stages are:&nbsp;<br>
1.&nbsp;&nbsp;Instruction&nbsp;fetch (from&nbsp;the instruction cache).&nbsp;<br>
2.&nbsp;&nbsp;Instruction decode and&nbsp;register&nbsp;read;&nbsp;branch&nbsp;target&nbsp;calculation and execution.&nbsp;<br>
3.&nbsp;&nbsp;Shift&nbsp;and ALU operation,&nbsp;including data&nbsp;transfer&nbsp;memory address&nbsp;calculation.&nbsp;<br>
4.&nbsp;&nbsp;Data cache access.&nbsp;<br>
5.&nbsp;&nbsp;Result&nbsp;write-back to register&nbsp;file.&nbsp;<br>
The&nbsp;organization&nbsp;of&nbsp;the&nbsp;major pipeline&nbsp;components is illustrated&nbsp;in&nbsp;Figure 12.8 on&nbsp;<br>
page 330.&nbsp;The&nbsp;shaded bars delimit the pipeline&nbsp;stages and data&nbsp;which&nbsp;passes across&nbsp;<br>
these bars will&nbsp;be&nbsp;latched&nbsp;at&nbsp;the&nbsp;crossing&nbsp;point. Data which&nbsp;feeds around&nbsp;the end of&nbsp;a&nbsp;<br>
bar is being&nbsp;passed&nbsp;back&nbsp;or&nbsp;forward across pipeline&nbsp;stages,&nbsp;for&nbsp;example:&nbsp;<br>
•&nbsp;&nbsp;The register forwarding&nbsp;paths which&nbsp;pass&nbsp;intermediate&nbsp;results&nbsp;on&nbsp;to&nbsp;following&nbsp;<br>
instructions&nbsp;to&nbsp;avoid&nbsp;a&nbsp;register&nbsp;interlock&nbsp;stall&nbsp;caused by&nbsp;a&nbsp;read-after-write&nbsp;hazard.&nbsp;<br>
•&nbsp;&nbsp;The PC path which forwards&nbsp;pc + 4 from&nbsp;the fetch stage of&nbsp;the&nbsp;<i>next&nbsp;</i>instruction,&nbsp;<br>
giving pc&nbsp;+ 8&nbsp;for the current instruction,&nbsp;to be&nbsp;used&nbsp;as r15 and&nbsp;in the&nbsp;branch&nbsp;<br>
target&nbsp;calculation.&nbsp;<br>
Pipeline&nbsp;features&nbsp; &nbsp;&nbsp; Of&nbsp;particular&nbsp;note&nbsp;in&nbsp;this&nbsp;pipeline&nbsp;structure&nbsp;are:&nbsp;<br>
•&nbsp;&nbsp;The need&nbsp;for three register&nbsp;read&nbsp;ports&nbsp;to&nbsp;enable register-controlled shifts&nbsp;and store&nbsp;<br>
with base plus&nbsp;index addressing to issue in&nbsp;one cycle.&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;need&nbsp;for&nbsp;two&nbsp;register&nbsp;write&nbsp;ports&nbsp;to&nbsp;allow load&nbsp;with&nbsp;auto-index&nbsp;to&nbsp;issue&nbsp;in&nbsp;<br>
one cycle.&nbsp;<br>
•&nbsp;&nbsp;The address incrementer in the execute stage to support load and store multiple&nbsp;<br>
instructions.&nbsp;<br>
•&nbsp;&nbsp;The large&nbsp;number&nbsp;of&nbsp;sources&nbsp;for the&nbsp;next&nbsp;PC value.&nbsp;<br>
This last point reflects&nbsp;the&nbsp;many&nbsp;ways the&nbsp;ARM&nbsp;architecture&nbsp;allows the&nbsp;PC&nbsp;to&nbsp;be&nbsp;<br>
modified&nbsp;as&nbsp;a&nbsp;result&nbsp;of&nbsp;its&nbsp;visibility&nbsp;as&nbsp;r15&nbsp;in&nbsp;the register&nbsp;bank.&nbsp;<br>
PC&nbsp;modification&nbsp;<br>
The&nbsp;most common source of the next PC is&nbsp;the PC incrementer in the fetch stage;&nbsp;<br>
this value&nbsp;is&nbsp;available&nbsp;at&nbsp;the&nbsp;start of&nbsp;the&nbsp;next cycle, allowing one&nbsp;instruction to&nbsp;be&nbsp;<br>
fetched each&nbsp;cycle.&nbsp;<br>
The&nbsp;next&nbsp;most common&nbsp;source&nbsp;of the&nbsp;PC&nbsp;is the&nbsp;result&nbsp;of a branch&nbsp;instruction.&nbsp;The&nbsp;<br>
dedicated branch displacement adder computes&nbsp;the target&nbsp;address during&nbsp;the&nbsp;instruc-<br>
tion decode&nbsp;stage, causing a&nbsp;taken branch to&nbsp;incur a one-cycle penalty&nbsp;in addition to&nbsp;<br>
the&nbsp;cycle&nbsp;taken&nbsp;to&nbsp;execute&nbsp;the&nbsp;branch&nbsp;itself.&nbsp;Note&nbsp;that&nbsp;the displacement&nbsp;addition&nbsp;can&nbsp;<br>
take&nbsp;place in&nbsp;parallel with&nbsp;the&nbsp;instruction&nbsp;decode&nbsp;since&nbsp;the&nbsp;offset is&nbsp;a fixed&nbsp;field within&nbsp;<br>
the&nbsp;instruction;&nbsp;if&nbsp;the&nbsp;instruction&nbsp;turns&nbsp;out not to&nbsp;be a branch the computed target&nbsp;is&nbsp;<br>
simply&nbsp;discarded.&nbsp;<br>
<hr>
<A name=342></a><IMG src="index-342_1.png"><br>
<b>330</b>&nbsp;<br>
<b>ARM&nbsp;CPU&nbsp;Cores</b>&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;12.8 &nbsp;&nbsp;</b>StrongARM core pipeline organization.&nbsp;<br>
<hr>
<A name=343></a><IMG src="index-343_1.png"><br>
The StrongARM SA-110&nbsp;<br>
331&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 12.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>StrongARM&nbsp;loop&nbsp;test&nbsp;pipeline&nbsp;behaviour.&nbsp;<br>
The operation of&nbsp;the pipeline&nbsp;during&nbsp;this sequence&nbsp;is shown&nbsp;in&nbsp;Figure 12.9.&nbsp;Note how&nbsp;<br>
the condition&nbsp;codes become&nbsp;valid just&nbsp;in&nbsp;time&nbsp;to avoid increasing the&nbsp;branch&nbsp;penalty; the&nbsp;<br>
instruction immediately&nbsp;following the branch is&nbsp;fetched and&nbsp;discarded, but&nbsp;then&nbsp;the pro-<br>
cessor begins fetching from&nbsp;the branch target. The target&nbsp;address is&nbsp;generated concur-<br>
rently&nbsp;with&nbsp;the condition codes&nbsp;that&nbsp;determine&nbsp;whether or not&nbsp;it&nbsp;should&nbsp;be used.&nbsp;<br>
The same&nbsp;one&nbsp;cycle penalty&nbsp;applies to&nbsp;branch&nbsp;and&nbsp;link instructions which take the&nbsp;<br>
branch&nbsp;in&nbsp;the&nbsp;same&nbsp;way but use&nbsp;the&nbsp;execute&nbsp;and write&nbsp;stages&nbsp;to&nbsp;compute&nbsp;pc&nbsp;+ 4&nbsp;and write&nbsp;<br>
it to&nbsp;r14, the link&nbsp;register. It&nbsp;also&nbsp;applies to&nbsp;the&nbsp;normal subroutine return instruction,&nbsp;<br>
MOV&nbsp;pc, lr, where the target address comes from&nbsp;the register&nbsp;file rather than&nbsp;from&nbsp;the&nbsp;<br>
branch&nbsp;displacement adder,&nbsp;but it is still available at&nbsp;the end&nbsp;of the&nbsp;decode&nbsp;stage.&nbsp;<br>
If&nbsp;the&nbsp;return&nbsp;address&nbsp;must&nbsp;be&nbsp;computed,&nbsp;for example&nbsp;when&nbsp;returning&nbsp;from&nbsp;an&nbsp;<br>
exception,&nbsp;there&nbsp;is&nbsp;a&nbsp;two-cycle&nbsp;penalty since&nbsp;the ALU result is only&nbsp;available&nbsp;at&nbsp;the&nbsp;end&nbsp;<br>
of the&nbsp;execute&nbsp;stage,&nbsp;and where the PC is loaded&nbsp;from&nbsp;memory&nbsp;(from&nbsp;a jump&nbsp;table, or&nbsp;<br>
subroutine return from&nbsp;stack) there is a&nbsp;three-cycle penalty.&nbsp;<br>
Forwarding&nbsp;<br>
The&nbsp;execution&nbsp;pipeline&nbsp;includes&nbsp;three forwarding paths&nbsp;to each register&nbsp;operand&nbsp;to&nbsp;<br>
paths&nbsp;<br>
avoid stalls when&nbsp;read-after-write hazards&nbsp;occur.&nbsp;Values are&nbsp;forwarded from:&nbsp;<br>
1.&nbsp;&nbsp;the ALU result;&nbsp;<br>
2.&nbsp;&nbsp;data loaded from&nbsp;the data cache;&nbsp;<br>
3.&nbsp;&nbsp;the buffered&nbsp;ALU&nbsp;result.&nbsp;<br>
These paths&nbsp;remove all&nbsp;data-dependency&nbsp;stalls except when&nbsp;a loaded data value is&nbsp;<br>
used by&nbsp;the following instruction, in&nbsp;which case a single cycle stall&nbsp;is required.&nbsp;<br>
<hr>
<A name=344></a><b>332</b>&nbsp;<br>
<b>ARM CPU Cores</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Abort recovery&nbsp;<br>
It&nbsp;might seem&nbsp;that one of these paths&nbsp;could be avoided if the ALU&nbsp;result were writ-<br>
ten into the register&nbsp;file in&nbsp;the following&nbsp;stage rather than&nbsp;buffering it&nbsp;and delaying&nbsp;<br>
the write&nbsp;to the last stage. The&nbsp;merit of&nbsp;the delayed scheme&nbsp;is that data&nbsp;aborts can&nbsp;<br>
occur during&nbsp;the data&nbsp;cache access,&nbsp;perhaps&nbsp;requiring&nbsp;remedial&nbsp;action&nbsp;to&nbsp;recover the&nbsp;<br>
base register&nbsp;value&nbsp;(for&nbsp;instance&nbsp;when&nbsp;the&nbsp;base register&nbsp;is&nbsp;overwritten in a&nbsp;load mul-<br>
tiple&nbsp;sequence&nbsp;before&nbsp;the&nbsp;fault is&nbsp;generated). This scheme&nbsp;not only allows&nbsp;recovery&nbsp;<br>
but supports the cleanest&nbsp;recovery&nbsp;mechanism,&nbsp;leaving the base&nbsp;register value as it&nbsp;<br>
was&nbsp;at the&nbsp;start of&nbsp;the&nbsp;instruction and&nbsp;removing&nbsp;the need&nbsp;for the exception handler&nbsp;to&nbsp;<br>
undo any&nbsp;auto-indexing.&nbsp;<br>
Multiplier&nbsp;<br>
A feature of particular note is&nbsp;the StrongARM's&nbsp;multiplication unit which, despite&nbsp;<br>
the processor's high clock&nbsp;rate, computes at the rate of&nbsp;12&nbsp;bits per cycle,&nbsp;giving the&nbsp;<br>
product of&nbsp;two&nbsp;32-bit operands in one to three clock cycles.&nbsp;The high-speed&nbsp;multi-<br>
plier gives&nbsp;StrongARM&nbsp;considerable&nbsp;potential&nbsp;in&nbsp;applications&nbsp;which require signifi-<br>
cant digital signal processing&nbsp;performance.&nbsp;<br>
Instruction&nbsp;<br>
The I-cache holds 16 Kbytes&nbsp;of instructions in 512 lines of eight instructions (32&nbsp;<br>
cache&nbsp;<br>
bytes).&nbsp;The&nbsp;cache&nbsp;is&nbsp;32-way associative&nbsp;(using a CAM-RAM organization)&nbsp;with a&nbsp;<br>
cyclic replacement algorithm&nbsp;and uses the processor's&nbsp;virtual&nbsp;address. The&nbsp;block&nbsp;<br>
size&nbsp;is the&nbsp;same as the&nbsp;line&nbsp;size,&nbsp;so&nbsp;whole&nbsp;lines are&nbsp;loaded&nbsp;from&nbsp;memory at&nbsp;a time.&nbsp;<br>
Individual&nbsp;areas of&nbsp;memory&nbsp;may be&nbsp;marked&nbsp;as cacheable&nbsp;or uncacheable&nbsp;using&nbsp;the&nbsp;<br>
memory&nbsp;management tables, and the cache&nbsp;may be disabled and flushed (in its&nbsp;<br>
entirety) under&nbsp;software&nbsp;control.&nbsp;<br>
Data cache&nbsp;<br>
The data cache uses&nbsp;a similar organization to the instruction cache but with added&nbsp;<br>
functions&nbsp;to&nbsp;cope with&nbsp;data&nbsp;stores (instructions are&nbsp;read-only). It has&nbsp;a&nbsp;capacity of&nbsp;<br>
16 Kbytes&nbsp;with 512 32-byte&nbsp;lines arranged&nbsp;as&nbsp;a 32-way&nbsp;virtually addressed associa-<br>
tive cache with cyclic replacement. The block size is also 32 bytes. The cache&nbsp;may&nbsp;<br>
be disabled&nbsp;by&nbsp;software and&nbsp;individual&nbsp;regions of&nbsp;memory&nbsp;may be&nbsp;made&nbsp;uncache-<br>
able.&nbsp;(Making&nbsp;I/O&nbsp;regions uncacheable&nbsp;is usually a good&nbsp;idea.)&nbsp;<br>
The&nbsp;data&nbsp;cache uses&nbsp;a&nbsp;copy-back&nbsp;write strategy, and has&nbsp;two&nbsp;dirty bits per line&nbsp;so&nbsp;<br>
that&nbsp;when&nbsp;a&nbsp;line is&nbsp;evicted from&nbsp;the&nbsp;cache&nbsp;all,&nbsp;half&nbsp;or&nbsp;none&nbsp;of it&nbsp;is written&nbsp;to memory.&nbsp;<br>
The use of&nbsp;two&nbsp;dirty bits&nbsp;rather than one&nbsp;reduces memory traffic since&nbsp;the 'half&nbsp;dirty'&nbsp;<br>
case is&nbsp;quite common. The&nbsp;cache stores&nbsp;a copy&nbsp;of&nbsp;the&nbsp;physical&nbsp;address with&nbsp;each&nbsp;line&nbsp;<br>
for use&nbsp;when&nbsp;the&nbsp;line&nbsp;is&nbsp;written&nbsp;back&nbsp;to&nbsp;memory, and&nbsp;evicted&nbsp;lines&nbsp;are placed&nbsp;into&nbsp;the&nbsp;<br>
write buffer.&nbsp;<br>
Since&nbsp;the cache uses a&nbsp;copy-back write strategy, it&nbsp;is sometimes necessary&nbsp;to&nbsp;cause&nbsp;<br>
all dirty lines&nbsp;to&nbsp;be written&nbsp;back&nbsp;to&nbsp;memory. On&nbsp;StrongARM&nbsp;this is&nbsp;achieved&nbsp;using&nbsp;<br>
software&nbsp;to&nbsp;load&nbsp;new data&nbsp;into&nbsp;every&nbsp;line, causing dirty lines&nbsp;to&nbsp;be evicted.&nbsp;<br>
Synonyms&nbsp;<br>
As with any virtually addressed cache,&nbsp;care&nbsp;must be&nbsp;taken to&nbsp;ensure&nbsp;that&nbsp;all cacheable&nbsp;<br>
physical memory&nbsp;locations&nbsp;have unique&nbsp;virtual addresses&nbsp;that map to them. When&nbsp;two&nbsp;<br>
different&nbsp;virtual&nbsp;addresses&nbsp;map&nbsp;to&nbsp;the&nbsp;same&nbsp;physical&nbsp;location&nbsp;the&nbsp;virtual&nbsp;addresses&nbsp;are&nbsp;<br>
synonyms; where synonyms&nbsp;exist,&nbsp;neither&nbsp;virtual&nbsp;address should&nbsp;be&nbsp;cacheable.&nbsp;<br>
<hr>
<A name=345></a><b>The StrongARM&nbsp;SA-110</b>&nbsp;<br>
<b>333</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Cache&nbsp;<br>
The separate&nbsp;instruction and data caches create the potential for the two caches to&nbsp;<br>
consistency&nbsp;<br>
have inconsistent copies of&nbsp;the same&nbsp;physical memory&nbsp;location. Whenever&nbsp;a region&nbsp;<br>
of&nbsp;memory is treated as (writeable) data at&nbsp;one time&nbsp;and as executable instructions&nbsp;<br>
at another, great care&nbsp;must be&nbsp;taken to&nbsp;avoid&nbsp;inconsistencies.&nbsp;<br>
A common example&nbsp;of&nbsp;this situation is&nbsp;when&nbsp;a&nbsp;program&nbsp;is loaded&nbsp;(or&nbsp;copied from&nbsp;<br>
one&nbsp;memory&nbsp;location&nbsp;to another) and then&nbsp;executed.&nbsp;During the load&nbsp;phase the pro-<br>
gram&nbsp;is&nbsp;treated&nbsp;as&nbsp;data&nbsp;and&nbsp;passes&nbsp;through&nbsp;the data&nbsp;cache.&nbsp;When&nbsp;it&nbsp;is&nbsp;executed&nbsp;it&nbsp;is&nbsp;<br>
loaded into the instruction&nbsp;cache&nbsp;(which&nbsp;may have&nbsp;copies of&nbsp;previous&nbsp;instructions&nbsp;<br>
from&nbsp;the same&nbsp;addresses). To&nbsp;ensure&nbsp;correct&nbsp;operation:&nbsp;<br>
1.&nbsp;&nbsp;The&nbsp;load&nbsp;phase&nbsp;should&nbsp;be&nbsp;completed.&nbsp;<br>
2.&nbsp;&nbsp;The entire&nbsp;data&nbsp;cache&nbsp;should&nbsp;be&nbsp;'cleaned'&nbsp;(by&nbsp;loading new&nbsp;data into&nbsp;every line as&nbsp;<br>
described above) or,&nbsp;where the addresses&nbsp;of the affected cache lines are&nbsp;known,&nbsp;<br>
these lines may be&nbsp;explicitly cleaned&nbsp;and&nbsp;flushed.&nbsp;<br>
3.&nbsp;&nbsp;The instruction cache&nbsp;should&nbsp;be flushed&nbsp;(to&nbsp;remove obsolete instructions).&nbsp;<br>
Alternative solutions might involve making&nbsp;certain regions&nbsp;of&nbsp;memory&nbsp;uncacheable&nbsp;<br>
during the&nbsp;load&nbsp;phase.&nbsp;<br>
Note&nbsp;that&nbsp;this&nbsp;is not&nbsp;a&nbsp;problem&nbsp;for&nbsp;literals&nbsp;(data&nbsp;items included&nbsp;in the instruction&nbsp;<br>
stream) which&nbsp;are quite&nbsp;common in&nbsp;ARM&nbsp;code. Although&nbsp;a block&nbsp;of memory&nbsp;may&nbsp;be&nbsp;<br>
loaded into&nbsp;both&nbsp;caches since&nbsp;it&nbsp;contains&nbsp;a mixture of&nbsp;instructions and literals, so&nbsp;long&nbsp;<br>
as individual words&nbsp;(or bytes)&nbsp;are treated&nbsp;consistently&nbsp;as&nbsp;<i>either&nbsp;</i>instructions&nbsp;<i>or&nbsp;</i>data,&nbsp;<br>
there&nbsp;will&nbsp;be&nbsp;no&nbsp;problem.&nbsp;It&nbsp;is&nbsp;even acceptable for&nbsp;the program&nbsp;to&nbsp;change&nbsp;the&nbsp;value&nbsp;of&nbsp;<br>
a&nbsp;literal&nbsp;(though this is&nbsp;rarely used&nbsp;and is&nbsp;probably&nbsp;bad practice)&nbsp;so&nbsp;long&nbsp;as&nbsp;it&nbsp;does not&nbsp;<br>
affect the&nbsp;values&nbsp;of&nbsp;instructions&nbsp;which may&nbsp;be&nbsp;in the instruction&nbsp;cache.&nbsp;It is&nbsp;better&nbsp;<br>
practice,&nbsp;however,&nbsp;to&nbsp;avoid literals&nbsp;altogether&nbsp;and&nbsp;to&nbsp;keep data in&nbsp;data&nbsp;areas that are&nbsp;<br>
separate from&nbsp;code&nbsp;areas which&nbsp;contain&nbsp;instructions.&nbsp;<br>
Compiler issues&nbsp;<br>
The&nbsp;separation&nbsp;of&nbsp;the instruction and data&nbsp;caches should&nbsp;be observed&nbsp;by&nbsp;the com-<br>
piler, which should&nbsp;pool constants&nbsp;across&nbsp;compiler&nbsp;units&nbsp;rather&nbsp;than&nbsp;placing&nbsp;them&nbsp;at&nbsp;<br>
the&nbsp;end&nbsp;of&nbsp;each&nbsp;routine.&nbsp;This&nbsp;minimizes&nbsp;the&nbsp;pollution&nbsp;of&nbsp;the&nbsp;data&nbsp;cache&nbsp;with&nbsp;instruc-<br>
tions and&nbsp;of the instruction cache&nbsp;with data.&nbsp;<br>
The write buffer&nbsp;<br>
The write buffer smooths out small peaks in the write data bandwidth,&nbsp;decoupling&nbsp;<br>
the processor&nbsp;from&nbsp;stalls&nbsp;caused by&nbsp;the&nbsp;memory bus saturating.&nbsp;A large peak&nbsp;that&nbsp;<br>
causes the&nbsp;buffer to&nbsp;fill&nbsp;will&nbsp;stall the processor.&nbsp;Independent writes to&nbsp;the&nbsp;same&nbsp;<br>
16-byte area are&nbsp;merged&nbsp;within the&nbsp;write buffer, though only&nbsp;to&nbsp;the&nbsp;last&nbsp;address&nbsp;<br>
written into&nbsp;the buffer. The&nbsp;buffer&nbsp;stores up to&nbsp;eight addresses&nbsp;(each&nbsp;address&nbsp;aligned&nbsp;<br>
to&nbsp;a&nbsp;16-byte boundary), copying&nbsp;the virtual address&nbsp;for&nbsp;use&nbsp;when&nbsp;merging&nbsp;writes&nbsp;<br>
and&nbsp;the&nbsp;physical&nbsp;address to&nbsp;address the external&nbsp;memory, and up&nbsp;to 16 bytes of&nbsp;data&nbsp;<br>
for&nbsp;each&nbsp;address (so&nbsp;each&nbsp;address can handle a dirty half-line or&nbsp;up&nbsp;to&nbsp;four&nbsp;registers&nbsp;<br>
from&nbsp;a&nbsp;single store multiple).&nbsp;<br>
<hr>
<A name=346></a><IMG src="index-346_1.png"><br>
<b>334</b>&nbsp;<br>
<b>ARM CPU Cores</b>&nbsp;<br>
The write&nbsp;buffer&nbsp;may&nbsp;be disabled&nbsp;by&nbsp;software, and individual memory&nbsp;regions may&nbsp;<br>
be&nbsp;marked as bufferable or unbufferable&nbsp;using&nbsp;the&nbsp;MMU page&nbsp;tables.&nbsp;All&nbsp;cacheable&nbsp;<br>
regions are bufferable&nbsp;(evicted&nbsp;cache&nbsp;lines&nbsp;are&nbsp;written&nbsp;through&nbsp;the&nbsp;write buffer) but&nbsp;<br>
uncacheable&nbsp;regions may&nbsp;be&nbsp;bufferable&nbsp;or&nbsp;unbufferable.&nbsp;Normally&nbsp;the&nbsp;I/O region&nbsp;is&nbsp;<br>
unbufferable. An&nbsp;unbuffered&nbsp;write&nbsp;will wait for the write&nbsp;buffer&nbsp;to&nbsp;empty before it is&nbsp;<br>
written to&nbsp;memory.&nbsp;<br>
Data reads&nbsp;that&nbsp;miss the&nbsp;data&nbsp;cache&nbsp;are&nbsp;checked against&nbsp;entries in&nbsp;the write&nbsp;buffer&nbsp;to&nbsp;<br>
ensure consistency,&nbsp;but instruction&nbsp;reads&nbsp;are&nbsp;not checked&nbsp;against&nbsp;the&nbsp;write&nbsp;buffer.&nbsp;<br>
Whenever&nbsp;memory locations&nbsp;which&nbsp;have&nbsp;been&nbsp;used&nbsp;as&nbsp;data&nbsp;are&nbsp;to&nbsp;be&nbsp;used&nbsp;as&nbsp;instruc-<br>
tions&nbsp;a&nbsp;special&nbsp;instruction should&nbsp;be&nbsp;used&nbsp;to&nbsp;ensure&nbsp;that&nbsp;the&nbsp;write&nbsp;buffer&nbsp;has drained.&nbsp;<br>
MMU&nbsp;<br>
StrongARM&nbsp;incorporates&nbsp;the standard ARM memory&nbsp;management architecture,&nbsp;<br>
organization&nbsp;<br>
using separate translation&nbsp;look-aside&nbsp;buffers&nbsp;(TLBs)&nbsp;for&nbsp;instructions&nbsp;and&nbsp;data. Each&nbsp;<br>
TLB&nbsp;has&nbsp;32 translation entries&nbsp;arranged as a fully&nbsp;associative&nbsp;cache with cyclic&nbsp;<br>
replacement. A&nbsp;TLB&nbsp;miss invokes&nbsp;table-walking&nbsp;hardware to fetch the translation&nbsp;<br>
and access&nbsp;permission&nbsp;information&nbsp;from&nbsp;main&nbsp;memory.&nbsp;<br>
StrongARM&nbsp;<br>
A photograph&nbsp;of&nbsp;a StrongARM&nbsp;die&nbsp;is shown in&nbsp;Figure 12.10&nbsp;with&nbsp;an overlay indicat-&nbsp;<br>
SJlicon&nbsp;<br>
ing the&nbsp;major functional areas. The die area&nbsp;is, not surprisingly,&nbsp;dominated by&nbsp;the&nbsp;<br>
instruction cache (1CACHE)&nbsp;and&nbsp;the&nbsp;data&nbsp;cache&nbsp;(DCACHE).&nbsp;Each&nbsp;cache&nbsp;has its own&nbsp;<br>
MMU (IMMU and DMMU). The processor core has the instruction issue&nbsp;unit&nbsp;<br>
(IBOX) and&nbsp;the execution&nbsp;unit&nbsp;(EBOX) with high-speed&nbsp;multiplication&nbsp;hardware&nbsp;<br>
(MUL).&nbsp;The write buffer and&nbsp;external bus&nbsp;controller&nbsp;complete&nbsp;the processor logic.&nbsp;<br>
&nbsp;<br>
<b>Figure 12.10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>StrongARM die&nbsp;photograph.<br>
<hr>
<A name=347></a><IMG src="index-347_1.png"><br>
<b>The ARM920T&nbsp;and&nbsp;</b>ARM940T&nbsp;<br>
335&nbsp;<br>
The high-frequency&nbsp;on-chip&nbsp;clock is&nbsp;generated by&nbsp;a phase-locked loop&nbsp;(PLL) from&nbsp;<br>
an external 3.68 MHz clock input.&nbsp;<br>
The characteristics of the StrongARM&nbsp;are summarized&nbsp;in&nbsp;Table 12.4.&nbsp;<br>
<b>Table&nbsp;12.4 &nbsp; &nbsp;</b>StrongARM characteristics.&nbsp;<br>
&nbsp;<br>
12.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The ARM920T&nbsp;and ARM940T&nbsp;<br>
The&nbsp;ARM920T and&nbsp;ARM940T are based upon&nbsp;the ARM9TDMI&nbsp;processor core (see&nbsp;<br>
Section 9.3 on page 260),&nbsp;to&nbsp;which&nbsp;instruction&nbsp;and&nbsp;data&nbsp;caches have been&nbsp;added.&nbsp;<br>
The instruction and&nbsp;data&nbsp;ports&nbsp;are&nbsp;merged via an AMBA&nbsp;bus master&nbsp;unit,&nbsp;and a&nbsp;<br>
write&nbsp;buffer and memory&nbsp;management&nbsp;unit&nbsp;(ARM920T) or&nbsp;memory&nbsp;protection unit&nbsp;<br>
(ARM940T) are&nbsp;also&nbsp;incorporated.&nbsp;<br>
ARM920T&nbsp;<br>
The overall&nbsp;organization of&nbsp;the ARM920T&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;Figure 12.11 on&nbsp;<br>
page 336.&nbsp;<br>
ARM920T&nbsp;<br>
The instruction and&nbsp;data caches are&nbsp;both 16&nbsp;Kbytes in size&nbsp;and are&nbsp;built using a seg-<br>
caches&nbsp;<br>
mented CAM-RAM organization to give 64-way associativity. Each cache&nbsp;comprises&nbsp;<br>
eight&nbsp;segments&nbsp;of&nbsp;64&nbsp;lines, the&nbsp;required&nbsp;segment&nbsp;being addressed&nbsp;by&nbsp;A[7:5].&nbsp;They&nbsp;<br>
have 8-word&nbsp;(32 byte) lines and support&nbsp;lock-down in&nbsp;units&nbsp;of 256 bytes (correspond-<br>
ing to one line in each segment). The replacement strategy is pseudo-random&nbsp;or&nbsp;<br>
round-robin, and is&nbsp;determined&nbsp;by&nbsp;the&nbsp;'RR' bit (bit&nbsp;14) in&nbsp;CP15 register 1.&nbsp;A complete&nbsp;<br>
8-word&nbsp;line is reloaded on a cache&nbsp;miss.&nbsp;<br>
The instruction cache&nbsp;is read-only. The data&nbsp;cache supports&nbsp;a copy-back write strat-<br>
egy,&nbsp;and each&nbsp;line has one valid bit,&nbsp;two dirty&nbsp;bits&nbsp;and a write-back bit. The&nbsp;write-back&nbsp;<br>
bit duplicates information&nbsp;usually found in the translation&nbsp;system, and&nbsp;enables the&nbsp;<br>
cache&nbsp;to implement a write operation as write-through or copy-back without reference&nbsp;<br>
to the MMU.&nbsp;When a cache&nbsp;line is replaced any&nbsp;dirty data&nbsp;is sent to the&nbsp;write buffer,&nbsp;<br>
and this&nbsp;may&nbsp;amount&nbsp;to&nbsp;zero, four&nbsp;or eight&nbsp;words depending&nbsp;on the two dirty&nbsp;bits. The&nbsp;<br>
data cache allocates space only on a read miss, not&nbsp;on a&nbsp;write&nbsp;miss.&nbsp;<br>
As the&nbsp;data cache is accessed&nbsp;using virtual&nbsp;addresses, there&nbsp;is a problem&nbsp;whenever&nbsp;<br>
dirty data has&nbsp;to be written back to&nbsp;main&nbsp;memory&nbsp;since this&nbsp;action requires the physical&nbsp;<br>
address. The ARMS&nbsp;10 solves this&nbsp;by&nbsp;passing&nbsp;the&nbsp;virtual address&nbsp;back to the MMU&nbsp;<br>
<hr>
<A name=348></a><IMG src="index-348_1.png"><br>
<b>336</b>&nbsp;<br>
<b>ARM CPU Cores</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;12.11 &nbsp; &nbsp;</b>ARM920T&nbsp;organization.&nbsp;<br>
for translation,&nbsp;but&nbsp;of&nbsp;course&nbsp;there&nbsp;is&nbsp;no&nbsp;guarantee&nbsp;that&nbsp;the&nbsp;necessary translation&nbsp;entry&nbsp;<br>
is&nbsp;still in&nbsp;the&nbsp;TLB. The whole&nbsp;process&nbsp;can therefore&nbsp;be&nbsp;quite time&nbsp;consuming.&nbsp;The&nbsp;<br>
ARM920T&nbsp;avoids&nbsp;this&nbsp;problem&nbsp;by&nbsp;having&nbsp;a second&nbsp;tag&nbsp;store&nbsp;that&nbsp;is&nbsp;used&nbsp;to&nbsp;hold&nbsp;the&nbsp;<br>
physical&nbsp;address for each&nbsp;line&nbsp;in&nbsp;the&nbsp;cache. A cache&nbsp;line&nbsp;flush&nbsp;does&nbsp;not&nbsp;then&nbsp;need&nbsp;to&nbsp;<br>
involve&nbsp;the MMU and&nbsp;can&nbsp;always proceed without&nbsp;delay&nbsp;to transfer&nbsp;the dirty&nbsp;data to&nbsp;<br>
the write&nbsp;buffer.&nbsp;<br>
The ARM920T can force dirty cache lines to be flushed&nbsp;back to main&nbsp;memory&nbsp;<br>
(a process known&nbsp;as&nbsp;'cleaning') using&nbsp;either&nbsp;the&nbsp;cache&nbsp;index&nbsp;or the&nbsp;memory&nbsp;<br>
address. It is therefore possible to&nbsp;clean&nbsp;all of the entries corresponding to&nbsp;a par-<br>
ticular memory&nbsp;area.&nbsp;<br>
ARM920T&nbsp;write&nbsp;<br>
The&nbsp;write buffer&nbsp;will hold up&nbsp;to four&nbsp;addresses and 16 data words.&nbsp;<br>
buffer&nbsp;<br>
&nbsp;&nbsp;&nbsp;ARM920T&nbsp;MMU&nbsp;&nbsp;The&nbsp;&nbsp; MMU &nbsp;&nbsp;implements&nbsp;&nbsp; the&nbsp;&nbsp;&nbsp;memory &nbsp;management&nbsp;&nbsp;&nbsp;architecture&nbsp;&nbsp;&nbsp;<br>
described&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;Section 11.6 on page 302 and&nbsp;is controlled&nbsp;by&nbsp;the system&nbsp;<br>
control coprocessor,&nbsp;<br>
<hr>
<A name=349></a><b>The ARM920T&nbsp;and ARM940T</b>&nbsp;<br>
<b>337</b>&nbsp;<br>
CP15,&nbsp;as described in&nbsp;Section 11.5 on page 298. As&nbsp;the ARM920T&nbsp;has separate&nbsp;<br>
instruction&nbsp;and&nbsp;data&nbsp;memory&nbsp;ports it has two MMUs, one&nbsp;for each&nbsp;of the&nbsp;ports.&nbsp;<br>
The&nbsp;memory&nbsp;management&nbsp;hardware&nbsp;includes a 64-entry TLB&nbsp;for the&nbsp;instruction&nbsp;<br>
memory port&nbsp;and a 64-entry&nbsp;TLB for&nbsp;the data port. The ARM920T includes&nbsp;the&nbsp;<br>
ProcessID logic that is required to support Windows CE. The caches and MMUs come&nbsp;<br>
after&nbsp;the ProcessID insertion, so&nbsp;a context switch&nbsp;doesn't invalidate&nbsp;either&nbsp;the&nbsp;caches&nbsp;<br>
or the TLBs.&nbsp;In&nbsp;addition&nbsp;to&nbsp;supporting&nbsp;the&nbsp;64&nbsp;Kbyte large pages and&nbsp;the 4&nbsp;Kbyte small&nbsp;<br>
pages,&nbsp;the ARM920T&nbsp;MMU&nbsp;also&nbsp;supports&nbsp;1&nbsp;Kbyte 'tiny'&nbsp;page&nbsp;translation.&nbsp;<br>
The ARM920T MMU supports selective&nbsp;lock-down for&nbsp;TLB entries, ensuring&nbsp;<br>
that translations entries that&nbsp;are critical,&nbsp;for example to a&nbsp;real-time process, cannot&nbsp;<br>
be ejected.&nbsp;<br>
ARM920T&nbsp;silicon &nbsp;&nbsp;&nbsp; The&nbsp;characteristics&nbsp;of&nbsp;the ARM920T are summarized in Table 12.5.&nbsp;<br>
<b>Table&nbsp;12.5 &nbsp; &nbsp;</b>ARM920T characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.25&nbsp;urn</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;<br>
<b>2,500,000&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>220</b>&nbsp;&nbsp;&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>4</b>&nbsp;&nbsp;<b>Core&nbsp;area</b>&nbsp;&nbsp;&nbsp;<br>
<b>23-25 mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>560 mW</b>&nbsp;&nbsp;&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>2.5V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>0-200 MHz&nbsp;MIPS/W</b>&nbsp;&nbsp;&nbsp;<br>
<b>390</b>&nbsp;&nbsp;&nbsp;<br>
ARM940T&nbsp;<br>
The&nbsp;ARM940T is another CPU core based&nbsp;on&nbsp;the ARM9TDMI&nbsp;integer core.&nbsp;It&nbsp;is&nbsp;<br>
simpler than&nbsp;the ARM920T&nbsp;as it&nbsp;does&nbsp;not support virtual to&nbsp;physical address transla-<br>
tion. The organization&nbsp;of&nbsp;the ARM940T is shown in&nbsp;Figure&nbsp;12.12&nbsp;on&nbsp;page&nbsp;338.&nbsp;<br>
Memory&nbsp;<br>
The&nbsp;memory&nbsp;protection unit implements the architecture&nbsp;described in&nbsp;Section&nbsp;11.4&nbsp;<br>
protection&nbsp;unit&nbsp;<br>
on page 297.&nbsp;As the&nbsp;ARM940T has separate instruction and data&nbsp;memory&nbsp;ports&nbsp;it&nbsp;<br>
has two protection units, one&nbsp;for each&nbsp;of the&nbsp;ports.&nbsp;<br>
This&nbsp;configuration has no virtual to physical address translation&nbsp;mechanism.&nbsp;Many&nbsp;<br>
embedded&nbsp;systems do&nbsp;not&nbsp;require&nbsp;address&nbsp;translation,&nbsp;and&nbsp;as&nbsp;a&nbsp;full&nbsp;MMU&nbsp;requires sig-<br>
nificant&nbsp;silicon area,&nbsp;its&nbsp;omission when it&nbsp;is&nbsp;not required represents&nbsp;a significant cost&nbsp;<br>
saving. The AMBA interface and absence of&nbsp;address&nbsp;translation hardware both indi-<br>
cate the expectation that the&nbsp;application will be in embedded systems&nbsp;with other&nbsp;<br>
AMBA&nbsp;macrocells&nbsp;on the same&nbsp;chip.&nbsp;<br>
ARM940T&nbsp;<br>
Both&nbsp;instruction&nbsp;and data&nbsp;caches&nbsp;have&nbsp;a&nbsp;size of&nbsp;4&nbsp;Kbytes&nbsp;and&nbsp;comprise&nbsp;four&nbsp;1&nbsp;Kbyte&nbsp;<br>
caches&nbsp;<br>
segments,&nbsp;each&nbsp;of&nbsp;which uses&nbsp;a fully&nbsp;associative CAM-RAM&nbsp;structure.&nbsp;(For&nbsp;an&nbsp;<br>
explanation of&nbsp;these cache terms&nbsp;see&nbsp;Section 10.3&nbsp;on page 272.) They&nbsp;have&nbsp;a&nbsp;<br>
quad-word line structure, and always load&nbsp;a complete line on a&nbsp;cache&nbsp;miss if the&nbsp;<br>
address&nbsp;is&nbsp;cacheable as&nbsp;indicated by&nbsp;the&nbsp;memory protection unit.&nbsp;<br>
<hr>
<A name=350></a><IMG src="index-350_1.png"><br>
<b>338</b>&nbsp;<br>
<b>ARM CPU Cores</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 12.12&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM940T&nbsp;organization.&nbsp;<br>
The caches supports lock-down,&nbsp;which means that&nbsp;sections&nbsp;of&nbsp;the cache can&nbsp;be&nbsp;<br>
loaded&nbsp;and&nbsp;then&nbsp;the&nbsp;contents&nbsp;protected&nbsp;from&nbsp;being&nbsp;flushed.&nbsp;Locked-down&nbsp;sections&nbsp;of&nbsp;<br>
the cache are&nbsp;clearly unavailable for&nbsp;further&nbsp;general-purpose cache use,&nbsp;but the ability&nbsp;<br>
to guarantee that certain critical code sections will always be found in&nbsp;the&nbsp;cache may&nbsp;<br>
be&nbsp;more&nbsp;important&nbsp;than getting&nbsp;the best&nbsp;cache hit rate.&nbsp;The&nbsp;caches&nbsp;may be&nbsp;locked&nbsp;<br>
down in&nbsp;16-word units.&nbsp;<br>
The ARM9TDMI instruction port is used to&nbsp;load instructions&nbsp;and&nbsp;therefore&nbsp;only&nbsp;<br>
performs&nbsp;read&nbsp;operations. The only&nbsp;coherency problem&nbsp;arises when&nbsp;the&nbsp;program&nbsp;that&nbsp;<br>
the cache&nbsp;holds&nbsp;copies&nbsp;of&nbsp;is&nbsp;modified&nbsp;in&nbsp;main&nbsp;memory.&nbsp;Any&nbsp;modification&nbsp;of&nbsp;code&nbsp;<br>
(such as loading&nbsp;a&nbsp;new&nbsp;program&nbsp;into&nbsp;memory&nbsp;previously occupied by&nbsp;a&nbsp;program&nbsp;that&nbsp;<br>
is no longer required) must be handled carefully, and the instruction cache selectively&nbsp;<br>
or completely&nbsp;flushed before the new program&nbsp;is&nbsp;executed.&nbsp;<br>
The ARM9TDMI data port supports&nbsp;writes&nbsp;as&nbsp;well as reads, and therefore the data&nbsp;<br>
cache&nbsp;must&nbsp;implement some&nbsp;sort of write strategy (see&nbsp;'Write strategies'&nbsp;on&nbsp;<br>
page 278).&nbsp;<br>
<hr>
<A name=351></a>The&nbsp;ARM946E-S and&nbsp;ARM966E-S&nbsp;<br>
339&nbsp;<br>
<b>Table&nbsp;12.6&nbsp; &nbsp;</b>ARM940T characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.25&nbsp;urn</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;<br>
<b>802,000&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>220</b>&nbsp;&nbsp;&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3</b>&nbsp;&nbsp;<b>Core area</b>&nbsp;&nbsp;&nbsp;<br>
<b>8.1 mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>385 mW</b>&nbsp;&nbsp;&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>2.5V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>0-200&nbsp;MHz&nbsp;MIPSAV</b>&nbsp;<br>
<b>570</b>&nbsp;&nbsp;&nbsp;<br>
As the ARM9TDMI operates&nbsp;at high&nbsp;clock rates, the&nbsp;data&nbsp;cache&nbsp;is designed&nbsp;to sup-<br>
port write-back&nbsp;operation. The&nbsp;simpler write-through&nbsp;option is&nbsp;also&nbsp;available, and the&nbsp;<br>
memory protection unit is used&nbsp;to define&nbsp;which&nbsp;mode is&nbsp;selected&nbsp;for a&nbsp;particular&nbsp;<br>
address.&nbsp;Cache&nbsp;lines are allocated only&nbsp;on&nbsp;read&nbsp;misses.&nbsp;<br>
The ARM940T supports&nbsp;cache 'cleaning'&nbsp;through a software mechanism&nbsp;that&nbsp;<br>
is&nbsp;used&nbsp;to&nbsp;check&nbsp;every&nbsp;cache&nbsp;line&nbsp;and&nbsp;flush&nbsp;any&nbsp;that&nbsp;are&nbsp;dirty.&nbsp;This&nbsp;clearly&nbsp;takes&nbsp;some&nbsp;<br>
time. It does not have the&nbsp;mechanism&nbsp;in&nbsp;the ARM920T to clean lines by their&nbsp;<br>
memory&nbsp;address.&nbsp;<br>
ARM940T write&nbsp;<br>
The write buffer&nbsp;can&nbsp;hold&nbsp;up&nbsp;to&nbsp;eight&nbsp;words&nbsp;of&nbsp;data&nbsp;and&nbsp;four addresses.&nbsp;The&nbsp;memory&nbsp;<br>
buffer&nbsp;<br>
protection&nbsp;unit defines which addresses&nbsp;are&nbsp;bufferable. Dirty&nbsp;lines flushed&nbsp;from&nbsp;the&nbsp;<br>
data cache also&nbsp;pass&nbsp;through the write&nbsp;buffer.&nbsp;<br>
ARM940T silicon&nbsp;<br>
The characteristics of an&nbsp;ARM940T&nbsp;implemented on&nbsp;a 0.25&nbsp;um&nbsp;CMOS process are&nbsp;<br>
summarized in&nbsp;Table&nbsp;12.6&nbsp;and&nbsp;a plot&nbsp;of the layout&nbsp;is shown&nbsp;in Figure 12.13 on&nbsp;<br>
page&nbsp;340. It&nbsp;can&nbsp;be&nbsp;seen&nbsp;that&nbsp;the&nbsp;complete&nbsp;CPU core&nbsp;occupies&nbsp;a relatively&nbsp;small&nbsp;pro-<br>
portion of&nbsp;the&nbsp;area of a low-cost&nbsp;system-on-chip design.&nbsp;<br>
12.5 &nbsp; The&nbsp;ARM946E-S and ARM966E-S&nbsp;<br>
The ARM946E-S&nbsp;and ARM966E-S&nbsp;are synthesizable CPU cores based upon the&nbsp;<br>
ARM9E-S integer core. (See 'ARM9E-S'&nbsp;on&nbsp;page&nbsp;263.)&nbsp;<br>
Both&nbsp;CPU cores&nbsp;have AMBA&nbsp;AHB interfaces and can&nbsp;be synthesized&nbsp;with&nbsp;an&nbsp;<br>
embedded&nbsp;trace macrocell&nbsp;as&nbsp;described&nbsp;in&nbsp;Section&nbsp;8.8&nbsp;on&nbsp;page&nbsp;237.&nbsp;They&nbsp;are intended&nbsp;<br>
for embedded&nbsp;applications&nbsp;and&nbsp;do&nbsp;not&nbsp;have&nbsp;address translation hardware.&nbsp;<br>
ARM946E-S&nbsp;<br>
The ARM946E-S has&nbsp;a&nbsp;4-way&nbsp;set-associative cache. The&nbsp;set-associative organiza-<br>
cache&nbsp;<br>
tion&nbsp;was chosen over the CAM-RAM organization&nbsp;used in the&nbsp;ARM920T and&nbsp;<br>
ARM940T because it&nbsp;is&nbsp;easier&nbsp;to construct a&nbsp;set-associative cache&nbsp;with synthesiza-<br>
ble&nbsp;RAM&nbsp;structures&nbsp;available in&nbsp;standard&nbsp;ASIC&nbsp;libraries.&nbsp;Synthesizing&nbsp;CAM-RAM&nbsp;<br>
cache&nbsp;structures&nbsp;is&nbsp;still difficult for&nbsp;most design systems.&nbsp;<br>
<hr>
<A name=352></a><IMG src="index-352_1.png"><br>
<b>340</b>&nbsp;<br>
<b>ARM CPU Cores</b>&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;12.13 &nbsp;&nbsp;</b>ARM940T&nbsp;CPU core plot.&nbsp;<br>
The instruction and data caches can each be&nbsp;from&nbsp;4&nbsp;Kbytes to&nbsp;64&nbsp;Kbytes in&nbsp;size,&nbsp;<br>
and the&nbsp;two caches need&nbsp;not&nbsp;be&nbsp;the same&nbsp;size&nbsp;as each&nbsp;other.&nbsp;Both&nbsp;use&nbsp;an&nbsp;8-word&nbsp;line,&nbsp;<br>
support lock-down,&nbsp;and employ&nbsp;a&nbsp;software-selectable replacement&nbsp;algorithm&nbsp;which&nbsp;<br>
may&nbsp;be&nbsp;pseudo-random&nbsp;or round-robin.&nbsp;The&nbsp;write&nbsp;strategy&nbsp;is&nbsp;also&nbsp;software&nbsp;selectable&nbsp;<br>
between write-through and copy-back.&nbsp;<br>
The ARM946E-S incorporates&nbsp;memory protection units and has&nbsp;an overall organi-<br>
zation&nbsp;similar to the ARM940T (shown&nbsp;in&nbsp;Figure&nbsp;12.12 on&nbsp;page&nbsp;338).&nbsp;<br>
ARM966E-S&nbsp;<br>
The&nbsp;ARM966E-S does not&nbsp;employ&nbsp;caches. Instead,&nbsp;the&nbsp;synthesized&nbsp;macrocell incor-&nbsp;<br>
memory&nbsp;<br>
porates tightly&nbsp;coupled SRAM&nbsp;mapped&nbsp;to fixed memory addresses. These memories&nbsp;<br>
can&nbsp;be&nbsp;a&nbsp;range of sizes. One memory&nbsp;is connected&nbsp;only to the&nbsp;data&nbsp;port, whereas&nbsp;the&nbsp;<br>
second&nbsp;memory&nbsp;is connected&nbsp;to both ports.&nbsp;Generally the&nbsp;second&nbsp;memory is used by&nbsp;<br>
the instruction&nbsp;port, but data&nbsp;port access&nbsp;is important&nbsp;for two&nbsp;reasons:&nbsp;<br>
•&nbsp;&nbsp;Constants (such as addresses) embedded in&nbsp;code must be read through the data&nbsp;<br>
port.&nbsp;<br>
•&nbsp;&nbsp;There must&nbsp;be&nbsp;a mechanism&nbsp;for&nbsp;initializing the&nbsp;instruction&nbsp;memory&nbsp;before&nbsp;it&nbsp;can&nbsp;<br>
be&nbsp;used.&nbsp;The&nbsp;instruction port is read-only&nbsp;and therefore cannot be&nbsp;used to&nbsp;initialize&nbsp;<br>
the instruction memory.&nbsp;<br>
The ARM966E-S also&nbsp;incorporates&nbsp;a write&nbsp;buffer to&nbsp;optimize the&nbsp;use&nbsp;of the AMBA&nbsp;<br>
AHB&nbsp;bandwidth and&nbsp;supports the connection&nbsp;of on-chip&nbsp;coprocessors.&nbsp;<br>
<hr>
<A name=353></a><b>TheARM1020E</b>&nbsp;<br>
<b>341</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Soft IP&nbsp;<br>
These synthesizable CPU cores address the strong&nbsp;market demand for&nbsp;<br>
high-performance&nbsp;processors&nbsp;that&nbsp;can&nbsp;readily&nbsp;be&nbsp;resynthesized&nbsp;on&nbsp;new process&nbsp;<br>
technologies.&nbsp;They&nbsp;represent an alternative to&nbsp;the 'hard'&nbsp;macrocells&nbsp;that&nbsp;have&nbsp;been&nbsp;<br>
the usual&nbsp;delivery&nbsp;mechanism&nbsp;for ARM&nbsp;technology.&nbsp;<br>
12.6 &nbsp; TheARM1020E&nbsp;<br>
The ARM1020E CPU is based around the&nbsp;ARM10TDMI core described in&nbsp;<br>
Section 9.4 on&nbsp;page 263. It&nbsp;implements&nbsp;ARM architecture version v5TE&nbsp;which&nbsp;<br>
includes the Thumb instruction set and the&nbsp;signal processing instruction&nbsp;set exten-<br>
sions described in Section 8.9 on page 239.&nbsp;<br>
The&nbsp;organization&nbsp;of&nbsp;the ARM1020E&nbsp;is&nbsp;very&nbsp;similar to&nbsp;that&nbsp;of the ARM920T&nbsp;shown&nbsp;<br>
in&nbsp;Figure 12.11 on&nbsp;page&nbsp;336, the differences&nbsp;being&nbsp;the&nbsp;size&nbsp;of&nbsp;the cache and the bus&nbsp;<br>
widths. The&nbsp;only&nbsp;difference&nbsp;of&nbsp;substance (at&nbsp;the level of detail shown in&nbsp;this&nbsp;figure) is&nbsp;<br>
the use of&nbsp;two&nbsp;AMBA&nbsp;AHB bus&nbsp;master&nbsp;request-grant&nbsp;handshakes&nbsp;for&nbsp;the&nbsp;instruction&nbsp;<br>
and data&nbsp;sides,&nbsp;whereas the ARM920T&nbsp;arbitrates&nbsp;these&nbsp;internally&nbsp;to&nbsp;form&nbsp;a&nbsp;single&nbsp;<br>
external request-grant interface.&nbsp;<br>
ARM1020E&nbsp;<br>
The ARM1020E incorporates a 32 Kbyte instruction cache and a 32 Kbyte data&nbsp;<br>
caches&nbsp;<br>
cache.&nbsp;Both&nbsp;caches are 64-way&nbsp;associative and use&nbsp;a&nbsp;segmented&nbsp;CAM-RAM&nbsp;struc-<br>
ture.&nbsp;They&nbsp;have&nbsp;a 32-byte&nbsp;line size.&nbsp;Both caches use&nbsp;either&nbsp;a pseudo-random&nbsp;or&nbsp;a&nbsp;<br>
round-robin&nbsp;replacement algorithm&nbsp;and&nbsp;support lock-down.&nbsp;<br>
In order to&nbsp;satisfy&nbsp;the ARMlOTDMI's bandwidth requirements&nbsp;both caches have a&nbsp;<br>
64-bit&nbsp;data&nbsp;bus;&nbsp;the instruction&nbsp;cache&nbsp;can&nbsp;supply&nbsp;two&nbsp;instructions&nbsp;per cycle, and the&nbsp;<br>
data&nbsp;cache can&nbsp;supply two words of data&nbsp;during each&nbsp;cycle&nbsp;of a load multiple&nbsp;or write&nbsp;<br>
two&nbsp;words of data&nbsp;during each&nbsp;cycle of a&nbsp;store&nbsp;multiple.&nbsp;<br>
The&nbsp;instruction cache&nbsp;is&nbsp;read-only.&nbsp;The&nbsp;data&nbsp;cache&nbsp;employs a copy-back write&nbsp;strat-<br>
egy&nbsp;and has one valid, one&nbsp;dirty and one&nbsp;write-back bit&nbsp;per line. When a line is&nbsp;<br>
replaced&nbsp;in&nbsp;the&nbsp;cache it&nbsp;may result&nbsp;in&nbsp;zero&nbsp;or eight words&nbsp;being written back&nbsp;to main&nbsp;<br>
memory, depending&nbsp;on&nbsp;the state&nbsp;of&nbsp;the&nbsp;dirty&nbsp;bit.&nbsp;The&nbsp;full&nbsp;eight-word&nbsp;cast-out&nbsp;process&nbsp;<br>
can&nbsp;be&nbsp;implemented&nbsp;in&nbsp;four memory&nbsp;cycles&nbsp;due&nbsp;to&nbsp;the&nbsp;64-bit&nbsp;memory&nbsp;data&nbsp;bus.&nbsp;<br>
The write-back bit&nbsp;duplicates&nbsp;information&nbsp;usually&nbsp;found in the translation system,&nbsp;<br>
and enables&nbsp;the cache to&nbsp;implement a&nbsp;write&nbsp;operation&nbsp;as write-through&nbsp;or&nbsp;copy-back&nbsp;<br>
without reference to&nbsp;the&nbsp;MMU.&nbsp;<br>
Hit-under-miss&nbsp;<br>
The ARM1020E also supports&nbsp;'hit-under-miss'&nbsp;operation. This&nbsp;means that if one&nbsp;<br>
buffer&nbsp;<br>
data reference causes a cache&nbsp;miss, the cache can continue to satisfy&nbsp;subsequent&nbsp;<br>
data&nbsp;references&nbsp;(provided&nbsp;that&nbsp;they&nbsp;don't&nbsp;also&nbsp;miss)&nbsp;while it&nbsp;is&nbsp;fetching the line con-<br>
taining the&nbsp;missing data.&nbsp;<br>
<hr>
<A name=354></a><b>342</b>&nbsp;<br>
<b>ARM CPU Cores</b>&nbsp;<br>
ARM1020E write&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;write buffer comprises eight slots each capable of holding an address and a&nbsp;<br>
64-&nbsp;<br>
buffer&nbsp;<br>
bit&nbsp;data&nbsp;double-word. A separate four-slot&nbsp;write buffer is used&nbsp;to handle cache cast-&nbsp;<br>
outs to&nbsp;ensure&nbsp;that&nbsp;there&nbsp;is&nbsp;no&nbsp;conflict&nbsp;in&nbsp;the&nbsp;main&nbsp;write&nbsp;buffer&nbsp;between&nbsp;cast-outs and&nbsp;<br>
hit-under-miss write&nbsp;traffic.&nbsp;<br>
ARM1020E&nbsp;<br>
The&nbsp;memory&nbsp;management&nbsp;systems is&nbsp;based upon two 64-entry&nbsp;translation&nbsp;<br>
MMU&nbsp;<br>
look-aside buffers, one&nbsp;for&nbsp;each cache. The TLBs&nbsp;also&nbsp;support selective lock-down&nbsp;<br>
to&nbsp;ensure that&nbsp;translation entries&nbsp;for critical&nbsp;real-time&nbsp;code sections do not get&nbsp;<br>
ejected.&nbsp;<br>
ARM1020Ebus&nbsp;<br>
interface&nbsp;<br>
The external&nbsp;memory bus interface&nbsp;is&nbsp;AMBA AHB&nbsp;compliant (see Section&nbsp;8.2&nbsp;on&nbsp;<br>
page 216). The ARM1020E has separate&nbsp;AMBA&nbsp;AHB interfaces for the instruction and&nbsp;<br>
data memories. Each interface makes&nbsp;its&nbsp;own&nbsp;requests to the&nbsp;bus&nbsp;arbiter, though they&nbsp;<br>
share the 32-bit&nbsp;address and 64-bit unidirectional read and write&nbsp;data bus&nbsp;interfaces.&nbsp;<br>
ARM1020E&nbsp;<br>
silicon&nbsp;<br>
The target characteristics for an ARM1020E running at 1.5 V on 0.18 urn CMOS&nbsp;<br>
are summarized in Table 12.7. The CPU&nbsp;will&nbsp;run at&nbsp;supply&nbsp;voltages down to&nbsp;1.2&nbsp;V&nbsp;<br>
for improved power-efficiency.&nbsp;<br>
<b>Table&nbsp;12.7 &nbsp;&nbsp;&nbsp;</b>ARM 1020E target characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.18&nbsp;urn</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>7,000,000&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>500</b>&nbsp;&nbsp;&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>5</b>&nbsp;&nbsp;<b>Core&nbsp;area</b>&nbsp;&nbsp;&nbsp;<br>
<b>12mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>400 mW</b>&nbsp;&nbsp;&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>1.5V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>0-400 MHz&nbsp;MIPS/W</b>&nbsp;<br>
<b>1,250</b>&nbsp;&nbsp;&nbsp;<br>
ARM10200&nbsp;<br>
The ARM&nbsp;10200 is a reference chip&nbsp;design&nbsp;based&nbsp;upon&nbsp;the ARM1020E CPU&nbsp;core, to&nbsp;<br>
which the following&nbsp;additions have&nbsp;been made:&nbsp;<br>
•&nbsp;&nbsp;a VFP10 vector&nbsp;floatingpoint&nbsp;unit;&nbsp;<br>
•&nbsp;&nbsp;a high-performance synchronous&nbsp;DRAM interface;&nbsp;<br>
•&nbsp;&nbsp;a phase-locked&nbsp;loop circuit to&nbsp;generate the high-speed CPU clock.&nbsp;<br>
The ARM&nbsp;10200 is intended to&nbsp;be&nbsp;used&nbsp;for the evaluation&nbsp;of&nbsp;the ARM1020E CPU&nbsp;<br>
core&nbsp;and&nbsp;to&nbsp;support&nbsp;benchmarking&nbsp;and system&nbsp;prototyping&nbsp;activities.&nbsp;<br>
VFP10&nbsp;<br>
High-performance vector&nbsp;floating-point&nbsp;support is provided for the&nbsp;ARM10TDMI&nbsp;<br>
through&nbsp;the&nbsp;accompanying&nbsp;VFP&nbsp;10&nbsp;floating-point coprocessor. The&nbsp;VFP 10&nbsp;incorpo-<br>
rates&nbsp;a 5-stage&nbsp;load/store&nbsp;pipeline&nbsp;and&nbsp;a&nbsp;7-stage execution&nbsp;pipeline&nbsp;and&nbsp;supports sin-<br>
gle- and double-precision IEEE 754 floating-point arithmetic&nbsp;(see Section 6.3&nbsp;on&nbsp;<br>
page 158). It is&nbsp;capable&nbsp;of&nbsp;issuing a&nbsp;floating-point&nbsp;multiply-accumulate&nbsp;operation&nbsp;at&nbsp;<br>
a rate&nbsp;of&nbsp;one&nbsp;per clock cycle.&nbsp;It&nbsp;exploits&nbsp;the&nbsp;64-bit&nbsp;data&nbsp;memory&nbsp;interface&nbsp;of the&nbsp;<br>
<hr>
<A name=355></a><IMG src="index-355_1.png"><br>
<b>The&nbsp;ARM1020E</b>&nbsp;<br>
<b>343</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
ARM10TDMI to&nbsp;load or&nbsp;store&nbsp;one&nbsp;double-precision value or&nbsp;two&nbsp;single-precision&nbsp;<br>
values in a&nbsp;clock cycle. Both&nbsp;the arithmetic&nbsp;and load/store&nbsp;instructions&nbsp;include&nbsp;'vec-<br>
tor'&nbsp;variants that perform&nbsp;the same&nbsp;operation on a set of&nbsp;registers,&nbsp;and&nbsp;since vector&nbsp;<br>
operations&nbsp;and&nbsp;vector&nbsp;load/stores can&nbsp;run concurrently, a&nbsp;peak throughput of 800&nbsp;<br>
MFLOPS&nbsp;(at 400&nbsp;MHz) is&nbsp;achievable.&nbsp;<br>
<b>AR&nbsp;M&nbsp;1&nbsp;0&nbsp;2&nbsp;0&nbsp;0&nbsp;</b>&nbsp;<br>
A plot of&nbsp;the 0.25&nbsp;mm&nbsp;ARM10200 silicon is&nbsp;shown in&nbsp;Figure 12.14. This&nbsp;first ver-<br>
silicon&nbsp;<br>
sion of&nbsp;the&nbsp;chip&nbsp;has&nbsp;a fully synthesized VFP10 core and&nbsp;the cache was&nbsp;designed&nbsp;<br>
using generic design&nbsp;rules.&nbsp;The 0.18mm version of&nbsp;the chip&nbsp;will incorporate a&nbsp;<br>
VFP 10&nbsp;core with a&nbsp;manually&nbsp;laid-out&nbsp;custom&nbsp;datapath&nbsp;and&nbsp;synthesized control, and&nbsp;<br>
the&nbsp;caches&nbsp;will&nbsp;use more process specific&nbsp;design rules&nbsp;that will significantly&nbsp;reduce&nbsp;<br>
their relative&nbsp;size.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
<b>Figure 12.14&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM10200 chip&nbsp;<br>
plot.&nbsp;<br>
<hr>
<A name=356></a><b>344</b>&nbsp;<br>
<b>ARM CPU Cores</b>&nbsp;<br>
12.7 &nbsp; Discussion&nbsp;<br>
The ARM CPU cores described&nbsp;in&nbsp;this chapter highlight a&nbsp;number of important&nbsp;<br>
aspects&nbsp;of&nbsp;the development of&nbsp;high-performance&nbsp;low-power processor subsystems.&nbsp;<br>
The issues&nbsp;relating to the design of&nbsp;the processor core&nbsp;itself&nbsp;were discussed in&nbsp;<br>
Chapter 9 and&nbsp;summarized&nbsp;in Section&nbsp;9.5 on&nbsp;page&nbsp;266. Here we are&nbsp;concerned&nbsp;with&nbsp;<br>
the&nbsp;other&nbsp;components&nbsp;that&nbsp;are&nbsp;intimately&nbsp;connected to&nbsp;the&nbsp;processor core&nbsp;and are&nbsp;criti-<br>
cal&nbsp;to&nbsp;its&nbsp;ability&nbsp;to&nbsp;realize&nbsp;its&nbsp;intrinsic&nbsp;performance&nbsp;potential.&nbsp;<br>
Memory&nbsp;<br>
The performance of&nbsp;a processor is ultimately&nbsp;limited&nbsp;by&nbsp;the bandwidth of&nbsp;its associ-<br>
bandwidth&nbsp;<br>
ated memory&nbsp;system.&nbsp;The&nbsp;ARM CPU&nbsp;core family&nbsp;demonstrates&nbsp;how a cache&nbsp;<br>
memory system&nbsp;can&nbsp;be optimized&nbsp;to different performance points:&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;ARM7TDMI is&nbsp;designed to&nbsp;waste&nbsp;very few memory cycles.&nbsp;It&nbsp;requires&nbsp;a&nbsp;<br>
memory&nbsp;that can supply&nbsp;a&nbsp;word of&nbsp;data in every&nbsp;clock cycle. As it employs a von&nbsp;<br>
Neumann architecture&nbsp;(that is, it has a&nbsp;single&nbsp;memory port&nbsp;used&nbsp;for both instruc&nbsp;<br>
tion and data&nbsp;transfers), a unified&nbsp;cache can support its&nbsp;memory&nbsp;bandwidth&nbsp;<br>
requirements.&nbsp;The ARM710T, 720T&nbsp;and&nbsp;740T all&nbsp;include such a&nbsp;cache.&nbsp;<br>
•&nbsp;&nbsp;The ARM9TDMI&nbsp;requires&nbsp;more than one word of&nbsp;data per clock cycle and&nbsp;<br>
employs a&nbsp;Harvard architecture (separate instruction and data&nbsp;memory ports) to&nbsp;<br>
achieve this. Separate&nbsp;caches&nbsp;(and&nbsp;memory&nbsp;management&nbsp;units)&nbsp;can satisfy its&nbsp;<br>
needs.&nbsp;The&nbsp;ARM920T and&nbsp;940T incorporate&nbsp;separate&nbsp;32-bit&nbsp;caches.&nbsp;<br>
•&nbsp;&nbsp;The ARM10TDMI requires&nbsp;more than&nbsp;one instruction per clock cycle as it&nbsp;<br>
attempts&nbsp;to predict and remove branches before they&nbsp;enter the execution&nbsp;unit. It&nbsp;<br>
also&nbsp;transfers&nbsp;two data words per cycle&nbsp;during&nbsp;load&nbsp;and store multiple&nbsp;instruc&nbsp;<br>
tions. It&nbsp;therefore requires separate&nbsp;caches&nbsp;each wider than&nbsp;32&nbsp;bits,&nbsp;such&nbsp;as the&nbsp;<br>
64-bit&nbsp;caches in&nbsp;the&nbsp;ARM1020E.&nbsp;<br>
The separate&nbsp;caches&nbsp;used&nbsp;on&nbsp;the&nbsp;ARM9&nbsp;and ARM&nbsp;10&nbsp;series of&nbsp;CPUs can lead&nbsp;to&nbsp;<br>
coherency&nbsp;problems&nbsp;which are&nbsp;left to software&nbsp;to resolve.&nbsp;Alternative ways to provide&nbsp;<br>
the&nbsp;necessary&nbsp;bandwidth&nbsp;are illustrated by&nbsp;the double-bandwidth&nbsp;cache&nbsp;of&nbsp;the&nbsp;<br>
ARMS 10 and the dual-ported local&nbsp;memory on the&nbsp;AMULET3H subsystem&nbsp;<br>
(described in&nbsp;Section 14.6 on&nbsp;page 390).&nbsp;Both of these approaches use a unified&nbsp;<br>
memory&nbsp;model which simplifies software&nbsp;design&nbsp;but&nbsp;at&nbsp;the cost&nbsp;of somewhat&nbsp;more&nbsp;<br>
complex hardware.&nbsp;<br>
Cache&nbsp;<br>
The relative&nbsp;merits of set-associative RAM-RAM caches and fully associative&nbsp;<br>
associativity&nbsp;<br>
CAM-RAM caches&nbsp;have been&nbsp;discussed at&nbsp;length&nbsp;in&nbsp;this&nbsp;chapter and in&nbsp;Chapter 10.&nbsp;<br>
The&nbsp;earliest&nbsp;ARM&nbsp;CPU designs&nbsp;adopted&nbsp;the segmented CAM-RAM structure for a&nbsp;<br>
combination of performance and power-efficiency reasons. The&nbsp;ARM7 series of&nbsp;<br>
CPUs&nbsp;switched&nbsp;to a 4-way set-associative RAM-RAM&nbsp;organization&nbsp;principally&nbsp;<br>
because&nbsp;RAM&nbsp;is&nbsp;smaller&nbsp;than&nbsp;CAM&nbsp;(it&nbsp;requires&nbsp;about&nbsp;half&nbsp;the&nbsp;layout&nbsp;area&nbsp;per&nbsp;bit)&nbsp;and&nbsp;<br>
is&nbsp;more&nbsp;generally available in the standard design libraries of&nbsp;the&nbsp;many&nbsp;target&nbsp;<br>
processes that&nbsp;<br>
<hr>
<A name=357></a><b>Discussion</b>&nbsp;<br>
<b>345</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
the ARM&nbsp;must address. The later ARMS, ARM9 and&nbsp;ARM 10&nbsp;CPUs&nbsp;have reverted&nbsp;to&nbsp;<br>
the segmented&nbsp;CAM-RAM&nbsp;organization, at least in part to facilitate the support of&nbsp;<br>
cache&nbsp;lock-down (discussed&nbsp;further&nbsp;in&nbsp;Example 12.1&nbsp;on&nbsp;page&nbsp;346).&nbsp;<br>
Cache write&nbsp;<br>
Write-through caches&nbsp;are the simplest&nbsp;to&nbsp;design,&nbsp;and they cope&nbsp;well when the&nbsp;proces-<br>
strategy&nbsp;<br>
sor&nbsp;clock rate&nbsp;is&nbsp;a&nbsp;small multiple&nbsp;of&nbsp;the&nbsp;main memory cycle&nbsp;rate.&nbsp;Once&nbsp;the&nbsp;processor&nbsp;<br>
clock rises&nbsp;to&nbsp;ten or more times the&nbsp;memory&nbsp;cycle rate, the&nbsp;write data traffic generated&nbsp;<br>
by&nbsp;data&nbsp;store instructions&nbsp;will&nbsp;begin&nbsp;to&nbsp;saturate&nbsp;the&nbsp;external&nbsp;memory&nbsp;bus and&nbsp;the&nbsp;pro-<br>
cessor will&nbsp;frequently be stalled waiting for&nbsp;write cycles&nbsp;to&nbsp;complete.&nbsp;The&nbsp;only way&nbsp;<br>
around&nbsp;this problem&nbsp;is&nbsp;to&nbsp;use a cache&nbsp;strategy&nbsp;that&nbsp;does&nbsp;not&nbsp;result&nbsp;in all writes&nbsp;passing&nbsp;<br>
to main&nbsp;memory, for example&nbsp;by implementing&nbsp;a copy-back cache.&nbsp;<br>
Current main&nbsp;memory will typically&nbsp;cycle&nbsp;at around 10&nbsp;MHz, so the ARM?&nbsp;series&nbsp;<br>
of&nbsp;CPUs can&nbsp;operate&nbsp;satisfactorily&nbsp;at&nbsp;60&nbsp;Mhz with&nbsp;a&nbsp;write-through cache.&nbsp;The&nbsp;<br>
ARMS&nbsp;10&nbsp;is borderline at&nbsp;its first design&nbsp;clock&nbsp;rate,&nbsp;but had&nbsp;it&nbsp;not been&nbsp;superseded&nbsp;by&nbsp;<br>
the ARM9 series&nbsp;it would&nbsp;have&nbsp;been&nbsp;taken&nbsp;to&nbsp;higher clock rates&nbsp;and was therefore&nbsp;<br>
designed with&nbsp;a copy-back cache.&nbsp;Caches&nbsp;for the ARM9&nbsp;and ARM&nbsp;10 must employ&nbsp;a&nbsp;<br>
copy-back&nbsp;strategy if their&nbsp;performance is not to&nbsp;be compromised.&nbsp;<br>
Cache line&nbsp;<br>
Longer cache&nbsp;lines reduce&nbsp;the size of&nbsp;the&nbsp;tag store (for&nbsp;a given data&nbsp;store size),&nbsp;<br>
length&nbsp;<br>
reduce the cache miss rate and increase&nbsp;the&nbsp;miss cost (the time&nbsp;taken&nbsp;to&nbsp;load&nbsp;a cache&nbsp;<br>
line). The&nbsp;ARM CPU cores all use either&nbsp;a quad-word&nbsp;(16-byte) or&nbsp;an 8-word&nbsp;<br>
(32-byte) line, the smaller size being&nbsp;preferred for the smaller&nbsp;caches and&nbsp;<br>
embedded&nbsp;code&nbsp;and the&nbsp;larger size for&nbsp;larger caches&nbsp;and&nbsp;general-purpose&nbsp;code.&nbsp;<br>
The&nbsp;64-bit&nbsp;buses used on the ARM1020E allow a 32-byte&nbsp;cache line to be loaded&nbsp;<br>
and&nbsp;flushed&nbsp;in the same&nbsp;number of&nbsp;memory cycles as&nbsp;a 16-byte line&nbsp;requires&nbsp;with a&nbsp;<br>
32-bit bus.&nbsp;<br>
Memory&nbsp;<br>
management&nbsp;<br>
The&nbsp;ARM MMU is a&nbsp;sophisticated unit that&nbsp;occupies a similar silicon&nbsp;area&nbsp;to the&nbsp;<br>
processor core&nbsp;itself. Where&nbsp;its&nbsp;functionality&nbsp;is needed it&nbsp;must be included. Any&nbsp;<br>
general-purpose system&nbsp;where the mix of application code is&nbsp;unknown at design&nbsp;<br>
time probably&nbsp;requires&nbsp;this&nbsp;functionality. Embedded&nbsp;systems running known&nbsp;appli-<br>
cation&nbsp;code can&nbsp;be designed&nbsp;to&nbsp;work&nbsp;without memory&nbsp;management, and&nbsp;it is&nbsp;hard&nbsp;to&nbsp;<br>
justify the&nbsp;cost&nbsp;of the MMU&nbsp;for&nbsp;such&nbsp;systems.&nbsp;<br>
The ARM CPU&nbsp;cores have evolved into two distinct series, one with&nbsp;the&nbsp;full MMU&nbsp;<br>
for&nbsp;general-purpose&nbsp;applications&nbsp;and&nbsp;one with the much&nbsp;simpler memory&nbsp;protection&nbsp;<br>
unit for fixed-program&nbsp;embedded&nbsp;systems. The ARM740T&nbsp;and ARM940T&nbsp;are exam-<br>
ples of&nbsp;the latter,&nbsp;while the&nbsp;general-purpose CPUs include versions&nbsp;that support&nbsp;<br>
Windows CE&nbsp;(ARM720T,&nbsp;ARM920T and ARM1020E) and those that&nbsp;do&nbsp;not&nbsp;<br>
(ARM?&nbsp;1OT and ARMS 10).&nbsp;<br>
The&nbsp;latest&nbsp;development in&nbsp;the memory&nbsp;management architecture&nbsp;is&nbsp;the&nbsp;support&nbsp;for&nbsp;<br>
TLB lock-down in&nbsp;the&nbsp;ARMS&nbsp;10, ARM920T&nbsp;and ARM1020E. This&nbsp;has&nbsp;a&nbsp;similar role&nbsp;<br>
to&nbsp;cache lock-down:&nbsp;it&nbsp;can&nbsp;be used to&nbsp;ensure&nbsp;that&nbsp;critical real-time code runs&nbsp;as&nbsp;effi-<br>
ciently as&nbsp;possible.&nbsp;<br>
<hr>
<A name=358></a><b>346</b>&nbsp;<br>
<b>ARM&nbsp;CPU Cores</b>&nbsp;<br>
12.8 &nbsp; Example&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example&nbsp;12.1&nbsp;</b><br>
<b>Why&nbsp;is&nbsp;a&nbsp;segmented associative&nbsp;cache&nbsp;better suited&nbsp;to support&nbsp;lock-</b>&nbsp;<br>
<b>down&nbsp;than&nbsp;a set-associative&nbsp;cache?</b>&nbsp;<br>
Early ARM CPUs, such&nbsp;as the ARMS whose&nbsp;cache was&nbsp;studied&nbsp;in&nbsp;Section&nbsp;10.4&nbsp;<br>
on&nbsp;page&nbsp;279,&nbsp;used&nbsp;highly&nbsp;associative&nbsp;caches with&nbsp;a CAM-RAM structure. The&nbsp;<br>
ARM700&nbsp;series&nbsp;of&nbsp;CPUs&nbsp;abandoned CAM-RAM caches in favour of&nbsp;<br>
RAM-RAM set-associative&nbsp;caches because&nbsp;the&nbsp;RAM&nbsp;tag store&nbsp;uses less die area&nbsp;<br>
than&nbsp;the equivalent&nbsp;CAM&nbsp;tag store.&nbsp;Later ARM CPUs, from&nbsp;the ARMS 10&nbsp;<br>
onwards,&nbsp;have&nbsp;reverted&nbsp;to&nbsp;a CAM-RAM&nbsp;cache,&nbsp;at&nbsp;least in&nbsp;part&nbsp;because&nbsp;of&nbsp;the&nbsp;<br>
need&nbsp;to&nbsp;support partial cache&nbsp;lock-down.&nbsp;<br>
The&nbsp;reason&nbsp;why a&nbsp;CAM-RAM&nbsp;cache&nbsp;provides better support&nbsp;for lock-down is&nbsp;<br>
simply to do&nbsp;with its level&nbsp;of associativity. The cache&nbsp;locations that a particular&nbsp;<br>
memory&nbsp;location&nbsp;can&nbsp;map&nbsp;into&nbsp;are&nbsp;determined&nbsp;by&nbsp;decoding&nbsp;some&nbsp;of its&nbsp;address&nbsp;bits.&nbsp;In&nbsp;<br>
a direct-mapped cache there&nbsp;is&nbsp;only one cache location, a&nbsp;2-way set-associative&nbsp;cache&nbsp;<br>
offers a choice&nbsp;of two&nbsp;possible&nbsp;locations, 4-way&nbsp;offers four,&nbsp;and&nbsp;so&nbsp;on.&nbsp;<br>
In the ARM&nbsp;CPUs that support it,&nbsp;lock-down&nbsp;operates&nbsp;by&nbsp;reducing the range&nbsp;of this&nbsp;<br>
choice. With&nbsp;a&nbsp;4-way set-associative&nbsp;cache&nbsp;it&nbsp;is practical&nbsp;to&nbsp;lock down a&nbsp;quarter of&nbsp;the&nbsp;<br>
cache (leaving&nbsp;a 3-way cache), half&nbsp;of the&nbsp;cache&nbsp;(2-way), or three-quarters of the cache&nbsp;<br>
(leaving a direct-mapped cache).&nbsp;This&nbsp;is a coarse&nbsp;granularity&nbsp;and is inefficient if,&nbsp;for&nbsp;<br>
example, all that need&nbsp;be&nbsp;locked&nbsp;down&nbsp;is&nbsp;memory&nbsp;to hold&nbsp;a small interrupt handler.&nbsp;<br>
The CAM-RAM&nbsp;caches&nbsp;typically offer 64-way&nbsp;associativity,&nbsp;enabling&nbsp;the cache&nbsp;to&nbsp;<br>
be&nbsp;locked-down&nbsp;in&nbsp;units&nbsp;of&nbsp;1/64&nbsp;of&nbsp;the&nbsp;total&nbsp;cache, which is&nbsp;a much&nbsp;finer&nbsp;granularity.&nbsp;<br>
<b>Exercise 12.1.1&nbsp;</b><br>
Discuss the&nbsp;impact of&nbsp;the&nbsp;following cache&nbsp;features on performance and power dissipation:&nbsp;<br>
1.&nbsp;&nbsp;Increasing associativity by&nbsp;splitting the tag and data RAMs into&nbsp;multiple blocks&nbsp;<br>
which perform&nbsp;parallel look-ups.&nbsp;<br>
2.&nbsp;&nbsp;Serializing the&nbsp;tag and data RAM accesses.&nbsp;<br>
3.&nbsp;&nbsp;Exploiting sequential access&nbsp;patterns to&nbsp;bypass the tag look-up and to optimize&nbsp;<br>
the&nbsp;data&nbsp;RAM&nbsp;access&nbsp;mechanism.&nbsp;<br>
4.&nbsp;&nbsp;Including&nbsp;separate data&nbsp;and instruction caches&nbsp;(as on&nbsp;StrongARM).&nbsp;<br>
<b>Exercise&nbsp;12.1.2&nbsp;</b><br>
Explain&nbsp;why&nbsp;an on-chip&nbsp;write buffer cannot&nbsp;be used&nbsp;with an off-chip&nbsp;memory&nbsp;man-&nbsp;<br>
agement&nbsp;unit.&nbsp;<br>
<b>Exercise&nbsp;12.1.3&nbsp;</b><br>
Why, as processor speeds rise relative to&nbsp;memory speeds, does it&nbsp;become&nbsp;increas-&nbsp;<br>
ingly important to&nbsp;use&nbsp;a copy-back&nbsp;rather&nbsp;than&nbsp;a&nbsp;write-through&nbsp;cache write&nbsp;strategy?&nbsp;<br>
<hr>
<A name=359></a><IMG src="index-359_1.png"><br>
Embedded ARM&nbsp;<br>
Applications&nbsp;<br>
&nbsp;<br>
Summary of chapter contents&nbsp;<br>
Increasingly&nbsp;the trend in&nbsp;embedded&nbsp;system&nbsp;design is to integrate all the&nbsp;major system&nbsp;<br>
functions apart from some memory&nbsp;components into a single chip. The&nbsp;benefits in&nbsp;<br>
terms of component costs, reliability&nbsp;and&nbsp;power-efficiency&nbsp;are considerable.&nbsp;The devel-<br>
opment that makes this possible is the advance in&nbsp;semiconductor process&nbsp;technology&nbsp;<br>
which now&nbsp;allows&nbsp;chips incorporating millions&nbsp;of transistors to be built cheaply,&nbsp;and&nbsp;<br>
within a&nbsp;few&nbsp;years&nbsp;wil&nbsp;&nbsp;allow&nbsp;tens of&nbsp;mil&nbsp;ions of&nbsp;transistors on&nbsp;a&nbsp;chip.&nbsp;<br>
So,&nbsp;the&nbsp;era&nbsp;of&nbsp;complex&nbsp;systems&nbsp;on&nbsp;a&nbsp;single&nbsp;chip&nbsp;is&nbsp;upon&nbsp;us. The&nbsp;ARM has played a&nbsp;<br>
leading&nbsp;role&nbsp;in&nbsp;the opening&nbsp;of&nbsp;this&nbsp;era&nbsp;since&nbsp;its very&nbsp;smal&nbsp;&nbsp;core&nbsp;size leaves&nbsp;more&nbsp;silicon&nbsp;<br>
resources&nbsp;available for the rest&nbsp;of the system&nbsp;functions.&nbsp;In this&nbsp;chapter&nbsp;we&nbsp;look&nbsp;at&nbsp;sev-<br>
eral examples&nbsp;of ARM-based&nbsp;'systems on chips', but&nbsp;we&nbsp;are, in fact, only&nbsp;scratching&nbsp;<br>
the surface of this domain.&nbsp;The next few&nbsp;years&nbsp;will see&nbsp;a flood of embedded&nbsp;applica-<br>
tions, many&nbsp;of&nbsp;which&nbsp;will&nbsp;be&nbsp;based&nbsp;around&nbsp;ARM processor cores.&nbsp;<br>
Designing a 32-bit computer system is&nbsp;a&nbsp;complex undertaking. Designing one on&nbsp;<br>
a&nbsp;single chip where&nbsp;it must be&nbsp;'right&nbsp;first&nbsp;time' is still&nbsp;very&nbsp;challenging. There&nbsp;is no&nbsp;<br>
formula&nbsp;for&nbsp;success, but&nbsp;there&nbsp;are&nbsp;many&nbsp;very&nbsp;powerful&nbsp;design&nbsp;tools available&nbsp;to&nbsp;<br>
assist the&nbsp;designer. As&nbsp;in most&nbsp;engineering&nbsp;endeavours, one can only&nbsp;get&nbsp;so&nbsp;far by&nbsp;<br>
studying the&nbsp;problem&nbsp;and&nbsp;the experiences&nbsp;of&nbsp;others. Understanding&nbsp;an&nbsp;existing&nbsp;<br>
design is far easier than creating a new&nbsp;one.&nbsp;Developing a&nbsp;new&nbsp;system on&nbsp;a chip is&nbsp;<br>
one of today's&nbsp;greatest challenges in digital electronics.&nbsp;<br>
<b>347</b>&nbsp;<br>
<hr>
<A name=360></a><b>348</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
13.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The VLSI Ruby&nbsp;II Advanced Communication Processor&nbsp;<br>
VLSI&nbsp;Technology, Inc., were&nbsp;the first ARM semiconductor&nbsp;partner&nbsp;and were instru-<br>
mental,&nbsp;along with Acorn&nbsp;Computers Limited&nbsp;and Apple Computer, Inc.,&nbsp;in&nbsp;setting&nbsp;<br>
up&nbsp;ARM&nbsp;Limited&nbsp;as&nbsp;a&nbsp;separate&nbsp;company.&nbsp;Their&nbsp;relationship with&nbsp;the ARM&nbsp;predates&nbsp;<br>
the existence of&nbsp;ARM&nbsp;Limited, since&nbsp;they&nbsp;fabricated&nbsp;the very first&nbsp;ARM&nbsp;processors&nbsp;<br>
in&nbsp;1985 and licensed&nbsp;the&nbsp;technology&nbsp;from&nbsp;Acorn Computers in 1987.&nbsp;<br>
VLSI have manufactured many&nbsp;standard&nbsp;ARM-based&nbsp;chips for Acorn&nbsp;Computers&nbsp;<br>
and&nbsp;produced ARM610&nbsp;chips&nbsp;for&nbsp;Apple&nbsp;Newtons.&nbsp;They&nbsp;have&nbsp;also&nbsp;produced&nbsp;several&nbsp;<br>
ARM-based&nbsp;designs&nbsp;for&nbsp;customer specific&nbsp;products&nbsp;and a number which&nbsp;they&nbsp;have&nbsp;<br>
made&nbsp;available as&nbsp;standard&nbsp;parts. The Ruby&nbsp;II chip is&nbsp;one such&nbsp;standard&nbsp;part&nbsp;which&nbsp;is&nbsp;<br>
intended&nbsp;for&nbsp;use in&nbsp;portable&nbsp;communications&nbsp;devices.&nbsp;<br>
Ruby II&nbsp;<br>
The organization of Ruby&nbsp;II&nbsp;is illustrated in&nbsp;Figure 13.1&nbsp;on page 349. The chip is&nbsp;<br>
organization&nbsp;<br>
based around an&nbsp;ARM&nbsp;core and includes 2&nbsp;Kbytes&nbsp;of&nbsp;fast (zero&nbsp;wait state)&nbsp;on-chip&nbsp;<br>
SRAM.&nbsp;Critical&nbsp;routines&nbsp;can be&nbsp;loaded&nbsp;into&nbsp;the&nbsp;RAM under&nbsp;application&nbsp;control&nbsp;to&nbsp;get&nbsp;<br>
the&nbsp;best&nbsp;performance&nbsp;and minimum&nbsp;power&nbsp;consumption.&nbsp;There&nbsp;is&nbsp;a&nbsp;set&nbsp;of&nbsp;peripheral&nbsp;<br>
modules&nbsp;which share&nbsp;a&nbsp;number&nbsp;of&nbsp;pins,&nbsp;including&nbsp;a&nbsp;PCMCIA interface,&nbsp;four&nbsp;<br>
byte-wide parallel&nbsp;interfaces&nbsp;and two UARTs. A mode select&nbsp;block&nbsp;controls&nbsp;which&nbsp;<br>
combination of&nbsp;these&nbsp;interfaces is&nbsp;available&nbsp;at&nbsp;any&nbsp;time,&nbsp;and byte-wide FIFO buffers&nbsp;<br>
decouple&nbsp;the processor&nbsp;from&nbsp;having&nbsp;to&nbsp;respond to&nbsp;every&nbsp;byte&nbsp;which&nbsp;is&nbsp;transferred.&nbsp;<br>
A synchronous communications&nbsp;controller&nbsp;module&nbsp;supports a&nbsp;range of standard&nbsp;<br>
serial&nbsp;communication protocols,&nbsp;and&nbsp;a&nbsp;serial&nbsp;controller&nbsp;module provides a&nbsp;<br>
software-controlled data port which can&nbsp;be&nbsp;used to implement various&nbsp;serial control&nbsp;<br>
protocols&nbsp;such&nbsp;as the I2C&nbsp;bus defined by&nbsp;Philips which enables a range&nbsp;of serial devices&nbsp;<br>
such&nbsp;as battery-backed&nbsp;RAM, real-time clock, E2PROM and audio&nbsp;codecs to&nbsp;be&nbsp;<br>
connected.&nbsp;<br>
The external&nbsp;bus interface&nbsp;supports devices with 8-, 16- and 32-bit data buses&nbsp;<br>
and&nbsp;has flexible&nbsp;wait&nbsp;state&nbsp;generation.&nbsp;The&nbsp;counter-timer block&nbsp;has three&nbsp;8-bit&nbsp;<br>
counters connected to&nbsp;a&nbsp;24-bit prescaler,&nbsp;and an&nbsp;interrupt controller&nbsp;gives pro-<br>
grammable control of all&nbsp;on- and&nbsp;off-chip interrupt sources. The chip has four&nbsp;<br>
power-management modes:&nbsp;<br>
1.&nbsp;&nbsp;On-line&nbsp;-&nbsp;all circuits are clocked at&nbsp;full&nbsp;speed.&nbsp;<br>
2.&nbsp;&nbsp;Command - the ARM&nbsp;core&nbsp;runs with&nbsp;1&nbsp;to&nbsp;64&nbsp;wait&nbsp;states&nbsp;but&nbsp;all&nbsp;other&nbsp;circuitry&nbsp;runs&nbsp;<br>
at&nbsp;full&nbsp;speed.&nbsp;An&nbsp;interrupt&nbsp;switches the&nbsp;system&nbsp;into&nbsp;on-line mode&nbsp;immediately.&nbsp;<br>
3.&nbsp;&nbsp;Sleep -&nbsp;all&nbsp;circuitry is stopped apart from&nbsp;the timers and oscillators. Particular&nbsp;<br>
interrupts&nbsp;return the system&nbsp;to&nbsp;on-line&nbsp;mode.&nbsp;<br>
4.&nbsp;&nbsp;Stopped - all&nbsp;circuits&nbsp;(including&nbsp;the&nbsp;oscillators)&nbsp;are stopped. Particular interrupts&nbsp;<br>
return the&nbsp;system&nbsp;to on-line&nbsp;mode.&nbsp;<br>
Packaging&nbsp;<br>
The Ruby&nbsp;II&nbsp;is available in 144- and&nbsp;176-pin thin quad&nbsp;flat packs and&nbsp;can operate at&nbsp;<br>
up to&nbsp;32 MHz at&nbsp;<i>5&nbsp;</i>volts.&nbsp;At&nbsp;20 MHz&nbsp;using&nbsp;32-bit&nbsp;1 wait&nbsp;state memory the chip con-<br>
sumes&nbsp;30 mA&nbsp;in&nbsp;on-line mode,&nbsp;7.9 mA&nbsp;in&nbsp;command mode,&nbsp;1.5 mA&nbsp;in&nbsp;sleep mode&nbsp;<br>
and 150 uA&nbsp;in stop&nbsp;mode.&nbsp;<br>
<hr>
<A name=361></a><IMG src="index-361_1.png"><br>
<b>The VLSI ISDN&nbsp;Subscriber Processor</b>&nbsp;<br>
<b>349</b>&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;13.1 &nbsp; &nbsp;</b>Ruby&nbsp;II advanced communication controller&nbsp;organization.&nbsp;<br>
13.2 &nbsp; The&nbsp;VLSI&nbsp;ISDN&nbsp;Subscriber Processor&nbsp;<br>
The&nbsp;VLSI ISDN Subscriber&nbsp;Processor (VIP)&nbsp;is&nbsp;a programmable&nbsp;engine&nbsp;for&nbsp;<b>ISDN&nbsp;</b><br>
(Integrated&nbsp;Services Digital&nbsp;Network;&nbsp;a&nbsp;digital&nbsp;telephony&nbsp;standard) subscriber com-<br>
munications. The design was&nbsp;developed&nbsp;by&nbsp;Hagenuk GmbH for use in&nbsp;their ISDN&nbsp;<br>
product&nbsp;range&nbsp;and subsequently licensed&nbsp;back to&nbsp;VLSI Technology&nbsp;for sale as an&nbsp;<br>
<b>ASSP&nbsp;&nbsp;</b>(Application&nbsp;Specific Standard Part). It&nbsp;incorporates most of the circuitry&nbsp;<br>
required&nbsp;to&nbsp;implement&nbsp;a full-feature ISDN terminal, supporting voice, data&nbsp;and&nbsp;video&nbsp;<br>
services down the same&nbsp;digital line. The&nbsp;sort&nbsp;of applications it is&nbsp;targeted at&nbsp;include:&nbsp;<br>
• ISDN&nbsp;terminal equipment, such as&nbsp;domestic&nbsp;and&nbsp;digital PABX&nbsp;telephones, H.320&nbsp;<br>
videophones and&nbsp;integrated&nbsp;PC communications.&nbsp;<br>
<hr>
<A name=362></a><b>350</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
•&nbsp;&nbsp;ISDN&nbsp;to&nbsp;<b>DECT&nbsp;</b>(Digital European&nbsp;Cordless&nbsp;Telephone) controllers, allowing a&nbsp;<br>
number of&nbsp;cordless&nbsp;telephones to link to&nbsp;each other and to&nbsp;an&nbsp;ISDN line for&nbsp;<br>
domestic&nbsp;and business use.&nbsp;<br>
•&nbsp;&nbsp;ISDN to PCMCIA&nbsp;communication&nbsp;cards.&nbsp;<br>
The VIP chip incorporates&nbsp;the&nbsp;specialized&nbsp;interfaces required to&nbsp;connect to the&nbsp;<br>
ISDN&nbsp;SO-interface,&nbsp;support&nbsp;for telephony&nbsp;interfaces&nbsp;such&nbsp;as a numeric keypad, a&nbsp;<br>
number display, a microphone and&nbsp;an&nbsp;earphone, digital links&nbsp;for external&nbsp;signal pro-<br>
cessors or codecs, and power&nbsp;management features such as&nbsp;a programmable clock&nbsp;and&nbsp;<br>
an&nbsp;analogue to&nbsp;digital&nbsp;converter to&nbsp;monitor the battery state.&nbsp;<br>
The ARM6&nbsp;core performs&nbsp;general control and ISDN protocol functions.&nbsp;A 3 Kbyte&nbsp;<br>
on-chip&nbsp;RAM&nbsp;operates without wait&nbsp;states at&nbsp;the full&nbsp;processor clock rate&nbsp;of 36.864&nbsp;<br>
MHz.&nbsp;Critical&nbsp;code routines can&nbsp;be&nbsp;loaded into this&nbsp;RAM&nbsp;as&nbsp;required, for example, the&nbsp;<br>
signal&nbsp;processing routines required to support&nbsp;hands-free operation.&nbsp;<br>
VIP organization&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;organization&nbsp;of&nbsp;the VIP chip is illustrated&nbsp;in&nbsp;Figure 13.2&nbsp;on page 351 and a&nbsp;<br>
typical&nbsp;system&nbsp;configuration&nbsp;is&nbsp;shown in&nbsp;Figure&nbsp;13.3&nbsp;on&nbsp;page&nbsp;352.&nbsp;<br>
Memory&nbsp;<br>
The external memory&nbsp;interface&nbsp;supports 8-,&nbsp;16-&nbsp;and&nbsp;32-bit&nbsp;off-chip&nbsp;static RAMs&nbsp;and&nbsp;<br>
interface&nbsp;<br>
ROMs and&nbsp;16-&nbsp;and 32-bit dynamic&nbsp;RAMs. The&nbsp;addressable&nbsp;memory is divided&nbsp;into&nbsp;<br>
four&nbsp;ranges, each of which&nbsp;operates&nbsp;with&nbsp;a programmable number of&nbsp;wait states&nbsp;<br>
(where&nbsp;the minimum&nbsp;is&nbsp;one wait&nbsp;state giving a 54 ns&nbsp;access time).&nbsp;<br>
SO-interface&nbsp;<br>
The on-chip ISDN SO-interface&nbsp;allows&nbsp;connection to&nbsp;an SO-interface&nbsp;bus via&nbsp;isolat-<br>
ing transformers and&nbsp;surge protection.&nbsp;The&nbsp;on-chip functions include a&nbsp;phase-locked&nbsp;<br>
loop for data and clock&nbsp;recovery,&nbsp;framing,&nbsp;and low-level&nbsp;protocols. The&nbsp;192 Kbit/s&nbsp;<br>
raw data&nbsp;rate&nbsp;includes&nbsp;two&nbsp;64&nbsp;Kbit/s B&nbsp;channels and&nbsp;one&nbsp;16 Kbit/s D channel. In&nbsp;<br>
telephony&nbsp;applications&nbsp;the&nbsp;B channels&nbsp;carry&nbsp;8-bit speech samples at&nbsp;an&nbsp;8 KHz&nbsp;<br>
sample&nbsp;rate&nbsp;and the&nbsp;D channel is used&nbsp;for control purposes.&nbsp;<br>
Codec&nbsp;<br>
The&nbsp;G.711&nbsp;codec&nbsp;includes an&nbsp;on-chip&nbsp;analogue&nbsp;front&nbsp;end&nbsp;that&nbsp;allows direct&nbsp;connec-<br>
tion to&nbsp;both a&nbsp;telephone handset and a&nbsp;hands-free&nbsp;microphone and speaker. The&nbsp;<br>
input and&nbsp;output channels have&nbsp;independently&nbsp;programmable gains. The amplifica-<br>
tion&nbsp;stages&nbsp;have power-down modes to&nbsp;save&nbsp;power&nbsp;when they&nbsp;are inactive.&nbsp;<br>
ADCs&nbsp;<br>
The on-chip analogue to digital converters&nbsp;are based upon timing how long it takes&nbsp;<br>
to discharge a&nbsp;capacitor to the input&nbsp;voltage level. This&nbsp;is a very&nbsp;simple way&nbsp;to&nbsp;<br>
measure slowly&nbsp;varying voltages,&nbsp;requiring&nbsp;little&nbsp;more than&nbsp;an on-chip comparator,&nbsp;<br>
an output to&nbsp;charge&nbsp;the capacitor&nbsp;at&nbsp;the&nbsp;start of&nbsp;the conversion&nbsp;and a&nbsp;means of&nbsp;meas-<br>
uring the time&nbsp;from&nbsp;the start of the conversion to&nbsp;the point where the comparator&nbsp;<br>
switches. Typical&nbsp;uses&nbsp;would&nbsp;be&nbsp;to measure&nbsp;the&nbsp;voltage from&nbsp;a volume control&nbsp;<br>
potentiometer&nbsp;or to&nbsp;check the&nbsp;battery voltage&nbsp;in a portable&nbsp;application.&nbsp;<br>
<hr>
<A name=363></a><IMG src="index-363_1.png"><br>
<b>The VLSI ISDN&nbsp;Subscriber Processor</b>&nbsp;<br>
<b>351</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 13.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>VIP organization.&nbsp;<br>
Keypad&nbsp;interface&nbsp;&nbsp;The&nbsp;keyboard&nbsp;interface uses parallel&nbsp;output&nbsp;ports&nbsp;to&nbsp;strobe&nbsp;the&nbsp;columns&nbsp;of&nbsp;the&nbsp;keypad&nbsp;<br>
and parallel input ports&nbsp;with&nbsp;internal&nbsp;pull-down&nbsp;resistors to&nbsp;sense&nbsp;the&nbsp;rows.&nbsp;An&nbsp;OR&nbsp;<br>
gate on&nbsp;the inputs can generate&nbsp;an&nbsp;interrupt. If&nbsp;all the column&nbsp;outputs&nbsp;are&nbsp;active,&nbsp;any&nbsp;<br>
key&nbsp;press&nbsp;will&nbsp;generate&nbsp;an&nbsp;interrupt&nbsp;whereupon&nbsp;the ARM can activate individual&nbsp;col-<br>
umns and sense individual&nbsp;rows to&nbsp;determine the&nbsp;particular&nbsp;key&nbsp;pressed.&nbsp;<br>
Clocks and&nbsp;<br>
The chip&nbsp;has two clock&nbsp;sources. Normal operation&nbsp;is at&nbsp;38.864 MHz,&nbsp;with 460.8&nbsp;<br>
timers&nbsp;<br>
KHz used&nbsp;during&nbsp;power-down. A watchdog timer resets&nbsp;the CPU if&nbsp;there&nbsp;is no&nbsp;activ-<br>
ity&nbsp;for 1.28 seconds, and a 2.5&nbsp;ms&nbsp;tinier interrupts the processor from&nbsp;sleep&nbsp;mode&nbsp;<br>
for DRAM refresh&nbsp;and&nbsp;multitasking&nbsp;purposes.&nbsp;<br>
<hr>
<A name=364></a><IMG src="index-364_1.png"><br>
<b>352</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;13.3 &nbsp;&nbsp;</b>Typical VIP system configuration.&nbsp;<br>
13.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The OneC™ VWS22100 GSM chip&nbsp;<br>
The OneC VWS22100,&nbsp;developed&nbsp;by&nbsp;VLSI Technology,&nbsp;Inc., is a system-on-chip&nbsp;<br>
design for&nbsp;a GSM mobile telephone handset.&nbsp;With the addition of&nbsp;external&nbsp;program&nbsp;<br>
and data&nbsp;memory and a suitable radio&nbsp;module it provides all the&nbsp;functions required&nbsp;<br>
in a handset. An example of&nbsp;a&nbsp;GSM handset that uses the OneC&nbsp;VWS22100 inte-<br>
grated baseband device is the Samsung&nbsp;SGH2400, a dual-band&nbsp;(GSM&nbsp;900/1800)&nbsp;<br>
handset with&nbsp;hands-free voice-activated&nbsp;dialling,&nbsp;shown&nbsp;in Figure 13.4&nbsp;on page&nbsp;353.&nbsp;<br>
VWS22100&nbsp;<br>
The&nbsp;system&nbsp;architecture of the&nbsp;OneC&nbsp;VWS22100&nbsp;is typical of&nbsp;a controller used&nbsp;in&nbsp;<br>
organization&nbsp;<br>
today's&nbsp;mobile phone handsets, incorporating an&nbsp;ARM7TDMI&nbsp;core as a&nbsp;<br>
general-purpose controller handling the user interface and certain&nbsp;GSM protocol&nbsp;<br>
layers&nbsp;and&nbsp;a&nbsp;DSP&nbsp;core&nbsp;to&nbsp;handle the baseband&nbsp;signal processing&nbsp;aided by&nbsp;some&nbsp;<br>
special-purpose signal processing hardware&nbsp;blocks.&nbsp;It is illustrated&nbsp;in&nbsp;Figure 13.5 on&nbsp;<br>
page 354.&nbsp;<br>
DSP subsystem&nbsp;<br>
The DSP subsystem&nbsp;(shown&nbsp;in&nbsp;the&nbsp;shaded rectangle in&nbsp;Figure 13.5) is based&nbsp;around&nbsp;<br>
the&nbsp;16-bit&nbsp;Oak DSP&nbsp;core. It&nbsp;performs&nbsp;all&nbsp;the&nbsp;real-time&nbsp;signal&nbsp;processing&nbsp;functions&nbsp;<br>
which include:&nbsp;<br>
•&nbsp;&nbsp;voice coding;&nbsp;<br>
•&nbsp;&nbsp;equalization;&nbsp;<br>
<hr>
<A name=365></a><IMG src="index-365_1.png"><br>
<b>The OneC™ VWS22100 GSM&nbsp;</b><br>
<b>353</b>&nbsp;<br>
<b>chip</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;13.4 &nbsp;&nbsp;</b>Samsung's SGH2400 GSM handset uses the OneC VWS22100.&nbsp;<br>
&nbsp;<br>
•&nbsp;&nbsp;channel coding;&nbsp;<br>
•&nbsp;&nbsp;echo cancellation;&nbsp;<br>
•&nbsp;&nbsp;noise suppression;&nbsp;<br>
•&nbsp;&nbsp;voice recognition;&nbsp;<br>
•&nbsp;&nbsp;data&nbsp;compression.&nbsp;<br>
ARM7TDMI&nbsp;<br>
The ARM7TDMI core is responsible&nbsp;for the system&nbsp;control functions which&nbsp;<br>
subsystem&nbsp;<br>
include:&nbsp;<br>
•&nbsp;&nbsp;the user&nbsp;interface software;&nbsp;<br>
•&nbsp;&nbsp;the GSM&nbsp;protocol stack;&nbsp;<br>
•&nbsp;&nbsp;power management;&nbsp;<br>
•&nbsp;&nbsp;driving the peripheral&nbsp;interfaces;&nbsp;<br>
•&nbsp;&nbsp;running some&nbsp;data&nbsp;applications.&nbsp;<br>
Duty allocation&nbsp;<br>
The split of&nbsp;tasks between&nbsp;the&nbsp;ARM&nbsp;and&nbsp;Oak cores can be&nbsp;illustrated&nbsp;by&nbsp;examining&nbsp;<br>
some&nbsp;of&nbsp;the&nbsp;details in Figure&nbsp;13.5.&nbsp;<br>
<hr>
<A name=366></a><IMG src="index-366_1.png"><br>
<b>354</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;13.5 &nbsp;&nbsp;</b>OneC VWS22100 GSM chip&nbsp;organization.&nbsp;<br>
The audio and&nbsp;radio interfaces (on the left&nbsp;of the&nbsp;figure) are connected&nbsp;to both&nbsp;<br>
processing&nbsp;systems. The ARM system&nbsp;sets&nbsp;the gains of&nbsp;the amplifiers, controlling&nbsp;the&nbsp;<br>
radio transmission&nbsp;power level&nbsp;and the frequency&nbsp;synthesizers, causing the ringer to&nbsp;<br>
inform&nbsp;the user of&nbsp;an&nbsp;incoming&nbsp;call, and&nbsp;so&nbsp;on.&nbsp;<br>
<hr>
<A name=367></a><b>The Ericsson-VLSI Bluetooth Baseband Controller</b>&nbsp;<br>
<b>355</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The&nbsp;data&nbsp;streams, which include&nbsp;the encoded voice data&nbsp;and the symbols transmit-<br>
ted&nbsp;and received over&nbsp;the radio&nbsp;link,&nbsp;pass&nbsp;directly&nbsp;between the Oak&nbsp;system&nbsp;and the&nbsp;<br>
peripheral&nbsp;interfaces.&nbsp;<br>
On-chip&nbsp;debug&nbsp;<br>
There are&nbsp;two&nbsp;heterogeneous processing&nbsp;systems on&nbsp;the chip.&nbsp;The on-chip debug&nbsp;<br>
hardware&nbsp;employs a&nbsp;single&nbsp;JTAG&nbsp;interface&nbsp;to&nbsp;access&nbsp;several&nbsp;debug&nbsp;features,&nbsp;includ-<br>
ing the ARM7TDMI EmbeddedlCE&nbsp;module, debug technology&nbsp;on the Oak&nbsp;DSP&nbsp;<br>
core, and other test&nbsp;and debug&nbsp;facilities.&nbsp;<br>
Power&nbsp;<br>
The battery&nbsp;life of a&nbsp;mobile&nbsp;telephone handset&nbsp;is a&nbsp;significant issue in&nbsp;the present&nbsp;<br>
management&nbsp;<br>
market-place;&nbsp;'talk-time'&nbsp;and&nbsp;'standby'&nbsp;times feature prominently in product adver-<br>
tising.&nbsp;The&nbsp;OneC&nbsp;VWS22100&nbsp;incorporates a number of&nbsp;power&nbsp;management&nbsp;features&nbsp;<br>
to optimize the performance&nbsp;of the product&nbsp;it controls:&nbsp;<br>
•&nbsp;&nbsp;global&nbsp;and&nbsp;selective power-down&nbsp;modes;&nbsp;<br>
•&nbsp;&nbsp;the ability to slow&nbsp;down&nbsp;the&nbsp;system&nbsp;clock in&nbsp;idle mode;&nbsp;<br>
•&nbsp;&nbsp;the analogue&nbsp;circuits&nbsp;also can&nbsp;operate&nbsp;at&nbsp;reduced&nbsp;power;&nbsp;<br>
•&nbsp;&nbsp;the on-chip pulse-width&nbsp;modulation&nbsp;outputs&nbsp;control battery charging;&nbsp;<br>
•&nbsp;&nbsp;the on-chip analogue-to-digital converters (ADCs) provide&nbsp;for the&nbsp;monitoring of&nbsp;<br>
the temperature and battery&nbsp;voltage to give&nbsp;optimum&nbsp;operation.&nbsp;<br>
GSM handset&nbsp;<br>
The typical hardware&nbsp;architecture of&nbsp;a GSM&nbsp;cellular&nbsp;telephone handset based&nbsp;<br>
around&nbsp;the&nbsp;OneC&nbsp;VWS22100&nbsp;is illustrated&nbsp;in&nbsp;Figure 13.6&nbsp;on&nbsp;page&nbsp;356.&nbsp;<br>
13.4 &nbsp; The&nbsp;Ericsson-VLSI&nbsp;Bluetooth Baseband Controller&nbsp;<br>
Bluetooth is a de-facto standard&nbsp;for&nbsp;wireless data communication&nbsp;for the 2.4 GHz&nbsp;<br>
band&nbsp;developed&nbsp;by&nbsp;a consortium&nbsp;of companies&nbsp;including Ericsson, IBM, Intel,&nbsp;<br>
Nokia and Toshiba.&nbsp;The standard&nbsp;is&nbsp;intended to support&nbsp;short-range communication&nbsp;<br>
(from&nbsp;10cm&nbsp;to&nbsp;10m&nbsp;range)&nbsp;in a manner&nbsp;similar to that currently&nbsp;achieved with&nbsp;<br>
infrared&nbsp;communication using the IrDA standard, but avoiding the line-of-sight,&nbsp;<br>
alignment,&nbsp;and mutual&nbsp;interference&nbsp;restrictions&nbsp;of IrDA.&nbsp;Using&nbsp;radio&nbsp;communica-<br>
tion, Bluetooth is intended&nbsp;to support laptop to cellular telephone, printer, PDA,&nbsp;<br>
desktop,&nbsp;fax machines,&nbsp;keyboards, and so&nbsp;on,&nbsp;and it can also&nbsp;provide a bridge to&nbsp;<br>
existing&nbsp;data&nbsp;networks.&nbsp;As&nbsp;such&nbsp;it&nbsp;serves&nbsp;as&nbsp;a&nbsp;cable replacement technology for&nbsp;per-<br>
sonal&nbsp;networks.&nbsp;<br>
The standard supports a gross data&nbsp;rate&nbsp;of&nbsp;1&nbsp;Mbit/s,&nbsp;and&nbsp;uses a&nbsp;frequency&nbsp;hopping&nbsp;<br>
scheme&nbsp;and forward&nbsp;error&nbsp;correction to&nbsp;give&nbsp;robust communication&nbsp;in a noisy and&nbsp;<br>
uncoordinated environment.&nbsp;<br>
<hr>
<A name=368></a><IMG src="index-368_1.png"><br>
<b>356</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;13.6 &nbsp;&nbsp;</b>Typical GSM handset architecture.&nbsp;<br>
The Ericsson-VLSI Bluetooth&nbsp;Baseband&nbsp;Controller&nbsp;chip&nbsp;is&nbsp;a jointly developed stand-<br>
ard part&nbsp;which&nbsp;is intended for use&nbsp;in&nbsp;portable&nbsp;Bluetooth-based&nbsp;communication devices.&nbsp;<br>
Bluetooth&nbsp;<br>
Bluetooth units dynamically form&nbsp;ad hoc 'piconets',&nbsp;which are groups&nbsp;of two to&nbsp;<br>
'piconet'&nbsp;<br>
eight&nbsp;units&nbsp;that operate&nbsp;the&nbsp;same&nbsp;frequency-hopping scheme. All of&nbsp;the units are&nbsp;<br>
equal peers with&nbsp;identical&nbsp;implementations,&nbsp;though&nbsp;one of&nbsp;the units will operate&nbsp;as&nbsp;<br>
master&nbsp;when the&nbsp;piconet is established.&nbsp;The master defines the clock and hopping&nbsp;<br>
sequence&nbsp;that synchronize the&nbsp;piconet.&nbsp;<br>
Multiple piconets can&nbsp;be&nbsp;linked&nbsp;to form&nbsp;a 'scatternet'.&nbsp;<br>
Bluetooth&nbsp;<br>
The organization of the Bluetooth Baseband&nbsp;Controller&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;Figure 13.7 on&nbsp;<br>
controller&nbsp;<br>
page 357. The chip&nbsp;is based&nbsp;around a synthesized&nbsp;ARM7TDMI&nbsp;core and&nbsp;includes 64&nbsp;<br>
organization&nbsp;<br>
Kbytes of fast (zero wait state)&nbsp;on-chip SRAM&nbsp;and a 4K byte&nbsp;instruction cache.&nbsp;Critical&nbsp;<br>
routines can&nbsp;be&nbsp;loaded&nbsp;into&nbsp;the RAM&nbsp;to&nbsp;get&nbsp;the best performance. The&nbsp;cache improves&nbsp;<br>
the performance&nbsp;and power-efficiency&nbsp;of&nbsp;code&nbsp;resident&nbsp;in&nbsp;the&nbsp;off-chip&nbsp;memory.&nbsp;<br>
There is&nbsp;a set&nbsp;of&nbsp;peripheral&nbsp;modules which share a number of pins, including three&nbsp;<br>
UARTs, a USB interface and an I2C-bus interface. FIFO&nbsp;buffers&nbsp;decouple the proces-<br>
sor from&nbsp;having&nbsp;to&nbsp;respond to&nbsp;every&nbsp;byte which is&nbsp;transferred through these interfaces.&nbsp;<br>
The&nbsp;external bus&nbsp;interface supports devices&nbsp;with 8-&nbsp;and 16-bit&nbsp;databuses&nbsp;and has&nbsp;<br>
flexible wait&nbsp;state generation.&nbsp;The counter&nbsp;timer&nbsp;block has three 8-bit&nbsp;counters&nbsp;con-&nbsp;<br>
<hr>
<A name=369></a><IMG src="index-369_1.png"><br>
<b>The Ericsson-VLSI Bluetooth Baseband Controller</b>&nbsp;<br>
<b>357</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;13.7 &nbsp; &nbsp;</b>Ericsson-VLSI&nbsp;Bluetooth Baseband Controller organization.&nbsp;<br>
nected to&nbsp;a 24-bit prescaler, and an&nbsp;interrupt controller gives control of&nbsp;all on- and&nbsp;<br>
off-chip&nbsp;interrupt&nbsp;sources.&nbsp;<br>
Ericsson&nbsp;<br>
The Bluetooth&nbsp;Baseband Controller&nbsp;includes a power-optimized&nbsp;hardware&nbsp;block,&nbsp;the&nbsp;<br>
Bluetooth Core&nbsp;<br>
Ericsson Bluetooth&nbsp;Core (EBC), which&nbsp;handles&nbsp;all&nbsp;the Link Controller functionality&nbsp;<br>
within the Bluetooth specification and includes the interface logic to a&nbsp;Bluetooth&nbsp;<br>
radio implementation. The EBC&nbsp;performs&nbsp;all&nbsp;the&nbsp;packet-handling functions for&nbsp;<br>
point-to-point,&nbsp;multislot and&nbsp;point-to-multipoint communications.&nbsp;<br>
The baseband&nbsp;protocol uses a combination&nbsp;of&nbsp;circuit and packet&nbsp;switching. Slots&nbsp;<br>
can&nbsp;be reserved&nbsp;for synchronous channels, for&nbsp;example to&nbsp;support voice transmission.&nbsp;<br>
<hr>
<A name=370></a><IMG src="index-370_1.png"><br>
<b>358</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Power&nbsp;<br>
The chip has&nbsp;four&nbsp;power&nbsp;management&nbsp;modes:&nbsp;<br>
management&nbsp;<br>
1.&nbsp;&nbsp;On-line:&nbsp;all&nbsp;blocks are&nbsp;clocked at&nbsp;their normal&nbsp;speed. The&nbsp;ARM7TDMI core&nbsp;<br>
clock&nbsp;is between 13&nbsp;and&nbsp;40&nbsp;MHz,&nbsp;depending&nbsp;on the&nbsp;application. At the&nbsp;maximum&nbsp;<br>
data transfer&nbsp;rate the current consumption is&nbsp;around 30&nbsp;mA.&nbsp;<br>
2.&nbsp;&nbsp;Command:&nbsp;The&nbsp;ARM7TDMI&nbsp;clock&nbsp;is&nbsp;slowed&nbsp;by&nbsp;the insertion of&nbsp;wait&nbsp;states.&nbsp;<br>
3.&nbsp;&nbsp;Sleep: The ARM7TDMI clock is stopped,&nbsp;as are the clocks to a programmable&nbsp;<br>
subset of&nbsp;the other blocks. The current drawn in this&nbsp;mode&nbsp;is around 0.3&nbsp;mA.&nbsp;<br>
4.&nbsp;&nbsp;Stopped:&nbsp;The&nbsp;clock&nbsp;oscillator&nbsp;is&nbsp;turned&nbsp;off.&nbsp;<br>
Bluetooth&nbsp;<br>
A typical Bluetooth system&nbsp;is illustrated in Figure 13.8.&nbsp;The baseband&nbsp;controller&nbsp;<br>
system&nbsp;<br>
chip requires an external&nbsp;radio&nbsp;module&nbsp;and&nbsp;program&nbsp;ROM&nbsp;to complete the system.&nbsp;<br>
The high level&nbsp;of integration leads to&nbsp;a very&nbsp;compact and economic&nbsp;implementation&nbsp;<br>
of a&nbsp;sophisticated and highly&nbsp;functional&nbsp;radio&nbsp;communication system.&nbsp;<br>
V&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;13.8 &nbsp;&nbsp;</b>Typical Bluetooth application.&nbsp;<br>
Bluetooth silicon&nbsp;<br>
A photograph&nbsp;of a Bluetooth&nbsp;die is shown&nbsp;in&nbsp;Figure 13.9&nbsp;on page 359. The die area&nbsp;<br>
is dominated&nbsp;by the 64&nbsp;Kbyte&nbsp;SRAM,&nbsp;with the&nbsp;synthesized&nbsp;EBC&nbsp;(in&nbsp;the bottom&nbsp;<br>
right-hand quadrant) being&nbsp;the second&nbsp;largest block.&nbsp;<br>
The synthesized&nbsp;ARM7TDMI core&nbsp;in&nbsp;the&nbsp;top-right&nbsp;corner&nbsp;of&nbsp;the chip&nbsp;has far less&nbsp;<br>
visible&nbsp;structure than&nbsp;the ARM7TDMI&nbsp;hard&nbsp;macrocell&nbsp;shown Figure&nbsp;9.4&nbsp;on&nbsp;page&nbsp;255.&nbsp;<br>
This is because the hard&nbsp;macrocell&nbsp;was laid&nbsp;out by&nbsp;hand&nbsp;and&nbsp;manual designers use&nbsp;<br>
very regular&nbsp;datapath&nbsp;structures to&nbsp;give&nbsp;dense layout and&nbsp;to&nbsp;minimize the number of&nbsp;<br>
different cells&nbsp;that&nbsp;must be created.&nbsp;Synthesized cells use&nbsp;less dense&nbsp;and less&nbsp;regular&nbsp;<br>
structures.&nbsp;The&nbsp;advantage of&nbsp;the&nbsp;synthesized core&nbsp;is that&nbsp;it&nbsp;can&nbsp;be&nbsp;ported&nbsp;to&nbsp;a new&nbsp;<br>
CMOS&nbsp;process much more&nbsp;rapidly.&nbsp;<br>
The characteristics of&nbsp;the Bluetooth core&nbsp;are summarized in Table 13.1&nbsp;on&nbsp;<br>
page 359.&nbsp;The processor is capable of&nbsp;operating&nbsp;at up&nbsp;to&nbsp;39&nbsp;MHz, but the data shown&nbsp;<br>
in&nbsp;the table&nbsp;are&nbsp;representative of&nbsp;a&nbsp;typical&nbsp;GSM&nbsp;application.&nbsp;The&nbsp;chip&nbsp;I/Os operate at&nbsp;<br>
3.3 V, but&nbsp;the&nbsp;core logic typically operates&nbsp;at&nbsp;2.5 V&nbsp;<br>
<hr>
<A name=371></a><IMG src="index-371_1.png"><br>
<b>The Ericsson-VLSI Bluetooth Baseband Controller</b>&nbsp;<br>
359&nbsp;<br>
&nbsp;<br>
<b>Figure 13.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Bluetooth Baseband&nbsp;Controller&nbsp;die&nbsp;photograph.&nbsp;<br>
<b>Table&nbsp;13.1 &nbsp; &nbsp;</b>Bluetooth characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.25&nbsp;urn</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>4,300,000&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>12</b>&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3</b>&nbsp;&nbsp;<b>Die area</b>&nbsp;&nbsp;&nbsp;<br>
<b>20mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>75 mW</b>&nbsp;&nbsp;&nbsp;<br>
<b>Vdd (typical)</b>&nbsp;&nbsp;&nbsp;<br>
<b>2.5V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>0-13 MHz&nbsp;MIPS/W</b>&nbsp;<br>
<b>160</b>&nbsp;<br>
Digital&nbsp;radio&nbsp;<br>
The advent&nbsp;of&nbsp;low-cost high-performance digital systems&nbsp;has&nbsp;enabled&nbsp;radio&nbsp;commu-&nbsp;<br>
nication to find&nbsp;new application areas as epitomized by the rapid growth of the&nbsp;<br>
mobile phone&nbsp;market. Digital communication enables data to&nbsp;be&nbsp;sent&nbsp;in a form&nbsp;<br>
where most&nbsp;errors caused&nbsp;by interference can&nbsp;be&nbsp;detected&nbsp;and corrected. Digital&nbsp;<br>
technology&nbsp;also&nbsp;enables sophisticated radio&nbsp;techniques such&nbsp;as frequency&nbsp;hopping&nbsp;to&nbsp;<br>
be controlled,&nbsp;further&nbsp;reducing the effects of&nbsp;interference.&nbsp;<br>
<hr>
<A name=372></a><b>360&nbsp;</b><br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
Bluetooth extends this advantage to&nbsp;much smaller&nbsp;communication networks and&nbsp;<br>
points&nbsp;to&nbsp;a&nbsp;future&nbsp;where not only&nbsp;the&nbsp;individual but also&nbsp;all of&nbsp;their personal data&nbsp;<br>
appliances will&nbsp;be&nbsp;invisibly&nbsp;connected&nbsp;to&nbsp;each&nbsp;other&nbsp;and to&nbsp;global&nbsp;networks.&nbsp;<br>
Bluetooth&nbsp;<br>
The Bluetooth application area has become&nbsp;a focus&nbsp;for activities aimed at&nbsp;integrat-&nbsp;<br>
system-on-Chip&nbsp; &nbsp; &nbsp;&nbsp; ing&nbsp;digital&nbsp;and&nbsp;radio&nbsp;functions onto&nbsp;a&nbsp;single CMOS chip. The&nbsp;typical&nbsp;<br>
application&nbsp;<br>
shown&nbsp;in&nbsp;Figure 13.8&nbsp;on page&nbsp;358 can then&nbsp;be implemented on a&nbsp;single chip.&nbsp;<br>
The&nbsp;EEC&nbsp;block&nbsp;is&nbsp;also available&nbsp;as licensable&nbsp;intellectual&nbsp;property&nbsp;for use&nbsp;in&nbsp;other&nbsp;<br>
AMBA-based designs.&nbsp;<br>
13.5 &nbsp; The&nbsp;ARM7500&nbsp;and&nbsp;ARM7500FE&nbsp;<br>
The ARM7500&nbsp;is a highly&nbsp;integrated&nbsp;single-chip&nbsp;computer which combines the&nbsp;<br>
major components&nbsp;of the&nbsp;Acorn&nbsp;Rise&nbsp;PC&nbsp;(apart from&nbsp;the memory) onto&nbsp;a single&nbsp;<br>
chip. It was the first such system&nbsp;chip to employ&nbsp;as its processor&nbsp;macrocell a full&nbsp;<br>
ARM CPU, including&nbsp;cache&nbsp;and&nbsp;memory management, rather&nbsp;than&nbsp;just a&nbsp;basic inte-<br>
ger processor&nbsp;core. The&nbsp;ARM7500FE&nbsp;adds&nbsp;the&nbsp;FPA10&nbsp;floating-point&nbsp;coprocessor&nbsp;as&nbsp;<br>
an on-chip&nbsp;macrocell, and&nbsp;incorporates&nbsp;a&nbsp;number of&nbsp;other&nbsp;minor changes.&nbsp;<br>
Both of these&nbsp;devices&nbsp;are&nbsp;well&nbsp;suited&nbsp;to consumer&nbsp;multimedia&nbsp;applications such&nbsp;as&nbsp;<br>
set-top&nbsp;boxes, Internet&nbsp;appliances and games consoles, but have many&nbsp;other potential&nbsp;<br>
application areas.&nbsp;<br>
The principal macrocells on the&nbsp;ARM7500&nbsp;and ARM7500FE chips are:&nbsp;<br>
•&nbsp;&nbsp;the ARM&nbsp;CPU core;&nbsp;<br>
•&nbsp;&nbsp;the&nbsp;FPA10&nbsp;floating-point&nbsp;coprocessor (on&nbsp;the&nbsp;ARM7500FE&nbsp;only);&nbsp;<br>
•&nbsp;&nbsp;the video and&nbsp;sound&nbsp;macrocell;&nbsp;<br>
•&nbsp;&nbsp;the memory and&nbsp;I/O controller.&nbsp;<br>
The&nbsp;ARM&nbsp;CPU&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;The&nbsp;ARM&nbsp;CPU&nbsp;core&nbsp;contains&nbsp;most&nbsp;of&nbsp;the&nbsp;functionality&nbsp;of&nbsp;the&nbsp;ARM710&nbsp;<br>
CPU, the&nbsp;<br>
Core&nbsp;<br>
only&nbsp;compromise to allow&nbsp;room&nbsp;for the other macrocells&nbsp;being&nbsp;a reduction&nbsp;in&nbsp;the&nbsp;<br>
size&nbsp;of&nbsp;the cache&nbsp;from&nbsp;8&nbsp;Kbytes to&nbsp;4&nbsp;Kbytes.&nbsp;<br>
The CPU is based&nbsp;around&nbsp;the&nbsp;ARM7 integer core (a forerunner of&nbsp;the&nbsp;<br>
ARM7TDMI,&nbsp;without Thumb&nbsp;and embedded debug&nbsp;support),&nbsp;with&nbsp;a&nbsp;4&nbsp;Kbyte&nbsp;4-way&nbsp;<br>
set-associative mixed&nbsp;instruction&nbsp;and&nbsp;data&nbsp;cache,&nbsp;a&nbsp;memory&nbsp;management&nbsp;unit&nbsp;based&nbsp;<br>
on&nbsp;a 2-level&nbsp;page table with&nbsp;a&nbsp;64-entry&nbsp;translation look-aside&nbsp;buffer and&nbsp;a write&nbsp;buffer.&nbsp;<br>
The&nbsp;FPA10&nbsp;<br>
The FPA10&nbsp;was described in some&nbsp;detail in&nbsp;Section 6.4 on page 163. It provides a signif-&nbsp;<br>
floating-point&nbsp;<br>
icant enhancement of the ability&nbsp;of the system&nbsp;to handle&nbsp;floating-point&nbsp;data types&nbsp;<br>
unit&nbsp;<br>
(which,&nbsp;without the coprocessor, would be handled using the ARM floating-point library&nbsp;<br>
<hr>
<A name=373></a>The ARM7500&nbsp;<b>and ARM7500FE</b>&nbsp;<br>
<b>361</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
routines). The floating point&nbsp;performance is up to&nbsp;6 MFLOPS (measured using the&nbsp;<br>
Lin-pack benchmark running double-precision floating point&nbsp;code) at&nbsp;40 MHz.&nbsp;<br>
The video and&nbsp;<br>
The video&nbsp;controller&nbsp;can&nbsp;generate displays using a pixel&nbsp;clock of up&nbsp;to&nbsp;120&nbsp;MHz (which&nbsp;<br>
sound macrocell&nbsp;<br>
is generated by&nbsp;a simple off-chip voltage&nbsp;controlled oscillator using an on-chip phase&nbsp;<br>
comparator). It&nbsp;includes&nbsp;a 256-entry&nbsp;colour&nbsp;palette with&nbsp;on-chip&nbsp;8-bit&nbsp;digital-to-analogue&nbsp;<br>
converters for&nbsp;each of the red, green and blue outputs and additional control bits for&nbsp;<br>
external&nbsp;mixing&nbsp;and fading. A separate&nbsp;hardware cursor&nbsp;is supported,&nbsp;and&nbsp;the output&nbsp;can&nbsp;<br>
drive a high-resolution colour monitor or a single- or double-panel&nbsp;grey-scale or colour&nbsp;<br>
liquid crystal&nbsp;display.&nbsp;The&nbsp;display timing&nbsp;is&nbsp;fully&nbsp;programmable.&nbsp;<br>
The ARM7500 sound system&nbsp;can generate&nbsp;eight&nbsp;independent&nbsp;channels&nbsp;of&nbsp;8-bit&nbsp;<br>
(logarithmic) analogue stereo sound, played through&nbsp;an on-chip exponential&nbsp;<br>
digital-to-analogue converter.&nbsp;Alternatively,&nbsp;16-bit&nbsp;sound&nbsp;samples can be generated&nbsp;<br>
through a serial&nbsp;digital&nbsp;channel&nbsp;and an&nbsp;external&nbsp;CD-quality&nbsp;digital-to-analogue&nbsp;<br>
converter. The&nbsp;ARM7500FE&nbsp;only&nbsp;supports&nbsp;the latter 16-bit&nbsp;sound system.&nbsp;<br>
The data&nbsp;channels&nbsp;for&nbsp;the video, cursor&nbsp;and&nbsp;sound&nbsp;streams are generated using the&nbsp;<br>
DMA controllers in the memory&nbsp;and I/O&nbsp;controller.&nbsp;<br>
The memory&nbsp;and&nbsp;<br>
The memory&nbsp;controller supports the&nbsp;direct connection of&nbsp;up&nbsp;to four&nbsp;banks of&nbsp;<br>
I/O controller&nbsp;<br>
DRAM&nbsp;and&nbsp;two banks&nbsp;of&nbsp;ROM.&nbsp;Each&nbsp;bank&nbsp;can&nbsp;be&nbsp;programmed&nbsp;to&nbsp;be&nbsp;16&nbsp;or&nbsp;32&nbsp;bits&nbsp;<br>
wide&nbsp;and&nbsp;the&nbsp;memory controller will make double accesses&nbsp;for&nbsp;32-bit quantities in&nbsp;<br>
16-bit&nbsp;banks.&nbsp;<br>
The&nbsp;DRAM controller uses&nbsp;page mode accesses for sequential cycles in bursts&nbsp;of&nbsp;<br>
up&nbsp;to&nbsp;256&nbsp;transfers&nbsp;and&nbsp;supports&nbsp;a&nbsp;range&nbsp;of&nbsp;DRAM&nbsp;refresh&nbsp;modes, and&nbsp;the&nbsp;ROM&nbsp;<br>
controller also supports&nbsp;burst-mode where suitable devices are used. Three DMA&nbsp;<br>
controllers handle&nbsp;data&nbsp;streams for&nbsp;the video,&nbsp;cursor&nbsp;and sound channels.&nbsp;<br>
The&nbsp;I/O controller manages a 16-bit off-chip&nbsp;I/O&nbsp;bus&nbsp;(which&nbsp;is expandable to&nbsp;32&nbsp;<br>
bits using external buffers) and a number&nbsp;of on-chip interfaces. The off-chip bus sup-<br>
ports&nbsp;simple&nbsp;peripheral&nbsp;devices, intelligent&nbsp;peripheral&nbsp;modules, PC-style&nbsp;peripherals&nbsp;<br>
and an interface for&nbsp;PCMCIA&nbsp;cards.&nbsp;<br>
The on-chip interfaces include four analogue comparators which can&nbsp;be&nbsp;used to&nbsp;<br>
support&nbsp;four analogue input&nbsp;channels, two&nbsp;serial&nbsp;ports&nbsp;intended for keyboards and/or&nbsp;<br>
mice, counter-timers, eight&nbsp;general-purpose&nbsp;open-drain I/O&nbsp;lines&nbsp;and a programmable&nbsp;<br>
interrupt&nbsp;controller. Power&nbsp;management&nbsp;facilities are&nbsp;also available.&nbsp;<br>
System&nbsp;diagram&nbsp;<br>
There are many&nbsp;variations&nbsp;on how these chips could&nbsp;be&nbsp;used,&nbsp;but a&nbsp;typical&nbsp;system&nbsp;<br>
organization&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;Figure 13.10 on&nbsp;page&nbsp;362.&nbsp;<br>
Applications&nbsp;<br>
The ARM7500&nbsp;has&nbsp;been&nbsp;used&nbsp;in&nbsp;low-cost&nbsp;versions&nbsp;of&nbsp;the&nbsp;Acorn&nbsp;Rise PC&nbsp;and in&nbsp;the&nbsp;<br>
Online Media&nbsp;interactive video set-top box. Its principal&nbsp;limitation compared with&nbsp;the&nbsp;<br>
<hr>
<A name=374></a><IMG src="index-374_1.png"><br>
<b>362</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 13.10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Typical ARM7500 system organization.&nbsp;<br>
original Rise PC&nbsp;chip set is restricting the video data stream&nbsp;to normal DRAM, whereas&nbsp;<br>
high-resolution&nbsp;displays&nbsp;on&nbsp;the standard Rise&nbsp;PC use&nbsp;VRAM. This&nbsp;precludes the use of&nbsp;<br>
large&nbsp;numbers of colours on&nbsp;displays&nbsp;with&nbsp;high&nbsp;resolutions, but&nbsp;with&nbsp;LCD&nbsp;displays&nbsp;or&nbsp;<br>
monitors of television, VGA or super-VGA&nbsp;resolution the restriction is not&nbsp;apparent. It is&nbsp;<br>
only at&nbsp;resolutions of&nbsp;1,280&nbsp;x 1,024&nbsp;and&nbsp;above&nbsp;that&nbsp;the&nbsp;number of&nbsp;colours&nbsp;becomes&nbsp;<br>
restricted because of the&nbsp;bandwidth limitations of standard&nbsp;DRAM.&nbsp;<br>
<hr>
<A name=375></a><IMG src="index-375_1.png"><br>
<IMG src="index-375_2.png"><br>
<b>The ARM7500&nbsp;and ARM7500FE</b>&nbsp;<br>
<b>363</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Since&nbsp;interactive video and games&nbsp;machines use TV quality&nbsp;displays, and portable&nbsp;<br>
computers use&nbsp;liquid&nbsp;crystal&nbsp;displays at VGA (640 x 480 pixel)&nbsp;resolution,&nbsp;the&nbsp;<br>
ARM7500 is ideally&nbsp;suited to&nbsp;these&nbsp;applications. Its high&nbsp;integration and power-saving&nbsp;<br>
features&nbsp;make&nbsp;it&nbsp;suitable&nbsp;for hand-held&nbsp;test&nbsp;equipment,&nbsp;and&nbsp;its&nbsp;high quality sound and&nbsp;<br>
graphics are good characteristics&nbsp;for multimedia applications.&nbsp;<br>
ARM7500 silicon&nbsp;<br>
A&nbsp;photograph&nbsp;of&nbsp;an&nbsp;ARM7500FE&nbsp;die is shown in Figure&nbsp;13.11 and the&nbsp;characteris-<br>
tics of&nbsp;the ARM7500&nbsp;are summarized&nbsp;in&nbsp;Table 13.2.&nbsp;Note&nbsp;the ARM7&nbsp;core&nbsp;in&nbsp;the&nbsp;<br>
upper&nbsp;left-hand&nbsp;corner&nbsp;of&nbsp;the&nbsp;die occupying&nbsp;only 5% of&nbsp;the die&nbsp;area.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;13.11 &nbsp; &nbsp;</b>ARM7500FE&nbsp;die&nbsp;photograph.&nbsp;<br>
<b>Table&nbsp;13.2 &nbsp; &nbsp;</b>ARM7500 characteristics.&nbsp;<br>
&nbsp;<br>
<hr>
<A name=376></a><IMG src="index-376_1.png"><br>
<IMG src="index-376_2.png"><br>
<b>364</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
13.6 &nbsp;&nbsp;<br>
TheARM7100&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;13.12 &nbsp;&nbsp;</b>The Psion Series&nbsp;5MX.&nbsp;<br>
The&nbsp;ARM?&nbsp;100 is a highly&nbsp;integrated&nbsp;microcontroller suited to a&nbsp;range of&nbsp;mobile&nbsp;<br>
applications&nbsp;such as&nbsp;smart&nbsp;mobile phones&nbsp;and palm-top computers. It is the basis of&nbsp;<br>
the Psion&nbsp;Series 5&nbsp;range of&nbsp;palm-top computers.&nbsp;<br>
A&nbsp;photograph&nbsp;of&nbsp;the&nbsp;Psion&nbsp;Series 5MX&nbsp;(which uses a&nbsp;later version of the 7100&nbsp;with&nbsp;<br>
a modified&nbsp;architecture&nbsp;and&nbsp;a&nbsp;more&nbsp;advanced&nbsp;process&nbsp;technology)&nbsp;is&nbsp;shown&nbsp;in&nbsp;<br>
Figure 13.12.&nbsp;<br>
ARM7100&nbsp;<br>
The&nbsp;organization&nbsp;of&nbsp;the&nbsp;ARM7100&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;Figure&nbsp;13.13&nbsp;on&nbsp;page&nbsp;365. The&nbsp;<br>
organization&nbsp;<br>
ARM710a&nbsp;CPU&nbsp;incorporates&nbsp;an&nbsp;ARM?&nbsp;processor core&nbsp;&nbsp;&nbsp;&nbsp;(a forerunner&nbsp;of the&nbsp;<br>
ARM7TDMI, without&nbsp;Thumb&nbsp;support),&nbsp;an&nbsp;ARM&nbsp;memory&nbsp;management&nbsp;unit,&nbsp;an&nbsp;<br>
8&nbsp;Kbyte 4-way&nbsp;associative quad-word&nbsp;line&nbsp;cache&nbsp;and&nbsp;a&nbsp;4-address 8-data&nbsp;word&nbsp;write&nbsp;<br>
buffer.&nbsp;The&nbsp;use of&nbsp;a&nbsp;cache&nbsp;memory in&nbsp;this&nbsp;class of&nbsp;product is primarily&nbsp;to improve&nbsp;<br>
power-efficiency, which&nbsp;it&nbsp;does by&nbsp;reducing&nbsp;the number of off-chip memory&nbsp;<br>
accesses.&nbsp;The incorporation of&nbsp;a&nbsp;memory&nbsp;management&nbsp;unit is required to support&nbsp;<br>
the class of operating&nbsp;system&nbsp;required to&nbsp;run&nbsp;the general-purpose application&nbsp;mix.&nbsp;<br>
The&nbsp;system-on-chip&nbsp;organization is&nbsp;based&nbsp;around the AMBA&nbsp;bus. The&nbsp;peripherals&nbsp;<br>
include an LCD controller, serial and&nbsp;parallel I/O ports, an interrupt controller, and&nbsp;a&nbsp;<br>
32-bit external&nbsp;bus interface&nbsp;to give efficient access&nbsp;to off-chip ROM,&nbsp;RAM&nbsp;and&nbsp;<br>
DRAM. A DRAM controller&nbsp;provides&nbsp;the&nbsp;necessary multiplexed&nbsp;address&nbsp;and&nbsp;control&nbsp;<br>
signals&nbsp;needed&nbsp;by&nbsp;this&nbsp;type&nbsp;of&nbsp;memory.&nbsp;<br>
<hr>
<A name=377></a><IMG src="index-377_1.png"><br>
<b>TheARM7100</b>&nbsp;<br>
<b>365</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 13.13&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM7100 organization.&nbsp;<br>
Power&nbsp;<br>
The&nbsp;ARM?&nbsp;100 is intended&nbsp;for use in battery-powered portable equipment where&nbsp;it&nbsp;<br>
management&nbsp;<br>
is expected to deliver high performance in&nbsp;response to user input, but to operate at&nbsp;<br>
very&nbsp;low&nbsp;power&nbsp;consumption levels&nbsp;when&nbsp;awaiting&nbsp;user&nbsp;input.&nbsp;To&nbsp;address these&nbsp;<br>
requirements&nbsp;the&nbsp;chip&nbsp;has&nbsp;three levels of&nbsp;power&nbsp;management:&nbsp;<br>
•&nbsp;&nbsp;in&nbsp;full operational&nbsp;mode&nbsp;the ARM CPU&nbsp;delivers around 14&nbsp;MIPS&nbsp;while consum&nbsp;<br>
ing 24mA&nbsp;at 3.0 V;&nbsp;<br>
•&nbsp;&nbsp;in idle&nbsp;mode&nbsp;with the CPU stopped but other systems&nbsp;running it consumes&nbsp;<br>
33 mW;&nbsp;<br>
•&nbsp;&nbsp;in&nbsp;standby&nbsp;mode, with&nbsp;only&nbsp;the&nbsp;32&nbsp;kHz&nbsp;clock&nbsp;running, it consumes 33&nbsp;uW.&nbsp;<br>
<hr>
<A name=378></a><IMG src="index-378_1.png"><br>
<b>366</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
Other features&nbsp;to enhance&nbsp;power-efficiency include support for self-refresh DRAM&nbsp;<br>
memories which will&nbsp;retain their contents&nbsp;with no intervention from&nbsp;the ARM?&nbsp;100.&nbsp;<br>
The Psion&nbsp;<br>
The organization of&nbsp;the&nbsp;Psion&nbsp;Series&nbsp;5 is&nbsp;illustrated&nbsp;in&nbsp;Figure 13.14. This&nbsp;shows how&nbsp;<br>
Series 5&nbsp;<br>
the various user interfaces connect to the ARM?&nbsp;100, giving a system&nbsp;of&nbsp;considera-<br>
ble architectural sophistication with&nbsp;minimal complexity&nbsp;at the chip&nbsp;level.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;13.14 &nbsp;&nbsp;</b>The Psion Series 5 hardware organization.&nbsp;<br>
<hr>
<A name=379></a><IMG src="index-379_1.png"><br>
The ARM7100&nbsp;<br>
367&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
The&nbsp;principal&nbsp;user&nbsp;input&nbsp;devices are the&nbsp;keyboard&nbsp;and the&nbsp;stylus pointing&nbsp;device.&nbsp;<br>
The former is connected simply to parallel&nbsp;I/O pins; the latter uses a transparent digi-<br>
tizing tablet overlaid on the&nbsp;LCD display&nbsp;and interfaced&nbsp;via an analogue-to-digital&nbsp;<br>
converter (ADC).&nbsp;<br>
Communications&nbsp;devices include an&nbsp;RS232&nbsp;serial interface&nbsp;for&nbsp;wired&nbsp;connection&nbsp;<br>
and an IrDA compliant infrared interface for&nbsp;wireless connection to&nbsp;printers,&nbsp;modems&nbsp;<br>
and host&nbsp;PCs (for software loading and&nbsp;backup). An audio&nbsp;codec allows sound to&nbsp;be&nbsp;<br>
digitized&nbsp;from&nbsp;a built-in&nbsp;microphone, stored&nbsp;in&nbsp;the memory, and&nbsp;played back&nbsp;later&nbsp;<br>
through the small&nbsp;built-in&nbsp;loud-speaker.&nbsp;<br>
Hardware expansion is&nbsp;catered&nbsp;for&nbsp;through PCcard slots.&nbsp;<br>
ARM7100 silicon&nbsp;<br>
A plot&nbsp;of&nbsp;the ARM?&nbsp;100 silicon&nbsp;layout&nbsp;is&nbsp;shown in&nbsp;Figure 13.15 and its principal&nbsp;<br>
characteristics&nbsp;are summarized in&nbsp;Table 13.3 on&nbsp;page&nbsp;368.&nbsp;<br>
It&nbsp;can be&nbsp;seen from&nbsp;Figure 13.15 that&nbsp;the silicon area is&nbsp;dominated by&nbsp;the&nbsp;CPU core&nbsp;<br>
which&nbsp;occupies&nbsp;all but the leftmost quarter&nbsp;of the chip core area. The&nbsp;8&nbsp;Kbyte cache&nbsp;<br>
RAM occupies&nbsp;the lower&nbsp;half&nbsp;of the CPU core area, with the cache&nbsp;tag&nbsp;store above it&nbsp;<br>
to&nbsp;the left, the&nbsp;MMU&nbsp;above&nbsp;that,&nbsp;and the ARM?&nbsp;core at&nbsp;the&nbsp;top right. All of the periph-<br>
erals&nbsp;and the AMBA bus are in the leftmost quarter.&nbsp;<br>
&nbsp;<br>
<b>Figure 13.15&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>ARM7100 die plot.&nbsp;<br>
<hr>
<A name=380></a><b>368</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
<b>Table&nbsp;13.3 &nbsp; &nbsp;</b>ARM?&nbsp;100 characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.6 um</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>N/A&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>30</b>&nbsp;&nbsp;&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>2</b>&nbsp;&nbsp;<b>Die area</b>&nbsp;&nbsp;&nbsp;<br>
<b>N/Amm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>14&nbsp;mW</b>&nbsp;&nbsp;&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>3.3V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>18.432&nbsp;MHz&nbsp;MIPS/W</b>&nbsp;<br>
<b>212</b>&nbsp;&nbsp;&nbsp;<br>
Comparison&nbsp;with&nbsp;<br>
The balance here is different from&nbsp;the ARM7500FE (see Figure&nbsp;13.11&nbsp;on&nbsp;page&nbsp;363).&nbsp;<br>
ARM7500FE&nbsp;<br>
The high-speed colour look-up table required to&nbsp;drive&nbsp;a CRT monitor on&nbsp;the&nbsp;<br>
ARM7500FE occupies&nbsp;more&nbsp;area than does the LCD&nbsp;controller on the ARM?&nbsp;100, and&nbsp;<br>
the floating-point hardware&nbsp;on the ARM7500FE also&nbsp;occupies a considerable area. To&nbsp;<br>
compensate the&nbsp;ARM7500FE&nbsp;has a&nbsp;half-size&nbsp;cache,&nbsp;but it&nbsp;still&nbsp;occupies&nbsp;a&nbsp;greater area.&nbsp;<br>
13.7 &nbsp; TheSA-1100&nbsp;<br>
The&nbsp;SA-1100&nbsp;is&nbsp;a high-performance integrated system-on-chip based&nbsp;around&nbsp;a mod-<br>
ified version of the SA-110 StrongARM&nbsp;CPU core described in Section 12.3 on&nbsp;<br>
page 327.&nbsp;It is intended&nbsp;for use in&nbsp;mobile phone handsets, modems,&nbsp;and&nbsp;other hand-<br>
held applications that require high performance with&nbsp;minimal power consumption.&nbsp;<br>
The organization of the chip&nbsp;is&nbsp;illustrated&nbsp;in&nbsp;Figure 13.16&nbsp;on&nbsp;page 369.&nbsp;<br>
CPU&nbsp;core&nbsp;<br>
The CPU core&nbsp;on the&nbsp;SA-1100 uses the same&nbsp;SA-1 processor core as the SA-110&nbsp;<br>
with a small&nbsp;modification&nbsp;to support the&nbsp;exception vector&nbsp;relocation&nbsp;mechanism&nbsp;<br>
required by&nbsp;Windows CE. The instruction&nbsp;cache is&nbsp;also similar, being a&nbsp;16 Kbyte&nbsp;<br>
cache using a 32-way associative CAM-RAM structure with 8-word&nbsp;lines. The&nbsp;<br>
memory&nbsp;management systems are unchanged&nbsp;apart from&nbsp;the&nbsp;inclusion&nbsp;of&nbsp;the&nbsp;<br>
ProcessID&nbsp;mechanism,&nbsp;again as required&nbsp;by&nbsp;Windows CE.&nbsp;<br>
The major differences from&nbsp;the SA-110 are&nbsp;on the data cache side, where&nbsp;the origi-<br>
nal 16 Kbyte cache&nbsp;has been&nbsp;replaced&nbsp;by&nbsp;an&nbsp;8 Kbyte 32-way associative&nbsp;cache&nbsp;in par-<br>
allel with a&nbsp;512 byte&nbsp;2-way set-associative&nbsp;cache.&nbsp;The memory&nbsp;management&nbsp;tables&nbsp;are&nbsp;<br>
used&nbsp;to&nbsp;determine which data&nbsp;cache&nbsp;a&nbsp;particular memory location&nbsp;should&nbsp;be mapped&nbsp;<br>
into&nbsp;(if&nbsp;any).&nbsp;The&nbsp;objective of&nbsp;the second&nbsp;'mini-cache'&nbsp;is&nbsp;to&nbsp;allow&nbsp;large&nbsp;data&nbsp;structures&nbsp;<br>
to be&nbsp;cached without causing&nbsp;major&nbsp;pollution of&nbsp;the main data&nbsp;cache.&nbsp;<br>
The&nbsp;other&nbsp;difference&nbsp;on&nbsp;the&nbsp;data cache side&nbsp;is&nbsp;the addition&nbsp;of&nbsp;a read&nbsp;buffer.&nbsp;This&nbsp;unit&nbsp;<br>
can be&nbsp;used to&nbsp;pre-load data&nbsp;before&nbsp;the&nbsp;processor&nbsp;requests&nbsp;it so&nbsp;that&nbsp;when&nbsp;it&nbsp;is&nbsp;<br>
requested it&nbsp;is&nbsp;available&nbsp;with&nbsp;much reduced&nbsp;latency.&nbsp;The&nbsp;read&nbsp;buffer&nbsp;is&nbsp;software&nbsp;con-<br>
trolled via coprocessor registers.&nbsp;<br>
The final&nbsp;extension&nbsp;to&nbsp;the CPU core&nbsp;is&nbsp;the addition of&nbsp;hardware&nbsp;breakpoint&nbsp;and&nbsp;<br>
watchpoint registers,&nbsp;again&nbsp;programmed via&nbsp;coprocessor registers.&nbsp;<br>
<hr>
<A name=381></a><IMG src="index-381_1.png"><br>
<b>TheSA-1100</b>&nbsp;<br>
<b>369</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 13.16&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>SA-1100 organization.&nbsp;<br>
Memory&nbsp;<br>
The memory controller supports up&nbsp;to four&nbsp;banks&nbsp;of&nbsp;32-bit&nbsp;off-chip DRAM, which&nbsp;<br>
controller&nbsp;<br>
may&nbsp;be conventional&nbsp;or&nbsp;of&nbsp;the&nbsp;'extended&nbsp;data&nbsp;out'&nbsp;(EDO)&nbsp;variety.&nbsp;ROM, flash&nbsp;<br>
memory&nbsp;and&nbsp;SRAM are also supported.&nbsp;<br>
Further&nbsp;memory expansion is supported&nbsp;through the PCMCIA interface&nbsp;(which&nbsp;<br>
requires some&nbsp;external&nbsp;'glue'&nbsp;logic), where&nbsp;two card slots&nbsp;are supported.&nbsp;<br>
<hr>
<A name=382></a><b>370</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;System&nbsp;control&nbsp;<br>
The on-chip&nbsp;system&nbsp;control&nbsp;functions include:&nbsp;<br>
•&nbsp;&nbsp;a&nbsp;reset&nbsp;controller;&nbsp;<br>
•&nbsp;&nbsp;a power&nbsp;management controller that handles low-battery&nbsp;warnings and&nbsp;switches&nbsp;<br>
the system&nbsp;between its&nbsp;various operating&nbsp;modes;&nbsp;<br>
•&nbsp;&nbsp;an operating system&nbsp;timer block that supports&nbsp;general timing and watchdog functions;&nbsp;<br>
•&nbsp;&nbsp;an interrupt&nbsp;controller;&nbsp;<br>
•&nbsp;&nbsp;a real-time&nbsp;clock that&nbsp;runs from&nbsp;a 32&nbsp;KHz&nbsp;crystal&nbsp;source;&nbsp;<br>
•&nbsp;&nbsp;28&nbsp;general-purpose&nbsp;I/O pins.&nbsp;<br>
Peripherals&nbsp;<br>
The peripheral&nbsp;subsystem&nbsp;includes&nbsp;an LCD controller&nbsp;and specialized&nbsp;serial ports&nbsp;<br>
for USB, SDLC, IrDA, codec&nbsp;and standard UART functions. A&nbsp;6-channel&nbsp;DMA&nbsp;<br>
controller releases&nbsp;the&nbsp;CPU&nbsp;from&nbsp;straightforward data&nbsp;transfer responsibilities.&nbsp;<br>
Bus structure&nbsp;<br>
As&nbsp;can be seen from&nbsp;Figure&nbsp;13.16,&nbsp;the&nbsp;SA-1100&nbsp;is built around&nbsp;two&nbsp;buses connected&nbsp;<br>
through a&nbsp;bridge:&nbsp;<br>
•&nbsp;&nbsp;The&nbsp;<i>system&nbsp;bus&nbsp;</i>connects&nbsp;all&nbsp;the&nbsp;bus&nbsp;masters and&nbsp;the off-chip&nbsp;memory.&nbsp;<br>
•&nbsp;&nbsp;<i>The peripheral bus&nbsp;</i>connects&nbsp;all the&nbsp;slave peripheral devices.&nbsp;<br>
This&nbsp;dual&nbsp;bus structure&nbsp;is similar to&nbsp;the AMBA ASB-APB (or AHB-APB) split. It&nbsp;<br>
minimizes&nbsp;the size of the&nbsp;bus that&nbsp;has a high duty cycle&nbsp;and also&nbsp;reduces&nbsp;the&nbsp;complex-<br>
ity&nbsp;and&nbsp;cost of&nbsp;the bus&nbsp;interface&nbsp;that&nbsp;must be&nbsp;built into&nbsp;all of the peripherals.&nbsp;<br>
Applications&nbsp;<br>
A typical SA-1100&nbsp;application&nbsp;will&nbsp;require&nbsp;a certain amount of off-chip&nbsp;memory,&nbsp;<br>
probably&nbsp;including some&nbsp;DRAM and&nbsp;some&nbsp;ROM and/or flash&nbsp;memory. All that is&nbsp;then&nbsp;<br>
required&nbsp;is&nbsp;the necessary interface&nbsp;electronics&nbsp;for the various peripheral&nbsp;interfaces,&nbsp;<br>
display,&nbsp;and so&nbsp;on. The resulting system&nbsp;is very&nbsp;simple at the&nbsp;PCB level, yet&nbsp;very&nbsp;pow-<br>
erful&nbsp;and sophisticated&nbsp;in&nbsp;terms of&nbsp;its&nbsp;processing&nbsp;capability&nbsp;and&nbsp;system&nbsp;architecture.&nbsp;<br>
SA-1100 silicon&nbsp;<br>
The characteristics of&nbsp;the SA-1100 chip&nbsp;are&nbsp;summarized in Table 13.4 and a plot of&nbsp;<br>
the die is&nbsp;shown in&nbsp;Figure&nbsp;13.17 on page 371. The chip can operate&nbsp;with&nbsp;a power&nbsp;<br>
supply&nbsp;voltage as low as 1.5V&nbsp;for optimum&nbsp;power-efficiency. Higher performance&nbsp;<br>
can be achieved at the cost&nbsp;of somewhat&nbsp;lower power-efficiency&nbsp;by&nbsp;operating&nbsp;the&nbsp;<br>
device at a slightly&nbsp;higher supply&nbsp;voltage.&nbsp;<br>
<b>Table&nbsp;13.4 &nbsp; &nbsp;</b>SA-1100 characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.35 um</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>2,500,000&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>220/250</b>&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3</b>&nbsp;&nbsp;<b>Die area</b>&nbsp;&nbsp;&nbsp;<br>
<b>75mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>330/550 mW</b>&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>1.5/2V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>190/220&nbsp;MHz&nbsp;MIPS/W</b>&nbsp;&nbsp;&nbsp;<br>
<b>665/450</b>&nbsp;<br>
<hr>
<A name=383></a><IMG src="index-383_1.png"><br>
<b>Examples and exercises</b>&nbsp;<br>
371&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure 13.17&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>SA-1100 die plot.&nbsp;<br>
13.8 &nbsp; Examples&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example&nbsp;13.1&nbsp;</b><br>
<b>Estimate the&nbsp;performance improvement&nbsp;which results from running&nbsp;a</b>&nbsp;<br>
<b>critical DSP routine&nbsp;in zero&nbsp;wait&nbsp;state on-chip&nbsp;RAM instead&nbsp;of two&nbsp;wait&nbsp;</b><br>
<b>state&nbsp;off-chip&nbsp;RAM.</b>&nbsp;<br>
Typical&nbsp;DSP routines&nbsp;are dominated by&nbsp;multiply-accumulate computations.&nbsp;A code&nbsp;<br>
sequence&nbsp;might&nbsp;be:&nbsp;<br>
initialize&nbsp;get&nbsp;next&nbsp;data&nbsp;<br>
LOOP&nbsp; &nbsp; LDR&nbsp;<br>
rO,&nbsp;&nbsp;[r3],&nbsp;&nbsp;#4&nbsp;<br>
value and&nbsp;next&nbsp;<br>
LDR&nbsp;<br>
rl, [r4],&nbsp;#4&nbsp;<br>
coefficient&nbsp;accumulate&nbsp;<br>
MLA&nbsp;<br>
r5,&nbsp;rO,&nbsp;rl,&nbsp;r5&nbsp;<br>
next&nbsp;term&nbsp;decrement&nbsp;loop&nbsp;<br>
<i>SUBS&nbsp;</i><br>
r2, r2,&nbsp;#1&nbsp;<br>
counter&nbsp;loop&nbsp;if&nbsp;not&nbsp;<br>
BNE&nbsp;<br>
LOOP&nbsp;<br>
finished&nbsp;<br>
This&nbsp;loop&nbsp;requires seven instruction fetches&nbsp;(including&nbsp;two&nbsp;in&nbsp;the&nbsp;branch&nbsp;shadow)&nbsp;<br>
and two&nbsp;data&nbsp;fetches. On a standard&nbsp;ARM&nbsp;core the multiply&nbsp;takes a data-dependent&nbsp;<br>
number of&nbsp;computation cycles, evaluating&nbsp;two bits per&nbsp;cycle. If we assume&nbsp;16-bit&nbsp;<br>
<hr>
<A name=384></a><b>372</b>&nbsp;<br>
<b>Embedded ARM&nbsp;Applications</b>&nbsp;<br>
coefficients and order the&nbsp;multiplication&nbsp;so&nbsp;that&nbsp;the coefficient determines the number&nbsp;<br>
of cycles, the&nbsp;multiply&nbsp;will&nbsp;require&nbsp;eight&nbsp;internal&nbsp;cycles.&nbsp;Each load also&nbsp;requires an&nbsp;<br>
internal&nbsp;cycle.&nbsp;<br>
If the&nbsp;data&nbsp;and&nbsp;coefficients are&nbsp;always&nbsp;in&nbsp;on-chip&nbsp;memory, the&nbsp;loop&nbsp;takes&nbsp;19&nbsp;clock&nbsp;<br>
cycles if executed from&nbsp;on-chip RAM, with&nbsp;14 additional&nbsp;wait state cycles&nbsp;if executed&nbsp;<br>
from&nbsp;two wait&nbsp;state&nbsp;off-chip&nbsp;RAM.&nbsp;<br>
The&nbsp;use&nbsp;of&nbsp;on-chip&nbsp;RAM&nbsp;therefore&nbsp;speeds&nbsp;the loop&nbsp;up&nbsp;by&nbsp;around&nbsp;75%.&nbsp;<br>
Note that this speed-up is a lot less than&nbsp;the factor three that&nbsp;might be expected&nbsp;<br>
from&nbsp;simply comparing memory access speeds.&nbsp;<br>
<b>Exercise 13.1.1&nbsp;</b><br>
Estimate the power&nbsp;saving that results&nbsp;from&nbsp;using the on-chip RAM. (Assume that&nbsp;<br>
on-chip&nbsp;accesses cost 2 nJ&nbsp;and off-chip accesses 10 nJ.)&nbsp;<br>
<b>Exercise&nbsp;13.1.2&nbsp;</b><br>
Repeat the estimates assuming&nbsp;the external&nbsp;memory is&nbsp;restricted&nbsp;to!6 bits&nbsp;wide.&nbsp;<br>
<b>Exercise&nbsp;13.1.3&nbsp;</b><br>
Repeat&nbsp;the&nbsp;estimates for&nbsp;both&nbsp;32-&nbsp;and&nbsp;16-bit&nbsp;external&nbsp;memory&nbsp;assuming&nbsp;that&nbsp;the&nbsp;<br>
processor supports Thumb&nbsp;mode (and the program&nbsp;is rewritten to use Thumb&nbsp;<br>
instructions) and high-speed&nbsp;multiplication.&nbsp;<br>
<b>Example&nbsp;13.2&nbsp;</b><br>
<b>Survey&nbsp;the designs presented in&nbsp;this&nbsp;chapter and summarize&nbsp;the</b>&nbsp;<br>
<b>power-saving techniques employed on the system&nbsp;chips&nbsp;</b><br>
<b>described here.</b>&nbsp;<br>
Firstly,&nbsp;all the system&nbsp;chips&nbsp;display&nbsp;a&nbsp;high&nbsp;level&nbsp;of&nbsp;integration&nbsp;which saves&nbsp;power&nbsp;<br>
whenever&nbsp;two modules&nbsp;on&nbsp;the&nbsp;same&nbsp;chip&nbsp;exchange&nbsp;data.&nbsp;<br>
All the chips are based&nbsp;around&nbsp;an ARM&nbsp;core&nbsp;which&nbsp;is, itself, very&nbsp;power-efficient.&nbsp;<br>
Though&nbsp;none&nbsp;of the&nbsp;chips&nbsp;has enough&nbsp;on-chip&nbsp;memory&nbsp;to remove the&nbsp;need&nbsp;for&nbsp;<br>
off-chip&nbsp;memory&nbsp;completely,&nbsp;several&nbsp;have&nbsp;a&nbsp;few kilobytes&nbsp;of&nbsp;on-chip&nbsp;RAM&nbsp;which&nbsp;can&nbsp;<br>
be loaded&nbsp;with&nbsp;critical routines to save&nbsp;power&nbsp;(and&nbsp;improve performance).&nbsp;<br>
Several&nbsp;of&nbsp;the&nbsp;chips incorporate clock&nbsp;control&nbsp;circuitry&nbsp;which reduces the&nbsp;clock fre-<br>
quency&nbsp;(or&nbsp;stops the clock altogether)&nbsp;when&nbsp;the&nbsp;chip&nbsp;is&nbsp;not&nbsp;fully loaded,&nbsp;and switches&nbsp;<br>
the&nbsp;clock&nbsp;to individual modules off when&nbsp;they&nbsp;are&nbsp;inactive.&nbsp;<br>
The chips are&nbsp;mainly based&nbsp;upon static&nbsp;or pseudo-static CMOS technology where,&nbsp;<br>
with&nbsp;a&nbsp;little&nbsp;care,&nbsp;digital&nbsp;circuits&nbsp;only&nbsp;consume power when&nbsp;they switch. Some&nbsp;of the&nbsp;<br>
chips&nbsp;also&nbsp;incorporate analogue functions&nbsp;which require&nbsp;continuous&nbsp;bias&nbsp;currents,&nbsp;so&nbsp;<br>
these&nbsp;circuits can&nbsp;usually&nbsp;be&nbsp;powered down when they&nbsp;are&nbsp;inactive.&nbsp;<br>
<b>Exercise 13.2.1&nbsp;</b><br>
In embedded&nbsp;systems there is&nbsp;usually&nbsp;no&nbsp;'reset'&nbsp;button to&nbsp;restart a&nbsp;system&nbsp;that has&nbsp;<br>
crashed. What techniques&nbsp;are used&nbsp;to recover from&nbsp;software&nbsp;crashes?&nbsp;<br>
<hr>
<A name=385></a><b>Examples and exercises&nbsp;</b><br>
<b>373</b>&nbsp;<br>
<b>Exercise 13.2.2&nbsp;</b><br>
Several of the&nbsp;chips described in this&nbsp;chapter incorporate&nbsp;counter/timer&nbsp;modules.&nbsp;<br>
What&nbsp;are these used&nbsp;for?&nbsp;<br>
<b>Exercise&nbsp;13.2.3&nbsp;</b><br>
The ARM7500 has an on-chip cache, AMULET2e&nbsp;(see&nbsp;Section 14.4 on page 384)&nbsp;<br>
has on-chip&nbsp;memory&nbsp;which&nbsp;can be&nbsp;configured&nbsp;either as&nbsp;a cache&nbsp;or&nbsp;as directly&nbsp;<br>
addressed&nbsp;memory,&nbsp;and Ruby&nbsp;II and&nbsp;VIP&nbsp;simply&nbsp;have&nbsp;directly&nbsp;addressed on-chip&nbsp;<br>
memory. Explain the difference between&nbsp;on-chip&nbsp;RAM and an on-chip&nbsp;cache and&nbsp;<br>
explain&nbsp;why the designers of&nbsp;these&nbsp;chips&nbsp;made the choices&nbsp;that they&nbsp;did.&nbsp;<br>
<hr>
<A name=386></a><IMG src="index-386_1.png"><br>
The AMULET Asynchronous&nbsp;<br>
ARM Processors&nbsp;<br>
&nbsp;<br>
Summary of chapter contents&nbsp;<br>
The AMULET&nbsp;processor cores are fully asynchronous implementations&nbsp;of&nbsp;the&nbsp;ARM&nbsp;<br>
architecture,&nbsp;which means&nbsp;that they are self-timed and operate&nbsp;without&nbsp;any&nbsp;exter-<br>
nal&nbsp;y supplied&nbsp;clock.&nbsp;<br>
Self-timed digital systems&nbsp;have&nbsp;potential&nbsp;advantages in the areas&nbsp;of&nbsp;<br>
power-efficiency&nbsp;and electromagnetic&nbsp;compatibility (EMC), but they require a radical&nbsp;<br>
redesign of&nbsp;the system architecture&nbsp;if&nbsp;the asynchronous&nbsp;timing&nbsp;framework is to&nbsp;be&nbsp;<br>
fully&nbsp;exploited,&nbsp;and designers need to learn a new&nbsp;mind&nbsp;set if they&nbsp;are&nbsp;to work in&nbsp;<br>
this&nbsp;style.&nbsp;Support&nbsp;for&nbsp;self-timed&nbsp;design&nbsp;from the&nbsp;tools&nbsp;industry&nbsp;is&nbsp;also&nbsp;lacking.&nbsp;<br>
The AMULET&nbsp;processor cores&nbsp;are research&nbsp;prototypes, developed at&nbsp;the&nbsp;Univer-<br>
sity&nbsp;of&nbsp;Manchester&nbsp;in&nbsp;England,&nbsp;and their commercial future&nbsp;is&nbsp;not&nbsp;yet&nbsp;clear. There&nbsp;is&nbsp;<br>
insufficient space in&nbsp;this&nbsp;book to present&nbsp;complete&nbsp;descriptions of them, but they&nbsp;<br>
are outlined&nbsp;here since&nbsp;they&nbsp;represent another,&nbsp;very different&nbsp;way&nbsp;to&nbsp;implement&nbsp;the&nbsp;<br>
ARM&nbsp;instruction set.&nbsp;See&nbsp;the&nbsp;'Bibliography'&nbsp;on page&nbsp;410 for references&nbsp;where fur-<br>
ther details on&nbsp;AMULET1 and&nbsp;AMULET2e may be found.&nbsp;Fuller details on&nbsp;AMULETS&nbsp;<br>
will be&nbsp;published&nbsp;in due course.&nbsp;<br>
The latest&nbsp;self-timed&nbsp;core, AMULET3, incorporates&nbsp;most of the features&nbsp;found in&nbsp;<br>
the clocked&nbsp;ARM cores,&nbsp;including&nbsp;support&nbsp;for&nbsp;the&nbsp;Thumb instruction&nbsp;set, debug&nbsp;<br>
hardware,&nbsp;an&nbsp;on-chip macrocell bus which supports&nbsp;system-on-chip&nbsp;modular&nbsp;<br>
design, and so&nbsp;on.&nbsp;It&nbsp;brings&nbsp;the asynchronous technology&nbsp;up to&nbsp;the point&nbsp;where it is&nbsp;<br>
ready&nbsp;to&nbsp;enter&nbsp;commercial use, and the&nbsp;next&nbsp;few years will tell&nbsp;if this&nbsp;technology&nbsp;has&nbsp;<br>
a&nbsp;role to&nbsp;play&nbsp;in the future&nbsp;of&nbsp;the&nbsp;ARM architecture.&nbsp;<br>
<b>374</b>&nbsp;<br>
<hr>
<A name=387></a><b>Self-timed&nbsp;design</b>&nbsp;<br>
<b>375</b>&nbsp;<br>
14.1 &nbsp; Self-timed&nbsp;design&nbsp;<br>
Today,&nbsp;and for the past quarter of a century, virtually&nbsp;all&nbsp;digital design&nbsp;has been&nbsp;<br>
based around&nbsp;the use&nbsp;of a global 'clock'&nbsp;signal which controls the&nbsp;operation&nbsp;of all&nbsp;<br>
of the components of the system. Complex&nbsp;systems&nbsp;may&nbsp;use&nbsp;multiple clocks, but&nbsp;<br>
then each clocked domain&nbsp;is designed as a&nbsp;synchronous&nbsp;subsystem,&nbsp;and the inter-<br>
faces between&nbsp;the different&nbsp;domains have&nbsp;to be designed very carefully&nbsp;to ensure&nbsp;<br>
reliable operation.&nbsp;<br>
Clocks have&nbsp;not always&nbsp;been so dominant. Many&nbsp;of the earliest computers&nbsp;<br>
employed control circuits which used local information to control local activity. How-<br>
ever, such&nbsp;'asynchronous'&nbsp;design styles&nbsp;fell out&nbsp;of favour when&nbsp;highly&nbsp;productive&nbsp;<br>
design&nbsp;methodologies based around the use of a central&nbsp;clock were developed to&nbsp;<br>
match the&nbsp;demands&nbsp;of an industry with access&nbsp;to integrated&nbsp;circuit technologies which&nbsp;<br>
offered rapidly&nbsp;increasing&nbsp;transistor resources.&nbsp;<br>
Clock&nbsp;problems &nbsp; &nbsp; &nbsp; Recently,&nbsp;however,&nbsp;clocked&nbsp;design styles have begun to run into&nbsp;practical&nbsp;<br>
problems:&nbsp;<br>
•&nbsp;&nbsp;Ever-increasing clock frequencies&nbsp;mean that&nbsp;maintaining&nbsp;global&nbsp;synchrony is getting&nbsp;<br>
harder;&nbsp;<b>clock skew&nbsp;</b>(the difference in&nbsp;the&nbsp;clock timing at different points on&nbsp;the chip)&nbsp;<br>
compromises performance and can ultimately&nbsp;lead to&nbsp;circuit&nbsp;malfunction.&nbsp;<br>
•&nbsp;&nbsp;High clock&nbsp;rates also lead to&nbsp;excessive&nbsp;<b>power consumption.&nbsp;</b>The clock&nbsp;distribu&nbsp;<br>
tion network can be responsible for a significant fraction&nbsp;of the total chip power&nbsp;<br>
consumption.&nbsp;Although&nbsp;clock-gating techniques can give a degree&nbsp;of&nbsp;control over&nbsp;<br>
the&nbsp;activity&nbsp;of&nbsp;the&nbsp;clock&nbsp;net,&nbsp;this&nbsp;is&nbsp;usually coarse-grained&nbsp;and&nbsp;can&nbsp;adversely&nbsp;<br>
affect clock skew.&nbsp;<br>
•&nbsp;&nbsp;Global&nbsp;synchrony maximizes supply current&nbsp;transients,&nbsp;causing&nbsp;<b>electromagnetic&nbsp;</b><br>
<b>interference.&nbsp;</b>EMC&nbsp;(Electromagnetic compatibility) legislation is becoming&nbsp;more&nbsp;<br>
stringent,&nbsp;and increasing&nbsp;clock&nbsp;rates make&nbsp;compliance ever more&nbsp;challenging.&nbsp;<br>
Motivation&nbsp;for&nbsp;<br>
For these&nbsp;reasons, asynchronous design techniques have&nbsp;recently&nbsp;attracted renewed&nbsp;<br>
self-timed&nbsp;<br>
interest&nbsp;as&nbsp;they&nbsp;address the&nbsp;above&nbsp;problems&nbsp;as&nbsp;follows:&nbsp;<br>
design&nbsp;<br>
•&nbsp;&nbsp;There is no problem&nbsp;with&nbsp;<b>clock skew&nbsp;</b>because there&nbsp;is no&nbsp;clock.&nbsp;<br>
•&nbsp;&nbsp;An asynchronous&nbsp;design only&nbsp;causes&nbsp;transitions in&nbsp;the&nbsp;circuit in&nbsp;response to&nbsp;a&nbsp;<br>
request&nbsp;to&nbsp;carry&nbsp;out useful work, avoiding&nbsp;the&nbsp;continuous&nbsp;drain caused&nbsp;by&nbsp;the&nbsp;clock&nbsp;<br>
signal and the&nbsp;overhead&nbsp;of complex power&nbsp;management&nbsp;systems.&nbsp;It can switch&nbsp;<br>
instantaneously&nbsp;between&nbsp;zero&nbsp;power dissipation&nbsp;and maximum&nbsp;performance. Since&nbsp;<br>
many&nbsp;embedded applications&nbsp;have rapidly&nbsp;varying&nbsp;workloads, an asynchronous&nbsp;<br>
processor&nbsp;appears to offer the&nbsp;potential of&nbsp;significant&nbsp;<b>power savings.</b>&nbsp;<br>
•&nbsp;&nbsp;Asynchronous circuits emit less&nbsp;<b>electromagnetic radiation&nbsp;</b>owing to their less&nbsp;<br>
coherent&nbsp;internal&nbsp;activity.&nbsp;<br>
<hr>
<A name=388></a><IMG src="index-388_1.png"><br>
<b>376</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
In&nbsp;addition, an&nbsp;asynchronous circuit has&nbsp;the&nbsp;potential&nbsp;to deliver typical&nbsp;rather&nbsp;than&nbsp;<br>
worst-case&nbsp;performance since&nbsp;its timing adjusts&nbsp;to actual&nbsp;conditions whereas&nbsp;a clocked&nbsp;<br>
circuit&nbsp;must be&nbsp;toleranced&nbsp;for worst-case&nbsp;conditions.&nbsp;<br>
The AMULET series&nbsp;of&nbsp;asynchronous microprocessors&nbsp;was developed at the&nbsp;<br>
University of&nbsp;Manchester, in&nbsp;England, as one aspect of&nbsp;the growing global&nbsp;research&nbsp;<br>
into asynchronous&nbsp;design.&nbsp;There&nbsp;are&nbsp;other&nbsp;examples of asynchronous&nbsp;microprocessor&nbsp;<br>
developed elsewhere which&nbsp;support&nbsp;other instruction&nbsp;set architectures, but&nbsp;only&nbsp;the&nbsp;<br>
AMULET processors implement&nbsp;the ARM&nbsp;instruction set.&nbsp;<br>
Self-timed&nbsp;<br>
Asynchronous design is a complex discipline&nbsp;with&nbsp;many&nbsp;different facets&nbsp;and&nbsp;many&nbsp;<br>
signalling&nbsp;<br>
different&nbsp;approaches. It is&nbsp;outside the scope&nbsp;of this book to&nbsp;offer any&nbsp;general intro-<br>
duction to asynchronous design, but a few&nbsp;basic concepts should enable the reader&nbsp;<br>
to come&nbsp;to grips&nbsp;with the&nbsp;most important&nbsp;features&nbsp;of&nbsp;the&nbsp;AMULET&nbsp;cores. The&nbsp;fore-<br>
most&nbsp;of&nbsp;these concepts&nbsp;is&nbsp;the idea&nbsp;of&nbsp;asynchronous communication.&nbsp;How is&nbsp;the&nbsp;flow&nbsp;<br>
of data controlled in the absence of any&nbsp;reference clock?&nbsp;<br>
The AMULET designs&nbsp;both use forms of the&nbsp;<i>Request—Acknowledge&nbsp;</i>handshake to&nbsp;<br>
control&nbsp;the&nbsp;flow&nbsp;of&nbsp;data.&nbsp;The&nbsp;sequence&nbsp;of actions&nbsp;comprising&nbsp;the communication&nbsp;of&nbsp;<br>
data&nbsp;from&nbsp;the&nbsp;<i>Sender&nbsp;</i>to&nbsp;the&nbsp;<i>Receiver&nbsp;</i>is&nbsp;as&nbsp;follows:&nbsp;<br>
1.&nbsp;&nbsp;The&nbsp;Sender places&nbsp;a valid&nbsp;data value onto a&nbsp;bus.&nbsp;<br>
2.&nbsp;&nbsp;The Sender&nbsp;then&nbsp;issues&nbsp;a&nbsp;<i>Request&nbsp;</i>event.&nbsp;<br>
3.&nbsp;&nbsp;The Receiver&nbsp;accepts&nbsp;the data&nbsp;when&nbsp;it is&nbsp;ready to&nbsp;do so.&nbsp;<br>
4.&nbsp;&nbsp;The Receiver&nbsp;issues&nbsp;<i>an&nbsp;Acknowledge&nbsp;</i>event to&nbsp;the&nbsp;Sender.&nbsp;<br>
5.&nbsp;&nbsp;The Sender&nbsp;may&nbsp;then&nbsp;remove&nbsp;the&nbsp;data&nbsp;from&nbsp;the&nbsp;bus&nbsp;and begin the&nbsp;next&nbsp;communi&nbsp;<br>
cation when&nbsp;it&nbsp;is ready to&nbsp;do so.&nbsp;<br>
The data is passed&nbsp;along the&nbsp;bus using a&nbsp;conventional binary&nbsp;encoding,&nbsp;but there&nbsp;<br>
are two ways that&nbsp;the Request&nbsp;and Acknowledge&nbsp;events may be signalled:&nbsp;<br>
Transition&nbsp;<br>
• AMULET 1&nbsp;uses transition&nbsp;encoding&nbsp;where&nbsp;a&nbsp;change&nbsp;in&nbsp;level&nbsp;(either&nbsp;high to&nbsp;low&nbsp;<br>
signalling&nbsp;<br>
or low to&nbsp;high) signals&nbsp;an&nbsp;event; this is illustrated&nbsp;in&nbsp;Figure&nbsp;14.1.&nbsp;<br>
&nbsp;<br>
<b>Figure 14.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>Transition-signalling communication protocol.&nbsp;<br>
<hr>
<A name=389></a><IMG src="index-389_1.png"><br>
<b>AMULET1</b>&nbsp;<br>
<b>377</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Level signalling&nbsp;<br>
AMULET2&nbsp;and&nbsp;AMULETS use&nbsp;level&nbsp;encoding where&nbsp;a rising edge signals an&nbsp;<br>
event and a return-to-zero&nbsp;phase must occur before&nbsp;the&nbsp;next&nbsp;event&nbsp;can be&nbsp;<br>
signalled;&nbsp;this&nbsp;is illustrated&nbsp;in&nbsp;Figure 14.2.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;14.2 &nbsp;&nbsp;</b>Level-signalling communication&nbsp;protocol.&nbsp;<br>
Transition&nbsp;signalling was used on AMULET 1 since it is&nbsp;conceptually&nbsp;cleaner;&nbsp;<br>
every transition has a role and its timing is therefore determined by&nbsp;the circuit's&nbsp;<br>
function. It&nbsp;also&nbsp;uses&nbsp;the minimum&nbsp;number&nbsp;of transitions,&nbsp;and should&nbsp;therefore&nbsp;be&nbsp;<br>
power-efficient. However, the&nbsp;CMOS circuits&nbsp;used to&nbsp;implement transition control&nbsp;are&nbsp;<br>
relatively slow&nbsp;and inefficient,&nbsp;so&nbsp;AMULET2&nbsp;and AMULETS&nbsp;use level signalling&nbsp;<br>
which&nbsp;employs circuits which are faster and&nbsp;more&nbsp;power-efficient despite using&nbsp;twice&nbsp;<br>
the&nbsp;number of transitions, but leave somewhat&nbsp;arbitrary&nbsp;decisions to&nbsp;be&nbsp;taken&nbsp;about the&nbsp;<br>
timing of the&nbsp;recovery&nbsp;(return-to-zero) phases&nbsp;in&nbsp;the protocol.&nbsp;<br>
Self-timed&nbsp;<br>
An asynchronous pipelined&nbsp;processing&nbsp;unit&nbsp;can&nbsp;be constructed&nbsp;using self-timing tech-<br>
pipelines&nbsp;<br>
niques to&nbsp;allow&nbsp;for the&nbsp;processing&nbsp;delay&nbsp;in&nbsp;each&nbsp;stage and one of&nbsp;the&nbsp;above&nbsp;protocols&nbsp;<br>
to send&nbsp;the result&nbsp;to&nbsp;the&nbsp;next&nbsp;stage.&nbsp;When&nbsp;the&nbsp;circuit&nbsp;is&nbsp;correctly&nbsp;designed&nbsp;variable&nbsp;<br>
processing&nbsp;and&nbsp;external&nbsp;delays&nbsp;can&nbsp;be&nbsp;accommodated; all&nbsp;that&nbsp;matters&nbsp;is the local&nbsp;<br>
sequencing&nbsp;of&nbsp;events (though long&nbsp;delays&nbsp;will,&nbsp;of course, lead&nbsp;to&nbsp;low performance).&nbsp;<br>
Unlike&nbsp;a clocked pipeline,&nbsp;where the&nbsp;whole&nbsp;pipeline&nbsp;must always be clocked at&nbsp;a&nbsp;<br>
rate determined by&nbsp;the slowest stage under worst-case environmental (voltage and&nbsp;<br>
temperature) conditions and assuming worst-case&nbsp;data,&nbsp;an asynchronous&nbsp;pipeline&nbsp;will&nbsp;<br>
operate&nbsp;at&nbsp;a&nbsp;variable&nbsp;rate&nbsp;determined by&nbsp;current&nbsp;conditions.&nbsp;It is&nbsp;possible&nbsp;to&nbsp;allow rare&nbsp;<br>
worst-case&nbsp;conditions&nbsp;to&nbsp;cause&nbsp;a&nbsp;processing&nbsp;unit&nbsp;to&nbsp;take&nbsp;a&nbsp;little&nbsp;longer. There&nbsp;will&nbsp;be&nbsp;<br>
some&nbsp;performance loss&nbsp;when&nbsp;these conditions do arise,&nbsp;but so long as&nbsp;they&nbsp;are rare&nbsp;<br>
enough the impact&nbsp;on overall performance&nbsp;will&nbsp;be&nbsp;small.&nbsp;<br>
&nbsp;&nbsp;&nbsp;14.2 &nbsp;&nbsp;<br>
AMULET1&nbsp;<br>
The&nbsp;AMULET 1&nbsp;&nbsp;&nbsp;&nbsp;processor core has&nbsp;the high-level organization illustrated&nbsp;<br>
in&nbsp;Figure 14.3 on&nbsp;page&nbsp;378. The design&nbsp;is based&nbsp;upon&nbsp;a set of&nbsp;interacting&nbsp;<br>
asynchronous&nbsp;<br>
<hr>
<A name=390></a><IMG src="index-390_1.png"><br>
<b>378</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;14.3 &nbsp;&nbsp;</b>AMULET1 internal organization.&nbsp;<br>
pipelines,&nbsp;all&nbsp;operating&nbsp;in&nbsp;their&nbsp;own&nbsp;time at&nbsp;their&nbsp;own&nbsp;speed.&nbsp;These&nbsp;pipelines&nbsp;might&nbsp;<br>
appear&nbsp;to&nbsp;introduce&nbsp;unacceptably long latencies into the&nbsp;processor but,&nbsp;unlike a syn-<br>
chronous pipeline,&nbsp;an&nbsp;asynchronous pipeline&nbsp;can have&nbsp;a very&nbsp;low&nbsp;latency.&nbsp;<br>
The operation of&nbsp;the processor begins&nbsp;with&nbsp;the address&nbsp;interface issuing instruction&nbsp;<br>
fetch requests to&nbsp;the&nbsp;memory. The address interface has an autonomous address&nbsp;<br>
incre-menter which&nbsp;enables it&nbsp;to&nbsp;prefetch&nbsp;instructions&nbsp;as&nbsp;far&nbsp;ahead as the capacities of&nbsp;<br>
the&nbsp;various pipeline buffers&nbsp;allow.&nbsp;<br>
Address&nbsp;<br>
Instructions&nbsp;that&nbsp;need to&nbsp;generate&nbsp;a new&nbsp;memory address, such as data transfer instruc-<br>
non-determin<br>
tions&nbsp;and unpredicted&nbsp;branches, calculate&nbsp;the&nbsp;new address&nbsp;in&nbsp;the execution&nbsp;pipeline&nbsp;and&nbsp;<br>
ism&nbsp;<br>
then send it&nbsp;to&nbsp;the address interface. Since&nbsp;it&nbsp;arrives with&nbsp;arbitrary&nbsp;timing relative&nbsp;to&nbsp;the&nbsp;<br>
internal incrementing loop&nbsp;within the address interface,&nbsp;the point of&nbsp;insertion of&nbsp;the&nbsp;<br>
new address into&nbsp;the address&nbsp;stream&nbsp;is&nbsp;non-deterministic, so the&nbsp;processor's depth&nbsp;of&nbsp;<br>
prefetch beyond&nbsp;a branch instruction is&nbsp;fundamentally&nbsp;non-deterministic.&nbsp;<br>
<hr>
<A name=391></a><IMG src="index-391_1.png"><br>
<b>AMULET1</b>&nbsp;<br>
<b>379</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Register&nbsp;<br>
If the&nbsp;execution&nbsp;pipeline is&nbsp;to work efficiently, the&nbsp;register&nbsp;file must&nbsp;be&nbsp;able&nbsp;to issue&nbsp;<br>
coherency&nbsp;<br>
the operands for an instruction before the result of the&nbsp;previous instruction has&nbsp;<br>
returned. However,&nbsp;in&nbsp;some&nbsp;cases&nbsp;an&nbsp;operand may&nbsp;depend&nbsp;on&nbsp;a&nbsp;preceding&nbsp;result&nbsp;(this&nbsp;<br>
is a&nbsp;<i>read-after-write&nbsp;</i>hazard),&nbsp;in&nbsp;which case&nbsp;the register&nbsp;file&nbsp;cannot&nbsp;issue&nbsp;the operand&nbsp;<br>
until&nbsp;the result has returned&nbsp;unless&nbsp;there&nbsp;is&nbsp;a&nbsp;forwarding&nbsp;mechanism&nbsp;to&nbsp;supply&nbsp;the&nbsp;<br>
correct value&nbsp;further down the pipeline.&nbsp;<br>
The register forwarding mechanism&nbsp;used&nbsp;on many&nbsp;RISC processors (including&nbsp;<br>
ARMS and StrongARM) is based&nbsp;upon the&nbsp;characteristics&nbsp;of a synchronous pipeline&nbsp;<br>
since it involves&nbsp;comparing the&nbsp;source&nbsp;operand register&nbsp;number in one&nbsp;pipeline stage&nbsp;<br>
with the destination&nbsp;register number&nbsp;in&nbsp;another&nbsp;stage.&nbsp;In an asynchronous pipeline&nbsp;the&nbsp;<br>
stages&nbsp;are&nbsp;all&nbsp;moving at&nbsp;different&nbsp;times and such&nbsp;a&nbsp;comparison&nbsp;can&nbsp;only&nbsp;be made by&nbsp;<br>
introducing&nbsp;explicit&nbsp;synchronization between&nbsp;the stages&nbsp;concerned, thereby&nbsp;losing&nbsp;<br>
most of&nbsp;the benefits&nbsp;of&nbsp;asynchronous&nbsp;operation.&nbsp;<br>
Register locking&nbsp;<br>
On&nbsp;AMULET&nbsp;1 register coherency&nbsp;is achieved&nbsp;through a&nbsp;novel form&nbsp;of&nbsp;register&nbsp;lock-<br>
ing, based&nbsp;on&nbsp;a&nbsp;register&nbsp;lock&nbsp;FIFO&nbsp;(first-in-first-out queue).&nbsp;The&nbsp;destination&nbsp;register&nbsp;<br>
numbers are stored, in&nbsp;decoded form, in&nbsp;a FIFO, until&nbsp;the associated&nbsp;result&nbsp;is&nbsp;<br>
returned&nbsp;from&nbsp;the execution&nbsp;or&nbsp;memory pipeline to the&nbsp;register&nbsp;bank.&nbsp;<br>
The&nbsp;organization&nbsp;of&nbsp;the lock&nbsp;FIFO is&nbsp;illustrated in Figure&nbsp;14.4. Each&nbsp;stage of&nbsp;the&nbsp;<br>
FIFO holds a '&nbsp;1'&nbsp;in the&nbsp;position&nbsp;corresponding to&nbsp;the&nbsp;destination register.&nbsp;In&nbsp;this figure&nbsp;<br>
the FIFO controls&nbsp;16 registers&nbsp;(in AMULET&nbsp;1 the FIFO has&nbsp;a column&nbsp;for each&nbsp;physi-<br>
cal&nbsp;register,&nbsp;including the&nbsp;ARM&nbsp;banked&nbsp;registers)&nbsp;and is shown in&nbsp;a&nbsp;state&nbsp;where&nbsp;the&nbsp;<br>
first&nbsp;result&nbsp;to&nbsp;arrive&nbsp;will&nbsp;be&nbsp;written&nbsp;into&nbsp;rO,&nbsp;the second into&nbsp;r2, the&nbsp;third&nbsp;into r!2 and&nbsp;the&nbsp;<br>
fourth FIFO stage is&nbsp;empty.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;14.4 &nbsp;&nbsp;</b>AMULET&nbsp;register lock FIFO&nbsp;organization.&nbsp;<br>
<hr>
<A name=392></a><b>380</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
If a&nbsp;subsequent&nbsp;instruction&nbsp;requests r!2 as&nbsp;a&nbsp;source&nbsp;operand,&nbsp;an&nbsp;inspection of&nbsp;the&nbsp;<br>
FIFO column&nbsp;corresponding&nbsp;to&nbsp;r!2&nbsp;(outlined in&nbsp;the&nbsp;figure)&nbsp;reveals whether or&nbsp;not&nbsp;r!2&nbsp;<br>
is valid. AT anywhere in the column&nbsp;signifies a pending&nbsp;write to r!2, so&nbsp;its current&nbsp;<br>
value is obsolete. The&nbsp;read&nbsp;waits until&nbsp;the '&nbsp;1'&nbsp;is&nbsp;cleared,&nbsp;then&nbsp;it&nbsp;can&nbsp;proceed.&nbsp;<br>
The&nbsp;'inspection'&nbsp;is implemented in&nbsp;hardware&nbsp;by&nbsp;a logical&nbsp;'OR'&nbsp;function&nbsp;across the&nbsp;<br>
column&nbsp;for&nbsp;each&nbsp;register.&nbsp;This&nbsp;may appear&nbsp;hazardous&nbsp;since&nbsp;the&nbsp;data&nbsp;in&nbsp;the&nbsp;FIFO may&nbsp;<br>
move down&nbsp;the FIFO while&nbsp;the 'OR'&nbsp;output&nbsp;is being&nbsp;used.&nbsp;However,&nbsp;data&nbsp;moves in&nbsp;an&nbsp;<br>
asynchronous&nbsp;FIFO by&nbsp;being duplicated&nbsp;from&nbsp;one&nbsp;stage into&nbsp;the next, only&nbsp;then&nbsp;is it&nbsp;<br>
removed from&nbsp;the first stage,&nbsp;so a&nbsp;propagating '&nbsp;1'&nbsp;will appear alternately in&nbsp;one&nbsp;or two&nbsp;<br>
positions&nbsp;and it&nbsp;will never disappear&nbsp;completely. The&nbsp;'OR'&nbsp;output&nbsp;will&nbsp;therefore be&nbsp;<br>
stable&nbsp;even&nbsp;though&nbsp;the&nbsp;data&nbsp;is&nbsp;moving.&nbsp;<br>
AMULET 1&nbsp;depends entirely on the register&nbsp;locking mechanism&nbsp;to maintain regis-<br>
ter coherency,&nbsp;and as&nbsp;a result&nbsp;the execution&nbsp;pipeline is&nbsp;stalled&nbsp;quite&nbsp;frequently in&nbsp;typi-<br>
cal code.&nbsp;(Register&nbsp;dependencies&nbsp;between&nbsp;consecutive instructions are common in&nbsp;<br>
typical&nbsp;code&nbsp;since the&nbsp;compiler&nbsp;makes no&nbsp;attempt&nbsp;to&nbsp;avoid them&nbsp;because&nbsp;standard&nbsp;<br>
ARM&nbsp;processors are&nbsp;insensitive&nbsp;to&nbsp;such&nbsp;dependencies.)&nbsp;<br>
AMULET!&nbsp;<br>
AMULET 1&nbsp;was developed to&nbsp;demonstrate the&nbsp;feasibility&nbsp;of designing a fully&nbsp;asyn-<br>
performance&nbsp;<br>
chronous implementation of&nbsp;a commercial&nbsp;microprocessor architecture.&nbsp;The proto-<br>
type&nbsp;chips were functional&nbsp;and ran&nbsp;test programs generated&nbsp;using standard ARM&nbsp;<br>
development tools.&nbsp;The&nbsp;performance&nbsp;of&nbsp;the&nbsp;prototypes&nbsp;is&nbsp;summarized&nbsp;in&nbsp;Table&nbsp;14.1,&nbsp;<br>
which&nbsp;shows the characteristics of the devices&nbsp;manufactured&nbsp;on&nbsp;two&nbsp;different&nbsp;pro-<br>
cess technologies by&nbsp;European Silicon&nbsp;Systems (ES2)&nbsp;and&nbsp;GEC Plessey&nbsp;Semicon-<br>
ductors&nbsp;(GPS).&nbsp;The layout of the 1 |im&nbsp;AMULET1 core is&nbsp;shown in Figure 14.5. The&nbsp;<br>
performance figures,&nbsp;based&nbsp;on&nbsp;the Dhrystone&nbsp;benchmark, show&nbsp;a&nbsp;performance&nbsp;<br>
which&nbsp;is of&nbsp;the same&nbsp;order as, but certainly no&nbsp;better than, an ARM6&nbsp;processor built&nbsp;<br>
<b>Table&nbsp;14.1 &nbsp; &nbsp;</b>AMULET1 characteristics.&nbsp;<br>
&nbsp;<br>
AMULET1/ES2&nbsp;&nbsp;&nbsp;<br>
AMULET1/GPS&nbsp;&nbsp;&nbsp;<br>
ARM6&nbsp;&nbsp;&nbsp;<br>
Process Area&nbsp;<br>
1 um&nbsp;<br>
0.7 |im&nbsp;<br>
1 um&nbsp;<br>
(mm2)&nbsp;<br>
5.5x4.1&nbsp;<br>
3.9x2.9&nbsp;<br>
4.1x2.7&nbsp;<br>
Transistors&nbsp;&nbsp;&nbsp;<br>
58,374&nbsp;<br>
58,374<br>
33,494<br>
Performance&nbsp;<br>
20.5 kDhrystones&nbsp;<br>
~40 kDhrystones3&nbsp;3&nbsp;<br>
31 kDhrystones&nbsp;<br>
Multiplier&nbsp;<br>
5.3&nbsp;ns/bit&nbsp;5&nbsp;V,&nbsp;20°C&nbsp;<br>
ns/bit&nbsp;5&nbsp;V,&nbsp;20°C&nbsp;<br>
25 ns/bit 5&nbsp;V,&nbsp;20&nbsp;<br>
Conditions&nbsp;<br>
152mW&nbsp;&nbsp;&nbsp;<br>
N/Ab&nbsp;&nbsp;&nbsp;<br>
MHz&nbsp;148&nbsp;mW&nbsp;&nbsp;&nbsp;<br>
Power&nbsp;&nbsp;&nbsp;<br>
MIPS/W&nbsp;&nbsp;&nbsp;<br>
77&nbsp;&nbsp;&nbsp;<br>
N/A&nbsp;&nbsp;&nbsp;<br>
120&nbsp;&nbsp;&nbsp;<br>
a.&nbsp;Estimated maximum&nbsp;performance, b.&nbsp;The&nbsp;GPS&nbsp;part&nbsp;<br>
does&nbsp;not support&nbsp;power&nbsp;measurement.&nbsp;&nbsp;&nbsp;<br>
<hr>
<A name=393></a><IMG src="index-393_1.png"><br>
<b>AMULET2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b><br>
<b>381</b>&nbsp;<br>
<b>•</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure 14.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>AMULET1 die&nbsp;plot.&nbsp;<br>
on&nbsp;the same&nbsp;process&nbsp;technology. However,&nbsp;AMULET&nbsp;1&nbsp;was built primarily to&nbsp;dem-<br>
onstrate the&nbsp;feasibility&nbsp;of&nbsp;self-timed design,&nbsp;which&nbsp;it&nbsp;manifestly&nbsp;does.&nbsp;<br>
14.3 &nbsp; AMULET2&nbsp;<br>
AMULET2&nbsp;is&nbsp;the&nbsp;second-generation&nbsp;asynchronous ARM processor. It&nbsp;employs&nbsp;an&nbsp;<br>
organization&nbsp;which is&nbsp;very&nbsp;similar to that used&nbsp;in AMULET 1, as&nbsp;illustrated in&nbsp;<br>
Figure 14.3 on&nbsp;page 378. As&nbsp;described earlier, the two-phase&nbsp;(transition)&nbsp;signalling&nbsp;<br>
used&nbsp;on&nbsp;AMULET 1&nbsp;was abandoned in&nbsp;favour&nbsp;of&nbsp;four-phase (level) signalling. In&nbsp;<br>
addition, a number&nbsp;of&nbsp;organizational&nbsp;features&nbsp;were&nbsp;added&nbsp;to&nbsp;enhance&nbsp;performance.&nbsp;<br>
AMULET2&nbsp;<br>
AMULET2&nbsp;employs&nbsp;the&nbsp;same&nbsp;register-locking&nbsp;mechanism&nbsp;as&nbsp;AMULET 1, but&nbsp;in&nbsp;<br>
register&nbsp;<br>
order to&nbsp;reduce&nbsp;the performance&nbsp;loss due to&nbsp;register&nbsp;dependency&nbsp;stalls,&nbsp;it&nbsp;also incor-<br>
forwarding&nbsp;<br>
porates forwarding mechanisms to&nbsp;handle&nbsp;common&nbsp;cases. The&nbsp;bypass&nbsp;mechanisms&nbsp;<br>
used in clocked processor pipelines are&nbsp;inapplicable to asynchronous pipelines, so&nbsp;<br>
novel&nbsp;techniques are&nbsp;required.&nbsp;The&nbsp;two techniques&nbsp;used on AMULET2 are:&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;<i>last result&nbsp;</i>register.&nbsp;The instruction decoder keeps a record of the destination of&nbsp;<br>
the result&nbsp;from&nbsp;the execution&nbsp;pipeline, and&nbsp;if&nbsp;the immediately&nbsp;following&nbsp;instruc&nbsp;<br>
tion uses this&nbsp;register as&nbsp;a&nbsp;source operand&nbsp;the register&nbsp;read&nbsp;phase&nbsp;is bypassed and&nbsp;<br>
the value is&nbsp;collected&nbsp;from&nbsp;the&nbsp;last&nbsp;result&nbsp;register.&nbsp;<br>
•&nbsp;&nbsp;A&nbsp;<i>last loaded data&nbsp;</i>register. The instruction decoder keeps a record of the&nbsp;destination&nbsp;<br>
of the last&nbsp;data&nbsp;item&nbsp;loaded&nbsp;from&nbsp;memory,&nbsp;and&nbsp;whenever&nbsp;this&nbsp;register is&nbsp;used&nbsp;as&nbsp;a&nbsp;<br>
source operand&nbsp;the register&nbsp;read&nbsp;phase is bypassed and the value is picked up directly&nbsp;<br>
<hr>
<A name=394></a><IMG src="index-394_1.png"><br>
<b>382</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
from&nbsp;the&nbsp;last&nbsp;loaded data register. A&nbsp;mechanism similar&nbsp;to&nbsp;the lock&nbsp;FIFO serves as a&nbsp;<br>
guard on the register&nbsp;to&nbsp;ensure&nbsp;that&nbsp;the&nbsp;correct&nbsp;value&nbsp;is&nbsp;collected.&nbsp;<br>
Both&nbsp;these mechanisms&nbsp;rely on&nbsp;the required&nbsp;result being&nbsp;available;&nbsp;where there is&nbsp;<br>
some&nbsp;uncertainty (for example&nbsp;when&nbsp;the result is produced by&nbsp;an&nbsp;instruction&nbsp;which&nbsp;is&nbsp;<br>
conditionally executed)&nbsp;the instruction&nbsp;decoder can&nbsp;fall back&nbsp;on the locking mecha-<br>
nism, exploiting&nbsp;the ability of the asynchronous&nbsp;organization to cope&nbsp;with&nbsp;variable&nbsp;<br>
delays&nbsp;in&nbsp;the supply&nbsp;of the operands.&nbsp;<br>
AMULET2 jump&nbsp;<br>
AMULET&nbsp;1 prefetches&nbsp;instructions&nbsp;sequentially from&nbsp;the&nbsp;current&nbsp;PC&nbsp;value&nbsp;and&nbsp;all devia-<br>
trace&nbsp;buffer&nbsp;<br>
tions from&nbsp;sequential&nbsp;execution must&nbsp;be issued as corrections from&nbsp;the&nbsp;execution pipe-<br>
line&nbsp;to&nbsp;the&nbsp;address interface. Every time&nbsp;the&nbsp;PC&nbsp;has&nbsp;to be&nbsp;corrected&nbsp;performance&nbsp;is&nbsp;lost&nbsp;<br>
and energy&nbsp;is wasted&nbsp;in prefetching instructions&nbsp;that are&nbsp;then discarded.&nbsp;<br>
AMULET2 attempts to&nbsp;reduce this inefficiency&nbsp;by remembering where&nbsp;branches&nbsp;<br>
were&nbsp;previously taken&nbsp;and guessing that&nbsp;control&nbsp;will subsequently&nbsp;follow the&nbsp;same&nbsp;<br>
path. The organization of the&nbsp;jump&nbsp;trace buffer is&nbsp;shown in&nbsp;Figure 14.6;&nbsp;it&nbsp;is&nbsp;similar&nbsp;to&nbsp;<br>
that&nbsp;used on the MU5&nbsp;mainframe&nbsp;computer developed at&nbsp;the University&nbsp;of Manchester&nbsp;<br>
between&nbsp;1969&nbsp;and 1974 (which&nbsp;also&nbsp;operated with asynchronous control).&nbsp;<br>
&nbsp;<br>
<b>Figure 14.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The AMULET2 jump trace buffer.&nbsp;<br>
The&nbsp;buffer caches the&nbsp;program&nbsp;counters&nbsp;and targets&nbsp;of&nbsp;recently taken branch&nbsp;<br>
instructions, and&nbsp;whenever it&nbsp;spots an&nbsp;instruction&nbsp;fetch from&nbsp;an&nbsp;address that it&nbsp;has&nbsp;<br>
stored&nbsp;it modifies the predicted&nbsp;control flow from&nbsp;sequential to&nbsp;the previous&nbsp;branch&nbsp;<br>
target.&nbsp;If this&nbsp;prediction&nbsp;turns&nbsp;out&nbsp;to be&nbsp;correct, exactly the&nbsp;right instruction&nbsp;sequence&nbsp;<br>
is fetched from&nbsp;memory;&nbsp;if it&nbsp;turns out&nbsp;to&nbsp;be&nbsp;wrong&nbsp;and&nbsp;the branch&nbsp;should&nbsp;not have&nbsp;<br>
<hr>
<A name=395></a><b>AMULET2</b>&nbsp;<br>
<b>383</b>&nbsp;<br>
been taken,&nbsp;the branch&nbsp;is&nbsp;executed as&nbsp;an&nbsp;'unbranch'&nbsp;instruction&nbsp;to&nbsp;return&nbsp;to&nbsp;the&nbsp;previ-<br>
ous sequential flow.&nbsp;<br>
Branch&nbsp;Statistics &nbsp; &nbsp; The&nbsp;effectiveness&nbsp;of&nbsp;the&nbsp;jump&nbsp;trace buffer depends on the statistics of typical&nbsp;<br>
branch&nbsp;behaviour.&nbsp;Typical&nbsp;figures are shown in&nbsp;Table 14.2.&nbsp;<br>
<b>Table&nbsp;14.2 &nbsp; &nbsp;</b>AMULET2 branch prediction&nbsp;statistics.&nbsp;<br>
&nbsp;<br>
Prediction&nbsp;algorithm&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;Correct&nbsp;&nbsp; &nbsp; &nbsp;Incorrect&nbsp; &nbsp; &nbsp;Redundant&nbsp;<br>
fetches&nbsp;&nbsp;&nbsp;<br>
Sequential&nbsp;<br>
33%&nbsp;<br>
67%&nbsp;&nbsp;&nbsp;&nbsp; 2&nbsp;per&nbsp;branch&nbsp;<br>
Trace buffer&nbsp;&nbsp;&nbsp;<br>
67%&nbsp;&nbsp;&nbsp;<br>
(ave.)&nbsp;33% &nbsp;&nbsp; &nbsp;1&nbsp;per&nbsp;<br>
b<br>
h&nbsp;(<br>
)<br>
In the absence&nbsp;of the jump&nbsp;trace buffer, the&nbsp;default sequential fetch&nbsp;pattern&nbsp;is equiv-<br>
alent&nbsp;to&nbsp;predicting&nbsp;that&nbsp;all&nbsp;branches&nbsp;are not taken.&nbsp;This&nbsp;is&nbsp;correct&nbsp;for one-third&nbsp;of&nbsp;all&nbsp;<br>
branches,&nbsp;and incorrect for the&nbsp;remaining two-thirds.&nbsp;A&nbsp;jump&nbsp;trace&nbsp;buffer&nbsp;with around&nbsp;<br>
20&nbsp;entries reverses&nbsp;these&nbsp;proportions, correctly&nbsp;predicting&nbsp;around&nbsp;two-thirds&nbsp;of all&nbsp;<br>
branches&nbsp;and&nbsp;mispredicting&nbsp;or failing&nbsp;to&nbsp;predict&nbsp;around&nbsp;one-third.&nbsp;<br>
Although&nbsp;the depth of prefetching beyond&nbsp;a branch&nbsp;is non-deterministic,&nbsp;a&nbsp;prefetch&nbsp;<br>
depth&nbsp;of around&nbsp;three instructions is&nbsp;observed&nbsp;on AMULET2. The fetched instructions&nbsp;<br>
are&nbsp;used&nbsp;when&nbsp;the&nbsp;branch&nbsp;is&nbsp;predicted&nbsp;correctly,&nbsp;but&nbsp;are&nbsp;discarded when&nbsp;the&nbsp;branch is&nbsp;<br>
mispredicted&nbsp;or&nbsp;not&nbsp;predicted.&nbsp;The jump&nbsp;trace&nbsp;buffer therefore reduces the&nbsp;average&nbsp;<br>
number of redundant&nbsp;fetches&nbsp;per branch from&nbsp;two to one. Since branches occur&nbsp;<br>
around&nbsp;once every five&nbsp;instructions&nbsp;in&nbsp;typical&nbsp;code, the jump&nbsp;trace&nbsp;buffer&nbsp;may&nbsp;be&nbsp;<br>
expected to reduce the instruction fetch bandwidth by&nbsp;around 20% and the total&nbsp;<br>
memory&nbsp;bandwidth&nbsp;by&nbsp;10%&nbsp;to&nbsp;15%.&nbsp;<br>
Where&nbsp;the&nbsp;system&nbsp;performance is&nbsp;limited&nbsp;by&nbsp;the&nbsp;available memory bandwidth, this&nbsp;<br>
saving&nbsp;translates&nbsp;directly&nbsp;into&nbsp;improved&nbsp;performance; in&nbsp;any&nbsp;case&nbsp;it&nbsp;represents a&nbsp;power&nbsp;<br>
saving&nbsp;due to&nbsp;the elimination&nbsp;of redundant activity.&nbsp;<br>
'Halt'&nbsp;<br>
Unlike some&nbsp;other&nbsp;microprocessors, the&nbsp;ARM does not have an explicit&nbsp;'Halt'&nbsp;<br>
instruction. Instead, when&nbsp;a program&nbsp;can&nbsp;find&nbsp;no&nbsp;more useful work&nbsp;to&nbsp;do it usually&nbsp;<br>
enters an idle&nbsp;loop, executing:&nbsp;<br>
B&nbsp;<br>
.&nbsp;<br>
; &nbsp; loop&nbsp;until &nbsp; interrupted&nbsp;<br>
Here the&nbsp;'.'&nbsp;denotes the current&nbsp;PC,&nbsp;so the branch&nbsp;target is the branch&nbsp;instruction&nbsp;<br>
itself,&nbsp;and&nbsp;the&nbsp;program&nbsp;sits in&nbsp;this&nbsp;single&nbsp;instruction&nbsp;loop until an&nbsp;interrupt causes it&nbsp;to&nbsp;<br>
do something&nbsp;else.&nbsp;<br>
Clearly&nbsp;the&nbsp;processor is doing no&nbsp;useful work&nbsp;while in this idle loop, so any&nbsp;power&nbsp;<br>
it uses is wasted. AMULET2 detects the opcode corresponding to a branch which&nbsp;<br>
loops&nbsp;to&nbsp;itself and&nbsp;uses&nbsp;this to&nbsp;stall a&nbsp;signal&nbsp;at one point in&nbsp;the asynchronous control&nbsp;<br>
network.&nbsp;This&nbsp;stall rapidly&nbsp;propagates throughout&nbsp;the control, bringing the&nbsp;processor&nbsp;<br>
<hr>
<A name=396></a><IMG src="index-396_1.png"><br>
<b>384</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
to&nbsp;an&nbsp;inactive,&nbsp;zero power state. An&nbsp;active&nbsp;interrupt request releases the stall, enabling&nbsp;<br>
the&nbsp;processor to&nbsp;resume&nbsp;normal throughput immediately.&nbsp;<br>
AMULET2 can therefore switch between zero&nbsp;power&nbsp;and maximum&nbsp;throughput&nbsp;<br>
states&nbsp;at&nbsp;a&nbsp;very high rate&nbsp;and&nbsp;with&nbsp;no software overhead;&nbsp;indeed, much&nbsp;existing ARM&nbsp;<br>
code&nbsp;will give optimum&nbsp;power-efficiency&nbsp;using this&nbsp;scheme even&nbsp;though it was not&nbsp;<br>
written&nbsp;with the scheme&nbsp;in&nbsp;mind. This&nbsp;makes&nbsp;the processor&nbsp;very applicable to&nbsp;<br>
low-power&nbsp;applications&nbsp;with bursty real-time&nbsp;load characteristics.&nbsp;<br>
14.4 &nbsp; AMULET2e&nbsp;<br>
AMULET2e is an AMULET2 processor core&nbsp;(see&nbsp;Section 14.3 on page 381) com-<br>
bined with&nbsp;4&nbsp;Kbytes&nbsp;of memory, which&nbsp;can&nbsp;be&nbsp;configured&nbsp;either as&nbsp;a cache&nbsp;or a&nbsp;fixed&nbsp;<br>
RAM area, and a&nbsp;flexible&nbsp;memory&nbsp;interface&nbsp;<i>(the funnel)&nbsp;</i>which allows 8-, 16-&nbsp;or&nbsp;<br>
32-bit external devices&nbsp;to be&nbsp;connected directly,&nbsp;including&nbsp;memories&nbsp;built&nbsp;from&nbsp;<br>
DRAM.&nbsp;The internal&nbsp;organization of&nbsp;AMULET2e&nbsp;is illustrated&nbsp;in&nbsp;Figure&nbsp;14.7.&nbsp;<br>
AMULET2e&nbsp;<br>
The cache comprises&nbsp;four&nbsp;1&nbsp;Kbyte&nbsp;blocks, each of&nbsp;which&nbsp;is a&nbsp;fully associative&nbsp;<br>
cache&nbsp;<br>
random&nbsp;replacement&nbsp;store&nbsp;with&nbsp;a&nbsp;quad-word&nbsp;line&nbsp;and&nbsp;block&nbsp;size.&nbsp;A&nbsp;pipeline&nbsp;register&nbsp;<br>
between the CAM&nbsp;and the RAM&nbsp;sections&nbsp;allows a&nbsp;following access to begin its&nbsp;<br>
CAM look-up&nbsp;while&nbsp;the&nbsp;previous access&nbsp;completes within the&nbsp;RAM;&nbsp;this exploits&nbsp;<br>
<b>Figure&nbsp;14.7&nbsp;&nbsp;&nbsp;AMULET2e&nbsp;internal&nbsp;organization.</b><br>
<hr>
<A name=397></a><IMG src="index-397_1.png"><br>
<b>AMULET2e</b>&nbsp;<br>
<b>385</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
the ability&nbsp;of the&nbsp;AMULET2&nbsp;core&nbsp;to issue&nbsp;multiple&nbsp;memory requests before&nbsp;the data&nbsp;<br>
is&nbsp;returned&nbsp;from&nbsp;the&nbsp;first.&nbsp;Sequential accesses are detected&nbsp;and bypass&nbsp;the CAM&nbsp;<br>
look-up, thereby&nbsp;saving&nbsp;power&nbsp;and&nbsp;improving&nbsp;performance.&nbsp;<br>
Cache line fetches are non-blocking, accessing the&nbsp;addressed&nbsp;item&nbsp;first and then&nbsp;<br>
allowing&nbsp;the processor&nbsp;to&nbsp;continue while&nbsp;the&nbsp;rest&nbsp;of the&nbsp;line&nbsp;is fetched.&nbsp;The&nbsp;line fetch&nbsp;<br>
automaton continues&nbsp;loading&nbsp;the line fetch&nbsp;buffer while&nbsp;the&nbsp;processor accesses&nbsp;the&nbsp;<br>
cache. There is&nbsp;an additional&nbsp;CAM entry that&nbsp;identifies references to&nbsp;the&nbsp;data which&nbsp;is&nbsp;<br>
stored&nbsp;in the line&nbsp;fetch&nbsp;buffer. Indeed,&nbsp;this&nbsp;data&nbsp;remains in the&nbsp;line fetch buffer where it&nbsp;<br>
can be accessed on&nbsp;equal&nbsp;terms to data&nbsp;in&nbsp;the&nbsp;cache&nbsp;until the&nbsp;next cache&nbsp;miss, where-<br>
upon the whole buffer is copied into the cache while the&nbsp;new data is loaded from&nbsp;<br>
external&nbsp;memory&nbsp;into the&nbsp;line&nbsp;fetch buffer.&nbsp;<br>
AMULET2e&nbsp;<br>
A plot&nbsp;of&nbsp;the&nbsp;AMULET2e&nbsp;die is&nbsp;shown&nbsp;in&nbsp;Figure 14.8 and the characteristics of&nbsp;the&nbsp;<br>
silicon&nbsp;<br>
device&nbsp;are&nbsp;summarized in&nbsp;Table&nbsp;14.3&nbsp;on&nbsp;page&nbsp;386. The AMULET2 core&nbsp;uses&nbsp;93,000&nbsp;<br>
transistors,&nbsp;the&nbsp;cache 328,000&nbsp;and the&nbsp;remainder are&nbsp;in the&nbsp;control logic and pads.&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 14.8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>AMULET2e die plot.&nbsp;<br>
Timing reference&nbsp;<br>
The absence of a&nbsp;reference clock in an asynchronous&nbsp;system&nbsp;makes timing&nbsp;memory&nbsp;<br>
accesses&nbsp;an issue&nbsp;that&nbsp;requires careful&nbsp;consideration.&nbsp;The solution&nbsp;incorporated&nbsp;into&nbsp;<br>
AMULET2e uses a single external reference&nbsp;delay connected directly to&nbsp;the chip&nbsp;<br>
and configuration registers, loaded at start-up, which&nbsp;specify&nbsp;the organization and&nbsp;<br>
timing properties of&nbsp;each&nbsp;memory&nbsp;region.&nbsp;The reference&nbsp;delay could,&nbsp;for example,&nbsp;<br>
reflect the external SRAM access time, so the RAM will&nbsp;be configured to take one&nbsp;<br>
<hr>
<A name=398></a><IMG src="index-398_1.png"><br>
<b>386</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
<b>Table&nbsp;14.3 &nbsp; &nbsp;</b>AMULET2e characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.5 urn</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>454,000&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>40</b>&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3</b>&nbsp;&nbsp;<b>Die area</b>&nbsp;&nbsp;&nbsp;<br>
<b>41 mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>140 mW</b>&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>3.3V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>none&nbsp;MIPS/W</b>&nbsp;&nbsp;&nbsp;<br>
<b>285</b>&nbsp;<br>
reference&nbsp;delay.&nbsp;The slower&nbsp;ROM&nbsp;may be configured to&nbsp;take&nbsp;several&nbsp;reference&nbsp;<br>
delays. (Note that&nbsp;the reference&nbsp;delay&nbsp;is&nbsp;only&nbsp;used&nbsp;for off-chip timing; all on-chip&nbsp;<br>
delays are self-timed.)&nbsp;<br>
AMULET26&nbsp;<br>
AMULET2e&nbsp;has been configured to&nbsp;make&nbsp;building&nbsp;small&nbsp;systems&nbsp;as&nbsp;straightforward&nbsp;<br>
systems&nbsp;<br>
as&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;possible.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;an&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Figure&nbsp;14.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shows&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;card&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
incorporating&nbsp;<br>
AMULET2e. The only components, apart from&nbsp;AMULET2e itself, are four&nbsp;SRAM&nbsp;<br>
chips,&nbsp;one&nbsp;ROM&nbsp;chip, a UART and an RS232&nbsp;line&nbsp;interface.&nbsp;The&nbsp;UART uses&nbsp;a&nbsp;crys-<br>
tal oscillator&nbsp;to&nbsp;control&nbsp;its bit&nbsp;rate, but&nbsp;all&nbsp;the system&nbsp;timing&nbsp;functions&nbsp;are&nbsp;controlled&nbsp;<br>
byAMULET2e.&nbsp;<br>
The&nbsp;ROM&nbsp;contains&nbsp;the&nbsp;standard&nbsp;ARM 'Angel'&nbsp;code&nbsp;and&nbsp;the&nbsp;host computer&nbsp;at&nbsp;the&nbsp;<br>
other end&nbsp;of the RS232 serial&nbsp;line runs the ARM development tools. This system&nbsp;dem-<br>
onstrates&nbsp;that&nbsp;using&nbsp;an&nbsp;asynchronous&nbsp;processor need&nbsp;be&nbsp;no&nbsp;more difficult&nbsp;than&nbsp;using&nbsp;a&nbsp;<br>
clocked processor provided&nbsp;that the&nbsp;memory&nbsp;interface&nbsp;has been&nbsp;carefully thought&nbsp;out.&nbsp;<br>
<b>chip&nbsp;selects&nbsp;18</b><br>
<b>8</b><br>
<b>18</b><br>
<b>8</b><br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;14.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AMULET2e&nbsp;test&nbsp;card&nbsp;organization.</b>&nbsp;<br>
<hr>
<A name=399></a>&nbsp;<br>
<b>AMULET3</b>&nbsp;<br>
<b>387</b>&nbsp;<br>
14.5 &nbsp; AMULETS&nbsp;<br>
AMULETS&nbsp;<i>is&nbsp;</i>being developed to establish the commercial viability of&nbsp;asynchro-<br>
nous design.&nbsp;Like its predecessors, AMULETS is a full-functionality&nbsp;<br>
ARM-compatible microprocessor with&nbsp;support for interrupts&nbsp;and&nbsp;memory&nbsp;<br>
faults.&nbsp;AMULET 1 and AMULET2 implemented the ARM6 architecture (ARM&nbsp;<br>
architecture version 3G).&nbsp;AMULETS supports ARM architecture&nbsp;version&nbsp;4T,&nbsp;<br>
including the&nbsp;16-bit Thumb instruction set.&nbsp;<br>
Performance&nbsp;<br>
The&nbsp;objective&nbsp;of&nbsp;the AMULETS project was to&nbsp;produce an&nbsp;asynchronous&nbsp;implemen-&nbsp;<br>
Objective&nbsp;<br>
tation of ARM&nbsp;architecture v4T which is competitive in terms of power-efficiency&nbsp;<br>
and performance with the ARM9TDMI. This&nbsp;implies a performance target of over&nbsp;<br>
100 MIPS&nbsp;(measured using&nbsp;Dhrystone 2.1)&nbsp;on a 0.35 (im process, compared to the&nbsp;<br>
40&nbsp;MIPS&nbsp;delivered&nbsp;by&nbsp;AMULET2e&nbsp;on&nbsp;a&nbsp;0.5 um&nbsp;process.&nbsp;<br>
Increasing the performance by&nbsp;more&nbsp;than&nbsp;a factor of two&nbsp;requires a&nbsp;radical change&nbsp;<br>
to&nbsp;the&nbsp;core&nbsp;organization. As&nbsp;with&nbsp;a clocked&nbsp;processor, the&nbsp;basic&nbsp;approach&nbsp;is based&nbsp;on&nbsp;a&nbsp;<br>
combination&nbsp;of&nbsp;increasing the&nbsp;cycle rate&nbsp;of&nbsp;the&nbsp;processor&nbsp;pipeline&nbsp;and&nbsp;decreasing&nbsp;the&nbsp;<br>
average&nbsp;number of cycles&nbsp;per&nbsp;instruction.&nbsp;Here, however,&nbsp;the&nbsp;'cycles'&nbsp;are not&nbsp;defined&nbsp;<br>
by&nbsp;an&nbsp;external&nbsp;clock and are&nbsp;not&nbsp;of&nbsp;fixed duration.&nbsp;<br>
AMULET3 core&nbsp;<br>
The organization of AMULETS is&nbsp;illustrated in Figure 14.10 on page 388. The six&nbsp;<br>
organization&nbsp;<br>
principal pipeline stages are&nbsp;as&nbsp;follows:&nbsp;<br>
•&nbsp;&nbsp;the instruction&nbsp;prefetch unit,&nbsp;which&nbsp;includes a branch target buffer;&nbsp;<br>
•&nbsp;&nbsp;the&nbsp;instruction decode, register&nbsp;read and forwarding stage;&nbsp;<br>
•&nbsp;&nbsp;the execute&nbsp;stage, which&nbsp;includes&nbsp;the shifter,&nbsp;multiplier&nbsp;and ALU;&nbsp;<br>
•&nbsp;&nbsp;the data&nbsp;memory interface;&nbsp;<br>
•&nbsp;&nbsp;the reorder buffer;&nbsp;<br>
•&nbsp;&nbsp;the register result write-back&nbsp;stage.&nbsp;<br>
The core employs a Harvard architecture (separate&nbsp;instruction and&nbsp;data&nbsp;memory&nbsp;<br>
ports)&nbsp;which provides the higher&nbsp;memory&nbsp;bandwidth&nbsp;required to&nbsp;support higher per-<br>
formance.&nbsp;Only&nbsp;those&nbsp;instructions&nbsp;that&nbsp;require&nbsp;data&nbsp;memory access (loads&nbsp;and&nbsp;stores)&nbsp;<br>
pass through the data&nbsp;memory,&nbsp;so the&nbsp;pipeline depth is greater&nbsp;for these instructions&nbsp;<br>
than, for&nbsp;example, for simple&nbsp;data&nbsp;processing&nbsp;instructions.&nbsp;<br>
Further details on each&nbsp;of the pipeline&nbsp;stages are&nbsp;given below.&nbsp;<br>
Instruction&nbsp;<br>
The prefetch&nbsp;unit&nbsp;operates&nbsp;autonomously,&nbsp;fetching&nbsp;32-bit&nbsp;(one&nbsp;ARM&nbsp;or two Thumb)&nbsp;<br>
prefetch&nbsp;unit&nbsp;<br>
instruction packets from&nbsp;memory whenever&nbsp;it&nbsp;has room&nbsp;to&nbsp;store them.&nbsp;<br>
It&nbsp;incorporates&nbsp;a&nbsp;branch&nbsp;prediction&nbsp;unit that&nbsp;is&nbsp;similar to&nbsp;the jump&nbsp;trace&nbsp;buffer used&nbsp;in&nbsp;<br>
AMULET2, but has extensions&nbsp;to support&nbsp;branch prediction&nbsp;in Thumb code.&nbsp;A two-&nbsp;<br>
<hr>
<A name=400></a><IMG src="index-400_1.png"><br>
<b>388</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;14.10 &nbsp;&nbsp;</b>AMULETS core organization.&nbsp;<br>
instruction&nbsp;Thumb&nbsp;packet&nbsp;may contain&nbsp;zero, one&nbsp;or&nbsp;two branch&nbsp;instructions, and the&nbsp;<br>
branch&nbsp;predictor must handle&nbsp;all&nbsp;of these&nbsp;cases. When&nbsp;executing Thumb code&nbsp;the&nbsp;<br>
16-entry&nbsp;branch&nbsp;prediction&nbsp;unit&nbsp;works in&nbsp;two 8-entry&nbsp;halves, with&nbsp;branches at&nbsp;even&nbsp;<br>
half-word addresses being&nbsp;stored in one half and branches at odd&nbsp;half-word&nbsp;<br>
addresses&nbsp;in&nbsp;the&nbsp;other.&nbsp;A packet&nbsp;with&nbsp;a branch&nbsp;in&nbsp;each&nbsp;half&nbsp;word&nbsp;may&nbsp;'hit'&nbsp;in&nbsp;both&nbsp;<br>
halves,&nbsp;whereupon&nbsp;the&nbsp;target&nbsp;of&nbsp;the&nbsp;first&nbsp;instruction (at&nbsp;the&nbsp;even address)&nbsp;takes&nbsp;<br>
priority.&nbsp;<br>
AMULET3 includes a zero-power&nbsp;'Halt'&nbsp;instruction,&nbsp;as&nbsp;did&nbsp;AMULET2. Here&nbsp;the&nbsp;<br>
halt&nbsp;takes effect&nbsp;in&nbsp;the&nbsp;prefetch unit&nbsp;rather&nbsp;than&nbsp;the&nbsp;execution unit, giving&nbsp;a&nbsp;faster&nbsp;<br>
resumption of&nbsp;full throughput&nbsp;when an&nbsp;interrupt&nbsp;occurs. Interrupts&nbsp;themselves are&nbsp;also&nbsp;<br>
handled&nbsp;here,&nbsp;again giving&nbsp;reduced latency.&nbsp;<br>
Decode&nbsp;and&nbsp;<br>
register read&nbsp;<br>
The&nbsp;decode&nbsp;stage&nbsp;includes&nbsp;Thumb&nbsp;and&nbsp;ARM&nbsp;decode&nbsp;logic,&nbsp;and&nbsp;the&nbsp;register&nbsp;read and&nbsp;<br>
forwarding mechanisms.&nbsp;<br>
The ARM7TDMI&nbsp;implemented&nbsp;the&nbsp;Thumb decode&nbsp;function&nbsp;by&nbsp;first&nbsp;converting&nbsp;<br>
Thumb instructions&nbsp;into&nbsp;their&nbsp;ARM&nbsp;equivalents,&nbsp;and then performing ARM&nbsp;decode.&nbsp;<br>
ARM9TDMI&nbsp;reduced&nbsp;decode&nbsp;latency&nbsp;by&nbsp;decoding Thumb&nbsp;instructions&nbsp;directly.&nbsp;<br>
AMULET3 adopts a&nbsp;middle way, decoding certain&nbsp;time-critical control signals&nbsp;<br>
directly&nbsp;and&nbsp;others via the&nbsp;ARM instruction decoder. The asynchronous&nbsp;pipeline&nbsp;<br>
<hr>
<A name=401></a>AMULETS&nbsp;<br>
389&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
allows some&nbsp;elasticity in&nbsp;its operation, and&nbsp;there&nbsp;is&nbsp;a separate&nbsp;Thumb&nbsp;decode&nbsp;stage that&nbsp;<br>
effectively collapses when ARM code is running.&nbsp;<br>
The&nbsp;register read and forwarding&nbsp;stage&nbsp;collects&nbsp;operands&nbsp;from&nbsp;the&nbsp;register&nbsp;file&nbsp;and&nbsp;<br>
searches&nbsp;the reorder buffer for newer values,&nbsp;supplying the&nbsp;correct&nbsp;up-to-date value to&nbsp;<br>
the&nbsp;execution&nbsp;unit.&nbsp;If the correct value is&nbsp;not&nbsp;yet available the forwarding&nbsp;process will&nbsp;<br>
stall&nbsp;until it&nbsp;becomes available.&nbsp;<br>
Following the insights of&nbsp;the StrongARM&nbsp;designers, the AMULETS&nbsp;register&nbsp;file&nbsp;<br>
has&nbsp;three read&nbsp;ports.&nbsp;This&nbsp;allows nearly&nbsp;all&nbsp;instructions&nbsp;to&nbsp;be&nbsp;issued&nbsp;in&nbsp;a&nbsp;single&nbsp;cycle.&nbsp;<br>
Execute&nbsp;<br>
The&nbsp;execution stage includes&nbsp;the adder,&nbsp;shifter&nbsp;and&nbsp;multiplier, and the&nbsp;PSRs&nbsp;also&nbsp;fit&nbsp;<br>
logically&nbsp;into&nbsp;this stage.&nbsp;The&nbsp;multiplier&nbsp;computes 8 bits&nbsp;of product in&nbsp;a cycle, but&nbsp;<br>
cycles&nbsp;much&nbsp;faster&nbsp;than&nbsp;the&nbsp;typical&nbsp;processor&nbsp;cycle&nbsp;time&nbsp;so it&nbsp;computes&nbsp;a&nbsp;32&nbsp;x&nbsp;32&nbsp;<br>
product&nbsp;in&nbsp;around&nbsp;20&nbsp;ns. The adder uses the carry&nbsp;arbitration&nbsp;scheme&nbsp;also used&nbsp;in&nbsp;<br>
the ARM9TDMI (see&nbsp;'Carry arbitration adder'&nbsp;on page 91).&nbsp;<br>
Data memory&nbsp;<br>
The data&nbsp;memory interface operates as&nbsp;a separate&nbsp;pipeline&nbsp;stage in load&nbsp;and store&nbsp;<br>
interface&nbsp;<br>
instructions but is bypassed&nbsp;by&nbsp;other types of instruction. A load that&nbsp;addresses&nbsp;a&nbsp;<br>
slow&nbsp;memory&nbsp;location&nbsp;will&nbsp;therefore not&nbsp;hold up other instructions&nbsp;in&nbsp;the pipeline,&nbsp;<br>
provided&nbsp;that&nbsp;they&nbsp;do&nbsp;not&nbsp;use&nbsp;the&nbsp;loaded value.&nbsp;<br>
Reorder buffer&nbsp;<br>
The reorder buffer accepts results&nbsp;from&nbsp;the execution unit and the data&nbsp;memory&nbsp;<br>
interface in&nbsp;the order that&nbsp;they become&nbsp;available&nbsp;and&nbsp;stores&nbsp;them&nbsp;until&nbsp;they can be&nbsp;<br>
written back to&nbsp;the register file in program&nbsp;order. Once&nbsp;a result is in the reorder&nbsp;<br>
buffer it is&nbsp;available&nbsp;for&nbsp;forwarding to&nbsp;any instruction that needs it.&nbsp;<br>
The structure&nbsp;used to achieve&nbsp;this functionality is illustrated in Figure&nbsp;14.11 on&nbsp;<br>
page&nbsp;390.&nbsp;The&nbsp;buffer has four&nbsp;'slots',&nbsp;and a slot&nbsp;is allocated to&nbsp;each&nbsp;result&nbsp;produced&nbsp;by&nbsp;<br>
an instruction&nbsp;when that&nbsp;instruction&nbsp;is issued. (Slots&nbsp;are&nbsp;also&nbsp;allocated to&nbsp;'store'&nbsp;<br>
instructions&nbsp;so&nbsp;that&nbsp;memory faults&nbsp;can be&nbsp;handled&nbsp;correctly.) As soon as&nbsp;the&nbsp;result&nbsp;is&nbsp;<br>
available&nbsp;it&nbsp;is&nbsp;moved into&nbsp;its&nbsp;slot.&nbsp;<br>
Forwarding&nbsp;from&nbsp;the reorder&nbsp;buffer requires a search&nbsp;of&nbsp;the buffer contents.&nbsp;Condi-<br>
tional&nbsp;ARM&nbsp;instructions&nbsp;may or&nbsp;may not return&nbsp;valid results&nbsp;to&nbsp;the&nbsp;buffer; multiple&nbsp;<br>
instructions&nbsp;may use the&nbsp;same&nbsp;destination register. Identifying&nbsp;the&nbsp;most&nbsp;up-to-date&nbsp;<br>
value for&nbsp;a particular register&nbsp;potentially requires waiting for a result&nbsp;to&nbsp;become&nbsp;availa-<br>
ble&nbsp;in&nbsp;a&nbsp;slot,&nbsp;seeing&nbsp;that&nbsp;it&nbsp;is&nbsp;invalid, and&nbsp;then&nbsp;(worst&nbsp;case) searching all the&nbsp;other&nbsp;slots&nbsp;<br>
in&nbsp;series. This&nbsp;case is&nbsp;rare, though,&nbsp;and is&nbsp;easily&nbsp;accommodated by&nbsp;the asynchronous&nbsp;<br>
timing framework.&nbsp;<br>
Register write&nbsp;<br>
The&nbsp;write-back stream&nbsp;delivered by&nbsp;the&nbsp;reorder buffer is&nbsp;in program&nbsp;order,&nbsp;so this&nbsp;<br>
stage&nbsp;of&nbsp;the pipeline&nbsp;simply&nbsp;delivers values&nbsp;to&nbsp;the&nbsp;register&nbsp;file, checking each&nbsp;one&nbsp;for&nbsp;<br>
validity&nbsp;and looking for any&nbsp;memory&nbsp;faults. If a fault is&nbsp;detected an exception is&nbsp;<br>
raised&nbsp;and&nbsp;subsequent&nbsp;results&nbsp;are&nbsp;discarded unti\&nbsp;the&nbsp;exception&nbsp;handling,&nbsp;mechanism&nbsp;<br>
has activated.&nbsp;<br>
<hr>
<A name=402></a><IMG src="index-402_1.png"><br>
&nbsp;<br>
<b>390</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;14.11 &nbsp; &nbsp;</b>The AMULETS reorder&nbsp;buffer organization.&nbsp;<br>
AMULETS&nbsp;<br>
The performance&nbsp;characteristics of&nbsp;AMULET3&nbsp;are&nbsp;summarized&nbsp;in&nbsp;Table 14.4.&nbsp;It can&nbsp;<br>
performance&nbsp;<br>
be seen that the objective of&nbsp;achieving comparability with&nbsp;the ARM9TDMI on the&nbsp;<br>
same&nbsp;process has been&nbsp;met.&nbsp;<br>
AMULET3&nbsp;has been&nbsp;used&nbsp;as&nbsp;the processing&nbsp;core&nbsp;in the&nbsp;DRACO telecommunica-<br>
tions&nbsp;controller;&nbsp;this is the&nbsp;subject of the next section.&nbsp;<br>
<b>Table&nbsp;14.4&nbsp; &nbsp;</b>AMULET3 characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.35&nbsp;urn&nbsp;Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>113,000&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>120</b>&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3&nbsp;Core area</b>&nbsp;&nbsp;&nbsp;<br>
<b>3 mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>154mW</b>&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>3.3V&nbsp;Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>none&nbsp;MIPS/W</b>&nbsp;<br>
<b>780</b>&nbsp;<br>
14.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The DRACO telecommunications controller&nbsp;<br>
The DRACO (DECT Radio&nbsp;Communications Controller)&nbsp;chip&nbsp;is the&nbsp;first com-<br>
&nbsp;<br>
mercial design&nbsp;based on AMULET technology; it uses&nbsp;the AMULET3H&nbsp;<br>
self-timed&nbsp;processing subsystem&nbsp;described later in&nbsp;this&nbsp;section as its&nbsp;compute&nbsp;<br>
and&nbsp;control&nbsp;engine.&nbsp;<br>
DRACO&nbsp;was developed in collaboration between Hagenuk&nbsp;GmbH&nbsp;(who&nbsp;<br>
designed the&nbsp;clocked telecommunications&nbsp;peripherals) and&nbsp;the University&nbsp;of&nbsp;<br>
Manchester&nbsp;(who were responsible for&nbsp;the&nbsp;AMULETS H subsystem)&nbsp;with funding&nbsp;<br>
from the European Union.&nbsp;<br>
<hr>
<A name=403></a><b>The DRACO telecommunications controller</b>&nbsp;<br>
<b>391</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Rationale for&nbsp;<br>
The decision to&nbsp;employ a&nbsp;self-timed processing&nbsp;subsystem&nbsp;in&nbsp;the&nbsp;DRACO chip&nbsp;was&nbsp;<br>
self-timing&nbsp;<br>
influenced&nbsp;primarily&nbsp;by&nbsp;the electromagnetic&nbsp;compatibility (EMC)&nbsp;advantages&nbsp;of&nbsp;<br>
self-timed logic. The radio interference generated by&nbsp;high-speed clocked systems&nbsp;<br>
can&nbsp;compromise the&nbsp;performance of&nbsp;the DECT&nbsp;radio communication;&nbsp;a&nbsp;harmonic of&nbsp;<br>
the clock&nbsp;is&nbsp;likely to fall within&nbsp;one&nbsp;of&nbsp;the&nbsp;DECT&nbsp;channel frequency bands,&nbsp;possibly&nbsp;<br>
rendering&nbsp;that&nbsp;channel&nbsp;unusable.&nbsp;<br>
The&nbsp;logical&nbsp;conclusion&nbsp;might&nbsp;be&nbsp;to&nbsp;make all&nbsp;of&nbsp;the&nbsp;chip operate&nbsp;in self-timed logic.&nbsp;<br>
However, many&nbsp;of the&nbsp;telecommunications&nbsp;interfaces are&nbsp;intrinsically&nbsp;highly&nbsp;synchro-<br>
nous&nbsp;and are much&nbsp;easier&nbsp;to&nbsp;design&nbsp;using synchronous synthesis tools.&nbsp;<br>
The&nbsp;synchronous&nbsp;peripheral&nbsp;subsystem should&nbsp;not&nbsp;compromise&nbsp;the&nbsp;EMC&nbsp;<br>
advantages&nbsp;offered by&nbsp;the&nbsp;self-timed processing&nbsp;subsystem&nbsp;since the characteristic&nbsp;<br>
frequencies&nbsp;of&nbsp;the peripherals are all much&nbsp;lower&nbsp;than&nbsp;the&nbsp;processing rate.&nbsp;All the&nbsp;<br>
high-speed&nbsp;processing&nbsp;and&nbsp;the&nbsp;heavily&nbsp;loaded&nbsp;external memory&nbsp;bus&nbsp;operate&nbsp;<br>
asynchro-nously,&nbsp;giving&nbsp;most of&nbsp;the advantages&nbsp;of&nbsp;a fully&nbsp;self-timed&nbsp;system&nbsp;without&nbsp;<br>
incurring the&nbsp;design&nbsp;cost&nbsp;of&nbsp;developing&nbsp;self-timed telecommunications&nbsp;peripherals.&nbsp;<br>
DRACO&nbsp;<br>
The&nbsp;DRACO chip includes&nbsp;the following&nbsp;functions&nbsp;in the&nbsp;synchronous peripheral&nbsp;<br>
functions&nbsp;<br>
subsystem:&nbsp;<br>
•&nbsp;&nbsp;an ISDN controller with a 16&nbsp;Kbit/s HDLC&nbsp;controller and transformerless ana&nbsp;<br>
logue&nbsp;ISDN interfaces;&nbsp;<br>
•&nbsp;&nbsp;a DECT radio&nbsp;interface baseband controller&nbsp;and analogue interface to the&nbsp;DECT&nbsp;<br>
radio&nbsp;subsystem;&nbsp;<br>
•&nbsp;&nbsp;a DECT&nbsp;encryption engine;&nbsp;<br>
•&nbsp;&nbsp;a four-channel&nbsp;full-duplex ADPCM/PCM conversion&nbsp;signal processor;&nbsp;<br>
•&nbsp;&nbsp;8&nbsp;Kbytes&nbsp;of&nbsp;shared RAM&nbsp;used&nbsp;for&nbsp;buffer space by&nbsp;the DECT&nbsp;controller;&nbsp;<br>
•&nbsp;&nbsp;a&nbsp;telecommunications&nbsp;codec with&nbsp;an&nbsp;analogue&nbsp;front-end&nbsp;for speech&nbsp;input and&nbsp;<br>
output which&nbsp;could alternatively&nbsp;be&nbsp;used&nbsp;for an&nbsp;analogue&nbsp;telecommunications port;&nbsp;<br>
•&nbsp;&nbsp;two&nbsp;high-speed&nbsp;UARTs with&nbsp;an&nbsp;IrDA interface&nbsp;that&nbsp;can be&nbsp;used&nbsp;by&nbsp;either&nbsp;UART;&nbsp;<br>
•&nbsp;&nbsp;an interrupt&nbsp;controller;&nbsp;<br>
•&nbsp;&nbsp;counter-timers and a&nbsp;watchdog&nbsp;timer;&nbsp;<br>
•&nbsp;&nbsp;a&nbsp;2&nbsp;Mbit/s&nbsp;IOM2&nbsp;highway&nbsp;controller&nbsp;with programmable&nbsp;switching&nbsp;functionality;&nbsp;<br>
•&nbsp;&nbsp;an I2C interface;&nbsp;<br>
•&nbsp;&nbsp;an analogue-to-digital&nbsp;converter (ADC) interface;&nbsp;<br>
•&nbsp;&nbsp;65 flexible&nbsp;I/O ports&nbsp;including an 8-bit parallel port&nbsp;with handshake&nbsp;capability;&nbsp;<br>
•&nbsp;&nbsp;2 general-purpose pulse-width modulation&nbsp;controllers;&nbsp;<br>
•&nbsp;&nbsp;an&nbsp;on-chip&nbsp;clock&nbsp;oscillator&nbsp;produces 38.864&nbsp;MHz,&nbsp;and&nbsp;on-chip&nbsp;phase-locked&nbsp;<br>
loops produce&nbsp;the 12.288 MHz&nbsp;master&nbsp;clock required&nbsp;by&nbsp;the ISDN interface and&nbsp;<br>
the 13.824 MHz&nbsp;master clock required&nbsp;by&nbsp;the DECT controller;&nbsp;<br>
<hr>
<A name=404></a><b>392</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
•&nbsp;&nbsp;an ISDN-DECT synchronizer phase-locked&nbsp;loop avoids bit&nbsp;loss in data transfers&nbsp;<br>
between&nbsp;the ISDN and&nbsp;DECT clock&nbsp;domains;&nbsp;<br>
•&nbsp;&nbsp;the clock&nbsp;system&nbsp;has&nbsp;power-down&nbsp;features.&nbsp;<br>
In addition, the self-timed&nbsp;AMULET3H processing&nbsp;subsystem&nbsp;incorporates:&nbsp;<br>
•&nbsp;&nbsp;a 100 MIPS&nbsp;AMULET3 32-bit&nbsp;processor&nbsp;that&nbsp;implements&nbsp;ARM&nbsp;architecture v4T&nbsp;<br>
(including&nbsp;the&nbsp;Thumb 16-bit&nbsp;compressed instruction&nbsp;set)&nbsp;with debug hardware;&nbsp;<br>
•&nbsp;&nbsp;8 Kbytes of&nbsp;dual-port high-speed RAM&nbsp;(local to the processor);&nbsp;<br>
•&nbsp;&nbsp;a self-timed on-chip bus with&nbsp;a bridge to the synchronous on-chip bus that con&nbsp;<br>
nects the synchronous peripherals;&nbsp;<br>
•&nbsp;&nbsp;a 32-channel&nbsp;DMA controller;&nbsp;<br>
•&nbsp;&nbsp;16&nbsp;Kbytes of&nbsp;ROM&nbsp;holding&nbsp;standard&nbsp;telecommunications&nbsp;application&nbsp;software;&nbsp;<br>
•&nbsp;&nbsp;an&nbsp;asynchronous event&nbsp;driven load&nbsp;module&nbsp;that holds the&nbsp;processor in&nbsp;zero-power&nbsp;<br>
wait&nbsp;mode&nbsp;while an analogue-to-digital conversion completes, thereby&nbsp;synchro&nbsp;<br>
nizing the&nbsp;software to&nbsp;external data&nbsp;rates;&nbsp;<br>
•&nbsp;&nbsp;a programmable external&nbsp;memory interface&nbsp;that&nbsp;supports the direct connection of&nbsp;<br>
SRAM,&nbsp;DRAM&nbsp;and&nbsp;flash&nbsp;memory;&nbsp;<br>
•&nbsp;&nbsp;an on-chip reference delay&nbsp;line calibrated by&nbsp;software&nbsp;to control off-chip memory&nbsp;<br>
access timings.&nbsp;<br>
AMULET3H&nbsp;<br>
AMULET3H is&nbsp;a subsystem&nbsp;based around an AMULET3 core&nbsp;that forms&nbsp;an asyn-&nbsp;<br>
chronous 'island'&nbsp;at&nbsp;the&nbsp;heart of&nbsp;the DRACO telecommunications&nbsp;controller&nbsp;in&nbsp;<br>
which&nbsp;it&nbsp;is interfaced&nbsp;to&nbsp;a&nbsp;range of&nbsp;synchronous peripheral controllers.&nbsp;To&nbsp;reap&nbsp;the&nbsp;<br>
benefits of&nbsp;asynchronous operation&nbsp;the core&nbsp;must have access to&nbsp;some&nbsp;memory&nbsp;that&nbsp;<br>
operates&nbsp;asynchronously,&nbsp;and there are&nbsp;significant electromagnetic compatibility&nbsp;<br>
benefits in&nbsp;having&nbsp;off-chip&nbsp;memory also&nbsp;operate asynchronously.&nbsp;<br>
MARBLE&nbsp;on-&nbsp;<br>
The&nbsp;organization&nbsp;of the asynchronous subsystem&nbsp;is illustrated&nbsp;in&nbsp;Figure 14.12&nbsp;on&nbsp;<br>
Chip&nbsp;bus&nbsp;<br>
page 393. The AMULET3 core is&nbsp;connected directly&nbsp;to a&nbsp;dual-ported RAM&nbsp;(dis-&nbsp;<br>
cussed&nbsp;further&nbsp;below)&nbsp;and then to the MARBLE on-chip&nbsp;bus. MARBLE is similar&nbsp;<br>
in concept&nbsp;to&nbsp;ARM's&nbsp;AMBA&nbsp;bus, the&nbsp;major&nbsp;difference being that it does not use a&nbsp;<br>
clock signal.&nbsp;Its transfer&nbsp;mechanism&nbsp;is&nbsp;based around&nbsp;a split transaction primitive.&nbsp;<br>
System&nbsp;components other than the local&nbsp;RAM are accessed via the&nbsp;MARBLE&nbsp;<br>
bus.&nbsp;These&nbsp;include&nbsp;on-chip&nbsp;ROM,&nbsp;a DMA controller,&nbsp;a&nbsp;bridge&nbsp;to&nbsp;the synchronous&nbsp;bus&nbsp;<br>
where&nbsp;the&nbsp;application-specific&nbsp;peripheral&nbsp;controllers&nbsp;reside, and an interface&nbsp;to&nbsp;exter-<br>
nal memory.&nbsp;<br>
External&nbsp;memory &nbsp; &nbsp;&nbsp;The&nbsp;external&nbsp;memory&nbsp;interface presents a conventional&nbsp;set of&nbsp;signals&nbsp;for&nbsp;<br>
off-chip&nbsp;<br>
interface&nbsp;<br>
devices.&nbsp;It&nbsp;is&nbsp;similar&nbsp;to&nbsp;the&nbsp;AMULET2e interface (see Section&nbsp;14.4&nbsp;on&nbsp;page 384),&nbsp;<br>
being&nbsp;highly&nbsp;configurable&nbsp;and using a&nbsp;reference&nbsp;delay&nbsp;to&nbsp;time external&nbsp;accesses.&nbsp;<br>
<hr>
<A name=405></a><IMG src="index-405_1.png"><br>
<b>The DRACO telecommunications controller</b>&nbsp;<br>
<b>393</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Synchronous&nbsp;</b><br>
<b>peripheral&nbsp;</b><br>
<b>interface</b><br>
&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
<b>Figure 14.12&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The AMULET3H&nbsp;asynchronous subsystem.&nbsp;<br>
Instead of using an off-chip&nbsp;reference delay,&nbsp;however,&nbsp;AMULETS H&nbsp;has&nbsp;an&nbsp;on-chip&nbsp;<br>
delay&nbsp;which can be calibrated&nbsp;by&nbsp;software against a timing&nbsp;reference, perhaps using&nbsp;<br>
a timer/counter in&nbsp;the&nbsp;synchronous peripheral subsystem&nbsp;for this purpose.&nbsp;<br>
Off-chip&nbsp;DRAM is supported directly, as&nbsp;are conventional ROM, SRAM&nbsp;and&nbsp;<br>
memory&nbsp;mapped&nbsp;peripheral&nbsp;devices.&nbsp;<br>
AMULET3H&nbsp;<br>
The AMULETS processor core has separate&nbsp;address and&nbsp;data buses for&nbsp;instruction&nbsp;<br>
memory&nbsp;<br>
and data&nbsp;memory accesses.&nbsp;This would normally require&nbsp;separate instruction and&nbsp;<br>
Organization&nbsp;<br>
data&nbsp;memories;&nbsp;RISC&nbsp;systems&nbsp;frequently&nbsp;employ&nbsp;a&nbsp;'modified&nbsp;Harvard'&nbsp;architecture&nbsp;<br>
where there&nbsp;are&nbsp;separate&nbsp;instruction&nbsp;and&nbsp;data caches&nbsp;with a&nbsp;unified&nbsp;main&nbsp;memory.&nbsp;<br>
The AMULET3H controller&nbsp;employs&nbsp;direct-mapped&nbsp;RAM rather&nbsp;than&nbsp;cache&nbsp;<br>
memory as&nbsp;this is&nbsp;more&nbsp;cost-effective and&nbsp;has more deterministic&nbsp;behaviour&nbsp;for&nbsp;real-<br>
time applications. It also avoids separate&nbsp;instruction&nbsp;and data&nbsp;memories (and the&nbsp;asso-<br>
ciated difficulties&nbsp;of keeping them&nbsp;coherent) through&nbsp;the use&nbsp;of&nbsp;a dual-ported&nbsp;memory&nbsp;<br>
structure&nbsp;(see&nbsp;Figure&nbsp;14.13&nbsp;on&nbsp;page&nbsp;394).&nbsp;Dual-porting&nbsp;the&nbsp;memory&nbsp;at the individual&nbsp;<br>
bit level&nbsp;would be&nbsp;too&nbsp;costly, so&nbsp;instead&nbsp;the&nbsp;memory is divided into eight 1&nbsp;Kbyte&nbsp;<br>
blocks, each&nbsp;of&nbsp;which has two&nbsp;ports which are arbitrated&nbsp;internally. When&nbsp;concurrent&nbsp;<br>
data and instruction accesses are to&nbsp;different RAM blocks, each can proceed&nbsp;<br>
<hr>
<A name=406></a><IMG src="index-406_1.png"><br>
<b>394</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure 14.13&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>AMULET3H memory&nbsp;organization.&nbsp;<br>
unimpeded&nbsp;by&nbsp;the other;&nbsp;when&nbsp;they&nbsp;happen&nbsp;to&nbsp;conflict&nbsp;on&nbsp;the same&nbsp;block,&nbsp;one access&nbsp;<br>
will&nbsp;suffer&nbsp;a&nbsp;delay while&nbsp;it&nbsp;waits for the&nbsp;other&nbsp;to complete.&nbsp;<br>
Conflicts (and&nbsp;average memory access times) are further reduced&nbsp;by including sep-<br>
arate&nbsp;quad-word&nbsp;instruction and data buffers&nbsp;in&nbsp;each RAM block.&nbsp;Each&nbsp;access&nbsp;to a&nbsp;<br>
block first checks to&nbsp;see whether the&nbsp;required&nbsp;data&nbsp;is&nbsp;in&nbsp;the&nbsp;buffer.&nbsp;Only&nbsp;if&nbsp;it&nbsp;is&nbsp;not&nbsp;<br>
must&nbsp;the&nbsp;RAM be&nbsp;interrogated,&nbsp;with&nbsp;a risk&nbsp;of conflict. Simulations suggest&nbsp;that&nbsp;about&nbsp;<br>
60%&nbsp;of instruction fetches&nbsp;may&nbsp;be satisfied&nbsp;from&nbsp;within these buffers and&nbsp;many&nbsp;short,&nbsp;<br>
time-critical loops&nbsp;will&nbsp;run&nbsp;entirely from&nbsp;them.&nbsp;<br>
These buffers, in effect,&nbsp;form&nbsp;simple 128-byte&nbsp;first-level&nbsp;caches in&nbsp;front of the&nbsp;<br>
RAM&nbsp;blocks.&nbsp;This&nbsp;is&nbsp;a&nbsp;particularly&nbsp;apt&nbsp;analogy&nbsp;when&nbsp;it&nbsp;is&nbsp;observed that&nbsp;the&nbsp;avoidance&nbsp;<br>
of the RAM&nbsp;array results&nbsp;in a&nbsp;faster read&nbsp;cycle, an&nbsp;occurrence which&nbsp;is accepted&nbsp;auto-<br>
matically&nbsp;by&nbsp;the asynchronous&nbsp;pipeline.&nbsp;<br>
Test interface&nbsp;<br>
AMULET3H is being developed&nbsp;for commercial&nbsp;use and&nbsp;must&nbsp;therefore be testable&nbsp;<br>
controller&nbsp;<br>
in production.&nbsp;There are&nbsp;many&nbsp;features in the design to ensure that this is possible,&nbsp;<br>
the&nbsp;most visible of&nbsp;which is the test&nbsp;interface&nbsp;controller&nbsp;(see&nbsp;Figure 14.12 on&nbsp;<br>
page 393).&nbsp;This extension to the external&nbsp;memory&nbsp;interface&nbsp;logic&nbsp;follows the exam-<br>
ple&nbsp;set&nbsp;by&nbsp;AMBA&nbsp;(see&nbsp;&quot;Test interface&quot;&nbsp;on&nbsp;page&nbsp;219) in&nbsp;enabling the external&nbsp;<br>
memory interface,&nbsp;which in&nbsp;normal operation is a MARBLE slave, to&nbsp;become&nbsp;a&nbsp;<br>
MARBLE&nbsp;master&nbsp;for test&nbsp;purposes.&nbsp;In test&nbsp;mode production test equipment can&nbsp;<br>
become&nbsp;a&nbsp;MARBLE&nbsp;master, allowing it&nbsp;to&nbsp;read&nbsp;on-chip ROM and to&nbsp;read&nbsp;and&nbsp;write&nbsp;<br>
on-chip RAM, and to&nbsp;access the&nbsp;many&nbsp;other test facilities&nbsp;built into the&nbsp;<br>
AMULET3H&nbsp;system, all of&nbsp;which&nbsp;are&nbsp;controlled&nbsp;via&nbsp;test&nbsp;registers connected&nbsp;to the&nbsp;<br>
MARBLE bus.&nbsp;<br>
<hr>
<A name=407></a><IMG src="index-407_1.png"><br>
<b>The DRACO telecommunications controller</b>&nbsp;<br>
<b>395</b>&nbsp;<br>
AMULET3H&nbsp;<br>
The simulated&nbsp;performance characteristics of&nbsp;the&nbsp;AMULET3H subsystem&nbsp;are&nbsp;sum-&nbsp;<br>
performance&nbsp;<br>
marized in&nbsp;Table&nbsp;14.5. (The&nbsp;transistor&nbsp;count,&nbsp;area&nbsp;and&nbsp;power figures&nbsp;are for&nbsp;the&nbsp;<br>
asynchronous&nbsp;subsystem&nbsp;only. Overall the&nbsp;DRACO&nbsp;die&nbsp;is&nbsp;7.8&nbsp;x&nbsp;7.3 mm.) The&nbsp;maxi-<br>
mum&nbsp;system&nbsp;performance is&nbsp;slightly lower than&nbsp;that&nbsp;of the AMULET3&nbsp;core&nbsp;<br>
(reported&nbsp;in&nbsp;Table 14.4&nbsp;on&nbsp;page 390)&nbsp;since the on-chip&nbsp;RAM&nbsp;cannot supply the&nbsp;<br>
processor's peak&nbsp;instruction&nbsp;bandwidth requirement.&nbsp;The&nbsp;system&nbsp;power-efficiency&nbsp;is&nbsp;<br>
lower than&nbsp;that of the processor alone since the memory&nbsp;system&nbsp;power is now&nbsp;<br>
included&nbsp;as&nbsp;well&nbsp;as the power consumed&nbsp;by&nbsp;the&nbsp;processor&nbsp;core&nbsp;itself.&nbsp;<br>
<b>Table&nbsp;14.5 &nbsp;&nbsp;&nbsp;</b>AMULET3H characteristics.&nbsp;<br>
&nbsp;<br>
<b>Process</b>&nbsp;&nbsp;&nbsp;<br>
<b>0.35&nbsp;urn</b>&nbsp;&nbsp;<b>Transistors</b>&nbsp;&nbsp;&nbsp;<br>
<b>825,000&nbsp;MIPS</b>&nbsp;&nbsp;&nbsp;<br>
<b>100</b>&nbsp;<br>
<b>Metal layers</b>&nbsp;&nbsp;&nbsp;<br>
<b>3</b>&nbsp;&nbsp;<b>Core area</b>&nbsp;&nbsp;&nbsp;<br>
<b>21mm2&nbsp;Power</b>&nbsp;&nbsp;&nbsp;<br>
<b>215 mW</b>&nbsp;<br>
<b>Vdd</b>&nbsp;&nbsp;&nbsp;<br>
<b>3.3V</b>&nbsp;&nbsp;<b>Clock</b>&nbsp;&nbsp;&nbsp;<br>
<b>none&nbsp;MIPSAV</b>&nbsp;<br>
<b>465</b>&nbsp;<br>
&nbsp;<br>
<b>Figure 14.14&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>DRACO die&nbsp;plot.&nbsp;<br>
It&nbsp;can&nbsp;be&nbsp;seen&nbsp;that the&nbsp;AMULET3H&nbsp;subsystem&nbsp;is&nbsp;competitive with&nbsp;the equivalent&nbsp;<br>
clocked ARM&nbsp;systems in&nbsp;terms of performance&nbsp;and power-efficiency.&nbsp;It&nbsp;has&nbsp;the&nbsp;<br>
<hr>
<A name=408></a><b>396</b>&nbsp;<br>
<b>The AMULET&nbsp;Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
advantages of&nbsp;better electromagnetic interference&nbsp;and system&nbsp;power&nbsp;management&nbsp;<br>
properties. Against these&nbsp;advantages must be weighed the present shortcomings in the&nbsp;<br>
available tool&nbsp;support&nbsp;for asynchronous design.&nbsp;<br>
DRACO&nbsp;<br>
The&nbsp;DRACO&nbsp;chip can&nbsp;be used in a&nbsp;number&nbsp;of&nbsp;telecommunications applications.&nbsp;A&nbsp;<br>
applications&nbsp;<br>
typical application is a combined ISDN terminal and DECT base-station which&nbsp;<br>
would enable&nbsp;a number of users to communicate with&nbsp;each other using cordless&nbsp;<br>
DECT handsets and to connect to the&nbsp;telecommunications network via the ISDN&nbsp;<br>
line or a cordless&nbsp;ISDN network terminator.&nbsp;The principal target&nbsp;market&nbsp;for the chip&nbsp;<br>
is in&nbsp;cordless&nbsp;DECT&nbsp;data&nbsp;applications.&nbsp;<br>
DRACO silicon&nbsp;<br>
A&nbsp;plot of the DRACO silicon layout&nbsp;is&nbsp;shown&nbsp;in&nbsp;Figure&nbsp;14.14&nbsp;on&nbsp;page 395.&nbsp;The&nbsp;<br>
AMULET3H asynchronous&nbsp;subsystem&nbsp;occupies&nbsp;the bottom&nbsp;half of the&nbsp;core area;&nbsp;<br>
the synchronous telecommunications peripherals occupy&nbsp;the top half. First silicon&nbsp;<br>
was fabricated early in&nbsp;2000.&nbsp;<br>
14.7 &nbsp; A&nbsp;self-timed&nbsp;future?&nbsp;<br>
Although AMULET3 will&nbsp;be used&nbsp;commercially&nbsp;the AMULET&nbsp;programme has,&nbsp;so&nbsp;<br>
far, been primarily of&nbsp;a&nbsp;research nature, and there is no&nbsp;immediate&nbsp;prospect of&nbsp;the&nbsp;<br>
AMULET cores replacing the clocked ARM&nbsp;cores in&nbsp;widespread use. However,&nbsp;<br>
there is a resurgence&nbsp;of&nbsp;world-wide&nbsp;interest in the potential of&nbsp;asynchronous design&nbsp;<br>
styles&nbsp;to&nbsp;save&nbsp;power, to&nbsp;improve electromagnetic compatibility, and to&nbsp;offer a&nbsp;more&nbsp;<br>
modular approach to the design of computing hardware.&nbsp;<br>
The power savings which result from&nbsp;removing&nbsp;the&nbsp;global&nbsp;clock, leaving&nbsp;each sub-<br>
system&nbsp;to&nbsp;perform&nbsp;its&nbsp;own&nbsp;timing functions&nbsp;whenever&nbsp;it&nbsp;has&nbsp;useful&nbsp;work&nbsp;to&nbsp;perform,&nbsp;<br>
are clear in&nbsp;theory but&nbsp;there&nbsp;are few demonstrations that&nbsp;the&nbsp;benefits can&nbsp;be&nbsp;realized&nbsp;in&nbsp;<br>
practice&nbsp;with&nbsp;circuits&nbsp;of&nbsp;sufficient complexity to be&nbsp;commercially interesting.&nbsp;The&nbsp;<br>
AMULET&nbsp;research is aimed directly at&nbsp;adding to&nbsp;the body&nbsp;of&nbsp;convincing demonstra-<br>
tions&nbsp;of&nbsp;the merits of&nbsp;asynchronous&nbsp;technology.&nbsp;<br>
An obstacle to&nbsp;the widespread adoption of&nbsp;self-timed&nbsp;design styles is the&nbsp;<br>
knowledge-base of&nbsp;the existing design&nbsp;community. Most 1C designers have been&nbsp;<br>
trained to&nbsp;have&nbsp;a&nbsp;strong&nbsp;aversion&nbsp;to&nbsp;asynchronous circuits&nbsp;because of&nbsp;the difficulties&nbsp;<br>
that&nbsp;were&nbsp;experienced&nbsp;by&nbsp;the&nbsp;designers&nbsp;of&nbsp;some&nbsp;early&nbsp;asynchronous&nbsp;computers.&nbsp;These&nbsp;<br>
difficulties resulted&nbsp;from&nbsp;an&nbsp;undisciplined&nbsp;approach&nbsp;to&nbsp;self-timed design,&nbsp;and modern&nbsp;<br>
developments&nbsp;offer&nbsp;asynchronous&nbsp;design&nbsp;frameworks&nbsp;which&nbsp;overcome most of&nbsp;the&nbsp;<br>
problems inherent in&nbsp;what is, admittedly, a&nbsp;more anarchic approach to&nbsp;logic design&nbsp;<br>
than&nbsp;that&nbsp;offered within&nbsp;the clocked framework.&nbsp;<br>
<hr>
<A name=409></a><b>Example and&nbsp;exercises&nbsp;</b><br>
<b>397</b>&nbsp;<br>
The next few&nbsp;years will tell whether or&nbsp;not AMULET and similar developments&nbsp;<br>
around&nbsp;the world can&nbsp;demonstrate the sort&nbsp;of&nbsp;advantages that will&nbsp;cause designers to&nbsp;<br>
throw away most&nbsp;of their&nbsp;past&nbsp;education and&nbsp;learn&nbsp;a&nbsp;new way to perform&nbsp;their duties.&nbsp;<br>
AMULET&nbsp;<br>
AMULET&nbsp;1&nbsp;was&nbsp;developed using European&nbsp;Community&nbsp;funding within&nbsp;the&nbsp;Open&nbsp;<br>
Support&nbsp;<br>
Microprocessor systems Initiative -&nbsp;Microprocessor Architecture&nbsp;Project&nbsp;(OMI-&nbsp;<br>
MAP). AMULET2 was developed within the&nbsp;Open Microprocessor&nbsp;systems&nbsp;Initia-<br>
tive - Deeply&nbsp;Embedded&nbsp;ARM (OMI-DE/ARM) project. The development of&nbsp;<br>
AMULETS and DRACO was supported primarily within the European Union&nbsp;<br>
funded OMI-DE2 and OMI-ATOM projects. Aspects of&nbsp;the work have benefited&nbsp;<br>
from&nbsp;support from&nbsp;the UK&nbsp;government&nbsp;through the&nbsp;Engineering&nbsp;and&nbsp;Physical Sci-<br>
ences Research Council (EPSRC) in the&nbsp;form&nbsp;of&nbsp;a&nbsp;PhD studentships and the tools&nbsp;<br>
development funded under&nbsp;ROPA grant GR/K61913.&nbsp;<br>
The work also&nbsp;received support in&nbsp;various forms from&nbsp;ARM Limited, GEC&nbsp;Plessey&nbsp;<br>
Semiconductors (now part of&nbsp;MITEL) and&nbsp;VLSI Technology, Inc. Tools&nbsp;from&nbsp;Com-<br>
pass Design&nbsp;Automation (now&nbsp;part of Avant!) were important to&nbsp;the success of both&nbsp;<br>
projects,&nbsp;and TimeMill from&nbsp;EPIC Design&nbsp;Technology, Inc. (now&nbsp;part&nbsp;of&nbsp;Synopsys)&nbsp;<br>
was&nbsp;vital to the accurate&nbsp;modelling of AMULET2 and AMULETS.&nbsp;<br>
14.8 &nbsp; Example&nbsp;and&nbsp;exercises&nbsp;<br>
<b>Example&nbsp;14.1&nbsp;</b><br>
<b>Summarize&nbsp;the advantages and disadvantages&nbsp;of&nbsp;self-timed&nbsp;design.</b>&nbsp;<br>
The advantages&nbsp;discussed&nbsp;here&nbsp;are:&nbsp;<br>
•&nbsp;&nbsp;improved electromagnetic compatibility (EMC);&nbsp;<br>
•&nbsp;&nbsp;improved power-efficiency;&nbsp;<br>
•&nbsp;&nbsp;improved design&nbsp;modularity;&nbsp;<br>
•&nbsp;&nbsp;the&nbsp;removal&nbsp;of&nbsp;the&nbsp;clock-skew&nbsp;problem;&nbsp;<br>
•&nbsp;&nbsp;the potential&nbsp;for typical&nbsp;rather&nbsp;than&nbsp;worst-case performance.&nbsp;<br>
The disadvantages&nbsp;are:&nbsp;<br>
•&nbsp;&nbsp;the unavailability&nbsp;of&nbsp;design&nbsp;tools&nbsp;for self-timed design;&nbsp;<br>
•&nbsp;&nbsp;the lack of&nbsp;designer experience;&nbsp;<br>
•&nbsp;&nbsp;an aversion&nbsp;to self-timed&nbsp;techniques has&nbsp;been&nbsp;encouraged in&nbsp;design&nbsp;education;&nbsp;<br>
•&nbsp;&nbsp;there is a lack of&nbsp;commercial-scale demonstrations of the above-claimed advantages.&nbsp;<br>
In general it is&nbsp;still a high-risk option to pursue a self-timed&nbsp;solution to a design&nbsp;<br>
problem,&nbsp;and&nbsp;the&nbsp;lack&nbsp;of&nbsp;tools&nbsp;can make&nbsp;it&nbsp;very&nbsp;labour&nbsp;intensive.&nbsp;<br>
<hr>
<A name=410></a><b>398</b>&nbsp;<br>
<b>The&nbsp;AMULET Asynchronous ARM&nbsp;Processors</b>&nbsp;<br>
<b>Exercise 14.1.1&nbsp;</b><br>
Estimate&nbsp;the&nbsp;effect&nbsp;on the performance of&nbsp;both clocked&nbsp;and self-timed processors of&nbsp;<br>
memory conflicts when the&nbsp;processor core&nbsp;has separate instruction and data ports&nbsp;<br>
both&nbsp;of which are connected&nbsp;to&nbsp;a single&nbsp;dual-port&nbsp;memory.&nbsp;Assume&nbsp;the memory&nbsp;is&nbsp;<br>
constructed from&nbsp;eight arbitrated&nbsp;segments&nbsp;similar&nbsp;to&nbsp;the&nbsp;AMULET3H&nbsp;memory but&nbsp;<br>
without the line buffers&nbsp;(see&nbsp;&quot;AMULET3H&nbsp;memory organization&quot;&nbsp;on page 393).&nbsp;<br>
You&nbsp;can&nbsp;assume&nbsp;that&nbsp;the&nbsp;processor&nbsp;fetches&nbsp;instructions&nbsp;continuously&nbsp;and requires&nbsp;<br>
about&nbsp;one&nbsp;data&nbsp;memory&nbsp;access&nbsp;for every two&nbsp;instructions.&nbsp;The&nbsp;instruction&nbsp;and&nbsp;data&nbsp;<br>
accesses&nbsp;from&nbsp;the clocked processor&nbsp;will&nbsp;be&nbsp;synchronized&nbsp;(by the&nbsp;clock!),&nbsp;so&nbsp;every&nbsp;<br>
time contention arises&nbsp;one of&nbsp;the two accesses will&nbsp;be stalled for one&nbsp;cycle. The&nbsp;asyn-<br>
chronous&nbsp;processor has&nbsp;no&nbsp;such&nbsp;sychronization so&nbsp;the&nbsp;two&nbsp;accesses&nbsp;have&nbsp;random&nbsp;rela-<br>
tive&nbsp;timing&nbsp;and&nbsp;the&nbsp;stall will&nbsp;be&nbsp;for whatever&nbsp;proportion&nbsp;of&nbsp;the&nbsp;first&nbsp;contending&nbsp;access&nbsp;<br>
time&nbsp;remains&nbsp;when&nbsp;the&nbsp;second contending access is&nbsp;requested.&nbsp;<br>
<b>Exercise&nbsp;14.1.2&nbsp;</b><br>
Estimate the&nbsp;effect on performance of the&nbsp;instruction&nbsp;and&nbsp;data&nbsp;line&nbsp;buffers in&nbsp;the&nbsp;<br>
AMULET3H&nbsp;memory&nbsp;system.&nbsp;Make the same&nbsp;assumptions as in the previous exercise.&nbsp;<br>
<hr>
<A name=411></a><IMG src="index-411_1.png"><br>
Appendix: Computer Logic&nbsp;<br>
Computer logic&nbsp;<br>
Computer design is based upon&nbsp;Boolean logic where a signal on a wire has&nbsp;one of two&nbsp;<br>
values:&nbsp;<b>true&nbsp;or&nbsp;false.&nbsp;</b>Typically a voltage near ground represents&nbsp;'false'&nbsp;and one near the&nbsp;<br>
supply&nbsp;voltage represents&nbsp;'true'; however, any&nbsp;representation that can reliably reflect two&nbsp;<br>
different&nbsp;states&nbsp;can&nbsp;be&nbsp;used. 'True'&nbsp;is sometimes called&nbsp;logic&nbsp;' 1'&nbsp;and 'false'&nbsp;logic '0'.&nbsp;<br>
Logic gates&nbsp;<br>
A&nbsp;logic&nbsp;gate&nbsp;produces&nbsp;a&nbsp;function of&nbsp;one&nbsp;or&nbsp;more&nbsp;logic inputs.&nbsp;A&nbsp;2-input&nbsp;'AND'&nbsp;gate,&nbsp;<br>
for example,&nbsp;produces a 'true'&nbsp;output if&nbsp;the first&nbsp;input&nbsp;is 'true'&nbsp;AND&nbsp;the second&nbsp;<br>
input&nbsp;is&nbsp;'true'. Since&nbsp;each&nbsp;input&nbsp;is&nbsp;either&nbsp;'true'&nbsp;or 'false',&nbsp;there&nbsp;are&nbsp;only&nbsp;four&nbsp;poss-<br>
ible input&nbsp;combinations, and&nbsp;the&nbsp;complete functionality&nbsp;of the gate&nbsp;can&nbsp;be&nbsp;expressed&nbsp;<br>
in a&nbsp;<b>truth table&nbsp;</b>as&nbsp;shown&nbsp;in&nbsp;Figure&nbsp;A.&nbsp;1,&nbsp;which&nbsp;also&nbsp;shows the&nbsp;logic&nbsp;symbol&nbsp;for&nbsp;an&nbsp;<br>
AND gate.&nbsp;An&nbsp;AND gate can&nbsp;be extended&nbsp;to&nbsp;more than&nbsp;two inputs&nbsp;(though current&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;A.1&nbsp; &nbsp;&nbsp;</b>The logic symbol and truth table for an AND&nbsp;gate.&nbsp;<br>
CMOS&nbsp;technology limits&nbsp;the practical&nbsp;<b>fan-in&nbsp;</b>to&nbsp;four&nbsp;inputs,&nbsp;reducing&nbsp;to&nbsp;three&nbsp;inputs&nbsp;<br>
on some&nbsp;sub-micron process technologies). The output is a&nbsp;'&nbsp;1'&nbsp;when all the inputs&nbsp;<br>
are T, and&nbsp;the&nbsp;output is&nbsp;'0'&nbsp;when&nbsp;at&nbsp;least one&nbsp;input is&nbsp;'0'.&nbsp;<br>
An OR gate is defined similarly, giving a&nbsp;'0'&nbsp;when all the inputs are&nbsp;'0'&nbsp;and a T&nbsp;<br>
when at&nbsp;least one input is a '&nbsp;1'. The logic symbol and&nbsp;truth&nbsp;table for a 2-input OR&nbsp;gate&nbsp;<br>
are shown in&nbsp;Figure A.2 on&nbsp;page&nbsp;400.&nbsp;<br>
A vital&nbsp;logic component is the inverter. This&nbsp;has one input&nbsp;and&nbsp;produces the oppo-<br>
site output.&nbsp;Its logic function is&nbsp;NOT.&nbsp;The output&nbsp;is&nbsp;false&nbsp;('0') if&nbsp;the&nbsp;input&nbsp;is&nbsp;true&nbsp;('!')&nbsp;<br>
and vice versa. An AND gate&nbsp;with&nbsp;an inverter on the&nbsp;output&nbsp;is a NAND (NOT AND)&nbsp;<br>
gate,&nbsp;and an&nbsp;OR&nbsp;gate&nbsp;with&nbsp;an&nbsp;inverter&nbsp;on the&nbsp;output&nbsp;is a&nbsp;NOR (NOT OR) gate.&nbsp;Inver-<br>
sion&nbsp;is often denoted by&nbsp;a circular&nbsp;'bubble'&nbsp;on&nbsp;the input&nbsp;or output&nbsp;of&nbsp;a&nbsp;gate.&nbsp;<br>
<b>399</b>&nbsp;<br>
<hr>
<A name=412></a><IMG src="index-412_1.png"><br>
<b>400</b>&nbsp;<br>
<b>Appendix:&nbsp;Computer&nbsp;Logic</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure A.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b>The&nbsp;logic symbol&nbsp;and truth table for&nbsp;an&nbsp;OR&nbsp;gate.&nbsp;<br>
In&nbsp;fact&nbsp;conventional&nbsp;simple&nbsp;CMOS&nbsp;gates&nbsp;are inherently inverting,&nbsp;so NAND is&nbsp;<br>
simpler than AND, the latter&nbsp;being&nbsp;formed&nbsp;by&nbsp;adding&nbsp;an&nbsp;inverter to&nbsp;the former, and&nbsp;<br>
similarly&nbsp;OR&nbsp;gates are formed&nbsp;from&nbsp;NOR&nbsp;gates by&nbsp;adding&nbsp;inverters.&nbsp;<br>
Boolean algebra&nbsp;<br>
All logic circuits&nbsp;can be&nbsp;constructed using&nbsp;only&nbsp;2-input NAND gates. This stems&nbsp;<br>
from&nbsp;the rules&nbsp;of Boolean algebra.&nbsp;First,&nbsp;observe that&nbsp;if&nbsp;both&nbsp;inputs&nbsp;of&nbsp;a&nbsp;NAND&nbsp;gate&nbsp;<br>
are&nbsp;connected&nbsp;to the&nbsp;same&nbsp;signal, the&nbsp;output&nbsp;is the inverse&nbsp;of the input,&nbsp;so&nbsp;we&nbsp;have&nbsp;<br>
an inverter.&nbsp;Next, connect&nbsp;an&nbsp;inverter to&nbsp;each input&nbsp;of&nbsp;a&nbsp;NAND&nbsp;gate.&nbsp;A&nbsp;brief&nbsp;exami-<br>
nation&nbsp;of&nbsp;the truth&nbsp;table&nbsp;reveals that the&nbsp;resulting circuit&nbsp;performs&nbsp;the OR&nbsp;function.&nbsp;<br>
Often&nbsp;logic equations are written&nbsp;using&nbsp;the notation&nbsp;of&nbsp;conventional&nbsp;arithmetic,&nbsp;<br>
using&nbsp;'•' for&nbsp;AND and '+' for OR.&nbsp;Thus&nbsp;<i>'A&nbsp;</i>AND&nbsp;&nbsp;<i>(B&nbsp;</i>OR&nbsp;Q'&nbsp;is written&nbsp;<i>'A-(B +&nbsp;</i>Q'.&nbsp;<br>
Logical&nbsp;inversion is&nbsp;denoted&nbsp;by&nbsp;an&nbsp;overbar:&nbsp;<i>'A&nbsp;</i>NAND&nbsp;5'&nbsp;is written&nbsp;<i>'A-B\&nbsp;</i>This&nbsp;nota-<br>
tion is&nbsp;very&nbsp;convenient&nbsp;provided that&nbsp;the context&nbsp;makes it&nbsp;clear that&nbsp;an equation is&nbsp;a&nbsp;<br>
Boolean logic&nbsp;equation where&nbsp;1 + 1&nbsp;= 1.&nbsp;<br>
Binary numbers&nbsp;<br>
Numbers&nbsp;are&nbsp;usually&nbsp;represented in&nbsp;computers in&nbsp;binary&nbsp;notation&nbsp;(there&nbsp;is&nbsp;a more&nbsp;<br>
complete&nbsp;discussion&nbsp;of&nbsp;data&nbsp;types and&nbsp;number representation in&nbsp;Section&nbsp;6.2&nbsp;on&nbsp;<br>
page 153).&nbsp;Here,&nbsp;instead of&nbsp;using&nbsp;the familiar base&nbsp;10&nbsp;number&nbsp;notation&nbsp;where&nbsp;each&nbsp;<br>
digit&nbsp;is&nbsp;in&nbsp;the range 0&nbsp;to&nbsp;9&nbsp;and&nbsp;positions have&nbsp;values which&nbsp;scale by&nbsp;powers&nbsp;of 10&nbsp;<br>
(units,&nbsp;tens, hundreds,...), binary&nbsp;numbers have&nbsp;digits which&nbsp;are&nbsp;either&nbsp;0&nbsp;or&nbsp;1&nbsp;and&nbsp;<br>
positions have values&nbsp;that&nbsp;scale by powers of&nbsp;2 (units, twos, fours, eights,&nbsp;<br>
six-teens,...).&nbsp;Since&nbsp;each&nbsp;binary digit (bit)&nbsp;is&nbsp;restricted&nbsp;to&nbsp;one&nbsp;of&nbsp;two values it can&nbsp;be&nbsp;<br>
represented by&nbsp;a Boolean value,&nbsp;and&nbsp;the&nbsp;complete&nbsp;binary&nbsp;number&nbsp;is represented by&nbsp;<br>
an ordered set&nbsp;of&nbsp;Boolean values.&nbsp;<br>
&nbsp;&nbsp;&nbsp;Binary addition&nbsp;&nbsp;The sum&nbsp;of&nbsp;two single-bit&nbsp;binary numbers can be formed&nbsp;using&nbsp;the logic gates we have&nbsp;<br>
met already.&nbsp;If&nbsp;both bits&nbsp;are zero the&nbsp;sum&nbsp;is&nbsp;zero;&nbsp;the sum&nbsp;of&nbsp;a one and a&nbsp;zero&nbsp;is&nbsp;one, but&nbsp;<br>
the&nbsp;sum&nbsp;of&nbsp;two ones is&nbsp;two,&nbsp;which&nbsp;is&nbsp;represented in&nbsp;binary&nbsp;notation&nbsp;by&nbsp;the two&nbsp;bits&nbsp;'&nbsp;10'.&nbsp;<br>
An adder for two single-bit&nbsp;inputs&nbsp;must&nbsp;therefore have two output&nbsp;bits:&nbsp;a&nbsp;sum&nbsp;bit&nbsp;with&nbsp;<br>
the same&nbsp;weight&nbsp;as&nbsp;the input&nbsp;bits&nbsp;and a carry&nbsp;bit&nbsp;which has twice&nbsp;that&nbsp;weight.&nbsp;<br>
<hr>
<A name=413></a><IMG src="index-413_1.png"><br>
<b>Appendix:&nbsp;Computer&nbsp;Logic</b>&nbsp;<br>
401&nbsp;<br>
If&nbsp;the inputs&nbsp;<i>are A&nbsp;</i>and&nbsp;<i>B,&nbsp;</i>the sum and carry are&nbsp;formed as follows:&nbsp;<br>
<i>sum &nbsp;&nbsp; =&nbsp;A-B+A-B&nbsp;</i><br>
Equation 18&nbsp;<br>
<i>carry&nbsp;= A-B</i>&nbsp;<br>
Equation 19&nbsp;<br>
The&nbsp;sum&nbsp;function&nbsp;arises&nbsp;frequently&nbsp;in&nbsp;digital&nbsp;logic&nbsp;and&nbsp;is&nbsp;called&nbsp;the&nbsp;<b>exclusive OR&nbsp;</b><br>
or&nbsp;XOR&nbsp;function. It&nbsp;is&nbsp;'exclusive'&nbsp;because&nbsp;it&nbsp;is&nbsp;true&nbsp;if&nbsp;<i>A&nbsp;</i>is&nbsp;true, or&nbsp;<i>B&nbsp;</i>is&nbsp;true,&nbsp;but&nbsp;not&nbsp;if&nbsp;<br>
they&nbsp;are&nbsp;both&nbsp;true.&nbsp;It&nbsp;has&nbsp;its own&nbsp;logic&nbsp;symbol&nbsp;which&nbsp;is&nbsp;shown&nbsp;in&nbsp;Figure&nbsp;A.3&nbsp;along&nbsp;<br>
with a&nbsp;(non-obvious)&nbsp;implementation&nbsp;which uses&nbsp;four&nbsp;NAND&nbsp;gates.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;A.3&nbsp; &nbsp;</b>The&nbsp;logic symbol and NAND circuit for an XOR gate.&nbsp;<br>
An&nbsp;adder&nbsp;for&nbsp;<i>N-bit&nbsp;</i>binary&nbsp;numbers&nbsp;can&nbsp;be&nbsp;constructed&nbsp;from single-bit&nbsp;adders, but&nbsp;<br>
all bits except the&nbsp;first may have to&nbsp;accept a&nbsp;carry&nbsp;input from&nbsp;the next&nbsp;lower stage.&nbsp;<br>
Each bit of the adder produces&nbsp;a&nbsp;sum and a carry-out from the inputs and the carry-in:&nbsp;<br>
<i>sum,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</i>=^4j-5j-Ci.1&nbsp;<i>+Ai-Bi-Ci.l&nbsp;+&nbsp;Ai-Bi-Ci.l+A^-B^C^&nbsp;</i><br>
Equation 20&nbsp;<br>
Q&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=y41-5i+/4i-Ci.i+5i-C1.1&nbsp;<br>
Equation&nbsp;21&nbsp;<br>
Here&nbsp;the&nbsp;equations&nbsp;apply&nbsp;for&nbsp;<i>i= 1 toN&nbsp;</i>and C0&nbsp;is&nbsp;zero.&nbsp;<br>
Multiplexers&nbsp;<br>
A common requirement in&nbsp;a processor implementation&nbsp;is to&nbsp;select the&nbsp;source of&nbsp;an&nbsp;<br>
operand from&nbsp;a&nbsp;number of&nbsp;alternative inputs&nbsp;on a&nbsp;cycle-by-cycle&nbsp;basis.&nbsp;The logic&nbsp;<br>
component that&nbsp;performs this&nbsp;function is a&nbsp;<b>multiplexer&nbsp;</b>(or simply&nbsp;a&nbsp;<b>'mux').&nbsp;A&nbsp;2-</b>&nbsp;<br>
input&nbsp;multiplexer&nbsp;has&nbsp;a&nbsp;Boolean&nbsp;<i>select&nbsp;</i>input&nbsp;<i>(S)&nbsp;</i>and&nbsp;two&nbsp;binary&nbsp;input&nbsp;values&nbsp;<i>A-t&nbsp;</i>and&nbsp;<br>
&lt;&nbsp;r&nbsp;&gt; .&nbsp;<br>
<i>BI,&nbsp;</i>where 1&nbsp;<i>&lt;i&lt;NandN&nbsp;</i>is the&nbsp;number of bits&nbsp;in each binary&nbsp;value. When&nbsp;5 is zero,&nbsp;<br>
.-• - -&nbsp;<br>
the&nbsp;output&nbsp;Z;&nbsp;should&nbsp;equal^j&nbsp;and&nbsp;when&nbsp;<i>S&nbsp;</i>is&nbsp;one&nbsp;<i>Z\&nbsp;</i>should equal&nbsp;<i>Br&nbsp;</i>This&nbsp;is&nbsp;a&nbsp;straight-&nbsp;<br>
forward&nbsp;logic&nbsp;function:&nbsp;<br>
Equation&nbsp;22&nbsp;<br>
<hr>
<A name=414></a><IMG src="index-414_1.png"><br>
<b>402</b>&nbsp;<br>
<b>Appendix:&nbsp;Computer&nbsp;Logic</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;Clocks&nbsp;<br>
Almost&nbsp;all&nbsp;processors are&nbsp;controlled&nbsp;by&nbsp;a&nbsp;free-running timing reference signal&nbsp;called&nbsp;<br>
a&nbsp;<b>clock.&nbsp;</b>(But&nbsp;not quite&nbsp;all; see&nbsp;Chapter 14&nbsp;on&nbsp;page&nbsp;374 for details of&nbsp;the AMULET&nbsp;<br>
processor cores that&nbsp;operate without&nbsp;any external timing reference signal). The&nbsp;<br>
clock controls the state&nbsp;changes within&nbsp;the processor.&nbsp;<br>
Generally, all the state&nbsp;is held&nbsp;within&nbsp;<b>registers.&nbsp;</b>During the clock cycle&nbsp;<b>combinato-</b><br>
<b>rial&nbsp;</b>logic (logic whose outputs depend&nbsp;only&nbsp;on the current&nbsp;input&nbsp;values) works out&nbsp;the&nbsp;<br>
next&nbsp;state values using Boolean logic gates&nbsp;as described&nbsp;above. At&nbsp;the end&nbsp;of the clock&nbsp;<br>
cycle&nbsp;the&nbsp;active&nbsp;clock&nbsp;edge causes all&nbsp;the registers&nbsp;to switch&nbsp;simultaneously&nbsp;to the next&nbsp;<br>
state. For&nbsp;maximum&nbsp;performance&nbsp;the clock frequency&nbsp;is set&nbsp;at&nbsp;the highest&nbsp;rate at&nbsp;<br>
which all&nbsp;the&nbsp;combinatorial&nbsp;logic can&nbsp;be&nbsp;guaranteed to&nbsp;complete, under&nbsp;worst-case&nbsp;<br>
conditions, in&nbsp;time&nbsp;for the next&nbsp;active clock edge.&nbsp;<br>
Sequential&nbsp;<br>
A register stores&nbsp;the state between active&nbsp;clock edges and changes&nbsp;its contents&nbsp;on&nbsp;<br>
circuits&nbsp;<br>
the active edge.&nbsp;It is a&nbsp;<b>sequential&nbsp;</b>logic&nbsp;circuit;&nbsp;its outputs&nbsp;depend&nbsp;not&nbsp;only on&nbsp;the&nbsp;<br>
current&nbsp;input values, but also&nbsp;on&nbsp;how&nbsp;they have&nbsp;changed&nbsp;in&nbsp;the past.&nbsp;<br>
The simplest sequential circuit is the R-S&nbsp;(Reset-Set) flip-flop. This is&nbsp;a circuit&nbsp;<br>
whose output&nbsp;is set&nbsp;high whenever the&nbsp;<i>Set&nbsp;</i>input is&nbsp;active&nbsp;and&nbsp;is&nbsp;reset&nbsp;low whenever the&nbsp;<br>
<i>Reset&nbsp;</i>input&nbsp;is&nbsp;active. If both&nbsp;inputs&nbsp;are active at&nbsp;the same&nbsp;time the flip-flop behaviour&nbsp;<br>
depends on the implementation;&nbsp;if&nbsp;both are inactive the flip-flop&nbsp;<i>remembers&nbsp;</i>the last&nbsp;<br>
state it&nbsp;was put&nbsp;into. An&nbsp;implementation&nbsp;of&nbsp;an&nbsp;R-S&nbsp;flip-flop&nbsp;using&nbsp;two&nbsp;NOR gates is&nbsp;<br>
shown&nbsp;in&nbsp;Figure&nbsp;A.4&nbsp;with&nbsp;its sequence table; this is&nbsp;no longer a simple&nbsp;truth&nbsp;table&nbsp;<br>
since the output&nbsp;is&nbsp;not&nbsp;a combinatorial&nbsp;function of&nbsp;the current&nbsp;input&nbsp;values.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;A.4&nbsp; &nbsp;</b>An R-S&nbsp;flip-flop circuit and&nbsp;sequence table.&nbsp;<br>
Transparent&nbsp;<br>
A&nbsp;transparent&nbsp;(or&nbsp;<b>D-type)&nbsp;</b>latch has a data&nbsp;input&nbsp;<i>(D)&nbsp;</i>and an enable&nbsp;signal&nbsp;<i>(En);&nbsp;</i>the&nbsp;output&nbsp;<br>
latches follows&nbsp;<br>
the&nbsp;<br>
<i>D&nbsp;</i>input whenever&nbsp;<i>En&nbsp;</i>is&nbsp;high, but remains&nbsp;constant&nbsp;at&nbsp;whatever&nbsp;value&nbsp;applied&nbsp;<br>
just before&nbsp;<i>En&nbsp;</i>went low&nbsp;while&nbsp;<i>En&nbsp;</i>stays&nbsp;low.&nbsp;This&nbsp;can&nbsp;be&nbsp;constructed&nbsp;from&nbsp;an&nbsp;R-S&nbsp;flip-flop&nbsp;<br>
by&nbsp;generating&nbsp;<i>R&nbsp;</i>and&nbsp;<i>S&nbsp;</i>from&nbsp;<i>D&nbsp;</i>and&nbsp;<i>En&nbsp;</i>as shown&nbsp;in&nbsp;Figure A.5&nbsp;on page&nbsp;403.&nbsp;<br>
<hr>
<A name=415></a><IMG src="index-415_1.png"><br>
<b>Appendix:&nbsp;Computer&nbsp;Logic</b>&nbsp;<br>
<b>403</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
&nbsp;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;<br>
<b>Figure&nbsp;A.5&nbsp; &nbsp;</b>A D-type transparent latch&nbsp;circuit and sequence table.&nbsp;<br>
In principle it&nbsp;should be possible to build&nbsp;any&nbsp;sequential circuit using&nbsp;a D-type&nbsp;<br>
latch&nbsp;provided the combinatorial logic between stages is&nbsp;slow&nbsp;enough. Applying a very&nbsp;<br>
short positive pulse to&nbsp;<i>En&nbsp;</i>will let the&nbsp;next&nbsp;state&nbsp;data through the latch and&nbsp;then hold&nbsp;it&nbsp;<br>
before&nbsp;the&nbsp;combinatorial&nbsp;logic&nbsp;has&nbsp;time&nbsp;to respond&nbsp;to&nbsp;the&nbsp;new&nbsp;values.&nbsp;However,&nbsp;in&nbsp;<br>
practice&nbsp;this turns out to&nbsp;be&nbsp;a&nbsp;very&nbsp;hard way to&nbsp;build&nbsp;a reliable&nbsp;circuit.&nbsp;<br>
Edge-triggered&nbsp;<br>
There&nbsp;are&nbsp;various ways&nbsp;to&nbsp;build more reliable&nbsp;latching&nbsp;circuits,&nbsp;most of which&nbsp;<br>
latches&nbsp;<br>
require&nbsp;each&nbsp;signal to pass through two&nbsp;transparent latches per&nbsp;clock cycle.&nbsp;In the&nbsp;<br>
simplest of&nbsp;these,&nbsp;the&nbsp;second&nbsp;latch is&nbsp;placed&nbsp;in&nbsp;series&nbsp;with&nbsp;the&nbsp;first&nbsp;and&nbsp;operates&nbsp;with&nbsp;<br>
the inverse enable function. At all times, one latch or the other is holding and the&nbsp;<br>
other is transparent. On one&nbsp;clock edge,&nbsp;where the&nbsp;first latch goes opaque and the&nbsp;<br>
second goes transparent, the&nbsp;input data value propagates through to&nbsp;the&nbsp;output.&nbsp;It is&nbsp;<br>
then held through the full&nbsp;cycle until the same&quot; edge in&nbsp;the following&nbsp;cycle. This&nbsp;is&nbsp;<br>
therefore an&nbsp;<b>edge-triggered latch;&nbsp;</b>its logic symbol, circuit and sequence table&nbsp;are&nbsp;<br>
shown in Figure A.6 on page 404. (In the table an 'x'&nbsp;in&nbsp;an input column&nbsp;indicates&nbsp;<br>
that the input has no effect on&nbsp;the output.)&nbsp;<br>
Edge-triggered&nbsp;latches&nbsp;require&nbsp;very&nbsp;careful&nbsp;design,&nbsp;since&nbsp;they&nbsp;are&nbsp;not&nbsp;simply&nbsp;com-<br>
binatorial&nbsp;logic&nbsp;circuits and&nbsp;their function&nbsp;depends critically&nbsp;on&nbsp;the&nbsp;dynamic properties&nbsp;<br>
of the circuit&nbsp;elements. If constructed,&nbsp;as&nbsp;suggested above, from&nbsp;two&nbsp;transparent&nbsp;<br>
latches&nbsp;in&nbsp;series, there are various&nbsp;<i>race&nbsp;conditions&nbsp;</i>which must&nbsp;be&nbsp;avoided.&nbsp;But, with&nbsp;<br>
good tools, reliable latches can&nbsp;be&nbsp;designed,&nbsp;and once a&nbsp;reliable&nbsp;latch is available,&nbsp;<br>
sequential circuits of arbitrary&nbsp;complexity&nbsp;can be&nbsp;constructed.&nbsp;<br>
Registers&nbsp;<br>
A set of edge-triggered (or equivalent) latches which&nbsp;jointly&nbsp;store the&nbsp;state of a&nbsp;<br>
binary value&nbsp;through a clock cycle is termed&nbsp;a&nbsp;<b>register.&nbsp;</b>A flexible&nbsp;form&nbsp;of&nbsp;register&nbsp;is&nbsp;<br>
connected&nbsp;to&nbsp;a free-running clock and&nbsp;has a&nbsp;'clock enable'&nbsp;control&nbsp;input so&nbsp;that con-<br>
trol logic can decide on&nbsp;a cycle-by-cycle&nbsp;basis whether&nbsp;or&nbsp;not&nbsp;to&nbsp;update&nbsp;the register's&nbsp;<br>
contents.&nbsp;A&nbsp;simple&nbsp;way&nbsp;to&nbsp;build&nbsp;such&nbsp;a&nbsp;register is to&nbsp;add a gate&nbsp;on the common&nbsp;clock&nbsp;<br>
<hr>
<A name=416></a><IMG src="index-416_1.png"><br>
<IMG src="index-416_2.png"><br>
<b>404</b>&nbsp;<br>
<b>Appendix:&nbsp;Computer&nbsp;Logic</b>&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;A.6&nbsp; &nbsp;</b>A D-type edge-triggered latch symbol, circuit and&nbsp;sequence&nbsp;table.&nbsp;<br>
line to the edge-triggered latches. If we&nbsp;use negative-edge triggered latches, an&nbsp;AND&nbsp;<br>
gate&nbsp;will remove the&nbsp;entire high-going&nbsp;clock pulse provided the&nbsp;enable input is low&nbsp;<br>
before the clock goes high and stays low until the clock has gone low again. (These&nbsp;<br>
are the&nbsp;<b>set-up and&nbsp;hold&nbsp;</b>conditions&nbsp;for the enable input.) If&nbsp;the&nbsp;enable&nbsp;is,&nbsp;itself, pro-<br>
duced from&nbsp;a&nbsp;similar register running off the same&nbsp;clock,&nbsp;it will&nbsp;meet these con-<br>
straints.&nbsp;The register&nbsp;circuit is shown&nbsp;in&nbsp;Figure&nbsp;A.7.&nbsp;<br>
&nbsp;<br>
<b>Figure&nbsp;A.7&nbsp; &nbsp;</b>A register&nbsp;with a clock enable control signal.<br>
<hr>
<A name=417></a>Glossary&nbsp;<br>
<b>ACM&nbsp;&nbsp;</b><i>Association&nbsp;for Computing&nbsp;Machinery;&nbsp;</i>the&nbsp;&nbsp;<b>ARM Limited&nbsp;</b>The company&nbsp;spun out from&nbsp;Acorn in&nbsp;<br>
American association&nbsp;for computing&nbsp;professionals.&nbsp;<br>
1990 to&nbsp;develop the&nbsp;ARM technology.&nbsp;Based in&nbsp;<br>
Cambridge,&nbsp;England,&nbsp;but&nbsp;with&nbsp;design&nbsp;and&nbsp;sales&nbsp;activities&nbsp;<br>
<b>Acorn Computers Limited&nbsp;</b>The&nbsp;UK&nbsp;company&nbsp;where&nbsp;&nbsp;in several&nbsp;world&nbsp;regions.&nbsp;<br>
the&nbsp;&nbsp;<i>ARM&nbsp;&nbsp;</i>processor was developed between 1983 and&nbsp;<br>
1985. Acorn also developed the&nbsp;<i>BBC&nbsp;&nbsp;</i>microcomputer,&nbsp;&nbsp;<b>ASCII&nbsp;&nbsp;</b><i>American Standard for Computer&nbsp;Information&nbsp;</i><br>
which&nbsp;established&nbsp;the&nbsp;wide&nbsp;spread&nbsp;educational&nbsp;use&nbsp;of&nbsp;&nbsp;<i>Interchange;&nbsp;&nbsp;</i>a&nbsp;standard way&nbsp;to&nbsp;represent&nbsp;printable&nbsp;and&nbsp;<br>
computers&nbsp;in&nbsp;the UK, and&nbsp;the Archimedes range&nbsp;of&nbsp;&nbsp;print&nbsp;control characters&nbsp;in&nbsp;7-bit&nbsp;binary&nbsp;numbers&nbsp;(often&nbsp;<br>
ARM-based computers which&nbsp;followed&nbsp;the&nbsp;BBC micro&nbsp;&nbsp;extended&nbsp;to&nbsp;8-bit&nbsp;fields&nbsp;in&nbsp;today's&nbsp;computers).&nbsp;<br>
into&nbsp;the schools&nbsp;market.&nbsp;<br>
<b>ASIC&nbsp;&nbsp;</b><i>Application-Specific Integrated&nbsp;Circuit;&nbsp;</i>a&nbsp;&nbsp;<i>VLSI&nbsp;</i><br>
<b>ADC&nbsp;&nbsp;</b><i>Analogue&nbsp;to Digital Converter,&nbsp;</i>an electronic cir-<br>
device&nbsp;designed for a particular&nbsp;application,&nbsp;usually for&nbsp;a&nbsp;<br>
cuit that takes an input which may&nbsp;vary&nbsp;continuously&nbsp;&nbsp;particular&nbsp;customer.&nbsp;<br>
within a specified range and&nbsp;converts it into&nbsp;an /z-bit&nbsp;<br>
binary number&nbsp;that approximates&nbsp;the&nbsp;input to&nbsp;one&nbsp;of 2&quot;&nbsp;&nbsp;<b>ASSP&nbsp;&nbsp;</b><i>Application-Specific Standard&nbsp;Pan;&nbsp;</i>a&nbsp;&nbsp;<i>VLSI&nbsp;</i><br>
discrete&nbsp;values&nbsp;within&nbsp;that&nbsp;range.&nbsp;<br>
device&nbsp;designed&nbsp;for a&nbsp;particular application&nbsp;that&nbsp;is&nbsp;sold&nbsp;as&nbsp;<br>
a standard&nbsp;component by&nbsp;the&nbsp;semiconductor&nbsp;manufac-<br>
<b>ALL)&nbsp;</b><i>Arithmetic-Logic Unit;&nbsp;</i>the component in&nbsp;a proces-<br>
turer. Often&nbsp;the&nbsp;chip will have&nbsp;been developed as an&nbsp;<i>ASIC,&nbsp;</i><br>
sor&nbsp;that&nbsp;performs the&nbsp;arithmetic&nbsp;(addition,&nbsp;subtraction,&nbsp;and&nbsp;&nbsp;but&nbsp;then&nbsp;in&nbsp;response&nbsp;to&nbsp;market&nbsp;demand&nbsp;the manufacturer&nbsp;<br>
sometimes including multiplication and division) and&nbsp;&nbsp;will have&nbsp;come&nbsp;to an agreement with the original cus-<br>
logic&nbsp;(shift, bit-wise AND, and&nbsp;so on)&nbsp;operations.&nbsp;<br>
tomer to make the chip&nbsp;available&nbsp;to&nbsp;other customers.&nbsp;<br>
<b>AMBA&nbsp;&nbsp;</b><i>Advanced Microcontroller Bus&nbsp;Architecture;&nbsp;</i>an&nbsp;&nbsp;<b>BBC&nbsp;&nbsp;</b>The&nbsp;&nbsp;<i>British Broadcasting Corporation;&nbsp;</i>the UK&nbsp;<br>
open standard&nbsp;for an&nbsp;on-chip&nbsp;bus&nbsp;which&nbsp;connects the&nbsp;vari-<br>
public&nbsp;service&nbsp;radio&nbsp;and&nbsp;television&nbsp;broadcasting&nbsp;company.&nbsp;<br>
ous&nbsp;modules used to build a&nbsp;complex embedded&nbsp;system&nbsp;&nbsp;The BBC is&nbsp;funded mainly&nbsp;through licence&nbsp;fees&nbsp;which are&nbsp;<br>
chip.&nbsp;<br>
a compulsory&nbsp;feature&nbsp;of&nbsp;television ownership&nbsp;in&nbsp;the&nbsp;UK.&nbsp;<br>
Their charter includes&nbsp;a&nbsp;duty&nbsp;to&nbsp;educate&nbsp;the&nbsp;public, and&nbsp;in&nbsp;<br>
<b>AMULET&nbsp;</b><br>
<i>Asynchronous Microprocessor&nbsp;Using&nbsp;</i>1982&nbsp;they&nbsp;produced&nbsp;a popular&nbsp;series&nbsp;called&nbsp;'The&nbsp;Compu-<br>
<i>Low-Energy Technology;&nbsp;</i>this&nbsp;term&nbsp;is&nbsp;used&nbsp;to&nbsp;describe&nbsp;&nbsp;ter Programme' based around the BBC&nbsp;micro which was&nbsp;<br>
the&nbsp;prototype asynchronous&nbsp;implementations of&nbsp;the&nbsp;<i>ARM&nbsp;&nbsp;</i>commissioned&nbsp;for the series.&nbsp;<br>
architecture&nbsp;developed&nbsp;at the&nbsp;University&nbsp;of Manchester.&nbsp;<br>
<b>BCD&nbsp;&nbsp;</b><i>Binary&nbsp;Coded&nbsp;Decimal;&nbsp;</i>a&nbsp;way&nbsp;to represent a&nbsp;<br>
<b>ANSI&nbsp;&nbsp;</b><i>American&nbsp;National&nbsp;Standards&nbsp;Institute;&nbsp;</i>the&nbsp;&nbsp;number&nbsp;by&nbsp;encoding&nbsp;each&nbsp;decimal digit as&nbsp;its&nbsp;binary&nbsp;<br>
American standards&nbsp;body that&nbsp;has defined&nbsp;many useful&nbsp;&nbsp;equivalent.&nbsp;<br>
conventions&nbsp;which&nbsp;are widely&nbsp;used&nbsp;in computing, for&nbsp;<br>
example&nbsp;<i>ASCII&nbsp;</i>and ANSI standard C.&nbsp;<br>
<b>BCS&nbsp;</b>The&nbsp;<i>British&nbsp;Computer&nbsp;Society;&nbsp;</i>the UK association&nbsp;<br>
<b>APCS&nbsp;</b><i>ARM Procedure Call&nbsp;Standard;&nbsp;</i>a calling&nbsp;conven-<br>
for computing&nbsp;professionals.&nbsp;<br>
tion&nbsp;defined by&nbsp;ARM Limited to allow&nbsp;procedures gener-<br>
C The&nbsp;<i>C&nbsp;&nbsp;</i>programming language,&nbsp;widely&nbsp;used&nbsp;for&nbsp;<br>
ated by different compilers (or written in&nbsp;assembly&nbsp;&nbsp;general-purpose&nbsp;and embedded system&nbsp;development.&nbsp;<br>
language)&nbsp;to&nbsp;call&nbsp;each&nbsp;other.&nbsp;<br>
CAM&nbsp;&nbsp;<i>Content Addressable Memory;&nbsp;</i>this is memory&nbsp;<br>
ARM Formerly&nbsp;<i>Advanced RISC&nbsp;Machine&nbsp;</i>(and&nbsp;before&nbsp;&nbsp;which contains&nbsp;a number of different data items and is&nbsp;<br>
that&nbsp;<i>Acorn RISC Machine),&nbsp;</i>but the acronym&nbsp;expansion&nbsp;&nbsp;accessed&nbsp;by&nbsp;presenting&nbsp;a data&nbsp;value which is&nbsp;compared&nbsp;<br>
has now&nbsp;been&nbsp;formally&nbsp;abandoned; a&nbsp;32-bit&nbsp;microproces-<br>
with&nbsp;all&nbsp;the&nbsp;stored&nbsp;items&nbsp;to&nbsp;see&nbsp;if&nbsp;there&nbsp;is a&nbsp;match.&nbsp;If&nbsp;there&nbsp;<br>
sor&nbsp;based on&nbsp;<i>RISC&nbsp;</i>design&nbsp;principles.&nbsp;<br>
is&nbsp;a&nbsp;match,&nbsp;the&nbsp;address of&nbsp;the&nbsp;matched location&nbsp;is output;&nbsp;<br>
<b>405</b>&nbsp;<br>
<hr>
<A name=418></a><b>406</b>&nbsp;<br>
<b>Glossary</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;otherwise the CAM signals&nbsp;a&nbsp;'miss'. It is&nbsp;also described as&nbsp;&nbsp;capacitor&nbsp;and&nbsp;leaks&nbsp;away&nbsp;in&nbsp;a&nbsp;few milliseconds&nbsp;(hence&nbsp;<br>
<i>associative memory,&nbsp;</i>and&nbsp;is an&nbsp;important component of&nbsp;an&nbsp;&nbsp;<i>dynamic);&nbsp;</i>to&nbsp;store for longer periods&nbsp;the DRAM&nbsp;must be&nbsp;<br>
associative cache&nbsp;or&nbsp;<i>TLB.</i>&nbsp;<br>
<i>refreshed&nbsp;</i>periodically, which means it&nbsp;must be read&nbsp;while&nbsp;<br>
it is&nbsp;still&nbsp;valid&nbsp;and then&nbsp;rewritten&nbsp;to restore the full&nbsp;charge.&nbsp;<br>
<b>CISC&nbsp;&nbsp;</b><i>Complex Instruction Set&nbsp;Computer,&nbsp;</i>a term&nbsp;cre-<br>
ated&nbsp;at the same&nbsp;time as&nbsp;<i>RISC&nbsp;</i>to&nbsp;describe&nbsp;earlier&nbsp;architec-<br>
<b>DSP&nbsp;</b><i>Digital Signal&nbsp;Processor;&nbsp;</i>a programmable&nbsp;processor&nbsp;<br>
tures that do not have the characteristics of RISCs.&nbsp;&nbsp;whose organization&nbsp;is optimized towards processing&nbsp;<br>
Typically a&nbsp;CISC&nbsp;has&nbsp;a variable&nbsp;instruction&nbsp;length mini-<br>
continuous&nbsp;streams&nbsp;of&nbsp;digital data. This&nbsp;should&nbsp;be&nbsp;con-<br>
computer&nbsp;style instruction set with many&nbsp;addressing&nbsp;&nbsp;trasted&nbsp;with&nbsp;a general-purpose&nbsp;processor such&nbsp;as the&nbsp;<i>ARM&nbsp;</i><br>
modes,&nbsp;memory-to-memory&nbsp;operations&nbsp;and&nbsp;support for&nbsp;&nbsp;that&nbsp;is optimized&nbsp;for&nbsp;control&nbsp;(decision making) operations.&nbsp;<br>
many&nbsp;data types.&nbsp;<br>
<b>EDO&nbsp;</b><i>Extended&nbsp;Data&nbsp;Out;&nbsp;</i>a particular&nbsp;interface&nbsp;standard&nbsp;<br>
<b>CMOS&nbsp;&nbsp;</b><i>Complementary Metal Oxide Semiconductor,&nbsp;&nbsp;</i>for&nbsp;<i>DRAM&nbsp;</i>memory&nbsp;that&nbsp;allows high-performance&nbsp;memory&nbsp;<br>
the predominant technology&nbsp;used for modern integrated&nbsp;&nbsp;systems to be&nbsp;built.&nbsp;<br>
circuits,&nbsp;CMOS&nbsp;combines&nbsp;<i>NMOS&nbsp;&nbsp;</i>and&nbsp;&nbsp;<i>PMOS&nbsp;&nbsp;</i>field-effect&nbsp;<br>
transistors on&nbsp;the&nbsp;same&nbsp;chip.&nbsp;This&nbsp;gives the&nbsp;technology&nbsp;&nbsp;<b>EEPROM&nbsp;&nbsp;</b>(also E2PROM.)&nbsp;&nbsp;<i>Electrically Erasable and&nbsp;</i><br>
active signal drive in both directions, hence fast&nbsp;switching,&nbsp;&nbsp;<i>Programmable Read Only Memory;&nbsp;</i>a&nbsp;&nbsp;<i>ROM&nbsp;&nbsp;</i>that can&nbsp;be&nbsp;<br>
and near&nbsp;zero&nbsp;power dissipation&nbsp;when it is not switching.&nbsp;<br>
programmed&nbsp;and erased&nbsp;by&nbsp;applying&nbsp;suitable&nbsp;electrical&nbsp;<br>
signals.&nbsp;Similar&nbsp;<i>to flash&nbsp;</i>memory,&nbsp;but uses&nbsp;a different tech-<br>
<b>Codec&nbsp;&nbsp;</b><i>Coder-decoder;&nbsp;&nbsp;</i>an electronic system&nbsp;that con-<br>
nology&nbsp;and&nbsp;is generally&nbsp;less flexible&nbsp;than flash.&nbsp;<br>
verts an input (for example an analogue speech signal)&nbsp;<br>
into&nbsp;a digitally&nbsp;encoded&nbsp;form&nbsp;and can&nbsp;also&nbsp;reverse&nbsp;this&nbsp;&nbsp;<b>EPLD&nbsp;&nbsp;</b><i>Electrically-Programmable Logic&nbsp;Device;&nbsp;</i>a&nbsp;<br>
conversion.&nbsp;The&nbsp;same term can also&nbsp;be&nbsp;used for a&nbsp;&nbsp;general-purpose logic&nbsp;chip&nbsp;which&nbsp;has&nbsp;a large&nbsp;number&nbsp;of&nbsp;<br>
<i>compressor-decompressor.</i>&nbsp;<br>
gates&nbsp;whose connectivity is&nbsp;defined by&nbsp;the state&nbsp;of on-chip&nbsp;<br>
memory&nbsp;cells. These&nbsp;cells&nbsp;may&nbsp;be reprogrammed to&nbsp;<br>
<b>CPI&nbsp;&nbsp;</b><i>Cycles&nbsp;Per Instruction;&nbsp;</i>a measure of processor effi-<br>
change the logic function&nbsp;of&nbsp;the device. (See&nbsp;also&nbsp;<i>FPGA,&nbsp;</i><br>
ciency&nbsp;based on&nbsp;the number of&nbsp;clock cycles divided by&nbsp;the&nbsp;&nbsp;which is&nbsp;a one-time configurable&nbsp;device.)&nbsp;<br>
number of instructions in&nbsp;a&nbsp;typical code&nbsp;sequence.&nbsp;<br>
EPROM&nbsp;&nbsp;<i>Electrically-Programmable Read Only Mem-</i><br>
<b>CPSR&nbsp;</b><i>Current Program&nbsp;Status&nbsp;Register;&nbsp;</i>an&nbsp;<i>ARM&nbsp;</i>regis-<br>
<i>ory;&nbsp;</i>a&nbsp;<i>ROM&nbsp;</i>which can be&nbsp;programmed&nbsp;by&nbsp;applying&nbsp;suit-<br>
ter&nbsp;which&nbsp;contains&nbsp;the condition&nbsp;code bits,&nbsp;interrupt&nbsp;disa-<br>
able&nbsp;electrical&nbsp;signals.&nbsp;Usually&nbsp;it&nbsp;can&nbsp;be&nbsp;erased&nbsp;using&nbsp;an&nbsp;<br>
ble flags&nbsp;and processor operating&nbsp;mode bits.&nbsp;<br>
ultra-violet&nbsp;light&nbsp;source and&nbsp;reprogrammed many&nbsp;times.&nbsp;<br>
<b>CPU&nbsp;</b>The&nbsp;<i>Central Processing Unit;&nbsp;</i>a term&nbsp;used&nbsp;somewhat&nbsp;&nbsp;<b>Flash&nbsp;&nbsp;</b>A form&nbsp;of&nbsp;electrically&nbsp;programmable read&nbsp;only&nbsp;<br>
imprecisely&nbsp;to refer to the processor in&nbsp;a computer. It&nbsp;might&nbsp;&nbsp;memory&nbsp;that&nbsp;can&nbsp;be erased and&nbsp;reprogrammed electroni-<br>
be just the integer core, or it&nbsp;might&nbsp;include the on-chip&nbsp;<i>MMU&nbsp;&nbsp;</i>cally.&nbsp;It&nbsp;is widely&nbsp;used&nbsp;to&nbsp;store infrequently&nbsp;changing pro-<br>
and cache, and&nbsp;possibly&nbsp;the main&nbsp;memory&nbsp;as&nbsp;well. In this&nbsp;&nbsp;grams and data&nbsp;in portable systems,&nbsp;and&nbsp;increasingly&nbsp;used&nbsp;<br>
book its use is restricted to&nbsp;those processor&nbsp;cores that&nbsp;&nbsp;as a&nbsp;form of non-volatile file store.&nbsp;<br>
include cache memory, and it is&nbsp;used&nbsp;to describe the system&nbsp;<br>
comprising the processor, cache and MMU (if&nbsp;present).&nbsp;<br>
<b>FPA&nbsp;&nbsp;</b><i>Floating-Point Accelerator;&nbsp;</i>additional hardware to&nbsp;<br>
speed up floating-point operations, for&nbsp;example, the ARM&nbsp;<br>
DAC&nbsp;<i>Digital-to-Analogue Converter;&nbsp;</i>an electronic circuit&nbsp;&nbsp;FPA10.&nbsp;<br>
that converts&nbsp;a digital&nbsp;signal, usually&nbsp;presented&nbsp;in&nbsp;binary&nbsp;&nbsp;<b>FPASC&nbsp;&nbsp;</b><i>Floating-Point Accelerator Support Code;&nbsp;</i>the&nbsp;<br>
form on&nbsp;<i>n&nbsp;</i>wires,&nbsp;into an analogue&nbsp;signal&nbsp;presented as&nbsp;one&nbsp;&nbsp;software&nbsp;that&nbsp;is&nbsp;run in an&nbsp;<i>ARM&nbsp;</i>system&nbsp;which&nbsp;includes&nbsp;an&nbsp;<br>
of 2&quot; values on&nbsp;a single wire.&nbsp;<br>
FPA 10 floating-point accelerator. The FPA&nbsp;10 implements&nbsp;<br>
<b>DECT&nbsp;&nbsp;</b><i>Digital European&nbsp;Cordless&nbsp;Telephone;&nbsp;</i>a Euro-<br>
a subset of the ARM&nbsp;floating-point instruction set&nbsp;in&nbsp;<br>
pean&nbsp;standard&nbsp;for&nbsp;cordless&nbsp;telephones&nbsp;where speech&nbsp;is&nbsp;&nbsp;hardware,&nbsp;and&nbsp;requires&nbsp;the&nbsp;FPASC to&nbsp;handle&nbsp;the&nbsp;remain-<br>
transferred&nbsp;in digital&nbsp;form&nbsp;between the handset&nbsp;and a local&nbsp;&nbsp;ing&nbsp;instructions.&nbsp;<br>
base-station&nbsp;through a radio&nbsp;link.&nbsp;<br>
<b>FPE&nbsp;</b><i>Floating-Point Emulator;&nbsp;</i>the software which&nbsp;is&nbsp;run&nbsp;<br>
<b>DRAM&nbsp;&nbsp;</b><i>Dynamic Random&nbsp;Access&nbsp;Memory;&nbsp;</i>the lowest&nbsp;&nbsp;in&nbsp;<i>an ARM&nbsp;</i>system which does not include an FPA 10 float-<br>
price per bit&nbsp;form of&nbsp;<i>RAM,&nbsp;</i>used as&nbsp;the&nbsp;main memory&nbsp;in&nbsp;&nbsp;ing-point accelerator to&nbsp;support the&nbsp;ARM&nbsp;floating-point&nbsp;<br>
most&nbsp;computer&nbsp;systems.&nbsp;The&nbsp;data&nbsp;is&nbsp;stored&nbsp;as&nbsp;charge&nbsp;on&nbsp;a&nbsp;<br>
instruction&nbsp;set.&nbsp;<br>
<hr>
<A name=419></a><b>Glossary</b>&nbsp;<br>
<b>407</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<b>FPGA&nbsp;&nbsp;</b><i>Field-Programmable Gate Array;&nbsp;</i>a&nbsp;&nbsp;<b>ISDN&nbsp;&nbsp;</b><i>Integrated Services&nbsp;Digital&nbsp;Network;&nbsp;</i>an&nbsp;interna-<br>
general-purpose&nbsp;logic chip&nbsp;which has a large&nbsp;number of&nbsp;&nbsp;tional standard&nbsp;for&nbsp;digital telephony&nbsp;where&nbsp;speech&nbsp;is&nbsp;sent&nbsp;<br>
gates&nbsp;whose connectivity&nbsp;is&nbsp;defined by&nbsp;the state of&nbsp;&nbsp;as&nbsp;a 64 Kbit/s&nbsp;data stream.&nbsp;The&nbsp;standard also defines con-<br>
one-time&nbsp;programmable on-chip components&nbsp;such&nbsp;as&nbsp;&nbsp;trol protocols.&nbsp;<br>
anti-fuses.&nbsp;(See also&nbsp;<i>EPLD,&nbsp;&nbsp;</i>which is&nbsp;a&nbsp;reprogrammable&nbsp;&nbsp;<b>JTAG&nbsp;&nbsp;</b><i>Joint&nbsp;Test Action Group;&nbsp;</i>the committee which&nbsp;<br>
device.)&nbsp;<br>
defined&nbsp;the test standard&nbsp;based&nbsp;on&nbsp;a serial interface which&nbsp;<br>
<b>FPSR&nbsp;&nbsp;</b><i>Floating-Point Status&nbsp;Register,&nbsp;</i>a user-visible&nbsp;reg-<br>
is used on&nbsp;many&nbsp;ARM chips.&nbsp;<br>
ister in the&nbsp;<i>ARM&nbsp;</i>floating-point architecture which controls&nbsp;&nbsp;<b>LCD.&nbsp;&nbsp;</b><i>Liquid Crystal&nbsp;Display;&nbsp;</i>the&nbsp;display&nbsp;technology&nbsp;<br>
various options&nbsp;and&nbsp;indicates&nbsp;error&nbsp;conditions.&nbsp;<br>
favoured&nbsp;for most&nbsp;portable&nbsp;applications&nbsp;such&nbsp;as&nbsp;lap-top&nbsp;com-<br>
<b>FPU&nbsp;&nbsp;</b><i>Floating-Point Unit;&nbsp;</i>the component in a processor&nbsp;&nbsp;puters and&nbsp;<i>PDAs&nbsp;</i>due to its low weight and power consumption.&nbsp;<br>
that carries out the floating-point operations.&nbsp;<br>
<b>LRU&nbsp;&nbsp;</b><i>Least-Recently Used;&nbsp;</i>this&nbsp;term&nbsp;describes an&nbsp;algo-<br>
rithm for&nbsp;choosing which&nbsp;value&nbsp;in&nbsp;an&nbsp;associative cache or&nbsp;<br>
<b>FSM&nbsp;</b><i>Finite&nbsp;State Machine;&nbsp;</i>a&nbsp;sequential digital&nbsp;circuit that&nbsp;&nbsp;<i>TLB&nbsp;</i>to evict&nbsp;in&nbsp;order to&nbsp;make&nbsp;room&nbsp;for a new value.&nbsp;<br>
has an internal&nbsp;state and whose&nbsp;outputs and next&nbsp;state are&nbsp;<br>
combinatorial logic functions&nbsp;of&nbsp;its inputs&nbsp;and current&nbsp;state.&nbsp;<br>
<b>MFLOPS&nbsp;&nbsp;</b><i>Millions of&nbsp;Floating-Point Operations&nbsp;Per&nbsp;</i><br>
<i>Second;&nbsp;&nbsp;</i>a measure of the performance of a computer&nbsp;<br>
<b>GSM&nbsp;</b><i>Global System&nbsp;for&nbsp;Mobile communications;&nbsp;</i>a dig-<br>
when executing&nbsp;floating-point operations.&nbsp;<br>
ital standard&nbsp;for&nbsp;mobile telephony&nbsp;used&nbsp;throughout Europe&nbsp;<br>
and&nbsp;Asia and in other&nbsp;world&nbsp;regions.&nbsp;<br>
<b>MIPS&nbsp;</b><i>Millions of Instructions&nbsp;Per&nbsp;Second;&nbsp;</i>a measure&nbsp;of&nbsp;<br>
the rate&nbsp;at&nbsp;which a processor can execute&nbsp;its&nbsp;own instruc-<br>
<b>1C&nbsp;&nbsp;</b><i>Integrated&nbsp;Circuit;&nbsp;</i>a semiconductor device&nbsp;where&nbsp;&nbsp;tions. Since different instruction sets have&nbsp;different&nbsp;<br>
several&nbsp;(up&nbsp;to&nbsp;several&nbsp;million)&nbsp;transistors have been&nbsp;&nbsp;semantic&nbsp;content per&nbsp;instruction,&nbsp;comparing&nbsp;two proces-<br>
printed&nbsp;during&nbsp;the same manufacturing&nbsp;process. An 1C&nbsp;is&nbsp;&nbsp;sors on&nbsp;the&nbsp;basis of&nbsp;their&nbsp;native&nbsp;MIPS&nbsp;rating&nbsp;is&nbsp;meaning-<br>
sometimes referred&nbsp;to&nbsp;as&nbsp;a 'chip'.&nbsp;<br>
less. Benchmark programs attempt to provide&nbsp;a&nbsp;basis for&nbsp;<br>
<b>IDE&nbsp;</b><i>Integrated Drive&nbsp;Electronics;&nbsp;</i>an interface for a hard&nbsp;&nbsp;valid&nbsp;comparison, and&nbsp;'Dhrystone MIPS'&nbsp;is&nbsp;a normalized&nbsp;<br>
disk drive&nbsp;where&nbsp;all&nbsp;the&nbsp;intelligence&nbsp;is&nbsp;in&nbsp;the&nbsp;drive&nbsp;elec-<br>
rating&nbsp;that&nbsp;is&nbsp;(arguably) more&nbsp;valid.&nbsp;<br>
tronics&nbsp;and the host computer&nbsp;interface&nbsp;comprises&nbsp;a&nbsp;data&nbsp;&nbsp;<b>MMU&nbsp;&nbsp;</b><i>Memory&nbsp;Management&nbsp;Unit;&nbsp;</i>the part of&nbsp;the&nbsp;pro-<br>
bus and a few&nbsp;address lines.&nbsp;<br>
cessor that&nbsp;translates&nbsp;the&nbsp;virtual&nbsp;address into&nbsp;the&nbsp;physical&nbsp;<br>
address,&nbsp;using&nbsp;page tables&nbsp;in&nbsp;memory. It&nbsp;includes the&nbsp;<br>
<b>IEE&nbsp;</b>The&nbsp;<i>Institution&nbsp;of&nbsp;Electrical&nbsp;Engineers;&nbsp;</i>the UK pro-<br>
table-walking&nbsp;hardware&nbsp;and the&nbsp;<i>TLB.</i>&nbsp;<br>
fessional&nbsp;association for electronics&nbsp;(and&nbsp;electrical) engi-<br>
neers.&nbsp;The&nbsp;IEE sponsors&nbsp;colloquia and&nbsp;publishes journals&nbsp;&nbsp;<b>Modem&nbsp;&nbsp;</b><i>Modulator-demodulator;&nbsp;&nbsp;</i>an&nbsp;electronic system&nbsp;<br>
in the computing&nbsp;area.&nbsp;<br>
or subsystem that converts digital data into a form that&nbsp;can&nbsp;<br>
be sent (for&nbsp;example) over&nbsp;a&nbsp;conventional voice telephone&nbsp;<br>
<b>IEEE&nbsp;&nbsp;</b>The&nbsp;&nbsp;<i>Institute of Electrical&nbsp;and&nbsp;Electronics&nbsp;Engi-</i><br>
connection, and&nbsp;can recover digital data from&nbsp;a similar&nbsp;<br>
<i>neers,&nbsp;Inc.;&nbsp;</i>the&nbsp;American professional association for elec-<br>
received audio signal.&nbsp;Simple&nbsp;modems use one audio fre-<br>
tronics&nbsp;and electrical engineers.&nbsp;Membership is&nbsp;not&nbsp;restricted&nbsp;&nbsp;quency&nbsp;for a 0&nbsp;and&nbsp;a different&nbsp;frequency&nbsp;for&nbsp;a 1, but&nbsp;<br>
to US nationals,&nbsp;and the IEEE&nbsp;is very&nbsp;active in sponsoring&nbsp;&nbsp;today's&nbsp;high-speed modems use much more sophisticated&nbsp;<br>
international&nbsp;conferences and&nbsp;publishing&nbsp;journals in&nbsp;the&nbsp;&nbsp;modulation techniques.&nbsp;<br>
computing area, often in collaboration with the/4CM.&nbsp;<br>
<b>NMOS&nbsp;&nbsp;</b><i>N-type&nbsp;Metal Oxide Semiconductor;&nbsp;</i>a semicon-<br>
<b>I2C&nbsp;&nbsp;</b><i>Inter-IC;&nbsp;&nbsp;</i>a&nbsp;serial&nbsp;bus&nbsp;standard used to connect /Cs&nbsp;&nbsp;ductor technology&nbsp;that pre-dates&nbsp;<i>CMOS&nbsp;&nbsp;</i>that was&nbsp;used to&nbsp;<br>
together&nbsp;on&nbsp;a printed&nbsp;circuit board. It is particularly&nbsp;useful&nbsp;&nbsp;build&nbsp;some 8-&nbsp;and&nbsp;16-bit&nbsp;microprocessors. It supports&nbsp;a&nbsp;<br>
for connecting small&nbsp;<i>CMOS RAMs&nbsp;</i>and&nbsp;<i>RTC&nbsp;</i>chips&nbsp;that are&nbsp;&nbsp;logic family&nbsp;with&nbsp;active pull-down and&nbsp;passive&nbsp;pull-up&nbsp;<br>
powered up even&nbsp;when&nbsp;the rest&nbsp;of the system&nbsp;is&nbsp;switched&nbsp;off.&nbsp;<br>
outputs, and gates&nbsp;with&nbsp;a low&nbsp;output&nbsp;draw&nbsp;current even&nbsp;<br>
when&nbsp;not switching. NMOS&nbsp;transistors&nbsp;are&nbsp;used, with&nbsp;<br>
<b>I/O&nbsp;&nbsp;</b><i>Input/Output;&nbsp;&nbsp;</i>the activity&nbsp;of&nbsp;transferring data&nbsp;&nbsp;<i>PMOS&nbsp;</i>transistors,&nbsp;to form CMOS.&nbsp;NMOS transistors are&nbsp;<br>
between the computer&nbsp;and&nbsp;its environment through a&nbsp;&nbsp;more effective&nbsp;than PMOS transistors, which is why&nbsp;<br>
peripheral device.&nbsp;<br>
NMOS superseded PMOS as&nbsp;the technology&nbsp;of&nbsp;choice&nbsp;for&nbsp;<br>
<b>IrDA&nbsp;&nbsp;</b><i>Infra-red Data Association;&nbsp;</i>an organization estab-<br>
microprocessors, but&nbsp;the&nbsp;combination&nbsp;of&nbsp;the&nbsp;two&nbsp;in&nbsp;<br>
lished&nbsp;to&nbsp;standardize infra-red communication protocols&nbsp;&nbsp;CMOS, though more complex to manufacture,&nbsp;is greatly&nbsp;<br>
across the industry,&nbsp;the acronym is frequently&nbsp;applied to a&nbsp;&nbsp;superior to either in both speed and power-efficiency.&nbsp;<br>
system&nbsp;interface&nbsp;that complies&nbsp;with&nbsp;the resulting&nbsp;standards.&nbsp;<br>
<hr>
<A name=420></a><b>408</b>&nbsp;<br>
<b>Glossary</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;<b>OS&nbsp;</b><i>Operating System;&nbsp;</i>the central code&nbsp;in a&nbsp;system&nbsp;that&nbsp;&nbsp;write memory&nbsp;used&nbsp;to&nbsp;store&nbsp;programs&nbsp;and&nbsp;data&nbsp;in&nbsp;a&nbsp;com-<br>
manages&nbsp;the application code,&nbsp;handling scheduling,&nbsp;&nbsp;puter;&nbsp;the&nbsp;term&nbsp;is&nbsp;also&nbsp;used&nbsp;to&nbsp;describe&nbsp;the&nbsp;semiconductor&nbsp;<br>
resource&nbsp;allocation, protection,&nbsp;and so&nbsp;on.&nbsp;<br>
components&nbsp;used&nbsp;to&nbsp;build&nbsp;this&nbsp;memory and&nbsp;also&nbsp;used&nbsp;in&nbsp;<br>
structures&nbsp;such as&nbsp;caches and&nbsp;<i>TLBs.</i>&nbsp;<br>
<b>PC&nbsp;&nbsp;</b><i>Program Counter;&nbsp;</i>the register in a processor that&nbsp;<br>
holds the address of the next instruction to be fetched. Usu-<br>
<b>RISC&nbsp;&nbsp;</b><i>Reduced&nbsp;Instruction&nbsp;Set Computer;&nbsp;</i>a&nbsp;processor&nbsp;<br>
ally&nbsp;the context should&nbsp;differentiate&nbsp;this&nbsp;use from&nbsp;the next.&nbsp;<br>
with&nbsp;an&nbsp;architecture&nbsp;with&nbsp;certain&nbsp;characteristics based&nbsp;<br>
<b>PC&nbsp;&nbsp;</b><i>Personal Computer;&nbsp;</i>although apparently&nbsp;generic,&nbsp;&nbsp;on ideas expounded around 1980 by Patterson (U.C.&nbsp;<br>
Berkeley), Ditzel (Bell&nbsp;Laboratories) and Hennessy&nbsp;<br>
this&nbsp;term&nbsp;is now&nbsp;used&nbsp;to&nbsp;refer to&nbsp;desktop&nbsp;computers&nbsp;which&nbsp;&nbsp;(Stanford University).&nbsp;<br>
are compatible with the IBM PC, which means,&nbsp;<i>inter alia,&nbsp;</i><br>
that&nbsp;they&nbsp;use&nbsp;a processor with&nbsp;the Intel x86 instruction&nbsp;set&nbsp;&nbsp;<b>ROM&nbsp;&nbsp;</b><i>Read&nbsp;Only Memory;&nbsp;</i>the&nbsp;fixed&nbsp;program&nbsp;store in&nbsp;a&nbsp;<br>
architecture.&nbsp;<br>
computer, also used to&nbsp;describe&nbsp;the semiconductor devices&nbsp;<br>
which may be&nbsp;used in&nbsp;this&nbsp;role. Contrast&nbsp;with&nbsp;<i>RAM.</i>&nbsp;<br>
<b>PCMCIA&nbsp;&nbsp;</b><i>Personal Computer&nbsp;Memory Card&nbsp;Interna-</i><br>
<i>tional Association;&nbsp;</i>the organization responsible for a&nbsp;&nbsp;<b>RS232&nbsp;&nbsp;</b>A&nbsp;particular&nbsp;standard for&nbsp;asynchronous&nbsp;serial&nbsp;<br>
physical&nbsp;form&nbsp;and&nbsp;interface&nbsp;standard&nbsp;for cards&nbsp;which&nbsp;plug&nbsp;&nbsp;communications,&nbsp;enabling&nbsp;the connection&nbsp;of&nbsp;modems,&nbsp;<br>
into PCs (and&nbsp;other portable equipment). Despite the&nbsp;&nbsp;printers, and&nbsp;communication&nbsp;with&nbsp;other&nbsp;machines.&nbsp;<br>
name,&nbsp;the standard&nbsp;is&nbsp;not&nbsp;limited&nbsp;to&nbsp;memory&nbsp;cards;&nbsp;vari-<br>
ous peripheral interface cards&nbsp;are also&nbsp;conformant.&nbsp;&nbsp;<b>RTC&nbsp;&nbsp;</b><i>Real-Time Clock;&nbsp;</i>a&nbsp;clock source&nbsp;which&nbsp;allows&nbsp;a&nbsp;<br>
PCMCIA&nbsp;cards are often referred&nbsp;to&nbsp;simply as&nbsp;'PC-cards'.&nbsp;<br>
computer to&nbsp;work out the time&nbsp;of day,&nbsp;date, and so on.&nbsp;<br>
Normally this&nbsp;is&nbsp;a&nbsp;small battery-backed system&nbsp;with&nbsp;a&nbsp;low&nbsp;<br>
<b>PDA&nbsp;&nbsp;</b><i>Personal Digital&nbsp;Assistant;&nbsp;</i>a&nbsp;term&nbsp;first&nbsp;coined&nbsp;to&nbsp;&nbsp;frequency&nbsp;crystal&nbsp;oscillator&nbsp;which&nbsp;runs&nbsp;all&nbsp;the&nbsp;time, even&nbsp;<br>
describe the Apple Newton, but&nbsp;now applied&nbsp;to&nbsp;any palm-<br>
when&nbsp;the&nbsp;computer&nbsp;itself is&nbsp;turned&nbsp;off.&nbsp;<br>
top computer.&nbsp;<br>
<b>RTL&nbsp;</b><i>Register&nbsp;Transfer Level;&nbsp;</i>an&nbsp;abstract view&nbsp;of&nbsp;a hard-<br>
<b>PLA&nbsp;&nbsp;</b><i>Programmable Logic&nbsp;Array;&nbsp;</i>a pseudo-regular&nbsp;&nbsp;ware&nbsp;system&nbsp;such as&nbsp;a processor where&nbsp;multi-bit values&nbsp;<br>
structure&nbsp;on&nbsp;an&nbsp;integrated&nbsp;circuit that&nbsp;implements&nbsp;a&nbsp;com-<br>
are viewed&nbsp;as flowing between&nbsp;registers&nbsp;along&nbsp;buses.&nbsp;<br>
plex multi-output combinatorial&nbsp;logic&nbsp;function.&nbsp;<br>
<b>RTOS&nbsp;&nbsp;</b><i>Real-Time Operating&nbsp;System;&nbsp;</i>an operating&nbsp;<br>
<b>PLL&nbsp;&nbsp;</b><i>Phase-Locked Loop;&nbsp;</i>a circuit used to generate a&nbsp;&nbsp;system&nbsp;that&nbsp;supports&nbsp;programs&nbsp;that&nbsp;must&nbsp;satisfy&nbsp;external&nbsp;<br>
clock signal&nbsp;using another clock&nbsp;signal&nbsp;as a&nbsp;reference.&nbsp;<br>
timing constraints.&nbsp;These are often small (a few&nbsp;kilobytes)&nbsp;<br>
<b>PMOS&nbsp;&nbsp;</b><i>P-type&nbsp;Metal&nbsp;Oxide&nbsp;Semiconductor,&nbsp;</i>a semicon-<br>
and well&nbsp;suited&nbsp;to&nbsp;use&nbsp;in&nbsp;embedded systems.&nbsp;<br>
ductor&nbsp;technology&nbsp;that&nbsp;pre-dates&nbsp;<i>CMOS&nbsp;</i>and&nbsp;<i>NMOS&nbsp;</i>that&nbsp;&nbsp;<b>SDLC&nbsp;</b><i>Synchronous Data&nbsp;Link&nbsp;Controller;&nbsp;</i>a peripheral&nbsp;<br>
was&nbsp;used&nbsp;to&nbsp;build&nbsp;early 4-bit&nbsp;microprocessors. It supports&nbsp;&nbsp;that&nbsp;connects&nbsp;a computer&nbsp;to&nbsp;a&nbsp;clocked&nbsp;serial&nbsp;interface&nbsp;and&nbsp;<br>
a logic&nbsp;family&nbsp;with active&nbsp;pull-up and passive&nbsp;pull-down&nbsp;&nbsp;supports&nbsp;one&nbsp;or&nbsp;more&nbsp;standard&nbsp;protocols.&nbsp;<br>
outputs, and gates with&nbsp;a&nbsp;high&nbsp;output&nbsp;draw&nbsp;current&nbsp;even&nbsp;&nbsp;<b>SoC&nbsp;&nbsp;</b><i>System-on-Chip;&nbsp;&nbsp;</i>a&nbsp;single&nbsp;integrated circuit that&nbsp;<br>
when&nbsp;not switching. PMOS transistors are used, with&nbsp;&nbsp;incorporates all&nbsp;of the functionality&nbsp;of&nbsp;an&nbsp;electronic&nbsp;sys-<br>
NMOS transistors, to&nbsp;form&nbsp;CMOS.&nbsp;<br>
tem,&nbsp;including&nbsp;the processor, memory and&nbsp;peripherals.&nbsp;At&nbsp;<br>
<b>PSR&nbsp;</b><i>Program Status&nbsp;Register,&nbsp;</i>the register in&nbsp;a proces-<br>
the&nbsp;time of writing&nbsp;most SoCs still&nbsp;require off-chip&nbsp;<br>
sor&nbsp;that&nbsp;holds&nbsp;various&nbsp;bits&nbsp;of&nbsp;information such&nbsp;as&nbsp;the&nbsp;con-<br>
memory&nbsp;resources in addition&nbsp;to their on-chip&nbsp;memory,&nbsp;<br>
dition&nbsp;codes, the&nbsp;interrupt&nbsp;disable&nbsp;bits&nbsp;and&nbsp;the operating&nbsp;&nbsp;but all other system&nbsp;components&nbsp;are on chip.&nbsp;<br>
mode bits. The&nbsp;<i>ARM&nbsp;</i>has a&nbsp;<i>CPSR&nbsp;</i>(Current&nbsp;Program&nbsp;Status&nbsp;&nbsp;<b>SPSR&nbsp;&nbsp;</b><i>Saved Program Status Register,&nbsp;</i>an&nbsp;&nbsp;<i>ARM&nbsp;&nbsp;</i>register&nbsp;<br>
Register), and&nbsp;an&nbsp;<i>SPSR&nbsp;</i>(Saved Program&nbsp;Status Register)&nbsp;<br>
for each&nbsp;non-user&nbsp;mode.&nbsp;<br>
used&nbsp;to&nbsp;save the values&nbsp;of&nbsp;the&nbsp;<i>CPSR&nbsp;</i>when&nbsp;an&nbsp;exception occurs.&nbsp;<br>
<b>SRAM&nbsp;&nbsp;</b><i>Static Random Access&nbsp;Memory;&nbsp;</i>more expensive&nbsp;<br>
<b>PSU&nbsp;</b><i>Power Supply Unit;&nbsp;</i>the&nbsp;electronics that provides&nbsp;&nbsp;than&nbsp;<i>DRAM,&nbsp;</i>this&nbsp;form&nbsp;of&nbsp;<i>RAM&nbsp;</i>holds&nbsp;its&nbsp;data in flip-flops&nbsp;<br>
the regulated supply&nbsp;voltage(s) required&nbsp;by&nbsp;the&nbsp;system,&nbsp;&nbsp;which do&nbsp;not&nbsp;require&nbsp;refreshing. SRAM has&nbsp;a&nbsp;lower access&nbsp;<br>
usually using&nbsp;a&nbsp;mains electricity&nbsp;or&nbsp;battery power&nbsp;source.&nbsp;<br>
time&nbsp;than&nbsp;DRAM and&nbsp;can retain&nbsp;its contents indefinitely&nbsp;<br>
RAM&nbsp;<i>Random&nbsp;Access&nbsp;Memory;&nbsp;</i>a misnomer,&nbsp;since&nbsp;<i>ROM&nbsp;&nbsp;</i>with almost no power dissipation. It&nbsp;is used&nbsp;for most RAM&nbsp;<br>
is also random access, RAM is&nbsp;used to refer to the read-&nbsp;<br>
functions on processor chips, such&nbsp;as&nbsp;cache&nbsp;and&nbsp;<i>TLB</i>&nbsp;<br>
<hr>
<A name=421></a><b>Glossary</b>&nbsp;<br>
409&nbsp;<br>
&nbsp;&nbsp;&nbsp;memory, and may&nbsp;be used&nbsp;for&nbsp;the main&nbsp;memory&nbsp;in some&nbsp;&nbsp;attempt&nbsp;to&nbsp;categorize&nbsp;chip&nbsp;transistor&nbsp;counts as&nbsp;SSI, MSI,&nbsp;<br>
smaller embedded systems.&nbsp;<br>
LSI (Small, Medium and&nbsp;Large&nbsp;Scale&nbsp;Integration), VLSI,&nbsp;<br>
and&nbsp;so&nbsp;on,&nbsp;on&nbsp;the basis&nbsp;of&nbsp;orders&nbsp;of&nbsp;magnitude, but pro-<br>
<b>TLB&nbsp;&nbsp;</b><i>Translation Look-aside&nbsp;Buffer,&nbsp;</i>a&nbsp;cache of recently&nbsp;&nbsp;cess technology&nbsp;advanced faster&nbsp;than new terms could be&nbsp;<br>
used page&nbsp;table&nbsp;entries&nbsp;which&nbsp;avoids the overhead of&nbsp;page&nbsp;&nbsp;coined. The next&nbsp;term, ULSI&nbsp;(Ultra&nbsp;Large Scale&nbsp;Integra-<br>
table-walking&nbsp;on&nbsp;every memory&nbsp;access.&nbsp;<br>
tion)&nbsp;never&nbsp;gained&nbsp;widespread&nbsp;use, and&nbsp;would probably&nbsp;<br>
<b>UART&nbsp;&nbsp;</b><i>Universal Asynchronous Receiver/Transmitter;&nbsp;</i>a&nbsp;&nbsp;now be obsolete anyway.&nbsp;<br>
peripheral device that interfaces&nbsp;a&nbsp;serial line (typically&nbsp;&nbsp;<b>VLSI&nbsp;Technology, Inc.&nbsp;</b>VLSI Technology,&nbsp;Inc.,&nbsp;some-<br>
with&nbsp;an&nbsp;<i>RS232&nbsp;</i>signalling&nbsp;protocol)&nbsp;to&nbsp;a processor bus.&nbsp;<br>
times&nbsp;abbreviated to just&nbsp;<i>VLSI,&nbsp;</i>manufactured&nbsp;the first ARM&nbsp;<br>
<b>USB&nbsp;&nbsp;</b><i>Universal Serial Bus;&nbsp;</i>a&nbsp;standard interface on&nbsp;&nbsp;chips designed&nbsp;at Acorn Computers and, with Acorn and&nbsp;<br>
more&nbsp;recent&nbsp;PCs that&nbsp;supports the connection of&nbsp;various&nbsp;&nbsp;Apple, established ARM Limited&nbsp;as a&nbsp;separate company&nbsp;in&nbsp;<br>
peripherals. It&nbsp;uses&nbsp;a&nbsp;high-speed&nbsp;serial protocol and&nbsp;an&nbsp;&nbsp;1990. VLSI was the first ARM semiconductor partner and&nbsp;<br>
electrical interface that allows devices to be&nbsp;connected&nbsp;&nbsp;manufactures&nbsp;a range&nbsp;of&nbsp;ARM-based CPUs and&nbsp;system&nbsp;<br>
and&nbsp;disconnected&nbsp;while&nbsp;the machine&nbsp;is&nbsp;running&nbsp;(that&nbsp;is,&nbsp;it&nbsp;&nbsp;chips. It is&nbsp;now owned&nbsp;by&nbsp;Philips&nbsp;Semiconductors.&nbsp;<br>
is 'hot-pluggable').&nbsp;<br>
<b>VM&nbsp;&nbsp;</b><i>Virtual Memory;&nbsp;</i>the&nbsp;address space that the program&nbsp;<br>
VHDL&nbsp;&nbsp;<i>VHSIC Hardware Description Language&nbsp;</i>(where&nbsp;&nbsp;runs in which is&nbsp;mapped to physical memory&nbsp;by&nbsp;the&nbsp;<i>MMU.&nbsp;</i><br>
VHSIC expands to&nbsp;<i>Very High-Speed Integrated&nbsp;Circuit);&nbsp;</i>a&nbsp;&nbsp;The virtual space may&nbsp;be&nbsp;larger&nbsp;than&nbsp;the physical&nbsp;space,&nbsp;<br>
standard language&nbsp;for describing&nbsp;hardware at a behav-<br>
and parts&nbsp;of the&nbsp;virtual space may&nbsp;be paged out onto a&nbsp;<br>
ioural or structural level which is&nbsp;supported by&nbsp;most semi-<br>
hard disk or&nbsp;may not&nbsp;exist&nbsp;anywhere.&nbsp;<br>
conductor&nbsp;design&nbsp;tool companies.&nbsp;<br>
<b>VRAM&nbsp;&nbsp;</b><i>Video Random&nbsp;Access Memory;&nbsp;</i>a form&nbsp;of&nbsp;<br>
<b>VLSI&nbsp;</b><i>Very Large Scale Integration;&nbsp;</i>the process&nbsp;of putting&nbsp;&nbsp;<i>DRAM&nbsp;</i>with on-chip shift registers to give high-bandwidth&nbsp;<br>
a lot of&nbsp;transistors onto a single chip.&nbsp;There was&nbsp;an&nbsp;<br>
access to sequential data for generating&nbsp;video&nbsp;displays.&nbsp;<br>
<hr>
<A name=422></a>Index&nbsp;<br>
abort recovery 331-2 abort timing&nbsp;<br>
self-timed design&nbsp;375—7 analogue&nbsp;to&nbsp;digital&nbsp;<br>
146&nbsp;absolute&nbsp;addressing&nbsp;17&nbsp;<br>
converters&nbsp;(ADCs)&nbsp;350-1&nbsp;AND&nbsp;gate&nbsp;399&nbsp;<br>
abstraction&nbsp;3-7,&nbsp;152&nbsp;access&nbsp;<br>
ANSI&nbsp;C data types 157-8 APB&nbsp;(Advanced&nbsp;<br>
permissions 305-8 accessing&nbsp;<br>
Peripheral Bus)&nbsp;217, 219-20 APCS (ARM&nbsp;<br>
operands&nbsp;168-9 accessing&nbsp;state&nbsp;235-6&nbsp;<br>
Procedure Call Standard) 176-9 applications&nbsp;<br>
accumulator&nbsp;(ACC)&nbsp;register&nbsp;7&nbsp;Acorn&nbsp;<br>
ARM7TDMI 255-6&nbsp;<br>
Computers 36, 348 activity&nbsp;factors&nbsp;(of&nbsp;<br>
ARMS 258&nbsp;<br>
a&nbsp;logic&nbsp;gate)&nbsp;30&nbsp;adder&nbsp;design&nbsp;87-92&nbsp;<br>
ARM9TDMI 262-3&nbsp;<br>
carry&nbsp;arbitration&nbsp;91—2&nbsp;<br>
ARM10TDMI 266&nbsp;<br>
carry&nbsp;look-ahead&nbsp;88, 89&nbsp;<br>
ARM7500&nbsp;361-3&nbsp;<br>
carry-save 94&nbsp;<br>
embedded applications&nbsp;347&nbsp;<br>
carry-select 88-9, 90&nbsp;<br>
SA-1100 370&nbsp;<br>
ripple-carry 88&nbsp;<br>
Thumb instruction set 189, 203-4&nbsp;<br>
addition/subtraction 51,243^,400-1&nbsp;<br>
arbitration 217-18 architectural&nbsp;<br>
address incrementer 214-16 address&nbsp;<br>
inheritance 37-8 architectural&nbsp;variants&nbsp;<br>
non-determinism 378&nbsp;address space&nbsp;<br>
147—8&nbsp;argument&nbsp;passing 179 arguments&nbsp;<br>
model 180-1 address&nbsp;translation 303&nbsp;<br>
176&nbsp;arithmetic&nbsp;operations&nbsp;51, 243^t,&nbsp;<br>
addressing&nbsp;<br>
400-1&nbsp;<br>
absolute&nbsp;17&nbsp;<br>
<i>see also&nbsp;</i>adder&nbsp;design;&nbsp;multiplication&nbsp;arithmetic-logic&nbsp;<br>
auto-indexing 58&nbsp;<br>
unit&nbsp;(ALU)&nbsp;7,&nbsp;88-90&nbsp;ARM&nbsp;10200&nbsp;342-3&nbsp;ARM1020E&nbsp;<br>
base plus&nbsp;index 17&nbsp;<br>
341-2 ARM10TDMI&nbsp;256,263-6,344&nbsp;ARM2&nbsp;88, 147&nbsp;<br>
base&nbsp;plus&nbsp;offset 17,58-9&nbsp;<br>
ARM3&nbsp; 147,279-82&nbsp;ARM6&nbsp;74,88,90-1,96,&nbsp;147&nbsp;<br>
base plus scaled index 17&nbsp;<br>
ARM60 148&nbsp;ARM600&nbsp;148,282-3&nbsp;ARM610 148&nbsp;<br>
block copy&nbsp;61-3&nbsp;<br>
ARM7&nbsp;74,256&nbsp;ARM7100&nbsp;364-8&nbsp;ARM710T&nbsp;318-22&nbsp;<br>
exceptions&nbsp;111&nbsp;<br>
ARM720T&nbsp;318,322 ARM740T&nbsp;318,322-3&nbsp;ARM7500&nbsp;<br>
immediate 17&nbsp;<br>
360-3 ARM7500FE 360-3 ARM7TDMI&nbsp;101-2,&nbsp;<br>
indirect 17&nbsp;<br>
248-56, 353 ARM7TDMI-S&nbsp;255&nbsp;ARM8&nbsp;95,256-9&nbsp;<br>
initializing pointer&nbsp;56-7&nbsp;<br>
ARM810&nbsp;323-6 ARM920T&nbsp;335-7&nbsp;ARM940T&nbsp;337-9&nbsp;<br>
instruction formats 14—16&nbsp;<br>
ARM946E-S 339^1 ARM966E-S 339^11&nbsp;ARM9E-S&nbsp;<br>
modes&nbsp;17&nbsp;<br>
241,245,263&nbsp;ARM9TDMI&nbsp;79,91,245,256,260-3&nbsp;<br>
multiple register data&nbsp;transfers 60&nbsp;<br>
ARM&nbsp;assembler&nbsp;45&nbsp;ARM Development Board 44, 46&nbsp;<br>
number of addresses 14-16&nbsp;<br>
ARM&nbsp;instructions&nbsp;see instructions;&nbsp;Thumb instruction set&nbsp;<br>
post-indexed&nbsp;59&nbsp;<br>
ARM Limited 35,&nbsp;36, 348&nbsp;<br>
pre-indexed 58&nbsp;<br>
register&nbsp;load&nbsp;and&nbsp;store instructions 57—8&nbsp;<br>
register-indirect 17,&nbsp;56&nbsp;<br>
stack 17,60-1&nbsp;<br>
AHB (Advanced&nbsp;High-performance&nbsp;Bus)&nbsp;217,&nbsp;220 alignment&nbsp;<br>
checking 306 ALU&nbsp;design&nbsp;12-13&nbsp;AMBA&nbsp;(Advanced&nbsp;<br>
Microcontroller&nbsp;Bus&nbsp;Architecture)&nbsp;216-20,&nbsp;<br>
232 AMULET processor cores&nbsp;<br>
374-97&nbsp;<br>
AMULET1&nbsp;377-81,397&nbsp;<br>
AMULET2&nbsp;381^t, 397&nbsp;<br>
AMULET2e&nbsp;384-6&nbsp;<br>
AMULET3&nbsp;387-90,396,397&nbsp;<br>
AMULET3H 390,392,393-6&nbsp;<br>
DRACO telecommunications controller 390-6&nbsp;<br>
&nbsp;&nbsp;&nbsp;<b>413</b>&nbsp;<br>
&nbsp;<br>
<hr>
<A name=423></a><b>414</b>&nbsp;<br>
<b>Index</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;ARM&nbsp;Procedure&nbsp;Call&nbsp;Standard&nbsp;(APCS)&nbsp;176-9&nbsp;<br>
C compiler&nbsp;19-20,44&nbsp;C&nbsp;<br>
ARM Project Manager 46&nbsp;<br>
functions&nbsp;176 cache&nbsp;<br>
ARM&nbsp;Software&nbsp;Development Toolkit&nbsp;46-7&nbsp;<br>
269, 272-83, 308&nbsp;<br>
ARM system&nbsp;control coprocessor 293-4&nbsp;<br>
AMULET2e&nbsp;384-5&nbsp;<br>
ARMsd 44,&nbsp;45&nbsp;<br>
ARM3&nbsp;279-82&nbsp;<br>
ARMulator 44, 45-6, 225&nbsp;<br>
ARM600&nbsp;282-3&nbsp;<br>
arrays&nbsp;157, 169-70&nbsp;<br>
ARM710T&nbsp;318-20&nbsp;<br>
ASB (Advanced&nbsp;System&nbsp;Bus)&nbsp;217&nbsp;<br>
ARM920T&nbsp;335-6&nbsp;<br>
ASCII&nbsp;156&nbsp;<br>
ARM940T&nbsp;337-9&nbsp;<br>
assemblers&nbsp;45&nbsp;<br>
ARM946E-S 339^0&nbsp;<br>
assembly language&nbsp;programming 49—71&nbsp;<br>
ARM1020E 341&nbsp;<br>
assembly-level abstraction&nbsp;152&nbsp;<br>
associativity&nbsp;344—5&nbsp;<br>
associativity 344—5&nbsp;<br>
controls 308&nbsp;<br>
asynchronous design styles&nbsp;375-7&nbsp;<br>
direct-mapped 273-5&nbsp;<br>
auto-indexing 58&nbsp;<br>
double-bandwidth&nbsp;324-5&nbsp;<br>
fully associative 277-8&nbsp;<br>
barrel shifter 92-3&nbsp;<br>
Harvard&nbsp;272&nbsp;<br>
base&nbsp;plus&nbsp;index addressing 17&nbsp;<br>
hit rate 273&nbsp;<br>
base plus offset addressing 17,&nbsp;58—9&nbsp;<br>
input/output interactions 313-14, 314-15&nbsp;<br>
base&nbsp;plus&nbsp;scaled&nbsp;index addressing 17&nbsp;<br>
line of data 273&nbsp;<br>
base registers 17,&nbsp;56&nbsp;<br>
line length 345&nbsp;<br>
BBC microcomputer 36&nbsp;<br>
memory bandwidth 344&nbsp;<br>
Berkeley RISC designs 37&nbsp;<br>
miss rate 273&nbsp;<br>
big-endian&nbsp;41,&nbsp;105-6,&nbsp;157&nbsp;<br>
organization 273&nbsp;<br>
binary notation 154,400-1&nbsp;<br>
performance metrics&nbsp;273&nbsp;<br>
bit 400-1&nbsp;<br>
power&nbsp;efficiency&nbsp;320&nbsp;<br>
bit-wise logical operations 51&nbsp;<br>
primary role of 317&nbsp;<br>
set-associative 275-7&nbsp;<br>
bitfields&nbsp;157&nbsp;<br>
speeds 320&nbsp;<br>
block copy addressing 61-3&nbsp;<br>
StrongARMSA-110 332,333&nbsp;<br>
Bluetooth&nbsp;355-60&nbsp;<br>
unified&nbsp;272, 280&nbsp;<br>
Boolean algebra 154,400&nbsp;<br>
virtual and physical 287-8&nbsp;<br>
boundary scan&nbsp;test&nbsp;architecture 226-32&nbsp;<br>
write strategies&nbsp;278, 345 callee-saved&nbsp;<br>
branch&nbsp;instructions&nbsp;63, 66, 84-5&nbsp;<br>
registers 178 caller-saved registers 178 CAM&nbsp;<br>
Branch and Branch&nbsp;with Link 113-15&nbsp;<br>
(content&nbsp;addressed&nbsp;memory) 277, 281-2&nbsp;carry&nbsp;<br>
Branch, Branch with Link&nbsp;and eXchange&nbsp;115-17&nbsp;<br>
arbitration adder 91—2 carry&nbsp;look-ahead adder&nbsp;<br>
conditional branches&nbsp;<i>63-4</i>&nbsp;<br>
88, 89 carry-save adder 94 carry-select&nbsp;adder&nbsp;<br>
delayed branches&nbsp;24, 37-8&nbsp;<br>
88-9,&nbsp;90&nbsp;chaining 235&nbsp;characters&nbsp;156, 157&nbsp;<br>
Thumb instruction set 191-4&nbsp;<br>
chunked stack model 182 CISC&nbsp;(Complex&nbsp;<br>
breakpoint&nbsp;instruction 140-1,200-1&nbsp;<br>
Instruction&nbsp;Set&nbsp;Computers)&nbsp;20&nbsp;clocking&nbsp;scheme&nbsp;<br>
buffers&nbsp;<br>
86&nbsp;clocks&nbsp;26-7,351,402&nbsp;<br>
control 308&nbsp;<br>
ARM10TDMI 263-5&nbsp;<br>
hit-under-miss support&nbsp;341&nbsp;<br>
ARM7TDMI 249&nbsp;<br>
jump trace buffer&nbsp;382-3&nbsp;<br>
ARMS 256&nbsp;<br>
write buffers 308, 321-2, 333^, 336, 339, 342&nbsp;<br>
clock skew&nbsp;375&nbsp;<br>
buses&nbsp;216-20&nbsp;<br>
self-timed design 375—7&nbsp;<br>
AHB (Advanced High-performance&nbsp;Bus) 217,220&nbsp;<br>
CMOS technology 4,28-31&nbsp;<br>
AMBA&nbsp;(Advanced Microcontroller&nbsp;Bus Architecture)&nbsp;216-20,&nbsp;<br>
codec 350&nbsp;<br>
232&nbsp;<br>
combinatorial&nbsp;logic 402 comparison&nbsp;operations&nbsp;<br>
APB (Advanced Peripheral Bus) 217, 219-20&nbsp;<br>
52&nbsp;compilers 19-20,44,333 Complex&nbsp;<br>
arbitration 217-18&nbsp;<br>
Instruction Set Computers (CISCs) 20&nbsp;computer&nbsp;<br>
ARM7TDMI 253&nbsp;<br>
architecture 2 computer&nbsp;logic 399&nbsp;computer&nbsp;<br>
ARM1020E 342&nbsp;<br>
organization&nbsp;2&nbsp;condition&nbsp;codes&nbsp;18, 53-5,&nbsp;112&nbsp;<br>
ASB (Advanced System&nbsp;Bus)&nbsp;217&nbsp;<br>
MARBLE&nbsp;on-chip bus&nbsp;392&nbsp;<br>
modes 219&nbsp;<br>
SA-1100 370&nbsp;<br>
signals 208&nbsp;<br>
test&nbsp;interface&nbsp;219&nbsp;<br>
transfers 218 byte&nbsp;<br>
ordering 157&nbsp;<br>
<hr>
<A name=424></a><b>Index</b>&nbsp;<br>
<b>415</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;condition mnemonics&nbsp;111—12&nbsp;<br>
desktop debugging&nbsp;232-3&nbsp;<br>
conditional branches 18,63-4&nbsp;<br>
destination of results 14&nbsp;<br>
conditional execution 65, 111-12&nbsp;<br>
development&nbsp;tools&nbsp;43—7&nbsp;<br>
conditional statements 170-2&nbsp;<br>
device&nbsp;drivers 315&nbsp;<br>
content addressed memory (CAM) 277, 281-2&nbsp;<br>
digital radio 359-60&nbsp;<br>
context switching&nbsp;167-8, 310-11&nbsp;<br>
Digital Signal Processing&nbsp;(DSP) 18,&nbsp;239-40, 352-3&nbsp;<br>
control flow instructions 17-18,63-8&nbsp;<br>
Direct&nbsp;Memory&nbsp;Access (DMA) 312-13&nbsp;<br>
control&nbsp;logic 10-11, 209-11&nbsp;<br>
direct-mapped cache 273-5&nbsp;<br>
control structures&nbsp;99-100&nbsp;<br>
DMA&nbsp;(Direct Memory Access) 312-13&nbsp;<br>
coprocessors&nbsp;<br>
domains 302-3&nbsp;<br>
architecture&nbsp;101&nbsp;<br>
double precision&nbsp;numbers 161&nbsp;<br>
ARM&nbsp;system&nbsp;control&nbsp;coprocessor&nbsp;293—4&nbsp;<br>
double-bandwidth&nbsp;cache 324-5&nbsp;<br>
data operations&nbsp;136-7,137-8&nbsp;<br>
double-bandwidth&nbsp;memory 257&nbsp;<br>
data transfers 138-9&nbsp;<br>
do..while loops&nbsp;174&nbsp;<br>
FPA10 168-8, 360-1&nbsp;<br>
DRACO telecommunications&nbsp;controller&nbsp;390-6&nbsp;<br>
handshake 101&nbsp;<br>
DRAM&nbsp;(dynamic&nbsp;random&nbsp;access&nbsp;memory)&nbsp;213-14, 215,&nbsp;272&nbsp;<br>
instructions 136-7&nbsp;<br>
DSP (Digital&nbsp;Signal Processing) 18,&nbsp;239-40, 352-3&nbsp;<br>
interfaces 101-3, 254, 261&nbsp;<br>
dynamic&nbsp;instruction frequency 21&nbsp;<br>
Piccolo coprocessor 240&nbsp;<br>
register transfers&nbsp;139-40&nbsp;<br>
early aborts 146 edge-triggered&nbsp;latches&nbsp;<br>
VFP10&nbsp;168,&nbsp;342-3&nbsp;copy-back&nbsp;<br>
403 electromagnetic&nbsp;interference&nbsp;375,&nbsp;<br>
278&nbsp;cores&nbsp;see processor&nbsp;cores&nbsp;count&nbsp;<br>
391 electronics&nbsp;technology 2 embedded&nbsp;<br>
leading zeros (CLZ) 124-5&nbsp;<br>
applications&nbsp;347 embedded&nbsp;debugging&nbsp;<br>
counter-timers 222&nbsp;<br>
233 embedded&nbsp;systems 144, 293&nbsp;<br>
CP15&nbsp;MMU registers 294-7,298-302&nbsp;CPSR&nbsp;<br>
embedded trace&nbsp;macrocell 237-9&nbsp;<br>
(Current&nbsp;Program&nbsp;Status&nbsp;Register)&nbsp;40&nbsp;CPU&nbsp;<br>
Embedded-ICE 230,234-6&nbsp;emulator&nbsp;<br>
cores&nbsp;see&nbsp;processor&nbsp;cores&nbsp;cross-development&nbsp;<br>
(ARMulator) 44,&nbsp;45-6, 225 endianness&nbsp;<br>
toolkit&nbsp;43—4&nbsp;<br>
41, 106-7, 157&nbsp;enumerated&nbsp;data&nbsp;types&nbsp;<br>
157 Ericsson&nbsp;355—60&nbsp;exceptions&nbsp;107-11,&nbsp;<br>
D-type latches 402-3&nbsp;<br>
191 execution&nbsp;82-5&nbsp;exponent bias 160&nbsp;<br>
data aborts 144-7&nbsp;<br>
expressions 168-70 extended&nbsp;packed&nbsp;<br>
data alignment 183&nbsp;<br>
decimal&nbsp;numbers&nbsp;162&nbsp;extensions&nbsp;13&nbsp;<br>
data cache 332&nbsp;<br>
external&nbsp;memory&nbsp;interface&nbsp;392—3&nbsp;<br>
data forwarding 80-1&nbsp;<br>
EXTEST&nbsp;(JTAG instruction) 229,231&nbsp;<br>
data operations 136-7&nbsp;<br>
data processing instructions 50-5, 82,119-22, 195-7&nbsp;<br>
fan-in&nbsp;(of&nbsp;logic gates)&nbsp;399 Fast&nbsp;<br>
data registers 227&nbsp;<br>
Interrupt&nbsp;Request (FIQ) 313 finite&nbsp;<br>
datastorage 183&nbsp;<br>
state machine (FSM)&nbsp;9&nbsp;FIQ&nbsp;(Fast&nbsp;<br>
data&nbsp;transfer&nbsp;instructions&nbsp;55-63, 82^t, 102, 125-30, 136&nbsp;<br>
Interrupt&nbsp;Request)&nbsp;313 floating-point&nbsp;<br>
coprocessor&nbsp;data&nbsp;transfers&nbsp;138—9&nbsp;<br>
ARM architecture&nbsp;163-8&nbsp;<br>
Thumb instruction&nbsp;set 198-200&nbsp;<br>
datatypes 158-63,342-3&nbsp;<br>
datatypes&nbsp;105,&nbsp;153-63&nbsp;<br>
registers 165-6,311&nbsp;<br>
FPA10&nbsp;data&nbsp;types&nbsp;163-8,360-1&nbsp;<br>
units 360-1&nbsp;<br>
VFP10 168,342-3&nbsp;<br>
FPA 10 coprocessor 163-8,360-1&nbsp;<br>
datapath design 9-10&nbsp;<br>
VFP10 coprocessor 168, 342-3 for&nbsp;<br>
datapath&nbsp;layout 98-9 datapath&nbsp;<br>
loops&nbsp;173&nbsp;forwarding&nbsp;paths&nbsp;331&nbsp;FPA&nbsp;10&nbsp;<br>
operation&nbsp;10&nbsp;datapath&nbsp;timing&nbsp;<br>
data&nbsp;types 163-8,360-1 fully associative&nbsp;<br>
86-7&nbsp;debug&nbsp;comms&nbsp;236&nbsp;<br>
cache 277-8 functions&nbsp;157,&nbsp;175-80&nbsp;<br>
debugging&nbsp;232-6,233, 253^t&nbsp;<br>
embedded trace&nbsp;macrocell 237-9&nbsp;<br>
gate abstraction 5-6&nbsp;<br>
VWS22100 GSM&nbsp;chip 355&nbsp;<br>
gate-level&nbsp;design&nbsp;6-7&nbsp;<br>
decimal numbers&nbsp;153 decode&nbsp;logic&nbsp;<br>
gated clocks 30&nbsp;<br>
388-9&nbsp;decoders 99-100 delayed&nbsp;<br>
branches 24, 37-8 demand-paged&nbsp;<br>
virtual memory 287&nbsp;denormalized&nbsp;<br>
numbers 160&nbsp;design&nbsp;for&nbsp;test&nbsp;see&nbsp;<br>
testing&nbsp;design trade-offs 19-24&nbsp;<br>
<hr>
<A name=425></a><b>416</b>&nbsp;<br>
<b>Index</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;half-word&nbsp;data&nbsp;transfer&nbsp;instructions&nbsp;127-9&nbsp;<br>
swap memory&nbsp;and register&nbsp;instructions (SWP)&nbsp;132-3&nbsp;<br>
'Halt'instruction 383-4&nbsp;<br>
types&nbsp;of 16&nbsp;<br>
hard&nbsp;macrocells&nbsp;100-1&nbsp;<br>
unused&nbsp;instruction&nbsp;space&nbsp;142-3&nbsp;<br>
hardware prototyping 223-4&nbsp;<br>
usage measurements&nbsp;21&nbsp;<br>
Harvard cache 272&nbsp;<br>
<i>see also&nbsp;</i>branch instructions; Thumb&nbsp;instruction set&nbsp;<br>
hazard, read-after-write 22&nbsp;<br>
integer&nbsp;unit organization 258,&nbsp;259&nbsp;integers&nbsp;155&nbsp;<br>
heap 180&nbsp;<br>
interrupt controller 222&nbsp;interrupt&nbsp;latency&nbsp;313&nbsp;<br>
<i>Hello World&nbsp;</i>program 69-71&nbsp;<br>
INTEST&nbsp;(JTAG&nbsp;instruction)&nbsp;229&nbsp;IRQ&nbsp;107-10&nbsp;ISDN&nbsp;<br>
hexadecimal notation 154&nbsp;<br>
Subscriber Processor&nbsp;349-52&nbsp;<br>
hierarchy of components&nbsp;175&nbsp;<br>
high-level languages&nbsp;151-85&nbsp;<br>
JTAG boundary scan test architecture 226-32,254&nbsp;<br>
hit-under-miss support&nbsp;341&nbsp;<br>
jump&nbsp;tables&nbsp;67-8&nbsp;jump&nbsp;trace&nbsp;buffer 382-3&nbsp;JumpStart&nbsp;<br>
tools&nbsp;47&nbsp;<br>
I/O (input/output) 42-3,312-15,361&nbsp;<br>
IDCODE (JTAG instruction)&nbsp;229&nbsp;<br>
keyboard interfaces 351&nbsp;<br>
idempotency 103,312 IEEE 754&nbsp;<br>
Standard 159 if...else 170-1&nbsp;<br>
latches&nbsp;402-3&nbsp;<br>
immediate addressing 17&nbsp;immediate&nbsp;<br>
late aborts&nbsp;161&nbsp;<br>
operands&nbsp;52&nbsp;implementation&nbsp;<br>
latency&nbsp;313,314&nbsp;<br>
86-101,201-3&nbsp;<br>
LDM&nbsp;data abort 145&nbsp;<br>
adder design 87-92&nbsp;<br>
leaf&nbsp;routines 175—6&nbsp;<br>
barrel shifter 92-3&nbsp;<br>
level signalling 377&nbsp;<br>
clocking&nbsp;scheme&nbsp;86&nbsp;<br>
libraries 185&nbsp;<br>
control structures&nbsp;99-100&nbsp;<br>
line&nbsp;length&nbsp;345&nbsp;<br>
coprocessor interface&nbsp;101-3&nbsp;<br>
link&nbsp;register&nbsp;66&nbsp;<br>
datapath&nbsp;layout 98-9&nbsp;<br>
linker 45&nbsp;<br>
datapath timing 86-7&nbsp;<br>
little-endian&nbsp;41, 106-7, 157&nbsp;<br>
multiplier design 93-6&nbsp;<br>
load&nbsp;instructions&nbsp;57-8&nbsp;<br>
register bank&nbsp;96-8&nbsp;<br>
load-store&nbsp;architecture 41,&nbsp;165&nbsp;<br>
In-Circuit Emulator&nbsp;(ICE)&nbsp;207,&nbsp;230,&nbsp;233-6&nbsp;<br>
logic&nbsp;<br>
index register&nbsp;17&nbsp;indirect addressing&nbsp;17&nbsp;<br>
combinatorial 402&nbsp;<br>
initialization&nbsp;10,252&nbsp;initializing address&nbsp;<br>
computer&nbsp;logic&nbsp;399&nbsp;<br>
pointer 56-7&nbsp;input/output&nbsp;(I/O) 42-3,&nbsp;<br>
control logic&nbsp;10-11,209-11&nbsp;<br>
312-15,&nbsp;361 instruction&nbsp;cache 332&nbsp;<br>
design&nbsp;8-9&nbsp;<br>
instruction&nbsp;decoders&nbsp;99&nbsp;instruction&nbsp;<br>
PLA (programmable logic array)&nbsp;99&nbsp;<br>
mapping&nbsp;201-3&nbsp;instruction register&nbsp;(IR)&nbsp;7,&nbsp;<br>
symbols 5&nbsp;<br>
227-8 instructions&nbsp;42,&nbsp;105^19&nbsp;<br>
logic gates 4-5,&nbsp;399-400 logical&nbsp;<br>
breakpoint 140-1&nbsp;<br>
operations 51&nbsp;loops&nbsp;173^t&nbsp;low&nbsp;<br>
condition codes&nbsp;112&nbsp;<br>
power&nbsp;<i>see&nbsp;</i>power&nbsp;management&nbsp;<br>
conditional execution&nbsp;65,&nbsp;111-13&nbsp;<br>
control flow 63-8&nbsp;<br>
macrocells&nbsp;100-1&nbsp;<br>
coprocessor&nbsp;135—40&nbsp;<br>
testing 230-2 MARBLE&nbsp;<br>
count&nbsp;leading zeros&nbsp;123-4&nbsp;<br>
on-chip&nbsp;bus&nbsp;392&nbsp;memory&nbsp;<br>
data operations&nbsp;136-7&nbsp;<br>
180-4&nbsp;<br>
data processing&nbsp;50-5, 82, 119-22&nbsp;<br>
address space model&nbsp;180-1&nbsp;<br>
data transfer 55-63,&nbsp;82^t,&nbsp;102, 125-30,&nbsp;136, 138-9&nbsp;<br>
bandwidth&nbsp;344&nbsp;<br>
design 14-19&nbsp;<br>
double-bandwidth&nbsp;257&nbsp;<br>
exceptions&nbsp;108-12&nbsp;<br>
bottlenecks&nbsp;79&nbsp;<br>
execution&nbsp;82-5&nbsp;<br>
content addressed&nbsp;memory&nbsp;(CAM)&nbsp;277,&nbsp;281-2&nbsp;<br>
frequencies 166&nbsp;<br>
controllers&nbsp;340,361,369&nbsp;<br>
'Halt' 383-4&nbsp;<br>
cost 270&nbsp;<br>
load instructions 57—8&nbsp;<br>
Direct Memory Access (DMA)&nbsp;312-13&nbsp;<br>
MU0 processors&nbsp;8&nbsp;<br>
DRAM (dynamic&nbsp;random&nbsp;access&nbsp;memory) 213-14, 215,&nbsp;272&nbsp;<br>
register transfer 130-35,&nbsp;139^1, 165-6&nbsp;<br>
efficiency&nbsp;183-4&nbsp;<br>
software interrupt&nbsp;117-19&nbsp;<br>
external&nbsp;memory interface&nbsp;392-3&nbsp;<br>
store instructions 57—8&nbsp;<br>
faults 143-7&nbsp;<br>
SWAP instruction 309&nbsp;<br>
<hr>
<A name=426></a><b>Index</b>&nbsp;<br>
<b>417</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;granularity 302&nbsp;<br>
OneCVWS22100&nbsp;GSM chip 352-5&nbsp;<br>
hierarchy 269-88&nbsp;<br>
Open&nbsp;Microprocessor&nbsp;systems&nbsp;Initiative (OMI)&nbsp;397&nbsp;<br>
interfaces&nbsp;208-16,251-2,350&nbsp;<br>
operands&nbsp;50-3,&nbsp;168-9&nbsp;<br>
mapping&nbsp;222,292,312&nbsp;<br>
operating&nbsp;system&nbsp;support&nbsp;290—315&nbsp;<br>
on-chip memory 271&nbsp;<br>
ARM MMU architecture 302-8&nbsp;<br>
organization&nbsp;40-1,&nbsp;105-6,&nbsp;393^t&nbsp;<br>
ARM system&nbsp;control coprocessor 293-4&nbsp;<br>
read-sensitive locations&nbsp;312&nbsp;<br>
context&nbsp;switching&nbsp;310—11&nbsp;<br>
size and speed&nbsp;270,272&nbsp;<br>
CP15&nbsp;registers&nbsp;294-7,298-302&nbsp;<br>
timing accesses 215, 385-6&nbsp;<br>
device&nbsp;drivers 315&nbsp;<br>
<i>see&nbsp;also&nbsp;</i>cache&nbsp;memory management&nbsp;unit (MMU) 283-8,291,&nbsp;<br>
embedded systems 293&nbsp;<br>
294, 317, 345&nbsp;<br>
input/output 312-15&nbsp;<br>
ARM710T 321&nbsp;<br>
memory management&nbsp;291&nbsp;<br>
ARM1020E 342&nbsp;<br>
multi-user&nbsp;systems&nbsp;291&nbsp;<br>
ARM920T&nbsp;336-7&nbsp;<br>
protection 291-2,294-8&nbsp;<br>
ARM940T 337&nbsp;<br>
resource allocation 292,315&nbsp;<br>
ARM MMU architecture 302-8&nbsp;<br>
single-user systems 292-3&nbsp;<br>
CP15 MMU registers 294-7, 298-302&nbsp;<br>
synchronization 308-9&nbsp;<br>
paging&nbsp;285-6&nbsp;<br>
orthogonal instructions&nbsp;16&nbsp;<br>
restartable instructions 287&nbsp;<br>
segmentation 284-5&nbsp;<br>
packed decimal numbers 161-2&nbsp;<br>
StrongARMSA-110 334&nbsp;<br>
packed structures&nbsp;157,184&nbsp;<br>
translation look-aside buffers&nbsp;(TLB) 287&nbsp;<br>
padding 183&nbsp;<br>
virtual memory 286-7&nbsp;<br>
page absent 143&nbsp;<br>
virtual&nbsp;and&nbsp;physical&nbsp;caches&nbsp;287—8&nbsp;<br>
page protected 143&nbsp;<br>
MIPS&nbsp;(Microprocessor without Interlocking&nbsp;Pipeline&nbsp;Stages)&nbsp;37&nbsp;<br>
page translation 304-5&nbsp;<br>
MMU&nbsp;<i>see&nbsp;</i>memory&nbsp;management&nbsp;unit&nbsp;(MMU)&nbsp;mnemonics&nbsp;<br>
paging&nbsp;285-6&nbsp;<br>
111-12 modes&nbsp;17&nbsp;<br>
parameters 176&nbsp;<br>
multi-user&nbsp;systems&nbsp;291&nbsp;<br>
pause controller 222&nbsp;<br>
multiple register&nbsp;transfer&nbsp;instructions&nbsp;60,&nbsp;129-31&nbsp;<br>
PCB testing 229&nbsp;<br>
multiplexers 401 multiplication 55, 93-6,&nbsp;122-4,&nbsp;<br>
peripherals 216,370&nbsp;<br>
242-3&nbsp;<br>
memory-mapped 312&nbsp;<br>
StrongARMSA-110 332&nbsp;<br>
reference peripheral specification&nbsp;220-2&nbsp;<br>
MU0 processors 7-13&nbsp;<br>
physical caches&nbsp;287-8 physical design 100-1&nbsp;<br>
ALU design&nbsp;12-13&nbsp;<br>
Piccolo coprocessor 240 piconets&nbsp;356&nbsp;<br>
components 7-8&nbsp;<br>
pipelining&nbsp;21-4,26&nbsp;<br>
control logic&nbsp;10-11&nbsp;<br>
ARM10TDMI 264&nbsp;<br>
datapath design 9-10&nbsp;<br>
ARM7TDMI 260-1&nbsp;<br>
datapath operation&nbsp;10&nbsp;<br>
ARMS 257&nbsp;<br>
extensions 13&nbsp;<br>
ARM9TDMI 260-1&nbsp;<br>
initialization 10&nbsp;<br>
stage organization&nbsp;78-82&nbsp;<br>
instruction set 8&nbsp;<br>
FPA10&nbsp;pipeline&nbsp;167&nbsp;<br>
logic design 8-9&nbsp;<br>
self-timed 377&nbsp;<br>
register&nbsp;transfer level&nbsp;design 10&nbsp;<br>
StrongARMSA-110 329-31&nbsp;<br>
mutual&nbsp;exclusion&nbsp;309&nbsp;<br>
3&nbsp;stage organization&nbsp;75—8 PLA&nbsp;<br>
(programmable&nbsp;logic&nbsp;array)&nbsp;99&nbsp;<br>
N-Trace 239 NaN&nbsp;(Not&nbsp;a&nbsp;<br>
pointer arithmetic&nbsp;169 pointer&nbsp;<br>
Number) 160 NAND 4-5,&nbsp;<br>
initialization 56-7&nbsp;pointers&nbsp;157&nbsp;<br>
399^(00&nbsp;never&nbsp;condition&nbsp;(NV)&nbsp;<br>
post-indexed addressing 59 power&nbsp;<br>
111&nbsp;non re-entrant&nbsp;code 178-9&nbsp;<br>
management&nbsp;28-32, 320, 375&nbsp;<br>
normalized numbers 159,160&nbsp;<br>
ARM7100&nbsp;365-6&nbsp;<br>
number of addresses 14-16&nbsp;<br>
ARM7TDMI 254&nbsp;<br>
numbers 153,&nbsp;155-6&nbsp;<br>
ARM9TDMI 262&nbsp;<br>
binary&nbsp;numbers&nbsp;400—1&nbsp;<br>
Bluetooth 357-8&nbsp;<br>
floating-point 158-63&nbsp;<br>
optimization 320-1&nbsp;<br>
ranges&nbsp;154-5&nbsp;<br>
VWS22100 GSM&nbsp;chip 355&nbsp;<br>
pre-indexed addressing&nbsp;mode 58&nbsp;<br>
Oak DSP core 352-3&nbsp;<br>
prefetch aborts 144 prefetch&nbsp;units&nbsp;<br>
on-chip debug 261&nbsp;<br>
387-8&nbsp;<br>
on-chip memory 271&nbsp;<br>
<hr>
<A name=427></a><b>418</b>&nbsp;<br>
<b>Index</b>&nbsp;<br>
&nbsp;&nbsp;&nbsp;printable characters 156 printed&nbsp;circuit&nbsp;<br>
transfer&nbsp;level design 10&nbsp;<br>
board&nbsp;(PCB) testing 229 priority&nbsp;<br>
use convention 177&nbsp;<br>
information 291&nbsp;privileged&nbsp;operating&nbsp;<br>
windows 37 reorder buffer 387 reset&nbsp;controller&nbsp;222&nbsp;<br>
modes&nbsp;106—7 Procedure&nbsp;Call&nbsp;Standard&nbsp;<br>
Reset-Set&nbsp;(R-S)&nbsp;flip-flop&nbsp;402&nbsp;resource&nbsp;allocation 292, 315&nbsp;<br>
(APCS)&nbsp;176-9&nbsp;procedures&nbsp;175—80&nbsp;<br>
restartable&nbsp;instructions&nbsp;287&nbsp;result&nbsp;returns&nbsp;179&nbsp;ripple-carry&nbsp;<br>
process&nbsp;synchronization&nbsp;309&nbsp;processor&nbsp;<br>
adder&nbsp;88&nbsp;RISC (Reduced&nbsp;Instruction&nbsp;Set Computer) 1,&nbsp;20,&nbsp;<br>
cores 74,&nbsp;247&nbsp;<br>
24-8, 35-6&nbsp;<br>
AMULET cores 374-97&nbsp;<br>
Berkeley RISC designs 37&nbsp;<br>
ARM7TDMI&nbsp;255&nbsp;<br>
ROM&nbsp;(Read Only&nbsp;Memory) 20&nbsp;<br>
ARM9TDMI 262&nbsp;<br>
Roman numerals 153 RTL&nbsp;<br>
CPU cores&nbsp;317^*5&nbsp;<br>
design 9&nbsp;<br>
debugging 233&nbsp;<br>
Ruby&nbsp;II Advanced&nbsp;Communication&nbsp;Processor&nbsp;348—9&nbsp;<br>
DSP cores 239^tO&nbsp;<br>
run-time environment 185&nbsp;<br>
StrongARMSA-110 328-9&nbsp;<br>
synthesizable 255,263,341&nbsp;<br>
SA-110&nbsp;<i>see&nbsp;</i>StrongARM&nbsp;SA-110&nbsp;<br>
processors&nbsp;<br>
SA-1100 368-71&nbsp;<br>
abstraction&nbsp;in hardware design 3-7&nbsp;<br>
scatternets 356&nbsp;<br>
components&nbsp;7—8&nbsp;<br>
scheduling 291&nbsp;<br>
definition 2&nbsp;<br>
section&nbsp;translation&nbsp;303—4&nbsp;<br>
design trade-offs 19-24&nbsp;<br>
segmentation 284—5&nbsp;<br>
instruction set design 14-19&nbsp;<br>
self-timed design 375—7&nbsp;<br>
MU0&nbsp;processors 7—13&nbsp;<br>
self-timed digital&nbsp;systems 374&nbsp;<br>
stored-program&nbsp;computers 2, 3&nbsp;<br>
self-timed signalling 376&nbsp;<br>
usage measurements&nbsp;21 program&nbsp;<br>
semantic gap 19&nbsp;<br>
counter&nbsp;(PC)&nbsp;register&nbsp;7 program&nbsp;<br>
semaphore 131&nbsp;<br>
design&nbsp;71&nbsp;program hierarchy&nbsp;175&nbsp;<br>
sequential circuits&nbsp;402&nbsp;<br>
programmer's model 39-43, 190-1&nbsp;<br>
sequential memory access&nbsp;212-13,320&nbsp;<br>
Project&nbsp;Manager&nbsp;46&nbsp;protection&nbsp;<br>
set-associative cache 275-7&nbsp;<br>
291-2, 294-8&nbsp;prototyping&nbsp;tools&nbsp;<br>
shifted register operands&nbsp;53&nbsp;<br>
223-4&nbsp;pseudo-code&nbsp;71&nbsp;Psion&nbsp;Series&nbsp;<br>
short integers 157&nbsp;<br>
5&nbsp;366-7&nbsp;public&nbsp;instructions&nbsp;227-9&nbsp;<br>
signal processing support 239-45&nbsp;<br>
Qflag 241-2&nbsp;<br>
signalling 376-7&nbsp;<br>
signed byte data transfer&nbsp;instructions&nbsp;128-30&nbsp;<br>
r15 119-20&nbsp;<br>
signed integers 155&nbsp;<br>
R-S&nbsp;(Reset-Set)&nbsp;flip-flop&nbsp;402&nbsp;<br>
single precision numbers 159&nbsp;<br>
Rapid Silicon Prototyping 223-4&nbsp;<br>
single&nbsp;word&nbsp;data transfer&nbsp;instructions&nbsp;125—8&nbsp;<br>
re-entrant code 178-9&nbsp;<br>
single-cycle execution 38&nbsp;<br>
read-after-write&nbsp;pipeline hazard&nbsp;22&nbsp;<br>
single-user&nbsp;systems&nbsp;292—3&nbsp;<br>
read-sensitive memory&nbsp;locations&nbsp;312&nbsp;<br>
SO-interface 350&nbsp;<br>
real&nbsp;numbers 156&nbsp;<br>
soft macrocells 100-1&nbsp;<br>
real-time debug 237-8&nbsp;<br>
soft&nbsp;memory errors&nbsp;143—4&nbsp;<br>
reference peripheral specification 220-2&nbsp;<br>
software development tools 43-7&nbsp;<br>
register bank&nbsp;75,96-8&nbsp;<br>
software&nbsp;interrupt&nbsp;117-19,194-5&nbsp;<br>
register-indirect addressing 17,&nbsp;56&nbsp;<br>
software tools&nbsp;239&nbsp;<br>
registers 402,403-4&nbsp;<br>
sound systems 361&nbsp;<br>
base registers 17,56&nbsp;<br>
SPSRs&nbsp;(Saved&nbsp;Program Status Register) 106, 107&nbsp;<br>
coherency 379&nbsp;<br>
stack&nbsp;<br>
CP15 294-7,298-302&nbsp;<br>
addressing&nbsp;17, 60—1&nbsp;<br>
EmbeddedlCE mapping 235&nbsp;<br>
behaviour&nbsp;182—3&nbsp;<br>
forwarding 381—2&nbsp;<br>
chunked stack model 182&nbsp;<br>
load&nbsp;and store instructions&nbsp;57—8&nbsp;<br>
and memory use 180&nbsp;<br>
locking 379-80&nbsp;<br>
stack-limit checking 178&nbsp;<br>
movement operations&nbsp;51&nbsp;<br>
Standard&nbsp;Test&nbsp;Access&nbsp;Port&nbsp;226&nbsp;<br>
operands 50-2, 53&nbsp;<br>
Stanford MIPS 37&nbsp;static&nbsp;<br>
protection unit 294-8&nbsp;<br>
instruction frequency 21&nbsp;.status&nbsp;<br>
transfer&nbsp;instructions 130-37, 139-41, 165-6&nbsp;<br>
register 132-3&nbsp;<br>
<hr>
</BODY>
</HTML>
